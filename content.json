{"meta":{"title":"TheRiver | blog","subtitle":"You have reached the world's edge, none but devils play past here","description":"","author":"TheRiver","url":"https://riverferry.site"},"pages":[{"title":"about","date":"2020-10-13T14:56:29.000Z","updated":"2022-09-12T16:24:32.295Z","comments":true,"path":"about/index.html","permalink":"https://riverferry.site/about/index.html","excerpt":"","text":"contact me by the options below:tg: t.me/Shamemoreemail: &#119;&#x61;&#x6e;&#103;&#56;&#52;&#x38;&#x31;&#x39;&#55;&#54;&#50;&#64;&#103;&#x6d;&#x61;&#x69;&#x6c;&#x2e;&#99;&#111;&#x6d;"},{"title":"tags","date":"2020-10-12T17:56:34.000Z","updated":"2022-09-12T16:24:32.355Z","comments":true,"path":"tags/index.html","permalink":"https://riverferry.site/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"promql 语法学习","slug":"2022-09-02-promql 语法学习","date":"2022-09-02T00:00:00.000Z","updated":"2022-09-12T16:24:32.294Z","comments":true,"path":"2022-09-02-promql 语法学习/","link":"","permalink":"https://riverferry.site/2022-09-02-promql%20%E8%AF%AD%E6%B3%95%E5%AD%A6%E4%B9%A0/","excerpt":"学习promql常用语法，更好的理解qps,tp99等参数","text":"学习promql常用语法，更好的理解qps,tp99等参数 promqlIn Prometheus’s expression language, an expression or sub-expression can evaluate to one of four types: Instant vector - a set of time series containing a single sample for each time series, all sharing the same timestamp Range vector - a set of time series containing a range of data points over time for each time series Scalar - a simple numeric floating point value String - a simple string value; currently unused gaugegauge是忽高忽低的一个类型，比较适合算瞬时值，或者 avg,min,max,topk这些,例如: 12345# HELP go_goroutines Number of goroutines that currently exist.# TYPE go_goroutines gaugego_goroutines 9topk(5,go_goroutines&#123;job&#x3D;&quot;$job&quot;&#125;) countercounter是持续递增的类型，例如rpc的数量，总的处理时间这些。 rate irate increaserate 1rate(grpc_server_handling_seconds_count&#123;job&#x3D;&quot;grpc-go&quot;,grpc_type&#x3D;&quot;unary&quot;&#125;[30s]) 1irate(grpc_server_handling_seconds_count&#123;job&#x3D;&quot;grpc-go&quot;,grpc_type&#x3D;&quot;unary&quot;&#125;[30s]) 1increase(grpc_server_handling_seconds_count&#123;job&#x3D;&quot;grpc-go&quot;,grpc_type&#x3D;&quot;unary&quot;&#125;[30s]) 我这里单线程发了100次rpc，总体增长是比较平滑的。rate是算duration(这里是30s)的开始和结尾2个point的数据，除以时间间隔得到的增长率。irate是取duration的最后2个时间点的数据，这个取决于step的大小，所以irate在开始和结尾的瞬间增长下降是很快的。而rate在30s就趋于稳定了，因为我这里客户端发的频率比较稳定。 increase和rate的区别是，increase不除以时间间隔，算的是增长不是增长率，这个可以看下源码一目了然： 12345678910111213141516// === rate(node parser.ValueTypeMatrix) Vector ===func funcRate(vals []parser.Value, args parser.Expressions, enh *EvalNodeHelper) Vector &#123; return extrapolatedRate(vals, args, enh, true, true)&#125;// === increase(node parser.ValueTypeMatrix) Vector ===func funcIncrease(vals []parser.Value, args parser.Expressions, enh *EvalNodeHelper) Vector &#123; return extrapolatedRate(vals, args, enh, true, false)&#125;func extrapolatedRate(vals []parser.Value, args parser.Expressions, enh *EvalNodeHelper, isCounter, isRate bool) Vector &#123;if isRate &#123; resultValue = resultValue / ms.Range.Seconds() &#125; 再看这里： 1rate(grpc_server_handling_seconds_count&#123;job&#x3D;&quot;grpc-go&quot;,grpc_type&#x3D;&quot;unary&quot;&#125;[2s]) 因为step=1s，这里rate的duration取2s，结果和irate一样了。 avg avg_over_timeavg_over_time(range-vector): the average value of all points in the specified interval. sum sum_over_timesum_over_time: The following functions allow aggregating each series of a given range vector over time and return an instant vector with per-series aggregation results: avg_over_time(range-vector): the average value of all points in the specified interval. min_over_time(range-vector): the minimum value of all points in the specified interval. max_over_time(range-vector): the maximum value of all points in the specified interval. sum_over_time(range-vector): the sum of all values in the specified interval. count_over_time(range-vector): the count of all values in the specified interval. quantile_over_time(scalar, range-vector): the φ-quantile (0 ≤ φ ≤ 1) of the values in the specified interval. stddev_over_time(range-vector): the population standard deviation of the values in the specified interval. stdvar_over_time(range-vector): the population standard variance of the values in the specified interval. last_over_time(range-vector): the most recent point value in specified interval. present_over_time(range-vector): the value 1 for any series in the specified interval. Note that all values in the specified interval have the same weight in the aggregation even if the values are not equally spaced throughout the interval. sum: Prometheus supports the following built-in aggregation operators that can be used to aggregate the elements of a single instant vector, resulting in a new vector of fewer elements with aggregated values: ORIGIN LINK sum (calculate sum over dimensions) min (select minimum over dimensions) max (select maximum over dimensions) avg (calculate the average over dimensions) group (all values in the resulting vector are 1) stddev (calculate population standard deviation over dimensions) stdvar (calculate population standard variance over dimensions) count (count number of elements in the vector) count_values (count number of elements with the same value) bottomk (smallest k elements by sample value) topk (largest k elements by sample value) quantile (calculate φ-quantile (0 ≤ φ ≤ 1) over dimensions) These operators can either be used to aggregate over all label dimensions or preserve distinct dimensions by including a without or by clause. These clauses may be used before or after the expression. 1&lt;aggr-op&gt; [without|by (&lt;label list&gt;)] ([parameter,] &lt;vector expression&gt;) or 1&lt;aggr-op&gt;([parameter,] &lt;vector expression&gt;) [without|by (&lt;label list&gt;)] 具体看官方文档吧，简单的说sum是对instant-vector的操作，还可以对label进行过滤。 这两个都是聚合操作，可以算多个实例的和。sum还可以根据label过滤。区别主要就是作用的对象不同，instant vs range; 测试效果： 12345678910&#x2F;&#x2F; querygrpc_server_handling_seconds_bucket&#123;job&#x3D;&quot;grpc-go&quot;,grpc_service&#x3D;~&quot;proto.DemoService&quot;,le&#x3D;~&quot;0.01|0.005|1&quot;&#125;&#x2F;&#x2F; resultgrpc_server_handling_seconds_bucket&#123;grpc_method&#x3D;&quot;SayHello&quot;, grpc_service&#x3D;&quot;proto.DemoService&quot;, grpc_type&#x3D;&quot;unary&quot;, instance&#x3D;&quot;0.0.0.0:50001&quot;, job&#x3D;&quot;grpc-go&quot;, le&#x3D;&quot;0.005&quot;&#125;231grpc_server_handling_seconds_bucket&#123;grpc_method&#x3D;&quot;SayHello&quot;, grpc_service&#x3D;&quot;proto.DemoService&quot;, grpc_type&#x3D;&quot;unary&quot;, instance&#x3D;&quot;0.0.0.0:50001&quot;, job&#x3D;&quot;grpc-go&quot;, le&#x3D;&quot;0.01&quot;&#125;231grpc_server_handling_seconds_bucket&#123;grpc_method&#x3D;&quot;SayHello&quot;, grpc_service&#x3D;&quot;proto.DemoService&quot;, grpc_type&#x3D;&quot;unary&quot;, instance&#x3D;&quot;0.0.0.0:50001&quot;, job&#x3D;&quot;grpc-go&quot;, le&#x3D;&quot;1&quot;&#125;231 12345&#x2F;&#x2F;querysum(grpc_server_handling_seconds_bucket&#123;job&#x3D;&quot;grpc-go&quot;,grpc_service&#x3D;~&quot;proto.DemoService&quot;,le&#x3D;~&quot;0.01|0.005|1&quot;&#125;) by (grpc_method)&#x2F;&#x2F;result&#123;grpc_method&#x3D;&quot;SayHello&quot;&#125; 693 over_time也是类似的。 histogram这是grpcserver的api接口拿到的数据： 1234567891011121314grpc_server_handling_seconds_bucket&#123;grpc_method&#x3D;&quot;SayHello&quot;,grpc_service&#x3D;&quot;proto.DemoService&quot;,grpc_type&#x3D;&quot;unary&quot;,le&#x3D;&quot;0.005&quot;&#125; 231grpc_server_handling_seconds_bucket&#123;grpc_method&#x3D;&quot;SayHello&quot;,grpc_service&#x3D;&quot;proto.DemoService&quot;,grpc_type&#x3D;&quot;unary&quot;,le&#x3D;&quot;0.01&quot;&#125; 231grpc_server_handling_seconds_bucket&#123;grpc_method&#x3D;&quot;SayHello&quot;,grpc_service&#x3D;&quot;proto.DemoService&quot;,grpc_type&#x3D;&quot;unary&quot;,le&#x3D;&quot;0.025&quot;&#125; 231grpc_server_handling_seconds_bucket&#123;grpc_method&#x3D;&quot;SayHello&quot;,grpc_service&#x3D;&quot;proto.DemoService&quot;,grpc_type&#x3D;&quot;unary&quot;,le&#x3D;&quot;0.05&quot;&#125; 231grpc_server_handling_seconds_bucket&#123;grpc_method&#x3D;&quot;SayHello&quot;,grpc_service&#x3D;&quot;proto.DemoService&quot;,grpc_type&#x3D;&quot;unary&quot;,le&#x3D;&quot;0.1&quot;&#125; 231grpc_server_handling_seconds_bucket&#123;grpc_method&#x3D;&quot;SayHello&quot;,grpc_service&#x3D;&quot;proto.DemoService&quot;,grpc_type&#x3D;&quot;unary&quot;,le&#x3D;&quot;0.25&quot;&#125; 231grpc_server_handling_seconds_bucket&#123;grpc_method&#x3D;&quot;SayHello&quot;,grpc_service&#x3D;&quot;proto.DemoService&quot;,grpc_type&#x3D;&quot;unary&quot;,le&#x3D;&quot;0.5&quot;&#125; 231grpc_server_handling_seconds_bucket&#123;grpc_method&#x3D;&quot;SayHello&quot;,grpc_service&#x3D;&quot;proto.DemoService&quot;,grpc_type&#x3D;&quot;unary&quot;,le&#x3D;&quot;1&quot;&#125; 231grpc_server_handling_seconds_bucket&#123;grpc_method&#x3D;&quot;SayHello&quot;,grpc_service&#x3D;&quot;proto.DemoService&quot;,grpc_type&#x3D;&quot;unary&quot;,le&#x3D;&quot;2.5&quot;&#125; 331grpc_server_handling_seconds_bucket&#123;grpc_method&#x3D;&quot;SayHello&quot;,grpc_service&#x3D;&quot;proto.DemoService&quot;,grpc_type&#x3D;&quot;unary&quot;,le&#x3D;&quot;5&quot;&#125; 351grpc_server_handling_seconds_bucket&#123;grpc_method&#x3D;&quot;SayHello&quot;,grpc_service&#x3D;&quot;proto.DemoService&quot;,grpc_type&#x3D;&quot;unary&quot;,le&#x3D;&quot;10&quot;&#125; 351grpc_server_handling_seconds_bucket&#123;grpc_method&#x3D;&quot;SayHello&quot;,grpc_service&#x3D;&quot;proto.DemoService&quot;,grpc_type&#x3D;&quot;unary&quot;,le&#x3D;&quot;+Inf&quot;&#125; 351grpc_server_handling_seconds_sum&#123;grpc_method&#x3D;&quot;SayHello&quot;,grpc_service&#x3D;&quot;proto.DemoService&quot;,grpc_type&#x3D;&quot;unary&quot;&#125; 160.067727291grpc_server_handling_seconds_count&#123;grpc_method&#x3D;&quot;SayHello&quot;,grpc_service&#x3D;&quot;proto.DemoService&quot;,grpc_type&#x3D;&quot;unary&quot;&#125; 351 这里的grpc-go的prome里面直接用了prome官方的bucket定义，如下： 1DefBuckets &#x3D; []float64&#123;.005, .01, .025, .05, .1, .25, .5, 1, 2.5, 5, 10&#125; 和上面api拿到的是一致的。 Bucket Count 0-0.005 231 0-0.01 231 0-0.025 231 0-0.05 231 0-0.1 231 0-0.25 231 0-0.5 231 0-1 231 0-2.5 331 0-5 331 0-10 331 0-+Inf 331 这里之前我的服务都是官方的demo，一个简单的回显程序所以速度很快，所以bucket都是231，后面我加了sleep(1s),后面的bucket就变了。 summarySummaries also measure events and are an alternative to histograms. They are cheaper, but lose more data. They are calculated on the application level hence aggregation of metrics from multiple instances of the same process is not possible. They are used when the buckets of a metric is not known beforehand, but it is highly recommended to use histograms over summaries whenever possible. summary和histogram有点像，但是summary是在client端计算quantile的，并且不能aggregation.summaries的quantitile是提前写死的，client返回这个的精确值，不像bucket是近似值，但是histogram是prom端计算的，所以quantitile是可以手动调整的，牺牲的是prom的性能不是client的性能。官方不推荐用summary,实际也比较少见使用。 referencehttps://prometheus.io/docs/prometheus/latest/querying/basics/ https://zhuanlan.zhihu.com/p/354565885 https://mp.weixin.qq.com/s/QkDUQOx9w1HZIFyyvIzp-A","categories":[],"tags":[{"name":"promql","slug":"promql","permalink":"https://riverferry.site/tags/promql/"}],"keywords":[]},{"title":"prometheus+grafana单机部署","slug":"2022-08-31-prometheus+grafana单机部署","date":"2022-08-31T00:00:00.000Z","updated":"2022-09-12T16:24:32.294Z","comments":true,"path":"2022-08-31-prometheus+grafana单机部署/","link":"","permalink":"https://riverferry.site/2022-08-31-prometheus+grafana%E5%8D%95%E6%9C%BA%E9%83%A8%E7%BD%B2/","excerpt":"今天有个python的grpc server,新起的服务，有一些功能还在调试需要测下性能，拿到rps,tp99,cpu等信息。就想着部署下prometheus+grafana在单机下使用，原来k8s下linkerd里面已经集成了这些，并且linkerd代理了每个服务，所以可以跨语言。我这里是单机的，服务的metric需要单独设置，官方的grpc只有go/java的exporter,网上找了只有几颗星的https://github.com/lchenn/py-grpc-prometheus个人实现的python版本，先拿来试着用，本文主要记录下单机部署prometheus+grafana的过程","text":"今天有个python的grpc server,新起的服务，有一些功能还在调试需要测下性能，拿到rps,tp99,cpu等信息。就想着部署下prometheus+grafana在单机下使用，原来k8s下linkerd里面已经集成了这些，并且linkerd代理了每个服务，所以可以跨语言。我这里是单机的，服务的metric需要单独设置，官方的grpc只有go/java的exporter,网上找了只有几颗星的https://github.com/lchenn/py-grpc-prometheus个人实现的python版本，先拿来试着用，本文主要记录下单机部署prometheus+grafana的过程 prometheus直接docker运行的，参考官方的步骤,prometheus只是pull数据的，本身不收集数据，所以docker运行简单方便。需要自己配置exporter，所以命令可以挂在宿主机的yml文件进去： 1234docker run \\ -p 9090:9090 \\ -v &#x2F;path&#x2F;to&#x2F;prometheus.yml:&#x2F;etc&#x2F;prometheus&#x2F;prometheus.yml \\ prom&#x2F;prometheus prometheus.yml简单配置： 1234567global: scrape_interval: 15sscrape_configs:- job_name: node static_configs: - targets: [&#39;localhost:9100&#39;] node exporter参考官方步骤即可，然后配置到prometheus的配置文件就行了。 grafana参考官方的步骤,我这里因为是阿里云的机器别人配置的，好像是有外部的防火墙配置，所以需要修改默认的3000端口，/etc/grafana/grafana.ini里面找到port就行了改一下，然后重启systemctl restart grafana-server;默认的用户和密码也在这个文件里面，第一次登陆成功会提升修改密码的。 然后就是配置数据源为prometheus： 再接着加dashboard,官方有模板，拿来用就行，我目前只部署了系统数据收集的node exporter,所以copy this过来就ok了，最终结果： referencehttps://help.aliyun.com/document_detail/123108.html https://grafana.com/grafana/dashboards/1860-node-exporter-full/ https://github.com/lchenn/py-grpc-prometheus https://grafana.com/docs/grafana/v9.0/setup-grafana/installation/rpm/ https://prometheus.io/docs/guides/node-exporter/ https://rm-rf.medium.com/how-to-install-and-configure-prometheus-node-exporter-node-exporter-as-a-service-on-centos-7-50339b086704 https://prometheus.io/docs/instrumenting/exporters/","categories":[],"tags":[{"name":"prometheus","slug":"prometheus","permalink":"https://riverferry.site/tags/prometheus/"},{"name":"grafana","slug":"grafana","permalink":"https://riverferry.site/tags/grafana/"}],"keywords":[]},{"title":"java and spring中的注解","slug":"2022-08-27-java and spring中的注解","date":"2022-08-27T00:00:00.000Z","updated":"2022-09-12T16:24:32.294Z","comments":true,"path":"2022-08-27-java and spring中的注解/","link":"","permalink":"https://riverferry.site/2022-08-27-java%20and%20spring%E4%B8%AD%E7%9A%84%E6%B3%A8%E8%A7%A3/","excerpt":"因为用到了spring boot在开发，所以开始正式学习java语法和生态。这一篇是关于注解的。","text":"因为用到了spring boot在开发，所以开始正式学习java语法和生态。这一篇是关于注解的。 spring@Component @Service @Repository @Control @RestControlhttps://www.baeldung.com/spring-component-repository-service https://www.baeldung.com/spring-bean-annotations inject@AutoWired @Resource @Injecthttps://stackoverflow.com/questions/4093504/resource-vs-autowired 这篇文章很不错，读完就懂了：Wiring in Spring: @Autowired, @Resource and @Inject lombok Project Lombok is a java library that automatically plugs into your editor and build tools, spicing up your java.Never write another getter or equals method again, with one annotation your class has a fully featured builder, Automate your logging variables, and much more. @Data All together now: A shortcut for @ToString, @EqualsAndHashCode, @Getter on all fields, @Setter on all non-final fields, and @RequiredArgsConstructor! https://projectlombok.org/features/Data @NoArgsConstructor, @RequiredArgsConstructor, @AllArgsConstructorhttps://projectlombok.org/features/constructor @Builderhttps://projectlombok.org/features/Builder javadoc也写的挺详细的: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051The builder annotation creates a so-called &#x27;builder&#x27; aspect to the class that is annotated or the class that contains a member which is annotated with @Builder.If a member is annotated, it must be either a constructor or a method. If a class is annotated, then a package-private constructor is generated with all fields as arguments (as if @AllArgsConstructor(access = AccessLevel.PACKAGE) is present on the class), and it is as if this constructor has been annotated with @Builder instead. Note that this constructor is only generated if you haven&#x27;t written any constructors and also haven&#x27;t added any explicit @XArgsConstructor annotations. In those cases, lombok will assume an all-args constructor is present and generate code that uses it; this means you&#x27;d get a compiler error if this constructor is not present.The effect of @Builder is that an inner class is generated named TBuilder, with a private constructor. Instances of TBuilder are made with the method named builder() which is also generated for you in the class itself (not in the builder class).The TBuilder class contains 1 method for each parameter of the annotated constructor / method (each field, when annotating a class), which returns the builder itself. The builder also has a build() method which returns a completed instance of the original type, created by passing all parameters as set via the various other methods in the builder to the constructor or method that was annotated with @Builder. The return type of this method will be the same as the relevant class, unless a method has been annotated, in which case it&#x27;ll be equal to the return type of that method.Complete documentation is found at the project lombok features page for @Builder . Before: @Builder class Example&lt;T&gt; &#123; private T foo; private final String bar; &#125; After: class Example&lt;T&gt; &#123; private T foo; private final String bar; private Example(T foo, String bar) &#123; this.foo = foo; this.bar = bar; &#125; public static &lt;T&gt; ExampleBuilder&lt;T&gt; builder() &#123; return new ExampleBuilder&lt;T&gt;(); &#125; public static class ExampleBuilder&lt;T&gt; &#123; private T foo; private String bar; private ExampleBuilder() &#123;&#125; public ExampleBuilder foo(T foo) &#123; this.foo = foo; return this; &#125; public ExampleBuilder bar(String bar) &#123; this.bar = bar; return this; &#125; @java.lang.Override public String toString() &#123; return &quot;ExampleBuilder(foo = &quot; + foo + &quot;, bar = &quot; + bar + &quot;)&quot;; &#125; public Example build() &#123; return new Example(foo, bar); &#125; &#125; &#125; summary其他的遇到了再补充，找到合适的资料就贴上来，尽量看上游的资料。 referencehttps://projectlombok.org/","categories":[],"tags":[{"name":"java","slug":"java","permalink":"https://riverferry.site/tags/java/"},{"name":"spring","slug":"spring","permalink":"https://riverferry.site/tags/spring/"}],"keywords":[]},{"title":"install linkerd on k8s with nginx ingress control","slug":"2022-06-28-install linkerd on k8s with nginx ingress control","date":"2022-06-28T00:00:00.000Z","updated":"2022-09-12T16:24:32.294Z","comments":true,"path":"2022-06-28-install linkerd on k8s with nginx ingress control/","link":"","permalink":"https://riverferry.site/2022-06-28-install%20linkerd%20on%20k8s%20with%20nginx%20ingress%20control/","excerpt":"linkerd安装后监听的本地端口，从外部访问需要特别配置。这篇文章环境基于gce下kubeadm部署的k8s，不同环境可能情况不同。","text":"linkerd安装后监听的本地端口，从外部访问需要特别配置。这篇文章环境基于gce下kubeadm部署的k8s，不同环境可能情况不同。 步骤按照官方的步骤就行了，装完linkerd和linkerd viz,最后 1linkerd viz dashboard &amp; 就自动监听127.0.0.1了，本地部署的话到这里就可以结束了。我用的gce通过kubeadm部署的，公有云环境稍微复杂点，最后我用的方案是ingress-nginx-control来实现，中间挺折腾的，记录下。 官方提供了几种expose access的方式,我用的nginx,如下： 12345678910111213141516171819202122232425262728293031323334353637apiVersion: v1kind: Secrettype: Opaquemetadata: name: web-ingress-auth namespace: linkerd-vizdata: auth: YWRtaW46JGFwcjEkbjdDdTZnSGwkRTQ3b2dmN0NPOE5SWWpFakJPa1dNLgoK---# apiVersion: networking.k8s.io/v1beta1 # for k8s &lt; v1.19apiVersion: networking.k8s.io/v1kind: Ingressmetadata: name: web-ingress namespace: linkerd-viz annotations: nginx.ingress.kubernetes.io/upstream-vhost: $service_name.$namespace.svc.cluster.local:8084 nginx.ingress.kubernetes.io/configuration-snippet: | proxy_set_header Origin &quot;&quot;; proxy_hide_header l5d-remote-ip; proxy_hide_header l5d-server-id; nginx.ingress.kubernetes.io/auth-type: basic nginx.ingress.kubernetes.io/auth-secret: web-ingress-auth nginx.ingress.kubernetes.io/auth-realm: &#x27;Authentication Required&#x27;spec: ingressClassName: nginx rules: - host: dashboard.example.com http: paths: - path: / pathType: Prefix backend: service: name: web port: number: 8084 这里声明了一个ingress和一个secret,我不打算加https,所以不搞证书了，按照示例的账号密码就可以了。然后需要自己部署ingress-nginx-control,来根据上面的ingress生成具体的服务.这里也按照官方文档安装就行了。 上面官方yam里面已经提供了service,默认是loadbalancer,在公有云上面比较麻烦，kubectl get service -n **后没有看到exterlnal ip,参考网上的方法,手动加： 12345...spec: type: LoadBalancer externalIPs: - 192.168.0.10 之后能看到ip了，我在node/master节点都可以访问，但通过本地或者其他地址访问还是不行，具体原因未知。后面为了节约时间手动改成nodeport了，改后也不能直接访问，还需要一步特别配置，在service的yml里面改一下： 1234567// beforespec: externalTrafficPolicy: Local// afterspec: externalTrafficPolicy: Cluster 再之后就ok了，可以通过域名用http访问了，账号密码官网有，这里改密码目前还没看怎么处理，毕竟是个测试环境，不打算长期用，就不折腾了，后面inject app后看看其他功能。 referencelinkerd.io ingress-nginx gke上安装步骤 Cloud Native - Service mesh install and setup How To Install and Use Linkerd with Kubernetes","categories":[],"tags":[{"name":"k8s","slug":"k8s","permalink":"https://riverferry.site/tags/k8s/"},{"name":"linkerd","slug":"linkerd","permalink":"https://riverferry.site/tags/linkerd/"}],"keywords":[]},{"title":"install kubesphere on k8s","slug":"2022-06-27-install kubesphere on k8s","date":"2022-06-27T00:00:00.000Z","updated":"2022-09-12T16:24:32.294Z","comments":true,"path":"2022-06-27-install kubesphere on k8s/","link":"","permalink":"https://riverferry.site/2022-06-27-install%20kubesphere%20on%20k8s/","excerpt":"原来在gke上面装过很顺利，后面自己kubeadm安装的cluster再安装遇到了一些问题，记录下","text":"原来在gke上面装过很顺利，后面自己kubeadm安装的cluster再安装遇到了一些问题，记录下 步骤按照官方文档安装就可以了，但是自己这里kubectl get svc/ks-console -n kubesphere-system看不到资源，日志也有报错：Stop if StorageClass was not found。gke环境sc这些默认都给配置好了，自己搭的环境就需要自己折腾了 参考这个链接，里面有处理方式，就是手动加了sc，但这样并不能解决对于我遇到的情况。 我用的rook作为存储插件，手动加sc可以参考： 12345678910111213141516171819[root@master ~]# cat sc.yamlapiVersion: ceph.rook.io/v1beta1kind: Poolmetadata: name: replicapool namespace: rook-cephspec: replicated: size: 3---apiVersion: storage.k8s.io/v1kind: StorageClassmetadata: name: block-serviceprovisioner: ceph.rook.io/blockparameters: pool: replicapool #The value of &quot;clusterNamespace&quot; MUST be the same as the one in which your rook cluster exist # clusterNamespace: rook-ceph gce下可以参考这个： 1234567apiVersion: storage.k8s.io/v1kind: StorageClassmetadata: name: gce-scprovisioner: kubernetes.io/gce-pdparameters: type: pd-ssd 另外还需要设置一个default的sc: 1kubectl patch storageclass gce-sc -p &#39;&#123;&quot;metadata&quot;: &#123;&quot;annotations&quot;:&#123;&quot;storageclass.kubernetes.io&#x2F;is-default-class&quot;:&quot;true&quot;&#125;&#125;&#125;&#39; 具体参考这里Change the default StorageClass 最后如下： 123[root@master ~]# kubectl get sc --all-namespacesNAME PROVISIONER RECLAIMPOLICY VOLUMEBINDINGMODE ALLOWVOLUMEEXPANSION AGEgce-sc (default) kubernetes.io&#x2F;gce-pd Delete Immediate false 47h 重新安装下kubesphere就ok. referencehttps://kubesphere.io/zh/docs/v3.3/quick-start/minimal-kubesphere-on-k8s/ https://cloud.google.com/sdk/gcloud/reference/container/clusters/create","categories":[],"tags":[{"name":"k8s","slug":"k8s","permalink":"https://riverferry.site/tags/k8s/"},{"name":"linkerd","slug":"linkerd","permalink":"https://riverferry.site/tags/linkerd/"}],"keywords":[]},{"title":"C++ Storage class specifiers","slug":"2022-04-07-C++ Storage class specifiers","date":"2022-04-07T00:00:00.000Z","updated":"2022-09-12T16:24:32.294Z","comments":true,"path":"2022-04-07-C++ Storage class specifiers/","link":"","permalink":"https://riverferry.site/2022-04-07-C++%20Storage%20class%20specifiers/","excerpt":"todo","text":"todo referencehttps://en.cppreference.com/w/cpp/language/storage_duration https://www.zhihu.com/question/20630104","categories":[],"tags":[{"name":"c++","slug":"c","permalink":"https://riverferry.site/tags/c/"}],"keywords":[]},{"title":"C++ std::mutex","slug":"2022-03-31-C++ std::mutex","date":"2022-03-31T00:00:00.000Z","updated":"2022-09-12T16:24:32.294Z","comments":true,"path":"2022-03-31-C++ std::mutex/","link":"","permalink":"https://riverferry.site/2022-03-31-C++%20std::mutex/","excerpt":"std::mutex/std::lock_guard/std::unique_lock/std::scoped_lock/std::recursive_mutex等族函数简单梳理","text":"std::mutex/std::lock_guard/std::unique_lock/std::scoped_lock/std::recursive_mutex等族函数简单梳理 date author gcc kernel glibc 20220331 river gcc-11.2.0 linux-4.18.1 glibc-2.35 class since file meaning std::mutex C++11 std_mutex.h pthread_mutex_t的封装 std::lock_guard C++11 std_mutex.h 简单的mutex的守卫类，没有对外接口，支持std::adopt_lock std::unique_lock C++11 unique_lock.h mutex的守卫类，有对外接口，支持std::adopt_lock/std::defer_lock/std::try_to_lock std::scoped_lock C++17 mutex 支持对多个mutex的加锁，内部依赖std::lock(…) std::recursive_mutex C++11 mutex 递归锁，通过pthread_mutex_t的attr中参数实现递归 std::adopt_lock C++17 std_mutex.h 不执行lock(),但保存mutex的地址/引用 std::defer_lock C++11 std_mutex.h 不执行lock(),也不own std::try_to_lock C++11 std_mutex.h 通过pthread_mutex_trylock的结果决定是否own std::lock C++11 mutex 依赖c++17的模板推导机制，支持锁多个lockable object std::mutex#include &lt;gcc-11.2.0/libstdc++-v3/include/bits/std_mutex.h&gt; datastructmutex::__mutex_base::_M_mutex即是pthread_mutex_t. lock()123456789void lock() &#123; int __e = __gthread_mutex_lock(&amp;_M_mutex); // EINVAL, EAGAIN, EBUSY, EINVAL, EDEADLK(may) if (__e) __throw_system_error(__e); &#125; 对应pthread_mutex_lock,失败抛异常. try_lock()123456bool try_lock() noexcept &#123; // XXX EINVAL, EAGAIN, EBUSY return !__gthread_mutex_trylock(&amp;_M_mutex); &#125; 对应pthread_mutex_trylock,不抛异常. unlock()123456void unlock() &#123; // XXX EINVAL, EAGAIN, EPERM __gthread_mutex_unlock(&amp;_M_mutex); &#125; 对应pthread_mutex_unlock. native_handle()123native_handle_type native_handle() noexcept &#123; return &amp;_M_mutex; &#125; 返回pthread_mutex_t. std::lock_guard1234567891011121314151617181920212223242526/** @brief A simple scoped lock type. * * A lock_guard controls mutex ownership within a scope, releasing * ownership in the destructor. */ template&lt;typename _Mutex&gt; class lock_guard &#123; public: typedef _Mutex mutex_type; explicit lock_guard(mutex_type&amp; __m) : _M_device(__m) &#123; _M_device.lock(); &#125; lock_guard(mutex_type&amp; __m, adopt_lock_t) noexcept : _M_device(__m) &#123; &#125; // calling thread owns mutex ~lock_guard() &#123; _M_device.unlock(); &#125; lock_guard(const lock_guard&amp;) = delete; lock_guard&amp; operator=(const lock_guard&amp;) = delete; private: mutex_type&amp; _M_device; &#125;; 非常简单的一个守卫类。传的是一个”mutex”的引用, 没有提供对外的函数。如果带std::adopt_lock初始化，则只引用不加锁,如下： 1std::lock_guard&lt;std::mutex&gt; lock(m,std::adopt_lock); 构造函数必须传入一个”mutex”的左值。 1234mutex m;lock_guard&lt;mutex&gt; l1; &#x2F;&#x2F; errlock_guard&lt;mutex&gt; l2(); &#x2F;&#x2F; 成函数声明了lock_guard&lt;mutex&gt; l3(m); &#x2F;&#x2F; ok unique_lock相比lock_guard，多了一堆外部接口。多了一个own成员表示是否持有，自由度更高，支持defer_lock def123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990/** @brief A movable scoped lock type. * * A unique_lock controls mutex ownership within a scope. Ownership of the * mutex can be delayed until after construction and can be transferred * to another unique_lock by move construction or move assignment. If a * mutex lock is owned when the destructor runs ownership will be released. * * @ingroup mutexes */ template&lt;typename _Mutex&gt; class unique_lock &#123; public: typedef _Mutex mutex_type; unique_lock() noexcept : _M_device(0), _M_owns(false) &#123; &#125; explicit unique_lock(mutex_type&amp; __m) : _M_device(std::__addressof(__m)), _M_owns(false) &#123; lock(); _M_owns = true; &#125; unique_lock(mutex_type&amp; __m, defer_lock_t) noexcept : _M_device(std::__addressof(__m)), _M_owns(false) &#123; &#125; unique_lock(mutex_type&amp; __m, try_to_lock_t) : _M_device(std::__addressof(__m)), _M_owns(_M_device-&gt;try_lock()) &#123; &#125; unique_lock(mutex_type&amp; __m, adopt_lock_t) noexcept : _M_device(std::__addressof(__m)), _M_owns(true) &#123; // XXX calling thread owns mutex &#125; template&lt;typename _Clock, typename _Duration&gt; unique_lock(mutex_type&amp; __m, const chrono::time_point&lt;_Clock, _Duration&gt;&amp; __atime) : _M_device(std::__addressof(__m)), _M_owns(_M_device-&gt;try_lock_until(__atime)) &#123; &#125; template&lt;typename _Rep, typename _Period&gt; unique_lock(mutex_type&amp; __m, const chrono::duration&lt;_Rep, _Period&gt;&amp; __rtime) : _M_device(std::__addressof(__m)), _M_owns(_M_device-&gt;try_lock_for(__rtime)) &#123; &#125; ~unique_lock() &#123; if (_M_owns) unlock(); &#125; unique_lock(const unique_lock&amp;) = delete; unique_lock&amp; operator=(const unique_lock&amp;) = delete; unique_lock(unique_lock&amp;&amp; __u) noexcept : _M_device(__u._M_device), _M_owns(__u._M_owns) &#123; __u._M_device = 0; __u._M_owns = false; &#125; unique_lock&amp; operator=(unique_lock&amp;&amp; __u) noexcept &#123; if(_M_owns) unlock(); unique_lock(std::move(__u)).swap(*this); __u._M_device = 0; __u._M_owns = false; return *this; &#125; explicit operator bool() const noexcept &#123; return owns_lock(); &#125; private: mutex_type* _M_device; bool _M_owns; &#125;; lock()12345678910111213void lock() &#123; if (!_M_device) __throw_system_error(int(errc::operation_not_permitted)); else if (_M_owns) __throw_system_error(int(errc::resource_deadlock_would_occur)); else &#123; _M_device-&gt;lock(); _M_owns = true; &#125; &#125; unique_lock构造函数可以不传”mutex”进来，所以分3种情况,最终调用posix的lock(). 没关联Mutex 没hold mutex hold mutex try_lock()12345678910111213bool try_lock() &#123; if (!_M_device) __throw_system_error(int(errc::operation_not_permitted)); else if (_M_owns) __throw_system_error(int(errc::resource_deadlock_would_occur)); else &#123; _M_owns = _M_device-&gt;try_lock(); return _M_owns; &#125; &#125; 也是3种情况，和lock()差不多，调用posix的try_lock(). try_lock_for() attempts to lock (i.e., takes ownership of) the associated TimedLockable mutex, returns if the mutex has been unavailable for the specified time duration (public member function) 支持不同时间格式的timeout来try_lock,底层是posix的pthread_mutex_timedlock/pthread_mutex_clocklock try_lock_until tries to lock (i.e., takes ownership of) the associated TimedLockable mutex, returns if the mutex has been unavailable until specified time point has been reached (public member function) 支持不同时间格式的timeout来try_lock,底层是posix的pthread_mutex_timedlock/pthread_mutex_clocklock unlock()1234567891011void unlock() &#123; if (!_M_owns) __throw_system_error(int(errc::operation_not_permitted)); else if (_M_device) &#123; _M_device-&gt;unlock(); _M_owns = false; &#125; &#125; 未拥有就unlock会异常 swap() swaps state with another std::unique_lock(public member function) release() disassociates the associated mutex without unlocking (i.e., releasing ownership of) it(public member function) 12345678mutex_type* release() noexcept &#123; mutex_type* __ret = _M_device; _M_device = 0; _M_owns = false; return __ret; &#125; 释放所有权，状态置为空，返回原来的mutex的地址。 mutex() returns a pointer to the associated mutex (public member function) 123mutex_type* mutex() const noexcept &#123; return _M_device; &#125; 返回锁的地址 owns_lock tests whether the lock owns (i.e., has locked) its associated mutex (public member function) 123bool owns_lock() const noexcept &#123; return _M_owns; &#125; scoped_lock代码不多，放上来了。scoped_lock只接收一个参数的话和lock_guard看起来没啥区别，主要是对于多个参数的使用比较好，如下： 12345678910111213// s1&#123; std::mutex m1, m2; std::lock(m1, m2); std::lock_guard&lt;std::mutex&gt; l1(m1, std::adopt_lock); std::lock_guard&lt;std::mutex&gt; l2(m2, std::adopt_lock); &#125;// s2&#123; std::mutex m1, m2; std::scoped_lock&lt;std::mutex, std::mutex&gt; sl(m1, m2);&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263#if __cplusplus &gt;= 201703L#define __cpp_lib_scoped_lock 201703 /** @brief A scoped lock type for multiple lockable objects. * * A scoped_lock controls mutex ownership within a scope, releasing * ownership in the destructor. */ template&lt;typename... _MutexTypes&gt; class scoped_lock &#123; public: explicit scoped_lock(_MutexTypes&amp;... __m) : _M_devices(std::tie(__m...)) &#123; std::lock(__m...); &#125; explicit scoped_lock(adopt_lock_t, _MutexTypes&amp;... __m) noexcept : _M_devices(std::tie(__m...)) &#123; &#125; // calling thread owns mutex ~scoped_lock() &#123; std::apply([](auto&amp;... __m) &#123; (__m.unlock(), ...); &#125;, _M_devices); &#125; scoped_lock(const scoped_lock&amp;) = delete; scoped_lock&amp; operator=(const scoped_lock&amp;) = delete; private: tuple&lt;_MutexTypes&amp;...&gt; _M_devices; &#125;; template&lt;&gt; class scoped_lock&lt;&gt; &#123; public: explicit scoped_lock() = default; explicit scoped_lock(adopt_lock_t) noexcept &#123; &#125; ~scoped_lock() = default; scoped_lock(const scoped_lock&amp;) = delete; scoped_lock&amp; operator=(const scoped_lock&amp;) = delete; &#125;; template&lt;typename _Mutex&gt; class scoped_lock&lt;_Mutex&gt; &#123; public: using mutex_type = _Mutex; explicit scoped_lock(mutex_type&amp; __m) : _M_device(__m) &#123; _M_device.lock(); &#125; explicit scoped_lock(adopt_lock_t, mutex_type&amp; __m) noexcept : _M_device(__m) &#123; &#125; // calling thread owns mutex ~scoped_lock() &#123; _M_device.unlock(); &#125; scoped_lock(const scoped_lock&amp;) = delete; scoped_lock&amp; operator=(const scoped_lock&amp;) = delete; private: mutex_type&amp; _M_device; &#125;;#endif // C++17 recursive_mutex 线程对已经获取的 std::mutex (已经上锁)再次上锁是错误的，尝试这样做会导致未定义行为。在某些情况下，一个线程会尝试在释放一个互斥量前多次获取。因此，C++标准库提供了 std::recursive_mutex 类。 recursive_mutex::__recursive_mutex_base::_M_mutex就是pthread_mutex_t.recursive_mutex和mutex的区别主要在构造函数中，给pthread_mutex_t加了attr(PTHREAD_MUTEX_RECURSIVE): 1234567891011121314151617181920static inline int__gthread_recursive_mutex_init_function (__gthread_recursive_mutex_t *__mutex)&#123; if (__gthread_active_p ()) &#123; pthread_mutexattr_t __attr; int __r; __r = __gthrw_(pthread_mutexattr_init) (&amp;__attr); if (!__r) __r = __gthrw_(pthread_mutexattr_settype) (&amp;__attr, PTHREAD_MUTEX_RECURSIVE); if (!__r) __r = __gthrw_(pthread_mutex_init) (__mutex, &amp;__attr); if (!__r) __r = __gthrw_(pthread_mutexattr_destroy) (&amp;__attr); return __r; &#125; return 0;&#125; PTHREAD_MUTEX_RECURSIVE在posix下的实现,就是保存了tid+count,来维持一个引用计数，如下： lock12345678910111213141516171819202122232425else if (__builtin_expect (PTHREAD_MUTEX_TYPE (mutex) == PTHREAD_MUTEX_RECURSIVE_NP, 1)) &#123; /* Recursive mutex. */ pid_t id = THREAD_GETMEM (THREAD_SELF, tid); /* Check whether we already hold the mutex. */ if (mutex-&gt;__data.__owner == id) &#123; /* Just bump the counter. */ if (__glibc_unlikely (mutex-&gt;__data.__count + 1 == 0)) /* Overflow of the counter. */ return EAGAIN; ++mutex-&gt;__data.__count; return 0; &#125; /* We have to get the mutex. */ LLL_MUTEX_LOCK_OPTIMIZED (mutex); assert (mutex-&gt;__data.__owner == 0); mutex-&gt;__data.__count = 1; &#125; unlock123456789101112else if (__builtin_expect (PTHREAD_MUTEX_TYPE (mutex) == PTHREAD_MUTEX_RECURSIVE_NP, 1)) &#123; /* Recursive mutex. */ if (mutex-&gt;__data.__owner != THREAD_GETMEM (THREAD_SELF, tid)) return EPERM; if (--mutex-&gt;__data.__count != 0) /* We still hold the mutex. */ return 0; goto normal; &#125; std::lockstd::lock对可变参数的对象进行加锁，实现上不放代码了，简单地说： 通过unique_lock来加锁 通过unique_lock::release释放所有权，不解锁 通过模板递归实例化来处理…args referencehttps://en.cppreference.com/w/cpp/thread/mutex","categories":[],"tags":[{"name":"c++","slug":"c","permalink":"https://riverferry.site/tags/c/"},{"name":"网络编程","slug":"网络编程","permalink":"https://riverferry.site/tags/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"}],"keywords":[]},{"title":"C++ std::thread","slug":"2022-03-30-C++ std::thread","date":"2022-03-30T00:00:00.000Z","updated":"2022-09-12T16:24:32.294Z","comments":true,"path":"2022-03-30-C++ std::thread/","link":"","permalink":"https://riverferry.site/2022-03-30-C++%20std::thread/","excerpt":"linux 2.1和linux2.6在线程实现上是不同的。在Linux2.4中，LinuxThreads是用单独的进程实现每个线程的，这使得它很难与posix线程的行为匹配。在linux2.6中，对linux内核和线程库进行了很大的修改，采用了一个称为Native POSIX线程库(NPTL)的新线程实现。它支持单个进程中有多个线程的模型，也更容易支持posix线程的语义。","text":"linux 2.1和linux2.6在线程实现上是不同的。在Linux2.4中，LinuxThreads是用单独的进程实现每个线程的，这使得它很难与posix线程的行为匹配。在linux2.6中，对linux内核和线程库进行了很大的修改，采用了一个称为Native POSIX线程库(NPTL)的新线程实现。它支持单个进程中有多个线程的模型，也更容易支持posix线程的语义。 date author gcc kernel glibc 20220331 river gcc-11.2.0 linux-4.18.1 glibc-2.35 std::threaddatastruct1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889class thread&#123; // ... using native_handle_type = __gthread_t; /// thread::id class id &#123; native_handle_type _M_thread; public: id() noexcept : _M_thread() &#123; &#125; explicit id(native_handle_type __id) : _M_thread(__id) &#123; &#125; private: friend class thread; friend struct hash&lt;id&gt;; friend bool operator==(id __x, id __y) noexcept;#if __cpp_lib_three_way_comparison friend strong_ordering operator&lt;=&gt;(id __x, id __y) noexcept;#else friend bool operator&lt;(id __x, id __y) noexcept;#endif template&lt;class _CharT, class _Traits&gt; friend basic_ostream&lt;_CharT, _Traits&gt;&amp; operator&lt;&lt;(basic_ostream&lt;_CharT, _Traits&gt;&amp; __out, id __id); &#125;; // member id _M_id; // ctor public: thread() noexcept = default;#ifdef _GLIBCXX_HAS_GTHREADS template&lt;typename _Callable, typename... _Args, typename = _Require&lt;__not_same&lt;_Callable&gt;&gt;&gt; explicit thread(_Callable&amp;&amp; __f, _Args&amp;&amp;... __args) &#123; static_assert( __is_invocable&lt;typename decay&lt;_Callable&gt;::type, typename decay&lt;_Args&gt;::type...&gt;::value, &quot;std::thread arguments must be invocable after conversion to rvalues&quot; );#ifdef GTHR_ACTIVE_PROXY // Create a reference to pthread_create, not just the gthr weak symbol. auto __depend = reinterpret_cast&lt;void(*)()&gt;(&amp;pthread_create);#else auto __depend = nullptr;#endif using _Wrapper = _Call_wrapper&lt;_Callable, _Args...&gt;; // Create a call wrapper with DECAY_COPY(__f) as its target object // and DECAY_COPY(__args)... as its bound argument entities. _M_start_thread(_State_ptr(new _State_impl&lt;_Wrapper&gt;( std::forward&lt;_Callable&gt;(__f), std::forward&lt;_Args&gt;(__args)...)), __depend); &#125; // dtor ~thread() &#123; if (joinable()) std::terminate(); &#125; // rule of four thread(const thread&amp;) = delete; thread(thread&amp;&amp; __t) noexcept &#123; swap(__t); &#125; thread&amp; operator=(const thread&amp;) = delete; thread&amp; operator=(thread&amp;&amp; __t) noexcept &#123; if (joinable()) std::terminate(); swap(__t); return *this; &#125; thread::id::native_handle_type在linux-posix下就是typedef pthread_t __gthread_t;c++的thread封装了pthread_t类型。删掉了拷贝构造和拷贝赋值函数。移动构造和移动赋值用到了经典了copy and swap idiom joinable checks whether the thread is joinable, i.e. potentially running in parallel context (public member function) 12345678910111213bool joinable() const noexcept &#123; return !(_M_id == id()); &#125;inline bool operator==(thread::id __x, thread::id __y) noexcept &#123; // pthread_equal is undefined if either thread ID is not valid, so we // can&#x27;t safely use __gthread_equal on default-constructed values (nor // the non-zero value returned by this_thread::get_id() for // single-threaded programs using GNU libc). Assume EqualityComparable. return __x._M_thread == __y._M_thread; &#125; 123456789int pthread_equal(pthread_t t1, pthread_t t2);/*The pthread_equal() function shall return a non-zero value if t1 and t2 are equal; otherwise, zero shall be returned. If either t1 or t2 are not valid thread IDs, the behavior is undefined.*/ linux3.2.0使用无符号长整形表示pthread_t,但在其他平台实现是不一样的。所以这里通过和默认值做比较来判断_M_id是否是有效的。之所以不用pthread_equal原因如上。 这里有点不好理解再补充下： thread的构造函数传入callable执行函数，内部会掉pthread_create,pthread_create会申请pthread_t的值，然后赋值给thread::id::_M_thread,所以只有pthread创建了线程std::thread才是joinable的。 join waits for the thread to finish its execution (public member function) 12345678910111213141516171819 void thread::join() &#123; int __e = EINVAL; if (_M_id != id()) __e = __gthread_join(_M_id._M_thread, 0); if (__e) __throw_system_error(__e); _M_id = id(); &#125;static inline int__gthread_join (__gthread_t __threadid, void **__value_ptr)&#123; return __gthrw_(pthread_join) (__threadid, __value_ptr);&#125; 调用posix的pthread_join来实现，第2个参数传的0，不接收pthread_exit传出来的值。最后给_M_id赋初始值表示无效。 detach permits the thread to execute independently from the thread handle (public member function) 12345678910111213141516171819void thread::detach() &#123; int __e = EINVAL; if (_M_id != id()) __e = __gthread_detach(_M_id._M_thread); if (__e) __throw_system_error(__e); _M_id = id(); &#125; static inline int__gthread_detach (__gthread_t __threadid)&#123; return __gthrw_(pthread_detach) (__threadid);&#125; 调用posix的pthread_detach来实现。最后给_M_id赋初始值表示无效。 swap swaps two thread objects (public member function) 1234567void swap(thread&amp; __t) noexcept &#123; std::swap(_M_id, __t._M_id); &#125; inline void swap(thread&amp; __x, thread&amp; __y) noexcept &#123; __x.swap(__y); &#125; 实现copy and swap hardware_concurrency returns the number of concurrent threads supported by the implementation (public static member function) 123456789101112// Returns a value that hints at the number of hardware thread contexts. static unsigned int hardware_concurrency() noexcept;unsigned int thread::hardware_concurrency() noexcept &#123; int __n = _GLIBCXX_NPROCS; if (__n &lt; 0) __n = 0; return __n; &#125; 在多核系统中返回cpu核心的数量，当无法获取返回0. get_id returns the id of the thread (public member function) 123id get_id() const noexcept &#123; return _M_id; &#125; 返回thread::id，还有个this_thread::get_id()可以返回任意thread的thread::id native_handle returns the underlying implementation-defined thread handle (public member function) 123native_handle_type native_handle() &#123; return _M_id._M_thread; &#125; 返回原生的线程id数据结构，posix下是pthread_t referencehttps://en.cppreference.com/w/cpp/thread/thread https://man7.org/linux/man-pages/man3/pthread_equal.3p.html https://bewaremypower.github.io/2018/12/31/C-11%E4%B8%ADstd-thread%E5%92%8Cpthread%E6%B7%B7%E7%94%A8%E7%9A%84%E5%9D%91/","categories":[],"tags":[{"name":"c++","slug":"c","permalink":"https://riverferry.site/tags/c/"},{"name":"网络编程","slug":"网络编程","permalink":"https://riverferry.site/tags/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/"}],"keywords":[]},{"title":"leveldb源码分析(1x) 总结","slug":"2021-11-10-leveldb源码分析(1x) 总结","date":"2021-11-10T00:00:00.000Z","updated":"2022-09-12T16:24:32.294Z","comments":true,"path":"2021-11-10-leveldb源码分析(1x) 总结/","link":"","permalink":"https://riverferry.site/2021-11-10-leveldb%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90(1x)%20%E6%80%BB%E7%BB%93/","excerpt":"项目有用到leveldb,打算最近看看源码，整理个系列文章，这是第10篇总结。源码注释地址","text":"项目有用到leveldb,打算最近看看源码，整理个系列文章，这是第10篇总结。源码注释地址 代码todo 总结referencehttps://web.archive.org/web/20120131105110/http://rdc.taobao.com/blog/cs/wp-content/plugins/leveldb%E5%AE%9E%E7%8E%B0%E8%A7%A3%E6%9E%90.pdf http://catkang.github.io/2017/01/17/leveldb-data.html https://www.bookstack.cn/read/Leveldb-handbook/spilt.2.b308da3c3d01f3cd.md https://izualzhy.cn/leveldb-block","categories":[],"tags":[{"name":"leveldb","slug":"leveldb","permalink":"https://riverferry.site/tags/leveldb/"}],"keywords":[]},{"title":"leveldb源码分析(10) lru cache","slug":"2021-11-08-leveldb源码分析(10) lru cache","date":"2021-11-08T00:00:00.000Z","updated":"2022-09-12T16:24:32.294Z","comments":true,"path":"2021-11-08-leveldb源码分析(10) lru cache/","link":"","permalink":"https://riverferry.site/2021-11-08-leveldb%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90(10)%20lru%20cache/","excerpt":"leveldb内部实现了一个简单的lru,整理下","text":"leveldb内部实现了一个简单的lru,整理下 通过内部实现的一个简单的hash_table和一个lru双向链表来实现。并且提供了shard的lru_cache,默认分成16片，减少锁冲突，有点像go里面的一个map的分片实现。 LRUHandle链表节点数据结构定义： 123456789101112131415161718192021struct LRUHandle &#123; void* value; void (*deleter)(const Slice&amp;, void* value); LRUHandle* next_hash; LRUHandle* next; LRUHandle* prev; size_t charge; // TODO(opt): Only allow uint32_t? size_t key_length; bool in_cache; // Whether entry is in the cache. uint32_t refs; // References, including cache reference, if present. uint32_t hash; // Hash of key(); used for fast sharding(分片) and comparisons char key_data[1]; // Beginning of key Slice key() const &#123; // next_ is only equal to this if the LRU handle is the list head of an // empty list. List heads never have meaningful keys. assert(next != this); return Slice(key_data, key_length); &#125;&#125;; delete支持外部传入自定义的回收函数指针 next是lru链表的下一节点 prev是lru链表的下一节点 next_hash是hash table拉链的下一节点 refs引用计数，=1的时候在lru_链表，&gt;1的时候在in_use_链表，=0的时候回收资源，在in_use_链表的时候即使cache超过容量，也不能回收 charge占用容量 HandleTable12345678910class HandleTable &#123; public: // ... private: // The table consists of an array of buckets where each bucket is // a linked list of cache entries that hash into the bucket. uint32_t length_; // bucket数量 uint32_t elems_; // 节点数量 LRUHandle** list_; // 保存指针的数组，数组大小是length_ &#125; length_是桶的大小，就是list_数组的大小，初始化为4，后面按2倍扩容 elems_节点数量，当节点数量&gt;length_的时候，开始扩容，resize函数 123456789101112131415161718// 如果没有冲突，Insert后返回空// 如果冲突，覆盖冲突节点(hash表key不能重复)LRUHandle* Insert(LRUHandle* h) &#123; LRUHandle** ptr = FindPointer(h-&gt;key(), h-&gt;hash); LRUHandle* old = *ptr; h-&gt;next_hash = (old == nullptr ? nullptr : old-&gt;next_hash); *ptr = h; if (old == nullptr) &#123; ++elems_; if (elems_ &gt; length_) &#123; // Since each cache entry is fairly large, we aim for a small // average linked list length (&lt;= 1). // 扩容的时机比较特殊，没有按装载因子算，元素个数大于桶的大小就扩容了， 链表不会太长 Resize(); &#125; &#125; return old;&#125; 如果是新的key，就插入到桶的拉链的尾。 如果是存在的key，则覆盖原来的值，insert完后调用FinishErase(table_.Insert(e)),来回收原来的key. 12345678910// 如果是存在的节点，直接覆盖节点的地址为next_hash的地址，return 原来的地址(finish函数remove) LRUHandle* Remove(const Slice&amp; key, uint32_t hash) &#123; LRUHandle** ptr = FindPointer(key, hash); LRUHandle* result = *ptr; if (result != nullptr) &#123; *ptr = result-&gt;next_hash; --elems_; &#125; return result; &#125; LRUCache12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152// A single shard of sharded cache.class LRUCache &#123; public: LRUCache(); ~LRUCache(); // Separate from constructor so caller can easily make an array of LRUCache void SetCapacity(size_t capacity) &#123; capacity_ = capacity; &#125; // Like Cache methods, but with an extra &quot;hash&quot; parameter. Cache::Handle* Insert(const Slice&amp; key, uint32_t hash, void* value, size_t charge, void (*deleter)(const Slice&amp; key, void* value)); Cache::Handle* Lookup(const Slice&amp; key, uint32_t hash); void Release(Cache::Handle* handle); void Erase(const Slice&amp; key, uint32_t hash); void Prune(); size_t TotalCharge() const &#123; MutexLock l(&amp;mutex_); return usage_; &#125; private: void LRU_Remove(LRUHandle* e); void LRU_Append(LRUHandle* list, LRUHandle* e); void Ref(LRUHandle* e); void Unref(LRUHandle* e); bool FinishErase(LRUHandle* e) EXCLUSIVE_LOCKS_REQUIRED(mutex_); // Initialized before use. // 容量 size_t capacity_; // mutex_ protects the following state. mutable port::Mutex mutex_; // 使用量 size_t usage_ GUARDED_BY(mutex_); // Dummy head of LRU list. // lru.prev is newest entry, lru.next is oldest entry. // Entries have refs==1 and in_cache==true. // lru头结点,头结点是dummy不保存外部数据 // refs==1在lru_链表，&gt;1在in_use链表，1代表cache本身的引用，client每使用一次会+1 LRUHandle lru_ GUARDED_BY(mutex_); // Dummy head of in-use list. // Entries are in use by clients, and have refs &gt;= 2 and in_cache==true. // in_use头结点，被client使用的在in_use_链表,其他的在lru_链表 LRUHandle in_use_ GUARDED_BY(mutex_); HandleTable table_ GUARDED_BY(mutex_);&#125;; 引用计数&gt;1放在in_use_链表，=1放在lru_，=0就开始释放资源了。 123456789101112void LRUCache::LRU_Append(LRUHandle* list, LRUHandle* e) &#123; // Make &quot;e&quot; newest entry by inserting just before *list e-&gt;next = list; e-&gt;prev = list-&gt;prev; e-&gt;prev-&gt;next = e; e-&gt;next-&gt;prev = e;&#125;void LRUCache::LRU_Remove(LRUHandle* e) &#123; e-&gt;next-&gt;prev = e-&gt;prev; e-&gt;prev-&gt;next = e-&gt;next;&#125; lru_和in_use_是dummy的头结点，初始化的时候，next和prev都指向自己。后面append插入dummy的左边第一个位置，remove移除dummy右边的第一个元素，因为是循环链表，所以dummy即是头也是尾。 12345678Cache::Handle* LRUCache::Lookup(const Slice&amp; key, uint32_t hash) &#123; MutexLock l(&amp;mutex_); LRUHandle* e = table_.Lookup(key, hash); if (e != nullptr) &#123; Ref(e); &#125; return reinterpret_cast&lt;Cache::Handle*&gt;(e);&#125; 通过hash table来实现O(1)的查找，没查一次引用计数+1，如果再lru_,则重新放入in_use_. ShardedLRUCache12345678910111213static const int kNumShardBits = 4;// 分片，16个static const int kNumShards = 1 &lt;&lt; kNumShardBits;class ShardedLRUCache : public Cache &#123; private: LRUCache shard_[kNumShards]; port::Mutex id_mutex_; uint64_t last_id_; // ...&#125; 用数组存了多个LRUCache,基本的实现，一目了然。","categories":[],"tags":[{"name":"c++","slug":"c","permalink":"https://riverferry.site/tags/c/"}],"keywords":[]},{"title":"leveldb源码分析(9) 完整的读取流程","slug":"2021-11-07-leveldb源码分析(9) 完整的读取流程","date":"2021-11-07T00:00:00.000Z","updated":"2022-09-12T16:24:32.294Z","comments":true,"path":"2021-11-07-leveldb源码分析(9) 完整的读取流程/","link":"","permalink":"https://riverferry.site/2021-11-07-leveldb%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90(9)%20%E5%AE%8C%E6%95%B4%E7%9A%84%E8%AF%BB%E5%8F%96%E6%B5%81%E7%A8%8B/","excerpt":"项目有用到leveldb,打算最近看看源码，整理个系列文章，这是第9篇完整的读取流程。源码注释地址","text":"项目有用到leveldb,打算最近看看源码，整理个系列文章，这是第9篇完整的读取流程。源码注释地址 代码todo 总结referencehttps://web.archive.org/web/20120131105110/http://rdc.taobao.com/blog/cs/wp-content/plugins/leveldb%E5%AE%9E%E7%8E%B0%E8%A7%A3%E6%9E%90.pdf http://catkang.github.io/2017/01/17/leveldb-data.html https://www.bookstack.cn/read/Leveldb-handbook/spilt.2.b308da3c3d01f3cd.md https://izualzhy.cn/leveldb-block","categories":[],"tags":[{"name":"leveldb","slug":"leveldb","permalink":"https://riverferry.site/tags/leveldb/"}],"keywords":[]},{"title":"leveldb源码分析(8) 迭代器 iterator","slug":"2021-11-06-leveldb源码分析(8) 迭代器 iterator","date":"2021-11-06T00:00:00.000Z","updated":"2022-09-12T16:24:32.294Z","comments":true,"path":"2021-11-06-leveldb源码分析(8) 迭代器 iterator/","link":"","permalink":"https://riverferry.site/2021-11-06-leveldb%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90(8)%20%E8%BF%AD%E4%BB%A3%E5%99%A8%20iterator/","excerpt":"项目有用到leveldb,打算最近看看源码，整理个系列文章，这是第8篇迭代器 iterator。源码注释地址","text":"项目有用到leveldb,打算最近看看源码，整理个系列文章，这是第8篇迭代器 iterator。源码注释地址 代码纯基类的定义： 123456789101112131415161718192021222324252627282930313233class LEVELDB_EXPORT Iterator &#123; public: Iterator(); Iterator(const Iterator&amp;) = delete; Iterator&amp; operator=(const Iterator&amp;) = delete; virtual ~Iterator(); virtual bool Valid() const = 0; virtual void SeekToFirst() = 0; virtual void SeekToLast() = 0; virtual void Seek(const Slice&amp; target) = 0; virtual void Next() = 0; virtual void Prev() = 0; virtual Slice key() const = 0; virtual Slice value() const = 0; virtual Status status() const = 0; using CleanupFunction = void (*)(void* arg1, void* arg2); void RegisterCleanup(CleanupFunction function, void* arg1, void* arg2); private: struct CleanupNode &#123; bool IsEmpty() const &#123; return function == nullptr; &#125; void Run() &#123; assert(function != nullptr); (*function)(arg1, arg2); &#125; CleanupFunction function; void* arg1; void* arg2; CleanupNode* next; &#125;; CleanupNode cleanup_head_;&#125;; 涉及的子类： 123456789class MemTableIterator : public Iteratorclass DBIter : public Iteratorclass ModelIter : public Iteratorclass Version::LevelFileNumIterator : public Iteratorclass Block::Iter : public Iteratorclass EmptyIterator : public Iteratorclass MergingIterator : public Iteratorclass KeyConvertingIterator : public Iteratorclass TwoLevelIterator : public Iterator MemTableIterator1234567// 对跳表的iterator进行了简单的封装class MemTableIterator : public Iterator &#123; // ... private: MemTable::Table::Iterator iter_; std::string tmp_; // For passing to EncodeKey&#125;; 就是封装了MemTable::Table::Iterator，也就是skiplist的封装，skiplist的构造见https://riverferry.site/2021-10-13-leveldb%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90(4)%20memtable%20and%20log/ DBIter123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687// Memtables and sstables that make the DB representation contain// (userkey,seq,type) =&gt; uservalue entries. DBIter// combines multiple entries for the same userkey found in the DB// representation into a single entry while accounting for sequence// numbers, deletion markers, overwrites, etc.class DBIter : public Iterator &#123; public: // Which direction is the iterator currently moving? // (1) When moving forward, the internal iterator is positioned at // the exact entry that yields this-&gt;key(), this-&gt;value() // (2) When moving backwards, the internal iterator is positioned // just before all entries whose user key == this-&gt;key(). enum Direction &#123; kForward, kReverse &#125;; DBIter(DBImpl* db, const Comparator* cmp, Iterator* iter, SequenceNumber s, uint32_t seed) : db_(db), user_comparator_(cmp), iter_(iter), sequence_(s), direction_(kForward), valid_(false), rnd_(seed), bytes_until_read_sampling_(RandomCompactionPeriod()) &#123;&#125; DBIter(const DBIter&amp;) = delete; DBIter&amp; operator=(const DBIter&amp;) = delete; ~DBIter() override &#123; delete iter_; &#125; bool Valid() const override &#123; return valid_; &#125; Slice key() const override &#123; assert(valid_); return (direction_ == kForward) ? ExtractUserKey(iter_-&gt;key()) : saved_key_; &#125; Slice value() const override &#123; assert(valid_); return (direction_ == kForward) ? iter_-&gt;value() : saved_value_; &#125; Status status() const override &#123; if (status_.ok()) &#123; return iter_-&gt;status(); &#125; else &#123; return status_; &#125; &#125; void Next() override; void Prev() override; void Seek(const Slice&amp; target) override; void SeekToFirst() override; void SeekToLast() override; private: void FindNextUserEntry(bool skipping, std::string* skip); void FindPrevUserEntry(); bool ParseKey(ParsedInternalKey* key); inline void SaveKey(const Slice&amp; k, std::string* dst) &#123; dst-&gt;assign(k.data(), k.size()); &#125; inline void ClearSavedValue() &#123; if (saved_value_.capacity() &gt; 1048576) &#123; std::string empty; swap(empty, saved_value_); &#125; else &#123; saved_value_.clear(); &#125; &#125; // Picks the number of bytes that can be read until a compaction is scheduled. size_t RandomCompactionPeriod() &#123; return rnd_.Uniform(2 * config::kReadBytesPeriod); &#125; DBImpl* db_; const Comparator* const user_comparator_; Iterator* const iter_; SequenceNumber const sequence_; Status status_; std::string saved_key_; // == current key when direction_==kReverse std::string saved_value_; // == current raw value when direction_==kReverse Direction direction_; bool valid_; Random rnd_; size_t bytes_until_read_sampling_;&#125;; Version::LevelFileNumIterator123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051// An internal iterator. For a given version/level pair, yields// information about the files in the level. For a given entry, key()// is the largest key that occurs in the file, and value() is an// 16-byte value containing the file number and file size, both// encoded using EncodeFixed64.class Version::LevelFileNumIterator : public Iterator &#123; public: LevelFileNumIterator(const InternalKeyComparator&amp; icmp, const std::vector&lt;FileMetaData*&gt;* flist) : icmp_(icmp), flist_(flist), index_(flist-&gt;size()) &#123; // Marks as invalid &#125; bool Valid() const override &#123; return index_ &lt; flist_-&gt;size(); &#125; void Seek(const Slice&amp; target) override &#123; index_ = FindFile(icmp_, *flist_, target); &#125; void SeekToFirst() override &#123; index_ = 0; &#125; void SeekToLast() override &#123; index_ = flist_-&gt;empty() ? 0 : flist_-&gt;size() - 1; &#125; void Next() override &#123; assert(Valid()); index_++; &#125; void Prev() override &#123; assert(Valid()); if (index_ == 0) &#123; index_ = flist_-&gt;size(); // Marks as invalid &#125; else &#123; index_--; &#125; &#125; Slice key() const override &#123; assert(Valid()); return (*flist_)[index_]-&gt;largest.Encode(); &#125; Slice value() const override &#123; assert(Valid()); EncodeFixed64(value_buf_, (*flist_)[index_]-&gt;number); EncodeFixed64(value_buf_ + 8, (*flist_)[index_]-&gt;file_size); return Slice(value_buf_, sizeof(value_buf_)); &#125; Status status() const override &#123; return Status::OK(); &#125; private: const InternalKeyComparator icmp_; const std::vector&lt;FileMetaData*&gt;* const flist_; uint32_t index_; // Backing store for value(). Holds the file number and size. mutable char value_buf_[16];&#125;; flist_用vector保存了这一层所有的sst文件。index_作为迭代器当前指向的位置，value返回16字节的字符串，包含sst文件的编号和大小，key返回sst文件的最大内部key TwoLevelIterator12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152class TwoLevelIterator : public Iterator &#123; public: TwoLevelIterator(Iterator* index_iter, BlockFunction block_function, void* arg, const ReadOptions&amp; options); ~TwoLevelIterator() override; void Seek(const Slice&amp; target) override; void SeekToFirst() override; void SeekToLast() override; void Next() override; void Prev() override; bool Valid() const override &#123; return data_iter_.Valid(); &#125; Slice key() const override &#123; assert(Valid()); return data_iter_.key(); &#125; Slice value() const override &#123; assert(Valid()); return data_iter_.value(); &#125; Status status() const override &#123; // It&#x27;d be nice if status() returned a const Status&amp; instead of a Status if (!index_iter_.status().ok()) &#123; return index_iter_.status(); &#125; else if (data_iter_.iter() != nullptr &amp;&amp; !data_iter_.status().ok()) &#123; return data_iter_.status(); &#125; else &#123; return status_; &#125; &#125; private: void SaveError(const Status&amp; s) &#123; if (status_.ok() &amp;&amp; !s.ok()) status_ = s; &#125; void SkipEmptyDataBlocksForward(); void SkipEmptyDataBlocksBackward(); void SetDataIterator(Iterator* data_iter); void InitDataBlock(); BlockFunction block_function_; void* arg_; const ReadOptions options_; Status status_; IteratorWrapper index_iter_; IteratorWrapper data_iter_; // May be nullptr // If data_iter_ is non-null, then &quot;data_block_handle_&quot; holds the // &quot;index_value&quot; passed to block_function_ to create the data_iter_. std::string data_block_handle_;&#125;; 关键是data_iter_和index_iter_,后面补充 Block::Iter1234567891011121314151617181920212223class Block &#123; public: // Initialize the block with the specified contents. explicit Block(const BlockContents&amp; contents); Block(const Block&amp;) = delete; Block&amp; operator=(const Block&amp;) = delete; ~Block(); size_t size() const &#123; return size_; &#125; Iterator* NewIterator(const Comparator* comparator); private: class Iter; uint32_t NumRestarts() const; const char* data_; size_t size_; uint32_t restart_offset_; // Offset in data_ of restart array bool owned_; // Block owns data_[]&#125;; 其中的Iter： 123class Block::Iter : public Iterator &#123; &#x2F;&#x2F; ...&#125; EmptyIterator123456789101112131415161718192021222324class EmptyIterator : public Iterator &#123; public: EmptyIterator(const Status&amp; s) : status_(s) &#123;&#125; ~EmptyIterator() override = default; bool Valid() const override &#123; return false; &#125; void Seek(const Slice&amp; target) override &#123;&#125; void SeekToFirst() override &#123;&#125; void SeekToLast() override &#123;&#125; void Next() override &#123; assert(false); &#125; void Prev() override &#123; assert(false); &#125; Slice key() const override &#123; assert(false); return Slice(); &#125; Slice value() const override &#123; assert(false); return Slice(); &#125; Status status() const override &#123; return status_; &#125; private: Status status_;&#125;; 暂时不知道这个有啥用，后面见到了再补充 MergingIterator123class MergingIterator : public Iterator &#123; // ...&#125; 后面补充 KeyConvertingIterator1234567891011121314151617181920212223242526272829303132333435363738394041// A helper class that converts internal format keys into user keysclass KeyConvertingIterator : public Iterator &#123; public: explicit KeyConvertingIterator(Iterator* iter) : iter_(iter) &#123;&#125; KeyConvertingIterator(const KeyConvertingIterator&amp;) = delete; KeyConvertingIterator&amp; operator=(const KeyConvertingIterator&amp;) = delete; ~KeyConvertingIterator() override &#123; delete iter_; &#125; bool Valid() const override &#123; return iter_-&gt;Valid(); &#125; void Seek(const Slice&amp; target) override &#123; ParsedInternalKey ikey(target, kMaxSequenceNumber, kTypeValue); std::string encoded; AppendInternalKey(&amp;encoded, ikey); iter_-&gt;Seek(encoded); &#125; void SeekToFirst() override &#123; iter_-&gt;SeekToFirst(); &#125; void SeekToLast() override &#123; iter_-&gt;SeekToLast(); &#125; void Next() override &#123; iter_-&gt;Next(); &#125; void Prev() override &#123; iter_-&gt;Prev(); &#125; Slice key() const override &#123; assert(Valid()); ParsedInternalKey key; if (!ParseInternalKey(iter_-&gt;key(), &amp;key)) &#123; status_ = Status::Corruption(&quot;malformed internal key&quot;); return Slice(&quot;corrupted key&quot;); &#125; return key.user_key; &#125; Slice value() const override &#123; return iter_-&gt;value(); &#125; Status status() const override &#123; return status_.ok() ? iter_-&gt;status() : status_; &#125; private: mutable Status status_; Iterator* iter_;&#125;; ModelIter123456789101112131415161718192021222324252627282930313233class ModelDB : public DB &#123; // ... class ModelIter : public Iterator &#123; public: ModelIter(const KVMap* map, bool owned) : map_(map), owned_(owned), iter_(map_-&gt;end()) &#123;&#125; ~ModelIter() override &#123; if (owned_) delete map_; &#125; bool Valid() const override &#123; return iter_ != map_-&gt;end(); &#125; void SeekToFirst() override &#123; iter_ = map_-&gt;begin(); &#125; void SeekToLast() override &#123; if (map_-&gt;empty()) &#123; iter_ = map_-&gt;end(); &#125; else &#123; iter_ = map_-&gt;find(map_-&gt;rbegin()-&gt;first); &#125; &#125; void Seek(const Slice&amp; k) override &#123; iter_ = map_-&gt;lower_bound(k.ToString()); &#125; void Next() override &#123; ++iter_; &#125; void Prev() override &#123; --iter_; &#125; Slice key() const override &#123; return iter_-&gt;first; &#125; Slice value() const override &#123; return iter_-&gt;second; &#125; Status status() const override &#123; return Status::OK(); &#125; private: const KVMap* const map_; const bool owned_; // Do we own map_ KVMap::const_iterator iter_; &#125;;&#125; referencehttps://web.archive.org/web/20120131105110/http://rdc.taobao.com/blog/cs/wp-content/plugins/leveldb%E5%AE%9E%E7%8E%B0%E8%A7%A3%E6%9E%90.pdf http://catkang.github.io/2017/01/17/leveldb-data.html https://www.bookstack.cn/read/Leveldb-handbook/spilt.2.b308da3c3d01f3cd.md https://izualzhy.cn/leveldb-block https://hardcore.feishu.cn/docs/doccnWaz1fjIxeyRosRTojk4irs","categories":[],"tags":[{"name":"leveldb","slug":"leveldb","permalink":"https://riverferry.site/tags/leveldb/"}],"keywords":[]},{"title":"leveldb源码分析(7) 版本控制 version","slug":"2021-11-05-leveldb源码分析(7) 版本控制 version","date":"2021-11-05T00:00:00.000Z","updated":"2022-09-12T16:24:32.294Z","comments":true,"path":"2021-11-05-leveldb源码分析(7) 版本控制 version/","link":"","permalink":"https://riverferry.site/2021-11-05-leveldb%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90(7)%20%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6%20version/","excerpt":"项目有用到leveldb,打算最近看看源码，整理个系列文章，这是第7篇版本控制 version。源码注释地址","text":"项目有用到leveldb,打算最近看看源码，整理个系列文章，这是第7篇版本控制 version。源码注释地址 代码VersionSet1234567891011121314151617181920212223242526272829303132333435class VersionSet &#123; Env* const env_; const std::string dbname_; const Options* const options_; // sstable的table cache TableCache* const table_cache_; // 对 key 做比较的 comparator const InternalKeyComparator icmp_; // 下一个可用的 FileNumber uint64_t next_file_number_; // manifest的file number uint64_t manifest_file_number_; // 最后用过的 SequnceNumber uint64_t last_sequence_; // log 文件的 FileNumber uint64_t log_number_; // 辅助 log 文件的 FileNumber，在 compact memtable 时，置为 0. uint64_t prev_log_number_; // 0 or backing store for memtable being compacted // Opened lazily // manifest 文件的封装 WritableFile* descriptor_file_; // manifest 文件的 writer log::Writer* descriptor_log_; // 双向循环链表的头节点 Version dummy_versions_; // Head of circular doubly-linked list of versions. // 当前的version Version* current_; // Per-level key at which the next compaction at that level should start. // Either an empty string, or a valid InternalKey. // 下一次 compact 的 start-key。compact_pointer_就保存着每个 level // 除了 current_外的 Version，并不会做 compact，所以这个值并不保存在 Version 中 std::string compact_pointer_[config::kNumLevels];&#125; Version12345678910111213141516class Version &#123; VersionSet* vset_; // VersionSet to which this Version belongs Version* next_; // Next version in linked list Version* prev_; // Previous version in linked list int refs_; // Number of live refs to this version // 2维数组保存每一层的sst文件(该版本的) std::vector&lt;FileMetaData*&gt; files_[config::kNumLevels]; // seek触发compaction FileMetaData* file_to_compact_; int file_to_compact_level_; // 容量触发compaction double compaction_score_; int compaction_level_;&#125; Version是一个链表类，头结点保存在vset_.dummy_versions_。Version还保存了当前版本下每个level的所有文件信息，以及将要压缩的文件和层级等信息。 VersionEdit12345678910111213141516171819class VersionEdit &#123; std::string comparator_; uint64_t log_number_; uint64_t prev_log_number_; uint64_t next_file_number_; SequenceNumber last_sequence_; bool has_comparator_; bool has_log_number_; bool has_prev_log_number_; bool has_next_file_number_; bool has_last_sequence_; // 上一次压缩的最大key std::vector&lt;std::pair&lt;int, InternalKey&gt;&gt; compact_pointers_; // 删除的sst DeletedFileSet deleted_files_; // 新增的sst std::vector&lt;std::pair&lt;int, FileMetaData&gt;&gt; new_files_;&#125; 每一次压缩都会新增/删除sst,删除也不一定真的删除，因为是多版本带引用计数的，这里versionEdit是2个version之间sst的变化，会wal到manifest持久化。重启db的时候根据manifest重建versionSet和version,看下manifest的内容: 1234567891011121314151617181920212223242526[root@dev testdb]# &#x2F;root&#x2F;leveldb&#x2F;build&#x2F;leveldbutil dump MANIFEST-000013--- offset 0; VersionEdit &#123; Comparator: leveldb.BytewiseComparator AddFile: 0 11 325262 &#39;1000372555&#39; @ 1009 : 1 .. &#39;999733429&#39; @ 8727 : 1 AddFile: 0 8 422 &#39;1189641421&#39; @ 20 : 1 .. &#39;846930886&#39; @ 12 : 1 AddFile: 0 5 333 &#39;1646668802&#39; @ 10 : 1 .. &#39;1646668802&#39; @ 1 : 1&#125;--- offset 163; VersionEdit &#123; LogNumber: 15 PrevLogNumber: 0 NextFile: 16 LastSeq: 20020 AddFile: 0 14 325262 &#39;1000372555&#39; @ 11009 : 1 .. &#39;999733429&#39; @ 18727 : 1&#125;--- offset 223; VersionEdit &#123; LogNumber: 15 PrevLogNumber: 0 NextFile: 17 LastSeq: 21954 CompactPointer: 0 &#39;999733429&#39; @ 8727 : 1 RemoveFile: 0 5 RemoveFile: 0 8 RemoveFile: 0 11 RemoveFile: 0 14 AddFile: 1 16 325291 &#39;1000372555&#39; @ 11009 : 1 .. &#39;999733429&#39; @ 18727 : 1&#125; 这里引入一个问题：manifest文件丢失，leveldb还能恢复数据吗？ 答案是可以的，因为log里面有完整的数据，重放log里没有写入的数据到memtable,再dump到level0里面，然后一层层压缩，建立新的manifest即可，具体参见这篇文章 recovertodo buildertodo 总结referencehttps://web.archive.org/web/20120131105110/http://rdc.taobao.com/blog/cs/wp-content/plugins/leveldb%E5%AE%9E%E7%8E%B0%E8%A7%A3%E6%9E%90.pdf http://catkang.github.io/2017/01/17/leveldb-data.html https://www.bookstack.cn/read/Leveldb-handbook/spilt.2.b308da3c3d01f3cd.md https://izualzhy.cn/leveldb-block https://hardcore.feishu.cn/docs/doccnWaz1fjIxeyRosRTojk4irs","categories":[],"tags":[{"name":"leveldb","slug":"leveldb","permalink":"https://riverferry.site/tags/leveldb/"}],"keywords":[]},{"title":"leveldb源码分析(6) 文件压缩","slug":"2021-11-04-leveldb源码分析(6) 文件压缩","date":"2021-11-04T00:00:00.000Z","updated":"2022-09-12T16:24:32.294Z","comments":true,"path":"2021-11-04-leveldb源码分析(6) 文件压缩/","link":"","permalink":"https://riverferry.site/2021-11-04-leveldb%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90(6)%20%E6%96%87%E4%BB%B6%E5%8E%8B%E7%BC%A9/","excerpt":"项目有用到leveldb,打算最近看看源码，整理个系列文章，这是第6篇文件压缩。源码注释地址","text":"项目有用到leveldb,打算最近看看源码，整理个系列文章，这是第6篇文件压缩。源码注释地址 文件分为minor compaction,major compaction,手动压缩 代码12345LogAndApply FinalizeVersionSet::Recover Finalize 123456789101112131415161718192021222324252627282930TEST_CompactRangeBackgroundCallDBImpl::Get... DBIter::FindNextUserEntry() DBIter::FindPrevUserEntry() DBIter::ParseKey DBImpl::RecordReadSampleDBImpl::Write DBImpl::MakeRoomForWriteDB::Open DBImpl::MaybeScheduleCompaction() DBImpl::BackgroundCall() DBImpl::BackgroundCompaction() LogAndApply DBImpl::CompactMemTable() LogAndAppyl DBImpl::DoCompactionWork(CompactionState* compact) DBImpl::CompactMemTable() LogAndApply DBImpl::InstallCompactionResults(CompactionState* compact) LogAndApplyDB::Open(const Options&amp; options, const std::string&amp; dbname, DB** dbptr) LogAndApply FinalizeFinalize函数就为了得到这两个值compaction_level_和compaction_score_，也即适合压缩的层级和分值。细节在后面整理了，这块总结下： 先计算每一层的Score，最大的那一层先压缩，计算策略是： level-0: level-0的所有sstable文件个数/4 level-n: level-n的所有sstable文件大小和/MaxBytesForLevel MaxBytesForLevel的值下文也写出来了。 这块第0层的策略和其他层不太一样，原因我参考这里记录下： level-0的sstable可能overlap,所以level-0上sstable过多会影响效率 level-0的sstable是immutable直接dump过来的，不受sstable的max_file_size(默认2M)控制 todo: immutable的大小限制由write_buffer_size控制，默认是4M。kL0_SlowdownWritesTrigger(=8, level-0的sstable文件个数&gt;=8的时候，MakeRoomForWrite里面开始慢处理写)/kL0_StopWritesTrigger(=12, level-0的sstable文件个数&gt;=12的时候，MakeRoomForWrite停止写) 这里的score最大值是1？ 实测.ldb的大小是3.5M? MaxBytesForLevel = 10(^i)? allowed_seek = max(100, sstable_size/16k), get一次这个值-1，小于0的时候合并 12345678910111213141516171819202122232425262728293031323334353637383940// Finalize: 敲定void VersionSet::Finalize(Version* v) &#123; // Precomputed best level for next compaction int best_level = -1; double best_score = -1; // kNumLevels = 7， 一共有几层？ 为什么这里只循环6次？ for (int level = 0; level &lt; config::kNumLevels - 1; level++) &#123; double score; if (level == 0) &#123; // We treat level-0 specially by bounding the number of files // instead of number of bytes for two reasons: // // (1) With larger write-buffer sizes, it is nice not to do too // many level-0 compactions. // // (2) The files in level-0 are merged on every read and // therefore we wish to avoid too many files when the individual // file size is small (perhaps because of a small write-buffer // setting, or very high compression ratios, or lots of // overwrites/deletions). // kL0_CompactionTrigger = 4 score = v-&gt;files_[level].size() / static_cast&lt;double&gt;(config::kL0_CompactionTrigger); &#125; else &#123; // Compute the rati(比率) of current size to size limit. const uint64_t level_bytes = TotalFileSize(v-&gt;files_[level]); score = static_cast&lt;double&gt;(level_bytes) / MaxBytesForLevel(options_, level); &#125; if (score &gt; best_score) &#123; best_level = level; best_score = score; &#125; &#125; v-&gt;compaction_level_ = best_level; v-&gt;compaction_score_ = best_score;&#125; TotalFileSize1234567static int64_t TotalFileSize(const std::vector&lt;FileMetaData*&gt;&amp; files) &#123; int64_t sum = 0; for (size_t i = 0; i &lt; files.size(); i++) &#123; sum += files[i]-&gt;file_size; &#125; return sum;&#125; MaxBytesForLevel123456789101112131415// 计算大于0的level层级的文件数据最大值// 第一个参数没有用到？也没见有重载的情况static double MaxBytesForLevel(const Options* options, int level) &#123; // Note: the result for level zero is not really used since we set // the level-0 compaction threshold(临界点) based on number of files. // Result for both level-0 and level-1 // level = 2开始每层*10 double result = 10. * 1048576.0; while (level &gt; 1) &#123; result *= 10; level--; &#125; return result;&#125; 这个值可以简单算下： level score_double score_LL 0 1.04858e+07 10485760 1 1.04858e+07 10485760 2 1.04858e+08 104857600 3 1.04858e+09 1048576000 4 1.04858e+10 10485760000 5 1.04858e+11 104857600000 6 1.04858e+12 1048576000000 state类保存Seek的状态信息 总结referencehttps://web.archive.org/web/20120131105110/http://rdc.taobao.com/blog/cs/wp-content/plugins/leveldb%E5%AE%9E%E7%8E%B0%E8%A7%A3%E6%9E%90.pdf http://catkang.github.io/2017/01/17/leveldb-data.html https://www.bookstack.cn/read/Leveldb-handbook/spilt.2.b308da3c3d01f3cd.md https://izualzhy.cn/leveldb-block","categories":[],"tags":[{"name":"leveldb","slug":"leveldb","permalink":"https://riverferry.site/tags/leveldb/"}],"keywords":[]},{"title":"leveldb源码分析(5) sstable文件","slug":"2021-10-27-leveldb源码分析(5) sstable文件","date":"2021-10-27T00:00:00.000Z","updated":"2022-09-12T16:24:32.293Z","comments":true,"path":"2021-10-27-leveldb源码分析(5) sstable文件/","link":"","permalink":"https://riverferry.site/2021-10-27-leveldb%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90(5)%20sstable%E6%96%87%E4%BB%B6/","excerpt":"项目有用到leveldb,打算最近看看源码，整理个系列文章，这是第5篇sstable文件。源码注释地址","text":"项目有用到leveldb,打算最近看看源码，整理个系列文章，这是第5篇sstable文件。源码注释地址 代码从上一篇的流程中可以看到这里会出现压缩的场景: 123456MakeRoomForWrite MaybeScheduleCompaction BackgroundCompaction CompactMemTable WriteLevel0Table BuildTable BuildTable中open一个新的文件名，然后执行finish 123456789101112131415161718Status TableBuilder::Finish() &#123; // 写 data_block Flush(); // 写 filter_block WriteRawBlock(r-&gt;filter_block-&gt;Finish(), kNoCompression, &amp;filter_block_handle); // 写 meta_index_block WriteBlock(&amp;meta_index_block, &amp;metaindex_block_handle); // 写 index_block WriteBlock(&amp;r-&gt;index_block, &amp;index_block_handle); // 写 footer r-&gt;status = r-&gt;file-&gt;Append(footer_encoding);&#125; WriteRawBlock/WriteBlock会调用Append写，posix下优先写buf,buf不够直接调用write写文件。 分别看看用处： BlockBuilderBlockBuilder的成员变量如下： 123456const Options* options_;std::string buffer_; // Destination bufferstd::vector&lt;uint32_t&gt; restarts_; // Restart pointsint counter_; // Number of entries emitted since restartbool finished_; // Has Finish() been called?std::string last_key_; buffer_指向的内容就是下图的第2行，其中每一个entry的格式是第一行的表示。restarts_记录了每一个前缀压缩新的开始点，最后会把这些值存入buffer_后面。其他几个字段没那么重要了。 data_blockdata_block的类型是BlockBuilder，add的kv(一个entry)是(key, value); filter_blockfilter_block的类型是FilterBlockBuilder,成员变量如下： 123456const FilterPolicy* policy_;std::string keys_; // Flattened(扁平) key contentsstd::vector&lt;size_t&gt; start_; // Starting index in keys_ of each keystd::string result_; // Filter data computed so farstd::vector&lt;Slice&gt; tmp_keys_; // policy_-&gt;CreateFilter() argumentstd::vector&lt;uint32_t&gt; filter_offsets_; keys_和start_在AddKey的时候赋值，如下: 12345void FilterBlockBuilder::AddKey(const Slice&amp; key) &#123; Slice k = key; start_.push_back(keys_.size()); keys_.append(k.data(), k.size());&#125; 看下StartBlock的实现： 12345678void FilterBlockBuilder::StartBlock(uint64_t block_offset) &#123; // kFilterBase = 2kb uint64_t filter_index = (block_offset / kFilterBase); assert(filter_index &gt;= filter_offsets_.size()); while (filter_index &gt; filter_offsets_.size()) &#123; GenerateFilter(); &#125;&#125; StartBlock被调用的地方有: TableBuilder构造函数 TableBuilder::Flush() 12345678910111213141516171819202122TableBuilder::TableBuilder(const Options&amp; options, WritableFile* file) : rep_(new Rep(options, file)) &#123; if (rep_-&gt;filter_block != nullptr) &#123; rep_-&gt;filter_block-&gt;StartBlock(0); &#125;&#125;void TableBuilder::Flush() &#123; Rep* r = rep_; assert(!r-&gt;closed); if (!ok()) return; if (r-&gt;data_block.empty()) return; assert(!r-&gt;pending_index_entry); WriteBlock(&amp;r-&gt;data_block, &amp;r-&gt;pending_handle); // data_block写到buf或文件 if (ok()) &#123; r-&gt;pending_index_entry = true; r-&gt;status = r-&gt;file-&gt;Flush(); // 缓存buf刷新到文件 &#125; if (r-&gt;filter_block != nullptr) &#123; r-&gt;filter_block-&gt;StartBlock(r-&gt;offset); // == &#125;&#125; filter_offsets_中存了每个filter的offset,每个filter记录sstable的data_block的2kb的kv的特征值(默认是bloom filter算的Bits)。所以StartBlock函数的入参拿到新的sstable中data_block的offset/2kb，如果比filter_offsets_原来的值大，就不断GenerateFilter生成新的filter,没生成一个filter_offsets_的size就加一。 看下Finish的实现: 12345678910111213141516Slice FilterBlockBuilder::Finish() &#123; if (!start_.empty()) &#123; GenerateFilter(); &#125; // Append array of per-filter offsets const uint32_t array_offset = result_.size(); for (size_t i = 0; i &lt; filter_offsets_.size(); i++) &#123; PutFixed32(&amp;result_, filter_offsets_[i]); &#125; PutFixed32(&amp;result_, array_offset); // kFilterBaseLg = 11 result_.push_back(kFilterBaseLg); // Save encoding parameter in result return Slice(result_);&#125; 注意，每执行一次GenerateFilter，keys_和start_都会clear.但filter_offsets_的值是一直在的。然后这个过程中生成的filter内容都保存在result_.最后Finish的时候filter_offsets_的值以及原来result_的size都会写到result_的后面，kFilterBaseLg=11(1 &lt;&lt; 11, 表示2kb)也会写到后面。也就是说最后Finish完就生成了一个新的filter_block。其中result_指向的内容如下： 这就是一个filter_block的内容。后面数据读取单独整理一篇再分析读取的逻辑。 meta_index_blockmeta_index_block的类型是BlockBuilder, add的kv(一个entry)是(filter.leveldb.BuiltinBloomFilter2, string(filter_block_handle)); filter_block_handle记录了filter_block的位置信息 index_blockindex_block的类型是BlockBuilder, add的kv(一个entry)是(last_key, string(pending_handle));last_key记录了data_block的最后一个key, pending_handle记录了最后一个data_block的位置信息。 last_key更新的位置: 12345void TableBuilder::Add(const Slice&amp; key, const Slice&amp; value) &#123; ... r-&gt;last_key.assign(key.data(), key.size()); ...&#125; pending_handle更新的位置： 123456789101112TableBuilder::Flush() WriteBlock(&amp;r-&gt;data_block, &amp;r-&gt;pending_handle) WriteRawBlock(block_contents, type, handle);void TableBuilder::WriteRawBlock(const Slice&amp; block_contents, CompressionType type, BlockHandle* handle) &#123;Rep* r = rep_;handle-&gt;set_offset(r-&gt;offset);// block_contents是data_block压缩后的值handle-&gt;set_size(block_contents.size());...&#125; footerFooter有2个数据成员, 记录了metaindex_handle_和index_handle_,也即meta_index_block和index_block的位置信息. 123456789101112131415161718192021// Footer encapsulates the fixed information stored at the tail// end of every table file.class Footer &#123; public: ... private: BlockHandle metaindex_handle_; BlockHandle index_handle_;&#125;;// BlockHandle is a pointer to the extent of a file that stores a data// block or a meta block.class BlockHandle &#123; public: ... private: uint64_t offset_; uint64_t size_;&#125;; referencehttps://web.archive.org/web/20120131105110/http://rdc.taobao.com/blog/cs/wp-content/plugins/leveldb%E5%AE%9E%E7%8E%B0%E8%A7%A3%E6%9E%90.pdf http://catkang.github.io/2017/01/17/leveldb-data.html https://www.bookstack.cn/read/Leveldb-handbook/spilt.2.b308da3c3d01f3cd.md https://izualzhy.cn/leveldb-block","categories":[],"tags":[{"name":"leveldb","slug":"leveldb","permalink":"https://riverferry.site/tags/leveldb/"}],"keywords":[]},{"title":"leveldb源码分析(4) memtable and log","slug":"2021-10-13-leveldb源码分析(4) memtable and log","date":"2021-10-13T00:00:00.000Z","updated":"2022-09-12T16:24:32.293Z","comments":true,"path":"2021-10-13-leveldb源码分析(4) memtable and log/","link":"","permalink":"https://riverferry.site/2021-10-13-leveldb%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90(4)%20memtable%20and%20log/","excerpt":"项目有用到leveldb,打算最近看看源码，整理个系列文章，这是第4篇memtable and log。源码注释地址","text":"项目有用到leveldb,打算最近看看源码，整理个系列文章，这是第4篇memtable and log。源码注释地址 代码细节在github fork的仓库注释了，这里主要记录下大概的流程。从put开始。 put1234567891011121314151617// slice是一个简单的c风格字符串的封装，记录了地址和大小// 用户传入的string的key和value经由slice对应的ctor进行转换Status DB::Put(const WriteOptions&amp; opt, const Slice&amp; key, const Slice&amp; value) &#123; WriteBatch batch; // ctor让rep_ resize为kHeader(12bytes = 8-seq + 4-count) batch.Put(key, value); return Write(opt, &amp;batch);&#125;void WriteBatch::Put(const Slice&amp; key, const Slice&amp; value) &#123; // 以第9个字节为起始地址，设置count(int32, 小端字节序)大小 WriteBatchInternal::SetCount(this, WriteBatchInternal::Count(this) + 1); // 第13个字节记录type, 0-&gt;delete 1-&gt;value rep_.push_back(static_cast&lt;char&gt;(kTypeValue)); PutLengthPrefixedSlice(&amp;rep_, key); // 第14个字节开始记录varint32(key的大小)+char*(key的data) PutLengthPrefixedSlice(&amp;rep_, value); // 继续在后面写入varint32(value的大小)+char*(value的data) // 至此，WriteBatch的rep_中记录了一些信息，我画个图表示下&#125; 1234567891011// write主要干了三件事Status DBImpl::Write(...) &#123; // step 1: 判断memtable还有空间没，是否需要新建memtable, 以及level-0的sstable文件个数是否达到阈值，需要慢速写/停止写, 具体在代码仓库记录 // 这里会new memtable MakeRoomForWrite(...) // step 2: 生成Log用的格式，并写入 log_-&gt;AddRecord(WriteBatchInternal::Contents(write_batch)); // step 3: 生成memtable用的格式，并写入 status = WriteBatchInternal::InsertInto(write_batch, mem_); // 2 3步下文分别梳理&#125; logAddRecord(…) 这块比较麻烦，代码里面我都注释了，这块只画个图描述下。日志是按block来处理的，代码里面一个block是32768字节，block由若干个record组成。每次put一个kv就是若干个record, 因为这里分段存储的，先看一个record的格式： 如果一个put的kv可以在block的avail剩余空间内存储，则type=kFullType, 只需要一个record: 如果block遗留空间不够，则要拆分为多个block, 可能是一个begin(1个) + middle(0-n个) + end(1个),如图： 另外需要注意的，如果一个block的剩余空间小于一个header(7个字节)，则去下一个block存储，也就是说data会被拆分到多个block, 但一个header是不能被拆分的。还有就是每次拼成一个record都会被flush刷盘。record里面的data就是rep_ ，没有再转换。 memtable1234567WriteBatchInternal::InsertInto(write_batch, mem_) Iterate(&amp;inserter) remove rep_前面13个字节 handler-&gt;Put(key, value) mem_-&gt;Add(sequence_, kTypeValue, key, value) handler-&gt;Delete(key) mem_-&gt;Add(sequence_, kTypeDeletion, key, Slice()) memtable先将数据存在heap, 然后把地址放到skiplist, 这里有一些数据结构： 12345678910111213141516171819MemTable::Add(...)&#123; // Format of an entry is concatenation of: // key_size : varint32 of internal_key.size() // key bytes : char[internal_key.size()] // value_size : varint32 of value.size() // value bytes : char[value.size()] const size_t encoded_len = VarintLength(internal_key_size) + internal_key_size + VarintLength(val_size) + val_size; arena_.Allocate(encoded_len); EncodeVarint32(buf, internal_key_size); memcpy(p, key.data(), key_size); EncodeFixed64(p, (s &lt;&lt; 8) | type); EncodeVarint32(p, val_size); memcpy(p, value.data(), val_size); table_.Insert(buf);&#125; 这里申请了一块内存，保存了key和value的值，大小是: 1234 encoded_len (key-len + key-data) + (seq) + (val-len + val-data)-&gt; (varint32 + char*) + (int64) + (varint32 + char*)-&gt; (1-5 + n) + 8 + (1-5 + n)bytes 然后把这块内存地址传给skiplist, 建立索引，这块我画个图记录下。skiplist初始化后是new了一块空间，用head_指过去，如图： 插入节点后： 12345Insert FindGreaterOrEqual // 找插入点 RandomHeight // 随机生成高度 NewNode // new heap SetNext // 完善链表 referencehttps://web.archive.org/web/20120131105110/http://rdc.taobao.com/blog/cs/wp-content/plugins/leveldb%E5%AE%9E%E7%8E%B0%E8%A7%A3%E6%9E%90.pdf","categories":[],"tags":[{"name":"leveldb","slug":"leveldb","permalink":"https://riverferry.site/tags/leveldb/"}],"keywords":[]},{"title":"leveldb源码分析(3) 内存管理 Arena","slug":"2021-10-12-leveldb源码分析(3) 内存管理 Arena","date":"2021-10-12T00:00:00.000Z","updated":"2022-09-12T16:24:32.293Z","comments":true,"path":"2021-10-12-leveldb源码分析(3) 内存管理 Arena/","link":"","permalink":"https://riverferry.site/2021-10-12-leveldb%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90(3)%20%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86%20Arena/","excerpt":"项目有用到leveldb,打算最近看看源码，整理个系列文章，这是第3篇架构内存管理Arena。前面gperftool分析结果已经显示了leveldb申请内存主要在Arena,这篇从源码角度再分析下。源码注释地址","text":"项目有用到leveldb,打算最近看看源码，整理个系列文章，这是第3篇架构内存管理Arena。前面gperftool分析结果已经显示了leveldb申请内存主要在Arena,这篇从源码角度再分析下。源码注释地址 调用关系从上篇gperftool的分析可以看到put数据的时候有2个地方申请了内存： MemTable::Add SkipList::Insert arena_.Allocate arena_-&gt;AllocateAligned 整体逻辑画了个图,后面源码具体分析 源码Arena::Allocate申请的内存小于可用大小alloc_bytes_remaining_的话，直接拿alloc_ptr_后面的，否则要重新申请： 大于kBlockSize / 4，直接申请一个新的block，指向的heap的大小就是需要的bytes 否则，申请一个新的block，指向的heap的大小是kBlockSize(当前代码是4096)。并更新alloc_ptr_和alloc_bytes_remaining_ 也就是说如果alloc_bytes_remaining_不够的话，就重新new一个空间，原来剩余的就浪费了 123456789101112131415161718192021222324252627282930313233343536373839inline char* Arena::Allocate(size_t bytes) &#123; // The semantics of what to return are a bit messy if we allow // 0-byte allocations, so we disallow them here (we don&#x27;t need // them for our internal use). assert(bytes &gt; 0); if (bytes &lt;= alloc_bytes_remaining_) &#123; char* result = alloc_ptr_; alloc_ptr_ += bytes; alloc_bytes_remaining_ -= bytes; return result; &#125; return AllocateFallback(bytes);&#125;char* Arena::AllocateFallback(size_t bytes) &#123; if (bytes &gt; kBlockSize / 4) &#123; // Object is more than a quarter of our block size. Allocate it separately // to avoid wasting too much space in leftover bytes. char* result = AllocateNewBlock(bytes); return result; &#125; // We waste the remaining space in the current block. alloc_ptr_ = AllocateNewBlock(kBlockSize); alloc_bytes_remaining_ = kBlockSize; char* result = alloc_ptr_; alloc_ptr_ += bytes; alloc_bytes_remaining_ -= bytes; return result;&#125;char* Arena::AllocateNewBlock(size_t block_bytes) &#123; char* result = new char[block_bytes]; blocks_.push_back(result); memory_usage_.fetch_add(block_bytes + sizeof(char*), std::memory_order_relaxed); return result;&#125; Arena::AllocateAligned注意AllocateFallback always returned aligned memory这句话，对应的是: Allocates size bytes of storage, suitably aligned to represent any object of that size, and returns a non-null pointer to the first byte of this block. On failure, it throws a bad_alloc exception. http://www.cplusplus.com/reference/new/operator%20new/ 也就是说new返回的是内存对齐的。如果是在原来空间上申请，需要自行对齐下，如下文。 123456789101112131415161718192021char* Arena::AllocateAligned(size_t bytes) &#123; const int align = (sizeof(void*) &gt; 8) ? sizeof(void*) : 8; static_assert((align &amp; (align - 1)) == 0, &quot;Pointer size should be a power of 2&quot;); size_t current_mod = reinterpret_cast&lt;uintptr_t&gt;(alloc_ptr_) &amp; (align - 1); size_t slop = (current_mod == 0 ? 0 : align - current_mod); // 当前alloc_ptr_距离对齐差几个字节 size_t needed = bytes + slop; char* result; if (needed &lt;= alloc_bytes_remaining_) &#123; result = alloc_ptr_ + slop; alloc_ptr_ += needed; alloc_bytes_remaining_ -= needed; &#125; else &#123; // AllocateFallback always returned aligned memory result = AllocateFallback(bytes); &#125; // 再次判断 assert((reinterpret_cast&lt;uintptr_t&gt;(result) &amp; (align - 1)) == 0); return result;&#125; 其他Arena没有实现删除合并的逻辑，本身内存池回收合并就比较麻烦，这里调用方是给memtable使用的，每个memtable删除的时候会析构整个Arena的空间，下一次新的memtable创建再重新申请。 12345Arena::~Arena() &#123; for (size_t i = 0; i &lt; blocks_.size(); i++) &#123; delete[] blocks_[i]; &#125;&#125;","categories":[],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://riverferry.site/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"leveldb","slug":"leveldb","permalink":"https://riverferry.site/tags/leveldb/"}],"keywords":[]},{"title":"leveldb源码分析(1) 编译安装","slug":"2021-10-11-leveldb源码分析(1) 编译安装","date":"2021-10-11T00:00:00.000Z","updated":"2022-09-12T16:24:32.293Z","comments":true,"path":"2021-10-11-leveldb源码分析(1) 编译安装/","link":"","permalink":"https://riverferry.site/2021-10-11-leveldb%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90(1)%20%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85/","excerpt":"项目有用到leveldb,打算最近看看源码，整理个系列文章，这是第一篇编译安装。源码注释地址","text":"项目有用到leveldb,打算最近看看源码，整理个系列文章，这是第一篇编译安装。源码注释地址 安装git clone –recurse-submodules https://github.com/google/leveldb.git yum install -y cmake 123cmake: symbol lookup error: cmake: undefined symbol: archive_write_add_filter_zstdyum install libarchive mkdir -p build &amp;&amp; cd build cmake -DCMAKE_BUILD_TYPE=Release .. &amp;&amp; cmake –build . cp libleveldb.a /usr/local/lib cp -r include/leveldb/ /usr/local/include/ 测试程序123456789101112131415161718192021222324252627282930313233343536#include &lt;cassert&gt;#include &lt;iostream&gt;#include &lt;string&gt;#include &lt;leveldb/db.h&gt;using namespace std;#define ASSERT_STATUS(status, db) \\ do&#123; \\ if (!status.ok()) \\ &#123; \\ delete db; \\ return -1; \\ &#125; \\ &#125; while (0) \\int main() &#123; leveldb::DB* db; leveldb::Options options; options.create_if_missing = true; leveldb::Status status = leveldb::DB::Open(options, &quot;/tmp/testdb&quot;, &amp;db); assert(status.ok()); std::string key = &quot;1001&quot;; std::string value = &quot;river&quot;; std::string str; status = db-&gt;Put(leveldb::WriteOptions(), key, value); ASSERT_STATUS(status, db); status = db-&gt;Get(leveldb::ReadOptions(), key, &amp;str); ASSERT_STATUS(status, db); cout &lt;&lt; &quot;get key = &quot; &lt;&lt; key &lt;&lt; &quot;, value = &quot; &lt;&lt; str &lt;&lt; endl; delete db; return 0;&#125; 12[root@dev leveldb]# .&#x2F;run get key &#x3D; 1001, value &#x3D; river 参考https://github.com/google/leveldb https://zh.wikipedia.org/wiki/LevelDB","categories":[],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://riverferry.site/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"leveldb","slug":"leveldb","permalink":"https://riverferry.site/tags/leveldb/"}],"keywords":[]},{"title":"leveldb源码分析(2) 架构与文件分析","slug":"2021-10-11-leveldb源码分析(2) 架构与文件分析","date":"2021-10-11T00:00:00.000Z","updated":"2022-09-12T16:24:32.293Z","comments":true,"path":"2021-10-11-leveldb源码分析(2) 架构与文件分析/","link":"","permalink":"https://riverferry.site/2021-10-11-leveldb%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90(2)%20%E6%9E%B6%E6%9E%84%E4%B8%8E%E6%96%87%E4%BB%B6%E5%88%86%E6%9E%90/","excerpt":"项目有用到leveldb,打算最近看看源码，整理个系列文章，这是第2篇架构与文件分析。网上找的中文资料大多数都是互相复制，年代也比较早，想找个框架图也不知道谁是作者，英文搜索发现leveldb的资料更少。所以打算主要参考github官方的介绍以及源码，然后借鉴一些网上的blog,最后自己手动画一个框架图，加深理解。源码注释地址","text":"项目有用到leveldb,打算最近看看源码，整理个系列文章，这是第2篇架构与文件分析。网上找的中文资料大多数都是互相复制，年代也比较早，想找个框架图也不知道谁是作者，英文搜索发现leveldb的资料更少。所以打算主要参考github官方的介绍以及源码，然后借鉴一些网上的blog,最后自己手动画一个框架图，加深理解。源码注释地址 11一些参数 aa bb kTargetFileSize 生成sstable的大小 write_buffer_size memtable的大小","categories":[],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://riverferry.site/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"leveldb","slug":"leveldb","permalink":"https://riverferry.site/tags/leveldb/"}],"keywords":[]},{"title":"gperftool分析leveldb内存申请","slug":"2021-10-10-gperftool分析leveldb内存申请","date":"2021-10-10T00:00:00.000Z","updated":"2022-09-12T16:24:32.293Z","comments":true,"path":"2021-10-10-gperftool分析leveldb内存申请/","link":"","permalink":"https://riverferry.site/2021-10-10-gperftool%E5%88%86%E6%9E%90leveldb%E5%86%85%E5%AD%98%E7%94%B3%E8%AF%B7/","excerpt":"总结下gperftool的使用，写了个leveldb大量写数据的demo用来测试。","text":"总结下gperftool的使用，写了个leveldb大量写数据的demo用来测试。 gperftool安装使用install libunwindgit clone &#x67;&#x69;&#x74;&#x40;&#103;&#105;&#116;&#104;&#x75;&#x62;&#46;&#x63;&#x6f;&#x6d;:libunwind/libunwind.git cd libunwind/ autoreconf -i ./configure make make install install gperftoolsgit clone https://github.com/gperftools/gperftools cd gperftools/ ./autogen.sh ./configure make make install prefix=/usr 图形化工具yum install graphviz yum install ghostscript 测试leveldb的demo1234567891011121314151617181920212223242526272829303132333435363738394041#include &lt;cassert&gt;#include &lt;iostream&gt;#include &lt;string&gt;#include &lt;leveldb/db.h&gt;#include &lt;gperftools/profiler.h&gt;using namespace std;// g++ -o run run.cpp -pthread -lleveldb -std=c++11#define ASSERT_STATUS(status, db) \\ do&#123; \\ if (!status.ok()) \\ &#123; \\ delete db; \\ return -1; \\ &#125; \\ &#125; while (0) \\int main() &#123; // ProfilerStart(&quot;/root/code/leveldb/heap.prof&quot;); leveldb::DB* db; leveldb::Options options; options.create_if_missing = true; leveldb::Status status = leveldb::DB::Open(options, &quot;/tmp/testdb&quot;, &amp;db); assert(status.ok()); for (auto k&#123;0&#125;; k &lt; 10000000; ++k) &#123; std::string key = to_string(k+600000); std::string value = &quot;river_fdsssssdddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddddd&quot; + to_string(k); status = db-&gt;Put(leveldb::WriteOptions(), key, value); ASSERT_STATUS(status, db); &#125; // cout &lt;&lt; &quot;get key = &quot; &lt;&lt; key &lt;&lt; &quot;, value = &quot; &lt;&lt; str &lt;&lt; endl; // cin.get(); delete db; // ProfilerStop(); cout &lt;&lt; &quot;ok!!!&quot; &lt;&lt; endl; return 0;&#125; 测试结果12345g++ run.cpp -std=c++11 -lleveldb -pthread -ltcmalloc -lprofiler -g -o runHEAPPROFILE=&quot;/root/code/leveldb/run&quot; ./runpprof --pdf run run.0001.heap &gt;run.pdf 参考https://github.com/gperftools/gperftools/blob/master/README https://github.com/libunwind/libunwind https://gperftools.github.io/gperftools/heapprofile.html https://www.cnblogs.com/GODYCA/archive/2013/05/28/3104281.html","categories":[],"tags":[{"name":"leveldb","slug":"leveldb","permalink":"https://riverferry.site/tags/leveldb/"},{"name":"gperftool","slug":"gperftool","permalink":"https://riverferry.site/tags/gperftool/"}],"keywords":[]},{"title":"protobuf varint and zigzag","slug":"2021-10-09-protobuf varint and zigzag","date":"2021-10-09T00:00:00.000Z","updated":"2022-09-12T16:24:32.293Z","comments":true,"path":"2021-10-09-protobuf varint and zigzag/","link":"","permalink":"https://riverferry.site/2021-10-09-protobuf%20varint%20and%20zigzag/","excerpt":"看leveldb源码的时候遇到了protobuf的varint,以前整理protobuf序列化格式的时候了解过，但没有整理过，这次从二进制和源码的角度好好梳理下","text":"看leveldb源码的时候遇到了protobuf的varint,以前整理protobuf序列化格式的时候了解过，但没有整理过，这次从二进制和源码的角度好好梳理下 Type Meaning Used For 0 Varint int32, int64, uint32, uint64, sint32, sint64, bool, enum 1 64-bit fixed64, sfixed64, double 2 Length-delimited string, bytes, embedded messages, packed repeated fields 3 Start group groups (deprecated) 4 End group groups (deprecated) 5 32-bit fixed32, sfixed32, float int32, int64, uint32, uint64, sint32, sint64, bool, enum采用Varint编码进行压缩，int32/uint32表示正数占用1-5个字节，如果用int32/int64表示负数则占用10个字节(因为int32/int64默认都是转换成了64位处理的，负数最高位非0，又因为标志位的原因需要多2个字节),tag也占用1个字节。字符串类型的是tag-len-value，没有压缩。 positive numberproto12345678syntax = &quot;proto3&quot;;package data;message Hello &#123; uint32 cmd = 1;&#125; demo123456789int main()&#123; data::Hello test; test.set_cmd(300); auto s = test.SerializeAsString(); int i = 300; return 0;&#125; output1234(gdb) x&#x2F;t s.data()0x7fffffffe440: 00000000 00000010 10101100 00001000(gdb) x&#x2F;t &amp;i0x7fffffffe46c: 00000000 00000000 00000001 00101100 analyze 12static_cast&lt;uint32_t&gt;((static_cast&lt;uint32_t&gt;(FIELD_NUMBER) &lt;&lt; 3) | (TYPE))(field_number &lt;&lt; 3) | wire_type = 0000 1000 source code12345678910111213141516171819202122232425template &lt;typename T&gt;PROTOBUF_ALWAYS_INLINE static uint8_t* UnsafeVarint(T value, uint8_t* ptr) &#123; static_assert(std::is_unsigned&lt;T&gt;::value, &quot;Varint serialization must be unsigned&quot;); ptr[0] = static_cast&lt;uint8_t&gt;(value); if (value &lt; 0x80) &#123; return ptr + 1; &#125; // Turn on continuation bit in the byte we just wrote. ptr[0] |= static_cast&lt;uint8_t&gt;(0x80); value &gt;&gt;= 7; ptr[1] = static_cast&lt;uint8_t&gt;(value); if (value &lt; 0x80) &#123; return ptr + 2; &#125; ptr += 2; do &#123; // Turn on continuation bit in the byte we just wrote. ptr[-1] |= static_cast&lt;uint8_t&gt;(0x80); value &gt;&gt;= 7; *ptr = static_cast&lt;uint8_t&gt;(value); ++ptr; &#125; while (value &gt;= 0x80); return ptr;&#125; Negative numbersint32/int64是有符号的,用来表示负数会占10个字节。所以表示负数的话尽可能用sint32/sint64,这样的话会使用zigzag编码，用正数表述负数(zigzag)然后用varint表示来节省空间。 signed original encoded as 0 0 -1 1 1 2 -2 3 2147483647 4294967294 -2147483648 4294967295 12345678910111213141516171819202122232425262728enum Type &#123; TYPE_DOUBLE = 1, // double, exactly eight bytes on the wire. TYPE_FLOAT = 2, // float, exactly four bytes on the wire. TYPE_INT64 = 3, // int64, varint on the wire. Negative numbers // take 10 bytes. Use TYPE_SINT64 if negative // values are likely. TYPE_UINT64 = 4, // uint64, varint on the wire. TYPE_INT32 = 5, // int32, varint on the wire. Negative numbers // take 10 bytes. Use TYPE_SINT32 if negative // values are likely. TYPE_FIXED64 = 6, // uint64, exactly eight bytes on the wire. TYPE_FIXED32 = 7, // uint32, exactly four bytes on the wire. TYPE_BOOL = 8, // bool, varint on the wire. TYPE_STRING = 9, // UTF-8 text. TYPE_GROUP = 10, // Tag-delimited message. Deprecated. TYPE_MESSAGE = 11, // Length-delimited message. TYPE_BYTES = 12, // Arbitrary byte array. TYPE_UINT32 = 13, // uint32, varint on the wire TYPE_ENUM = 14, // Enum, varint on the wire TYPE_SFIXED32 = 15, // int32, exactly four bytes on the wire TYPE_SFIXED64 = 16, // int64, exactly eight bytes on the wire TYPE_SINT32 = 17, // int32, ZigZag-encoded varint on the wire TYPE_SINT64 = 18, // int64, ZigZag-encoded varint on the wire MAX_TYPE = 18, // Constant useful for defining lookup tables // indexed by Type.&#125;; proto1234567message Hello &#123; optional int32 int_32 = 1; optional uint32 u_int_32 = 2; optional sint32 s_int_32 = 3; optional fixed32 f_32 = 4; optional sfixed32 sf_32 = 5;&#125; demo1234567891011121314#define OUTPUT_VALUE_AND_SIZE(TYPE, INPUT) \\ data::Hello VAR##TYPE; \\ VAR##TYPE.set_##TYPE(INPUT); \\ cout &lt;&lt; VAR##TYPE.TYPE() &lt;&lt; &quot; &quot; &lt;&lt; VAR##TYPE.SerializeAsString().length() &lt;&lt; endl; \\int main()&#123; OUTPUT_VALUE_AND_SIZE(int_32, -1); // -1 11 OUTPUT_VALUE_AND_SIZE(u_int_32, -1); // 4294967295 6 OUTPUT_VALUE_AND_SIZE(s_int_32, -1); // -1 2 OUTPUT_VALUE_AND_SIZE(f_32, -1); // 4294967295 5 OUTPUT_VALUE_AND_SIZE(sf_32, -1); // -1 5 return 0;&#125; source code12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849// 32 bitinline uint8_t* WireFormatLite::WriteInt32ToArray(int field_number, int32_t value, uint8_t* target) &#123; target = WriteTagToArray(field_number, WIRETYPE_VARINT, target); return WriteInt32NoTagToArray(value, target);&#125;inline uint8_t* WireFormatLite::WriteInt32NoTagToArray(int32_t value, uint8_t* target) &#123; return io::CodedOutputStream::WriteVarint32SignExtendedToArray(value, target);&#125;inline uint8_t* CodedOutputStream::WriteVarint32SignExtendedToArray( int32_t value, uint8_t* target) &#123; return WriteVarint64ToArray(static_cast&lt;uint64_t&gt;(value), target);&#125;// 64 bitinline uint8_t* WireFormatLite::WriteInt64ToArray(int field_number, int64_t value, uint8_t* target) &#123; target = WriteTagToArray(field_number, WIRETYPE_VARINT, target); return WriteInt64NoTagToArray(value, target);&#125;inline uint8_t* WireFormatLite::WriteInt64NoTagToArray(int64_t value, uint8_t* target) &#123; return io::CodedOutputStream::WriteVarint64ToArray( static_cast&lt;uint64_t&gt;(value), target);&#125;// sameinline uint8_t* CodedOutputStream::WriteVarint64ToArray(uint64_t value, uint8_t* target) &#123; return EpsCopyOutputStream::UnsafeVarint(value, target);&#125;inline uint32_t WireFormatLite::ZigZagEncode32(int32_t n) &#123; // Note: the right-shift must be arithmetic // Note: left shift must be unsigned because of overflow return (static_cast&lt;uint32_t&gt;(n) &lt;&lt; 1) ^ static_cast&lt;uint32_t&gt;(n &gt;&gt; 31);&#125;inline uint64_t WireFormatLite::ZigZagEncode64(int64_t n) &#123; // Note: the right-shift must be arithmetic // Note: left shift must be unsigned because of overflow return (static_cast&lt;uint64_t&gt;(n) &lt;&lt; 1) ^ static_cast&lt;uint64_t&gt;(n &gt;&gt; 63);&#125; referencehttps://developers.google.com/protocol-buffers/docs/encoding#varints protobuf编码之varint/zigzag","categories":[],"tags":[{"name":"protobuf","slug":"protobuf","permalink":"https://riverferry.site/tags/protobuf/"},{"name":"leveldb","slug":"leveldb","permalink":"https://riverferry.site/tags/leveldb/"}],"keywords":[]},{"title":"centos8虚拟机双网卡+docker配置本地环境","slug":"2021-10-06-centos8虚拟机双网卡+docker配置本地环境","date":"2021-10-06T00:00:00.000Z","updated":"2022-09-12T16:24:32.293Z","comments":true,"path":"2021-10-06-centos8虚拟机双网卡+docker配置本地环境/","link":"","permalink":"https://riverferry.site/2021-10-06-centos8%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%8F%8C%E7%BD%91%E5%8D%A1+docker%E9%85%8D%E7%BD%AE%E6%9C%AC%E5%9C%B0%E7%8E%AF%E5%A2%83/","excerpt":"最近公司网络策略变更，云服务器之间访问变得严格了，需要申请策略流程比较繁琐。所以想着在本地装一个虚拟机，用pc端的内网代理实现访问测试环境，再搞个docker把自己服务器镜像过来，配置过程还是有不少坑的，这篇文章记录下。","text":"最近公司网络策略变更，云服务器之间访问变得严格了，需要申请策略流程比较繁琐。所以想着在本地装一个虚拟机，用pc端的内网代理实现访问测试环境，再搞个docker把自己服务器镜像过来，配置过程还是有不少坑的，这篇文章记录下。 配置虚拟机环境以前个人用过vmware,但是公司环境考虑到版权问题，这个软件也没有内部license,所以只好用virtualbox。使用下来这个开源的东西确实不好用，凑活吧。 这里本地找到了一个原来下载的centos8的iso，就直接用了，网络策略使用双网卡，一个nat用来访问外网，一个host only用来本地ssh访问。一般的配置如下: 一开始安装通过光驱启动，安装完之后，启动方式改为硬盘启动。然后进去linux后，配置下网卡，/etc/sysconfig/network-scripts/里面把2个网卡的ONBOOT都改成yes,然后把host only的BOOTPROTO改成静态,便于ssh登录，参考: 1234567891011121314151617181920TYPE&#x3D;EthernetPROXY_METHOD&#x3D;noneBROWSER_ONLY&#x3D;noBOOTPROTO&#x3D;staticIPADDR&#x3D;*.*.*.*NETMASK&#x3D;255.255.255.0DNS1&#x3D;8.8.8.8DNS2&#x3D;114.114.114.114DEFROUTE&#x3D;yesIPV4_FAILURE_FATAL&#x3D;noIPV6INIT&#x3D;noIPV6_AUTOCONF&#x3D;noIPV6_DEFROUTE&#x3D;noIPV6_FAILURE_FATAL&#x3D;noIPV6_ADDR_GEN_MODE&#x3D;stable-privacyNAME&#x3D;enp0s8UUID&#x3D;*************************DEVICE&#x3D;enp0s8ONBOOT&#x3D;yesHWADDR&#x3D;*************** 由于是centos8,不能用systemctl restart network了，这里需要 123nmcli connecttion reloadnmcli device reapply enp0s8nmcli device reapply enp0s3 然后就可以本地iterm2用ssh登陆了 配置ssh加个私钥和alias用起来方便 12345678910// localssh-keygen -t rsa -C river -f localvmcat localvm.pub// remoteecho pub &gt;&gt; ~/.ssh/authorized_keys// local echo &quot;alias dev@local=&#x27;ssh -i ~/.ssh/localvm -p 22 root@0.0.0.0&#x27;&quot; &gt;&gt; ~/.zshrc 关闭图形界面: 1234567systemctl get-default// 设置为图形界面systemctl set-default graphical.target// 不开启图形界面systemctl set-default multi-user.target 配置yum源我这里没有墙，就不配源了 配置docker启动环境yum install -y yum-utils device-mapper-persistent-data lvm2 yum-config-manager –add-repo https://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo yum install docker-ce docker-ce-cli containerd.io 上面最后一步会报错Problem 1: problem with installed package podman-1.6.4-10.module_el8.2.0+305+5e198a41.x86_6，是因为centos8默认的podman会和docker冲突，这里可以选择卸载podman 1234// 参考:https://www.cnblogs.com/891288436xiaoyu/p/14092383.htmldnf remove podmanyum erase podman buildah sudo systemctl enable docker sudo systemctl start docker 123456789101112131415161718192021222324252627[root@localhost ~]# docker run --rm hello-worldUnable to find image &#x27;hello-world:latest&#x27; locallylatest: Pulling from library/hello-world2db29710123e: Pull completeDigest: sha256:9ade9cc2e26189a19c2e8854b9c8f1e14829b51c55a630ee675a5a9540ef6ccfStatus: Downloaded newer image for hello-world:latestHello from Docker!This message shows that your installation appears to be working correctly.To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the &quot;hello-world&quot; image from the Docker Hub. (amd64) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal.To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bashShare images, automate workflows, and more with a free Docker ID: https://hub.docker.com/For more examples and ideas, visit: https://docs.docker.com/get-started/ 安装容器镜像这里我是内网的仓库，具体就不记录了，记录下基本命令 docker login *** docker pull *** ok之后执行: docker run -itd ****:tagid /bin/bash docker container ls docker exec -it **** bash 大功告成 参考https://yeasy.gitbook.io/docker_practice/install/centos https://developer.aliyun.com/article/753261 https://rqsir.github.io/2019/05/23/VirtualBox-%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%BC%8F%E6%80%BB%E7%BB%93/","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://riverferry.site/tags/linux/"},{"name":"centos","slug":"centos","permalink":"https://riverferry.site/tags/centos/"}],"keywords":[]},{"title":"stl priority_queue源码分析","slug":"2021-05-24-stl priority_queue源码分析","date":"2021-09-24T00:00:00.000Z","updated":"2022-09-12T16:24:32.293Z","comments":true,"path":"2021-05-24-stl priority_queue源码分析/","link":"","permalink":"https://riverferry.site/2021-05-24-stl%20priority_queue%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/","excerpt":"分析stl sort函数的时候，发现优先级队列挺麻烦的，单独整理一篇","text":"分析stl sort函数的时候，发现优先级队列挺麻烦的，单独整理一篇 priority_queue123456#ifndef __STL_LIMITED_DEFAULT_TEMPLATEStemplate &lt;class _Tp, class _Sequence = vector&lt;_Tp&gt;, class _Compare = less&lt;typename _Sequence::value_type&gt; &gt;#elsetemplate &lt;class _Tp, class _Sequence, class _Compare&gt;#endif 看看常用的几个函数的实现： 1234567891011121314151617const_reference top() const &#123; return c.front(); &#125;void push(const value_type&amp; __x) &#123; __STL_TRY &#123; c.push_back(__x); push_heap(c.begin(), c.end(), comp); &#125; __STL_UNWIND(c.clear()); &#125;void pop() &#123;__STL_TRY &#123; pop_heap(c.begin(), c.end(), comp); c.pop_back();&#125;__STL_UNWIND(c.clear());&#125; // 不带自定义排序的版本，默认是个最大堆 push_heap这里添加新元素的方法是：从下往上堆化 先往完全二叉树的最后一个节点即随机迭代器的end()插入一个新元素，位置记为hole_index 然后逐层往上和父节点比较，如果不满足最大堆的性质就覆盖父节点(这里没有直接swap)，直到top_index也就是堆顶结束 这里传入了value是个值对象，在priority_queue::push_back(tmp)中value就是tmp,是vector的最后一个元素,在priority_queue::pop()中，value是数组原来最后的那个元素，但进到这个函数的时候最后一个元素已经被front()覆盖了，此时比堆化的是一个小数组。如下演示: 1234567891011121314151617181920212223242526272829303132// Heap-manipulation functions: push_heap, pop_heap, make_heap, sort_heap.template &lt;class _RandomAccessIterator, class _Distance, class _Tp&gt;void __push_heap(_RandomAccessIterator __first, _Distance __holeIndex, _Distance __topIndex, _Tp __value)&#123; _Distance __parent = (__holeIndex - 1) / 2; while (__holeIndex &gt; __topIndex &amp;&amp; *(__first + __parent) &lt; __value) &#123; *(__first + __holeIndex) = *(__first + __parent); __holeIndex = __parent; __parent = (__holeIndex - 1) / 2; &#125; *(__first + __holeIndex) = __value; // 这一步很重要，因为value不一定就是back()的元素&#125;template &lt;class _RandomAccessIterator, class _Distance, class _Tp&gt;inline void __push_heap_aux(_RandomAccessIterator __first, _RandomAccessIterator __last, _Distance*, _Tp*)&#123; __push_heap(__first, _Distance((__last - __first) - 1), _Distance(0), _Tp(*(__last - 1)));&#125;template &lt;class _RandomAccessIterator&gt;inline void push_heap(_RandomAccessIterator __first, _RandomAccessIterator __last)&#123; __push_heap_aux(__first, __last, __DISTANCE_TYPE(__first), __VALUE_TYPE(__first));&#125; pop_heap移除堆顶元素,这里比较复杂，一般介绍的删除堆顶的方法是: 把最后一个元素的值拷贝到堆顶 然后删除最后一个元素 在接着从堆顶往下堆化更新 但这里却不是这么实现的，简单概括下就是(按照默认的最大堆看)： 把堆顶的元素的值拷贝到最后一个元素 然后往下查找左右节点，把最大值(更新hole_index为当前的最大值的索引)拷贝到父节点(只比较左右节点，不和父节点比较) 如果一直找直到找到了最后一个节点，则把倒数第二个节点(hole_index)拷贝到父节点 push_heap插入原来被覆盖掉的尾节点back()的值，范围是从first到前面最后那个hole_index 分析：因为第一步用front()覆盖了back(),导致有2个重复的值，并且少了一个value(即原来的back()).后面一直按照com的规则，用最大值覆盖父节点，往下层走，保证上层都是符合堆化规则的。一直找到最后一层的最大值，这个最大值已经被copy然后赋值到上一层了，所以是重复存在的值，这时候相当于用value替换了这个重复的值，然后还是往上堆化. 画了个示意图： if (__secondChild == __len)这种情况需要特别处理: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647template &lt;class _RandomAccessIterator, class _Distance, class _Tp&gt;void __adjust_heap(_RandomAccessIterator __first, _Distance __holeIndex, _Distance __len, _Tp __value)&#123; _Distance __topIndex = __holeIndex; _Distance __secondChild = 2 * __holeIndex + 2; while (__secondChild &lt; __len) &#123; if (*(__first + __secondChild) &lt; *(__first + (__secondChild - 1))) // __secondChild = 孩子节点的较大值 __secondChild--; *(__first + __holeIndex) = *(__first + __secondChild); // __secondChild的值赋值给父节点__holeIndex __holeIndex = __secondChild; __secondChild = 2 * (__secondChild + 1); &#125; if (__secondChild == __len) &#123; // 碰到了最后的元素，也就是原来的堆顶元素 *(__first + __holeIndex) = *(__first + (__secondChild - 1)); __holeIndex = __secondChild - 1; &#125; __push_heap(__first, __holeIndex, __topIndex, __value); // push原来的最后那个元素&#125;template &lt;class _RandomAccessIterator, class _Tp, class _Distance&gt;inline void __pop_heap(_RandomAccessIterator __first, _RandomAccessIterator __last, _RandomAccessIterator __result, _Tp __value, _Distance*)&#123; *__result = *__first; // 用堆顶元素覆盖最后一个元素 __adjust_heap(__first, _Distance(0), _Distance(__last - __first), __value); // 传入原来最后的元素&#125;template &lt;class _RandomAccessIterator, class _Tp&gt;inline void __pop_heap_aux(_RandomAccessIterator __first, _RandomAccessIterator __last, _Tp*)&#123; __pop_heap(__first, __last - 1, __last - 1, _Tp(*(__last - 1)), __DISTANCE_TYPE(__first));&#125;template &lt;class _RandomAccessIterator&gt;inline void pop_heap(_RandomAccessIterator __first, _RandomAccessIterator __last)&#123; __pop_heap_aux(__first, __last, __VALUE_TYPE(__first));&#125; make_heap建堆，步骤： 从最后的一个非叶子节点(parent)开始往下堆化，每次用孩子节点的较大值覆盖父节点的值，一层一层往下执行 记录当前parent = old_parent 走到最后的位置是hole_index hole_index和它的now_parent是相同的值 push_heap原来的old_parent值到random_iter[old_parent : hole_index] 退一步(old_parent-1)，由底层到top,逐层一个一个执行上一步的步骤 执行到top停止 代码逻辑示例图： 直接swap交换的话逻辑会简单很多: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546template &lt;class _RandomAccessIterator, class _Distance, class _Tp&gt;void __adjust_heap(_RandomAccessIterator __first, _Distance __holeIndex, _Distance __len, _Tp __value)&#123; _Distance __topIndex = __holeIndex; _Distance __secondChild = 2 * __holeIndex + 2; while (__secondChild &lt; __len) &#123; if (*(__first + __secondChild) &lt; *(__first + (__secondChild - 1))) // __secondChild = 孩子节点的较大值 __secondChild--; *(__first + __holeIndex) = *(__first + __secondChild); // __secondChild的值赋值给父节点__holeIndex __holeIndex = __secondChild; __secondChild = 2 * (__secondChild + 1); &#125; if (__secondChild == __len) &#123; // 碰到了最后的元素，也就是原来的堆顶元素 *(__first + __holeIndex) = *(__first + (__secondChild - 1)); __holeIndex = __secondChild - 1; &#125; __push_heap(__first, __holeIndex, __topIndex, __value); // push原来的最后那个元素&#125;template &lt;class _RandomAccessIterator, class _Tp, class _Distance&gt;void __make_heap(_RandomAccessIterator __first, _RandomAccessIterator __last, _Tp*, _Distance*)&#123; if (__last - __first &lt; 2) return; // 只有一个元素 _Distance __len = __last - __first; // 元素个数 _Distance __parent = (__len - 2)/2; // 最后一个节点的父节点的距离 while (true) &#123; __adjust_heap(__first, __parent, __len, _Tp(*(__first + __parent))); if (__parent == 0) return; __parent--; &#125;&#125;template &lt;class _RandomAccessIterator&gt;inline void make_heap(_RandomAccessIterator __first, _RandomAccessIterator __last)&#123; __make_heap(__first, __last, __VALUE_TYPE(__first), __DISTANCE_TYPE(__first));&#125; time complexity时间复杂度 建堆 插入 删除 排序 O(n) O(logn) O(logn) O(nlogn) 总结 原地排序算法依赖于有序容器，快排也是原地排序(有序容器) 不稳定的排序，和快排一样 不是顺序访问，对cpu缓存不友好，这一点不如quicksort 数据交换次数多于快排","categories":[],"tags":[{"name":"c++","slug":"c","permalink":"https://riverferry.site/tags/c/"},{"name":"stl","slug":"stl","permalink":"https://riverferry.site/tags/stl/"},{"name":"算法","slug":"算法","permalink":"https://riverferry.site/tags/%E7%AE%97%E6%B3%95/"}],"keywords":[]},{"title":"mapreduce","slug":"2021-09-04-mapreduce","date":"2021-09-04T00:00:00.000Z","updated":"2022-09-12T16:24:32.293Z","comments":true,"path":"2021-09-04-mapreduce/","link":"","permalink":"https://riverferry.site/2021-09-04-mapreduce/","excerpt":"","text":"总结","categories":[],"tags":[],"keywords":[]},{"title":"一致性哈希","slug":"2021-09-03-一致性哈希","date":"2021-09-03T00:00:00.000Z","updated":"2022-09-12T16:24:32.293Z","comments":true,"path":"2021-09-03-一致性哈希/","link":"","permalink":"https://riverferry.site/2021-09-03-%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C/","excerpt":"","text":"总结","categories":[],"tags":[],"keywords":[]},{"title":"raft","slug":"2021-09-01-raft","date":"2021-09-01T00:00:00.000Z","updated":"2022-09-12T16:24:32.293Z","comments":true,"path":"2021-09-01-raft/","link":"","permalink":"https://riverferry.site/2021-09-01-raft/","excerpt":"分布式系统通过复制状态机来解决分布式的容错。对于多副本，如何保持一致性是很难的。raft作为分布式共识算法来解决一致性问题。以前有过mit的实验总结，这篇对于概念做一个总结，用自己的语言复一下论文。","text":"分布式系统通过复制状态机来解决分布式的容错。对于多副本，如何保持一致性是很难的。raft作为分布式共识算法来解决一致性问题。以前有过mit的实验总结，这篇对于概念做一个总结，用自己的语言复一下论文。 paxos的优缺点12345678910111213paxos的缺点：* 难以理解 * 单决策和多决策* 工程难以实现 * 论文缺乏细节，各种实现不一，并且没有公开对等的点对点的方式作为核心(也提议了一种弱领导人的方式提高性能)paxos算法本身被证明是正确可行的，但是工程实现遇到很多问题，需要对协议进行更改，最终导致实现的定制化的paxos的正确性没法证明了，比如chubby的实现优点：性能更好，可用性更高 raft特点raft一致性算法的特性： 安全性保证 可用性 不依赖时序保证一致性 小部分较慢的节点不会影响系统整体的性能 日志不允许有空洞(如果两个日志在某一索引位置term任期号相同，则认为从头到该索引的所有日志都相同) raft的优点： 工程实现简单 易于理解 操作的高效性 状态的数量少，考虑的情况没那么复杂 领导人选举 通过领导人保证日志的一致性，由领导人告诉节点日志条目应该放在日志中的位置，而不需要和其他节点进行商议。领导人失去连接后，新的领导人会被选出来。 节点初始状态是跟随者，只能响应领导者和候选者的rpc,如果跟随者一段时间内都没有收到消息，则会给自己的term加一，然后发起选举，争取投票，这个过程可能产生3种结果 成为领导人 每一个服务器给一个任期最多只投一张票，按照先来先服务的原则，保证同一任期内最多有1个领导人。一旦获得了多数票，则切换自己的状态为领导人，并发送附加日志的rpc心跳包(日志内容为空)来维持自己的领导，组织其他的选举发生 其他节点成为领导人 作为候选者，收到了其他节点的附加rpc请求，该节点的任期号不小于自己的节点，则承认对方为领导人，自己切换回跟随者状态。如果对方的任期号比自己的小，则拒绝，继续收集选票。 一段时间内都没有领导人选举成功 当有多个候选者收集选票的时候，选票会被瓜分，以至于没有人成功获选直至超时后大家都给任期号加1，再次尝试选举。这个过程可能一直僵持下去。 raft通过随机生成选举超时时间，来避免多个节点同时发起选举。解决这个问题。通过这种不确定性来保证算法的可理解性和正确性。 日志复制 由领导人接收客户端的日志，然后复制到集群中的其他节点，强制其他节点的日志和自己保持一致 日志由日志的索引，任期号，指令组成。领导人发送附加日志rpc给其他节点，当大多数节点都将该日志复制成功，领导人将该日志状态设为已提交，已提交的会被持久化，并保证所有节点最终都会应用该日志。已提交日志之前的所有日志也认为是已提交的。 raft维护着以下特性： 如果不同的日志中的两个日志条目拥有相同的索引号和任期号，那么他们存储了相同的指令 如果不同的日志中的两天日志条目拥有相同的索引号和任期号，那么他们前面的所有日志是相同的 第一个特性是这样保证的： 一个任期最多只会有1个领导人，所有相同任期的领导人是相同的。然后领导人只会增加日志(跟随者可能会覆盖老的日志)，不会删除修改老的日志，一个索引位置的日志是不会改变的。 第二个特性是这样保证的： 每一个附加日志rpc都会额外发送前一个日志的索引和任期号，当跟随者发现自己的prev日志的索引和任期号对不上则会拒绝接收新的日志条目，领导者需要再返回更老的日志条目来让跟随着对齐(通过领导者给每一个跟随者维护一个nextindex)。即s(n) = t(n), 且s(n-1) = t(n-1), 则[0,n]上s和t是一样的 安全性如果一个服务器节点已经应用了一个确定的日志条目到它的状态机中，那么其他的服务器节点不能在同一个日志索引位置应用一个不同的指令。 由于领导人只追加日志，不会修改删除自己的老的日志，并通过强制其他节点和自己保持一致来保证整体的一致性，所以领导人自己需要有领导人完整特性的保证，确保选举出来的领导人，拥有自己任期之前的所有已提交的日志。这需要一些特性来保证，如下： 选举限制：选举需要获得大多数节点的选票，日志的提交也需要大多数节点的确认，所以如果一个节点成功当选领导人，那么它肯定不会被拥有最新提交日志的节点拒绝。从而保证自己拥有最新的提交日志。选举的时候，候选者会在rpc中带上自己的最新的日志，跟随者/候选者会比对自身的日志，如果收到的日志比自己的旧，则不会同意当选，新的定义是： 如果任期不一样，则任期大的是新的 如果任期一样，则日志长的(日志索引更大的)是新的 领导人提交自己任期内的日志： 领导人拥有的老的任期内的日志，即使在大多数节点上保存了，也不能确保该日志是已经提交的，这里，领导人只能对自己任期内的日志通过大多数确认来提交。就是说领导人通过限制计算自己任期内的日志的大多数节点来维持的已提交状态，可以保证自己这个日志之前的所有在自己机器上的老的日志，也是已提交的(大多数写了) 成员变更如果跟随者或者候选者崩溃了，raft通过无限的重试来解决，这里raft的rpc请求保证都是幂等(全局的序列号)的，所以重试不会有问题。 集群变化这个挺复杂的，简单记录下，后面看看源码实现再分析。 首先这里存在出现2个相同任期下的不同领导人问题： 这里有个前提是lerder可以拿到新加入节点的信息，集群总数也会更新，然后这里出现问题的一种场景： s3作为old的leader(term=1),在集群新增了s4/s5后，s3宕机 然后s1通过term=2拿到了s1/s2的选票成为leader. s3恢复，用term=2拿到了S4/s5的选票成为leader s1和s3都是leader,并且term相同 论文中提到了2阶段的方案，通过共同一致来实现： old的集群拥有old的配置，比如(123) 新的集群拥有新的配置，比如(4,5) s3的配置是(123-45) s3需要同步(123-45给其他节点)，提交成功后，再提交一个(12345)给所有节点，这时候第二阶段下才是新的集群完全生效的时候，如果s3提交(12345)前失败了，对于new(45)的节点，不能单独依赖自己单一节点的大多数来选举，只有old和接收old-new的节点可以当选。 以后再补充吧 日志压缩时间久了日志太占空间了，可以对已经提交的持久化了的日志进行压缩，这个不需要领导人协调，因为已提交日志本身就是领导人确认的，这里可以通过lsm树做日志的压缩，还需要保存压缩日志最后的索引和任期号，用于后续日志的同步。如果作为领导人，有节点日志落后太多，也可以发送快照给他来同步。 客户端交互客户端随机发给一个节点，如果该节点不是领导人则会重定向到领导人，如果领导人崩溃了，则会超时，后面重新选举。 如果领导人提交了日志，但是响应客户端前崩溃了，客户端可能重新提交请求，导致新的领导人再次执行了。这里需要做幂等处理，可能的方案是用全局的序列号。 脏数据问题？对于只读的请求，领导人可能已经被废弃了，这时候可能返回脏数据给客户端，raft是这样处理的: 领导人返回只读请求前，先发一个空的提交日志给其他节点，保证自己前面的日志都被大多数节点持久化为已提交，考虑前面那个图，4任期日志前面的2只有在附加4的时候，才能保证2都被写提交。就是说领导人只能提交自己当前任期内的大多数日志，所以需要当前任期由日志写才能保证老的日志真的已提交了 第二点是返回只读请求前，领导人需要和大多数节点确认下，自己是不是最新的唯一的领导人，这个可以通过心跳包来确认(给大多数节点心跳来确认)，也可以通过租约机制？ referencehttps://github.com/maemual/raft-zh_cn/blob/master/raft-zh_cn.md","categories":[],"tags":[],"keywords":[]},{"title":"1504 Count Submatrices With All Ones","slug":"2021-06-23-1504 Count Submatrices With All Ones copy","date":"2021-06-23T00:00:00.000Z","updated":"2022-09-12T16:24:32.293Z","comments":true,"path":"2021-06-23-1504 Count Submatrices With All Ones copy/","link":"","permalink":"https://riverferry.site/2021-06-23-1504%20Count%20Submatrices%20With%20All%20Ones%20copy/","excerpt":"题目 给你一个只包含 0 和 1 的 rows * columns 矩阵 mat，请你返回有多少个子矩形的元素全部都是 1 。","text":"题目 给你一个只包含 0 和 1 的 rows * columns 矩阵 mat，请你返回有多少个子矩形的元素全部都是 1 。 1 solution动态规划算法，比较好理解，对于1d的数组，总的矩形个数是: 对于2d的数组，可以先算1d的个数，然后每次加上上一行的数组，合起来算最小宽度的新的数组的个数，这样可以涵盖所有的情况，如图: 代码如下： 12345678910111213141516171819202122232425262728293031323334353637// 1 solution 动态规划class Solution &#123;public: int numSubmat(vector&lt;vector&lt;int&gt;&gt;&amp; mat) &#123; int m = mat.size(); int n = mat[0].size(); int res = 0; for (int i = 0; i &lt; m; ++i) &#123; for (int j = 0; j &lt; n; ++j) &#123; if (mat[i][j]) mat[i][j] += j == 0 ? 0 :mat[i][j - 1]; &#125; &#125; for (int i = 0; i &lt; m; ++i) &#123; for (int j = 0; j &lt; n; ++j) &#123; if (mat[i][j] &gt; 0) &#123; res += mat[i][j]; auto small = mat[i][j]; for (int k = i - 1; k &gt;= 0 &amp;&amp; mat[k][j] &gt; 0; --k) &#123; small = min(mat[k][j], small); res += small; &#125; &#125; &#125; &#125; return res; &#125;&#125;; 时间复杂度 O(mmn) 空间复杂度 O(1) 2 solution单调栈算法，上面动态规划其实只是横向的动态规划，纵向每次都还要往上遍历包含重复的情况。而且往上有个规律就是上面宽度只能小于等于当前的宽度，这样才能构成新的矩形。这里存在单调性的情况，所以可以考虑用单调栈，但这个实现起来非常麻烦，我也是看着官方题解想了半天 可以先回顾下算柱状图中最大矩形的时候怎么用单调栈的: 12345678push i &#x3D; 0pop i &#x3D; 0, max &#x3D; 2 * 1 push i &#x3D; 1push i &#x3D; 2push i &#x3D; 3pop i &#x3D; 3, max &#x3D; 3 * 1pop i &#x3D; 2, max &#x3D; 2 * 2pop i &#x3D; 1, max &#x3D; 1 * 4 这里稍加转换可以用在本题，入栈的时候加上栈内的值的和就可以了，也就是 12push i &#x3D; 2, h[2] + h[1]push i &#x3D; 3, h[3] + h[2] + h[1] 直接这样写还是不行的，因为已经出栈i = 0, 也有一个1会被后面的使用，这是个理解的难点。因此题解里面栈内存的是pair(i, height), 也就是加了个高度。默认入栈高度为1，对于栈内元素全部出栈后接着入栈的第一个元素，高度要加上前面的pop元素的高度。说多了容易被语言困扰，看代码: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960// 2 solution 单调栈class Solution &#123;public: int numSubmat(vector&lt;vector&lt;int&gt;&gt;&amp; mat) &#123; int m = mat.size(); int n = mat[0].size(); int res = 0; vector&lt;int&gt; heights(m + 1, 0); auto addMutiRow = [&amp;m, &amp;res](vector&lt;int&gt;&amp; heights) &#123; int count = 0; // (row, high) stack&lt;pair&lt;int, int&gt;&gt; st; st.push(make_pair(0, 0)); int i = 1; int sum = 0; int high = 1; while (i &lt; m + 1) &#123; auto top = st.top(); if (heights[i] &gt;= heights[top.first]) &#123; sum += heights[i]; count += sum; st.push(make_pair(i++, high)); high = 1; &#125; else &#123; st.pop(); high += top.second; sum -= ((heights[top.first] - heights[i]) * top.second); &#125; &#125; return count; &#125;; for (int i = 0; i &lt; m; ++i) &#123; for (int j = 0; j &lt; n; ++j) &#123; if (mat[i][j]) mat[i][j] += j == 0 ? 0 :mat[i][j - 1]; &#125; &#125; for (int j = 0; j &lt; n; ++j) &#123; for (int i = 0; i &lt; m; ++i) heights[i + 1] = mat[i][j]; int num = addMutiRow(heights); res += num; &#125; return res; &#125;&#125;; 总结无意间发现了这道题，动态规划挺好理解的，单调栈看了思路后尝试自己写，结果写了半天没写出来，淦啊。然后钻牛角尖浪费了不少时间，就这样吧","categories":[],"tags":[{"name":"leetcode","slug":"leetcode","permalink":"https://riverferry.site/tags/leetcode/"}],"keywords":[]},{"title":"c++ stl 排序总结","slug":"2021-05-24-c++ stl 排序总结 ","date":"2021-05-24T00:00:00.000Z","updated":"2022-09-12T16:24:32.293Z","comments":true,"path":"2021-05-24-c++ stl 排序总结 /","link":"","permalink":"https://riverferry.site/2021-05-24-c++%20stl%20%E6%8E%92%E5%BA%8F%E6%80%BB%E7%BB%93%20/","excerpt":"条款31 中提到了这几种排序的性能优先级(时间和空间消耗)，前面的更优1 partition2 stable_partition3 nth_element4 partial_sort5 sort6 stable_sort? priority_queue(快排比堆排序好点，具体看上一篇文章)站在手写堆排序，快速选择的角度，来看看这些函数的源码是怎么实现的。","text":"条款31 中提到了这几种排序的性能优先级(时间和空间消耗)，前面的更优1 partition2 stable_partition3 nth_element4 partial_sort5 sort6 stable_sort? priority_queue(快排比堆排序好点，具体看上一篇文章)站在手写堆排序，快速选择的角度，来看看这些函数的源码是怎么实现的。 nth_element12345678910111213141516171819202122template &lt;class _RandomAccessIter&gt;inline void nth_element(_RandomAccessIter __first, _RandomAccessIter __nth, _RandomAccessIter __last) &#123; __nth_element(__first, __nth, __last, __VALUE_TYPE(__first));&#125;template &lt;class _RandomAccessIter, class _Tp&gt;void __nth_element(_RandomAccessIter __first, _RandomAccessIter __nth, _RandomAccessIter __last, _Tp*) &#123; while (__last - __first &gt; 3) &#123; _RandomAccessIter __cut = __unguarded_partition(__first, __last, _Tp(__median(*__first, *(__first + (__last - __first)/2), *(__last - 1)))); if (__cut &lt;= __nth) __first = __cut; // 缩小范围，更靠近结果 else __last = __cut; // 缩小范围，更靠近结果 &#125; __insertion_sort(__first, __last);&#125; 为了看起来方便，用的gcc 2.95.1的源码。这里有nth_element函数的重载，支持自定义比较函数，核心逻辑是一致的。就拿简单的没有自定义函数的来看。__last - __first &gt; 3的时候用快速选择，__nth_element里面while循环在重复调用__unguarded_partition,没有使用递归。 123456789101112131415161718192021222324252627282930313233343536// __median (an extension, not present in the C++ standard).template &lt;class _Tp&gt;inline const _Tp&amp; __median(const _Tp&amp; __a, const _Tp&amp; __b, const _Tp&amp; __c) &#123; if (__a &lt; __b) if (__b &lt; __c) return __b; else if (__a &lt; __c) return __c; else return __a; else if (__a &lt; __c) return __a; else if (__b &lt; __c) return __c; else return __b;&#125;template &lt;class _RandomAccessIter, class _Tp&gt;_RandomAccessIter __unguarded_partition(_RandomAccessIter __first, _RandomAccessIter __last, _Tp __pivot) &#123; while (true) &#123; while (*__first &lt; __pivot) ++__first; --__last; // 第一次进来是end() - 1, 后面的情况和++__first是对应的 while (__pivot &lt; *__last) --__last; if (!(__first &lt; __last)) return __first; iter_swap(__first, __last); // 大的放右边 小的放左边 ++__first; &#125;&#125; __median这里取的是中位数，很多地方快速排序会拿第一个或最后一个作为__pivot,无关紧要。__unguarded_partition的__pivot是值传递，因为这里会swap。然后最终都要走到插入排序__insertion_sort来收尾。因为看的是不带自定义比较函数的版本，所以这块的逻辑都是按默认的升序来的。看了下gcc 9.2.0逻辑也是差不多的，多了一种__heap_select的情况，不深究了。 这里的命名可以看出来需要传入random的iterator,这是要注意的。 新版本的带比较函数的版本有这样的注释： 1234567891011121314151617/** * @brief Sort a sequence just enough to find a particular position * using a predicate for comparison. * @ingroup sorting_algorithms * @param __first An iterator. * @param __nth Another iterator. * @param __last Another iterator. * @param __comp A comparison functor. * @return Nothing. * * Rearranges the elements in the range @p [__first,__last) so that @p *__nth * is the same element that would have been in that position had the * whole sequence been sorted. The elements either side of @p *__nth are * not completely sorted, but for any iterator @e i in the range * @p [__first,__nth) and any iterator @e j in the range @p [__nth,__last) it * holds that @p __comp(*j,*i) is false.*/ comp ([fisrt, nth), [nth, last)) = false; partition1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253template &lt;class _ForwardIter, class _Predicate&gt;_ForwardIter __partition(_ForwardIter __first, _ForwardIter __last, _Predicate __pred, forward_iterator_tag) &#123; if (__first == __last) return __first; while (__pred(*__first)) if (++__first == __last) return __first; _ForwardIter __next = __first; while (++__next != __last) if (__pred(*__next)) &#123; swap(*__first, *__next); ++__first; &#125; return __first;&#125;template &lt;class _BidirectionalIter, class _Predicate&gt;_BidirectionalIter __partition(_BidirectionalIter __first, _BidirectionalIter __last, _Predicate __pred, bidirectional_iterator_tag) &#123; while (true) &#123; while (true) if (__first == __last) return __first; else if (__pred(*__first)) ++__first; else break; --__last; while (true) if (__first == __last) return __first; else if (!__pred(*__last)) --__last; else break; iter_swap(__first, __last); ++__first; &#125;&#125;template &lt;class _ForwardIter, class _Predicate&gt;inline _ForwardIter partition(_ForwardIter __first, _ForwardIter __last, _Predicate __pred) &#123; return __partition(__first, __last, __pred, __ITERATOR_CATEGORY(__first));&#125; 这里对forward_iterator_tag和bidirectional_iterator_tag做了特化，因为is a的关系，random_access_iterator_tag也可以使用。这里特殊处理应该是有其他考虑。这里只看看单向的实现。 看了下和前面的nth_elements几乎一样的逻辑，单向的有点不同，但也好理解。nth_element强调的是在排序中的位置，partition更注重按功能分区，一次就完成了不需要多次执行缩小范围到具体的位置，并且支持的iterator的种类更多。 partial_sort同样是2个函数，一个多个自定义函数的参数，只看下默认的实现逻辑。 1234567891011121314151617181920212223242526272829303132// partial_sort, partial_sort_copy, and auxiliary functions.template &lt;class _RandomAccessIter, class _Tp&gt;void __partial_sort(_RandomAccessIter __first, _RandomAccessIter __middle, _RandomAccessIter __last, _Tp*) &#123; make_heap(__first, __middle); for (_RandomAccessIter __i = __middle; __i &lt; __last; ++__i) if (*__i &lt; *__first) __pop_heap(__first, __middle, __i, _Tp(*__i), __DISTANCE_TYPE(__first)); sort_heap(__first, __middle);&#125;template &lt;class _RandomAccessIter&gt;inline void partial_sort(_RandomAccessIter __first, _RandomAccessIter __middle, _RandomAccessIter __last) &#123; __partial_sort(__first, __middle, __last, __VALUE_TYPE(__first));&#125;// partial_sort, partial_sort_copy, and auxiliary functions.template &lt;class _RandomAccessIter, class _Tp&gt;void __partial_sort(_RandomAccessIter __first, _RandomAccessIter __middle, _RandomAccessIter __last, _Tp*) &#123; make_heap(__first, __middle); for (_RandomAccessIter __i = __middle; __i &lt; __last; ++__i) if (*__i &lt; *__first) __pop_heap(__first, __middle, __i, _Tp(*__i), __DISTANCE_TYPE(__first)); sort_heap(__first, __middle);&#125; sortpriority_queue123456#ifndef __STL_LIMITED_DEFAULT_TEMPLATEStemplate &lt;class _Tp, class _Sequence = vector&lt;_Tp&gt;, class _Compare = less&lt;typename _Sequence::value_type&gt; &gt;#elsetemplate &lt;class _Tp, class _Sequence, class _Compare&gt;#endif 前面都是函数模板，而priority_queue是一个单独的类。单独整理了一篇: stl priority_queue源码分析","categories":[],"tags":[{"name":"c++","slug":"c","permalink":"https://riverferry.site/tags/c/"},{"name":"stl","slug":"stl","permalink":"https://riverferry.site/tags/stl/"},{"name":"算法","slug":"算法","permalink":"https://riverferry.site/tags/%E7%AE%97%E6%B3%95/"}],"keywords":[]},{"title":"windows下vscode远程配置环境","slug":"2021-05-18-windows下vscode远程配置环境 copy","date":"2021-05-18T00:00:00.000Z","updated":"2022-09-12T16:24:32.292Z","comments":true,"path":"2021-05-18-windows下vscode远程配置环境 copy/","link":"","permalink":"https://riverferry.site/2021-05-18-windows%E4%B8%8Bvscode%E8%BF%9C%E7%A8%8B%E9%85%8D%E7%BD%AE%E7%8E%AF%E5%A2%83%20copy/","excerpt":"公司办公环境是mac下vscode通过ssh连接的docker编译环境，自己的win10就没配编译环境。一般简单的测试都是用在线的编译器，最近在看一些东西，感觉还是本地的方便一些，就把本地环境也搞了下。有些坑记录下，便于以后使用","text":"公司办公环境是mac下vscode通过ssh连接的docker编译环境，自己的win10就没配编译环境。一般简单的测试都是用在线的编译器，最近在看一些东西，感觉还是本地的方便一些，就把本地环境也搞了下。有些坑记录下，便于以后使用 vscode添加remote ssh 配置config~/.ssh/config里面的配置 123456# devHost 0.0.0.0User usernamePort 12345HostName 0.0.0.0IdentityFile E:&#x2F;*&#x2F;*&#x2F;rsa 注意分隔符 权限问题一直提示rsa文件权限不对，参考这里: Windows SSH: Permissions for ‘private-key’ are too open ssh port裸ssh 22端口不安全，我就改了，但是服务器厂商开了selinux,导致这里多了一步 vim /etc/ssh/sshd_config semanage port -a -t http_port_t -p tcp 8888 参考: SELinux 开放和关闭端口 结果 总结不建议直接用root用户，我懒得弄了","categories":[],"tags":[{"name":"vscode","slug":"vscode","permalink":"https://riverferry.site/tags/vscode/"}],"keywords":[]},{"title":"基数排序+计数排序+桶排序","slug":"2021-05-05-基数排序+计数排序+桶排序","date":"2021-05-05T00:00:00.000Z","updated":"2022-09-12T16:24:32.292Z","comments":true,"path":"2021-05-05-基数排序+计数排序+桶排序/","link":"","permalink":"https://riverferry.site/2021-05-05-%E5%9F%BA%E6%95%B0%E6%8E%92%E5%BA%8F+%E8%AE%A1%E6%95%B0%E6%8E%92%E5%BA%8F+%E6%A1%B6%E6%8E%92%E5%BA%8F/","excerpt":"基数排序+计数排序+桶排序梳理","text":"基数排序+计数排序+桶排序梳理 计数排序 计数排序（Counting sort）是一种稳定的线性时间排序算法。该算法于1954年由 Harold H. Seward 提出。计数排序使用一个额外的数组{\\displaystyle C} C ，其中第i个元素是待排序数组{\\displaystyle A}A中值等于{\\displaystyle i}i的元素的个数。然后根据数组{\\displaystyle C} C 来将{\\displaystyle A}A中的元素排到正确的位置。 数据量大，范围小,非比较排序 用累加数组解决稳定性问题 基数排序 基数排序（英语：Radix sort）是一种非比较型整数排序算法，其原理是将整数按位数切割成不同的数字，然后按每个位数分别比较。由于整数也可以表达字符串（比如名字或日期）和特定格式的浮点数，所以基数排序也不是只能使用于整数。 桶排序 桶排序（Bucket sort）或所谓的箱排序，是一个排序算法，工作的原理是将数组分到有限数量的桶里。每个桶再个别排序（有可能再使用别的排序算法或是以递归方式继续使用桶排序进行排序）。桶排序是鸽巢排序的一种归纳结果。当要被排序的数组内的数值是均匀分配的时候，桶排序使用线性时间。但桶排序并不是比较排序，他不受到nlogn下限的影响。 桶排序以下列程序进行： 设置一个定量的数组当作空桶子。 寻访序列，并且把项目一个一个放到对应的桶子去。 对每个不是空的桶子进行排序。 从不是空的桶子里把项目再放回原来的序列中。 拷贝一份wiki上的代码: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364#include&lt;iterator&gt;#include&lt;iostream&gt;#include&lt;vector&gt;using namespace std;const int BUCKET_NUM = 10;struct ListNode&#123; explicit ListNode(int i=0):mData(i),mNext(NULL)&#123;&#125; ListNode* mNext; int mData;&#125;;ListNode* insert(ListNode* head,int val)&#123; ListNode dummyNode; ListNode *newNode = new ListNode(val); ListNode *pre,*curr; dummyNode.mNext = head; pre = &amp;dummyNode; curr = head; while(NULL!=curr &amp;&amp; curr-&gt;mData&lt;=val)&#123; pre = curr; curr = curr-&gt;mNext; &#125; newNode-&gt;mNext = curr; pre-&gt;mNext = newNode; return dummyNode.mNext;&#125;ListNode* Merge(ListNode *head1,ListNode *head2)&#123; ListNode dummyNode; ListNode *dummy = &amp;dummyNode; while(NULL!=head1 &amp;&amp; NULL!=head2)&#123; if(head1-&gt;mData &lt;= head2-&gt;mData)&#123; dummy-&gt;mNext = head1; head1 = head1-&gt;mNext; &#125;else&#123; dummy-&gt;mNext = head2; head2 = head2-&gt;mNext; &#125; dummy = dummy-&gt;mNext; &#125; if(NULL!=head1) dummy-&gt;mNext = head1; if(NULL!=head2) dummy-&gt;mNext = head2; return dummyNode.mNext;&#125;void BucketSort(int n,int arr[])&#123; vector&lt;ListNode*&gt; buckets(BUCKET_NUM,(ListNode*)(0)); for(int i=0;i&lt;n;++i)&#123; int index = arr[i]/BUCKET_NUM; ListNode *head = buckets.at(index); buckets.at(index) = insert(head,arr[i]); &#125; ListNode *head = buckets.at(0); for(int i=1;i&lt;BUCKET_NUM;++i)&#123; head = Merge(head,buckets.at(i)); &#125; for(int i=0;i&lt;n;++i)&#123; arr[i] = head-&gt;mData; head = head-&gt;mNext; &#125;&#125; 164基数排序求解123456789101112131415161718192021222324252627282930313233343536373839404142// 基数排序class Solution &#123;public: // &#x27;nums&#x27; must consist of values from 0 to 1000000000 only int maximumGap(vector&lt;int&gt;&amp; nums) &#123; int n = nums.size(); if (n &lt; 2) return 0; vector&lt;int&gt; oVec(n); int max_num = *max_element(nums.cbegin(), nums.cend()); for (int i = 1; i &lt;= max_num; i *= 10) &#123; array&lt;int, 10&gt; count&#123;&#125;; for (int j = 0; j &lt; n; ++j) &#123; int idx = nums[j] / i % 10; count[idx]++; &#125; for (int k = 1; k &lt; 10; ++k) count[k] += count[k-1]; // 反向很重要，保持稳定性，这样排百位的时候个位也是有序的 for (int j = n - 1; j &gt;= 0; --j) &#123; int idx = nums[j] / i % 10; oVec[count[idx] - 1] = nums[j]; count[idx]--; &#125; nums.swap(oVec); &#125; int ans = 0; for (int i = 1; i &lt; n; ++i) ans = max(nums[i] - nums[i-1], ans); return ans; &#125;&#125;; 桶排序求解计算桶的长度： 1l &#x3D; max(1, ((max_num - min_num) &#x2F; (n - 1))) 这里算的是非负整数，长度至少为1。长度这么取也是有道理的： 数组里面每2个数之间的差值都 &gt;= (max_num - min_num) / (n - 1)),可以证明: 12345678假定数组里面每2个数的差值都&lt; (max_num - min_num) &#x2F; (n - 1)),一共有n个数，故可知：num(n) - num(n-1) + num(n-1) - num(n-2) ... + num(2) - num(1)&#x3D; num(n) - num(1) num(n) - num(1) &lt; (n-1)*(max_num - min_num) &#x2F; (n - 1))num(n) - num(1) &lt; max_num - min_num这显然不合理，所以就是说数组中必然存在2数之间差值大于(max_num - min_num) &#x2F; (n - 1)的，而(max_num - min_num) &#x2F; (n - 1)指的是桶的长度，所以说数组中必然存在相邻2数之间差值大于桶长度l的，也就是存在相邻的2个数跨相邻(相邻中间也可能存在空的桶)的桶。这个数必然大于一个桶内的2个数的差值，所以只需要记录每个桶的最大值和最小值，最后计算&quot;相邻&quot;桶的最大值和最小值的差值来找最大值就是结果。 计算桶的个数： 1((max_num - min_num) &#x2F; l ) + 1 因为是左开右闭区间，加1保证最大值在一个桶内 计算一个输入值对应桶的索引: 1(num - min_num) &#x2F; l 因为是左开右闭区间，数组又是从0开始的 123456789101112131415161718192021222324252627282930313233343536// 桶排序class Solution &#123;public: int maximumGap(vector&lt;int&gt;&amp; nums) &#123; int n = nums.size(); if (n &lt; 2) return 0; int max_num = *max_element(nums.begin(), nums.end()); int min_num = *min_element(nums.begin(), nums.end()); int bl = max(1, (max_num - min_num) / (n - 1)); int bc = (max_num - min_num) / bl + 1; // 本题的数的取值范围是 // nums&#x27; must consist of values from 0 to 1000000000 only vector&lt;pair&lt;int, int&gt;&gt; bucket(bc, &#123;INT_MAX, INT_MIN&#125;); int ans = 0; for (const auto&amp; num : nums) &#123; int idx = (num - min_num) / bl; bucket[idx].first = min(bucket[idx].first, num); bucket[idx].second = max(bucket[idx].second, num); &#125; int prev_second = INT_MIN; for (int i = 0; i &lt; bc; ++i) &#123; if (prev_second != INT_MIN &amp;&amp; bucket[i].first != INT_MAX) ans = max(ans, bucket[i].first - prev_second); if (bucket[i].second != INT_MIN) prev_second = bucket[i].second; &#125; return ans; &#125;&#125;; referenceleetcode 164 https://zh.wikipedia.org/wiki/%E6%A1%B6%E6%8E%92%E5%BA%8F","categories":[],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://riverferry.site/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"keywords":[]},{"title":"并查集","slug":"2021-05-04-并查集","date":"2021-05-04T00:00:00.000Z","updated":"2022-09-12T16:24:32.292Z","comments":true,"path":"2021-05-04-并查集/","link":"","permalink":"https://riverferry.site/2021-05-04-%E5%B9%B6%E6%9F%A5%E9%9B%86/","excerpt":"在计算机科学中，并查集（英文：Disjoint-set data structure，直译为不交集数据结构）是一种数据结构，用于处理一些不交集（Disjoint sets，一系列没有重复元素的集合）的合并及查询问题。并查集支持如下操作：查询：查询某个元素属于哪个集合，通常是返回集合内的一个“代表元素”。这个操作是为了判断两个元素是否在同一个集合之中。合并：将两个集合合并为一个。添加：添加一个新集合，其中有一个新元素。添加操作不如查询和合并操作重要，常常被忽略。由于支持查询和合并这两种操作，并查集在英文中也被称为联合-查找数据结构（Union-find data structure）或者合并-查找集合（Merge-find set）。","text":"在计算机科学中，并查集（英文：Disjoint-set data structure，直译为不交集数据结构）是一种数据结构，用于处理一些不交集（Disjoint sets，一系列没有重复元素的集合）的合并及查询问题。并查集支持如下操作：查询：查询某个元素属于哪个集合，通常是返回集合内的一个“代表元素”。这个操作是为了判断两个元素是否在同一个集合之中。合并：将两个集合合并为一个。添加：添加一个新集合，其中有一个新元素。添加操作不如查询和合并操作重要，常常被忽略。由于支持查询和合并这两种操作，并查集在英文中也被称为联合-查找数据结构（Union-find data structure）或者合并-查找集合（Merge-find set）。 code1234567891011121314151617181920212223242526272829303132333435363738394041424344class unionFindSet&#123;public: unionFindSet(int n):parents_(n, 0), ranks_(n, 0) &#123; for (int i = 0; i &lt; parents_.size(); ++i) parents_[i] = i; &#125; int find(int i) &#123; // path compression if (parents_[i] != i) parents_[i] = find(parents_[i]); return parents_[i]; &#125; bool unionTwo(int x, int y) &#123; // merge auto px = find(x); auto py = find(y); if (px == py) return false; if (ranks_[px] &lt; ranks_[py]) parents_[px] = py; else if (ranks_[px] &gt; ranks_[py]) parents_[py] = px; else &#123; parents_[px] = py; ranks_[py]++; &#125; return true; &#125;private: vector&lt;int&gt; parents_; vector&lt;int&gt; ranks_;&#125;; 737123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133// dfs// class Solution &#123;// public:// bool areSentencesSimilarTwo(vector&lt;string&gt;&amp; sentence1, vector&lt;string&gt;&amp; sentence2, vector&lt;vector&lt;string&gt;&gt;&amp; similarPairs) &#123;// int n1 = sentence1.size();// int n2 = sentence2.size();// if (n1 != n2)// return false;// unordered_map&lt;string, unordered_set&lt;string&gt;&gt; simiMap;// for (const auto&amp; p : similarPairs)// &#123;// // 对称性// simiMap[p.front()].insert(p.back());// simiMap[p.back()].insert(p.front());// &#125;// for (int i = 0; i &lt; n1; ++i)// &#123;// const auto&amp; s1 = sentence1[i];// const auto&amp; s2 = sentence2[i];// // 自身// if (s1 == s2)// continue;// unordered_set&lt;string&gt; visited;// if (!arewordsSimilarTwo(s1, s2, simiMap, visited))// return false;// &#125;// return true;// &#125;// // dfs// bool arewordsSimilarTwo(const string&amp; s1, const string&amp; s2, unordered_map&lt;string, unordered_set&lt;string&gt;&gt;&amp; simiMap, unordered_set&lt;string&gt;&amp; visited)// &#123;// if (s1 == s2)// return true;// visited.insert(s1);// for (const auto&amp; s : simiMap[s1])// &#123;// if (visited.count(s))// continue;// auto ret = arewordsSimilarTwo(s, s2, simiMap, visited);// if (ret)// return true;// &#125;// return false;// &#125;// &#125;;// ufsclass unionFindSet&#123;public: string find(const string&amp; s) &#123; if (!parents_.count(s)) parents_.emplace(s, s); if (parents_[s] != s) parents_[s] = find(parents_[s]); return parents_[s]; &#125; bool unionTwo(const string&amp; s1, const string&amp; s2) &#123; auto p1 = find(s1); auto p2 = find(s2); if (p1 == p2) return false; if (ranks_[p1] &lt; ranks_[p2]) &#123; parents_[p1] = p2; &#125; else if (ranks_[p1] &gt; ranks_[p2]) &#123; parents_[p2] = p1; &#125; else &#123; parents_[p1] = p2; ranks_[p2]++; &#125; return true; &#125;private: unordered_map&lt;string, string&gt; parents_; unordered_map&lt;string, int&gt; ranks_;&#125;;class Solution &#123;public: bool areSentencesSimilarTwo(vector&lt;string&gt;&amp; sentence1, vector&lt;string&gt;&amp; sentence2, vector&lt;vector&lt;string&gt;&gt;&amp; similarPairs) &#123; int n1 = sentence1.size(); int n2 = sentence2.size(); if (n1 != n2) return false; unionFindSet ufs; for (const auto&amp; p : similarPairs) &#123; ufs.unionTwo(p.front(), p.back()); &#125; for (int i = 0; i &lt; n1; ++i) &#123; const auto&amp; s1 = sentence1[i]; const auto&amp; s2 = sentence2[i]; if (s1 == s2) continue; auto p1 = ufs.find(s1); auto p2 = ufs.find(s2); if (p1 != p2) return false; &#125; return true; &#125;&#125;; 68412345678910111213141516class Solution &#123;public: vector&lt;int&gt; findRedundantConnection(vector&lt;vector&lt;int&gt;&gt;&amp; edges) &#123; if (edges.empty()) return &#123;&#125;; unionFindSet ufs(edges.size() + 1); for (const auto edge : edges) &#123; if (!ufs.unionTwo(edge.front(), edge.back())) return edge; &#125; return &#123;&#125;; &#125;&#125;; 5471234567891011121314151617181920212223class Solution &#123;public: int findCircleNum(vector&lt;vector&lt;int&gt;&gt;&amp; isConnected) &#123; if (isConnected.empty()) return 0; unionFindSet ufs(isConnected.size()); for (int i = 0; i &lt; isConnected.size(); ++i) &#123; for (int j = 1; j &lt; isConnected[0].size(); ++j) &#123; if (isConnected[i][j]) ufs.unionTwo(i, j); &#125; &#125; unordered_set&lt;int&gt; oSet; for (int i = 0; i &lt; isConnected.size(); ++i) oSet.insert(ufs.find(i)); return oSet.size(); &#125;&#125;; 399 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100class unionFindSet&#123;public: bool exist(const string&amp; s) &#123; return parents_.count(s); &#125; pair&lt;string, double&gt; find(const string&amp; s) &#123; // 初始化单个节点 if (!parents_.count(s)) parents_.emplace(s, pair&lt;string, double&gt;&#123;s, 1.0&#125;); // path compression if (parents_[s].first != s) &#123; auto p = find(parents_[s].first); parents_[s].first = p.first; parents_[s].second *= p.second; &#125; return parents_[s]; &#125; // x/y = val bool unionTwo(const string&amp; x, const string&amp; y, double val) &#123; // merge const auto&amp; [px, vx] = find(x); const auto&amp; [py, vy] = find(y); if (px == py) return false; if (ranks_[px] &lt; ranks_[py]) &#123; parents_[px] = make_pair(py, val * vy / vx); &#125; else if (ranks_[px] &gt; ranks_[py]) parents_[py] = make_pair(px, vx / val / vy); else &#123; // px/py = ? // x / px = vx // y / py = vy // x / y = val // vx * ? = val * vy parents_[px] = make_pair(py, val * vy / vx); ranks_[py]++; &#125; return true; &#125;private: unordered_map&lt;string, pair&lt;string, double&gt;&gt; parents_; unordered_map&lt;string, int&gt; ranks_;&#125;;// 根据题目可知，除法的传递是需要支持的// 自身的除法也要支持(equations中存在的元素)// 反向的除法也要支持class Solution &#123;public: vector&lt;double&gt; calcEquation(vector&lt;vector&lt;string&gt;&gt;&amp; equations, vector&lt;double&gt;&amp; values, vector&lt;vector&lt;string&gt;&gt;&amp; queries) &#123; unionFindSet ufs; for (int i = 0; i &lt; equations.size(); ++i) &#123; ufs.unionTwo(equations[i].front(), equations[i].back(), values[i]); &#125; vector&lt;double&gt; ans; for (const auto&amp; it: queries) &#123; auto a = it.front(); auto b = it.back(); if (!ufs.exist(a) || !ufs.exist(b)) ans.push_back(-1.0); else &#123; const auto&amp; [pa, va] = ufs.find(a); const auto&amp; [pb, vb] = ufs.find(b); if (pa != pb) ans.push_back(-1.0); else &#123; // pa == pb // a / b = ? // a / pa * pa / b // a / pa / b / pa // va / vb ans.push_back(va / vb); &#125; &#125; &#125; return ans; &#125;&#125;; 6851 8391 referenceleetcode 737 leetcode 684 leetcode 547 leetcode 399 leetcode 685 leetcode 839 https://www.youtube.com/watch?v=VJnUwsE4fWA","categories":[],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://riverferry.site/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"keywords":[]},{"title":"矩阵快速幂","slug":"2021-05-03-矩阵快速幂","date":"2021-05-03T00:00:00.000Z","updated":"2022-09-12T16:24:32.292Z","comments":true,"path":"2021-05-03-矩阵快速幂/","link":"","permalink":"https://riverferry.site/2021-05-03-%E7%9F%A9%E9%98%B5%E5%BF%AB%E9%80%9F%E5%B9%82/","excerpt":"todo","text":"todo","categories":[],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://riverferry.site/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"keywords":[]},{"title":"树状数组","slug":"2021-05-02-树状数组","date":"2021-05-02T00:00:00.000Z","updated":"2022-09-12T16:24:32.292Z","comments":true,"path":"2021-05-02-树状数组/","link":"","permalink":"https://riverferry.site/2021-05-02-%E6%A0%91%E7%8A%B6%E6%95%B0%E7%BB%84/","excerpt":"树状数组或二元索引树（英语：Binary Indexed Tree），又以其发明者命名为Fenwick树.按照Peter M. Fenwick的说法，正如所有的整数都可以表示成2的幂和，我们也可以把一串序列表示成一系列子序列的和。采用这个想法，我们可将一个前缀和划分成多个子序列的和，而划分的方法与数的2的幂和具有极其相似的方式。一方面，子序列的个数是其二进制表示中1的个数，另一方面，子序列代表的f[i]的个数也是2的幂","text":"树状数组或二元索引树（英语：Binary Indexed Tree），又以其发明者命名为Fenwick树.按照Peter M. Fenwick的说法，正如所有的整数都可以表示成2的幂和，我们也可以把一串序列表示成一系列子序列的和。采用这个想法，我们可将一个前缀和划分成多个子序列的和，而划分的方法与数的2的幂和具有极其相似的方式。一方面，子序列的个数是其二进制表示中1的个数，另一方面，子序列代表的f[i]的个数也是2的幂 code1234567891011121314151617181920212223242526272829class fenwickTree&#123;public: fenwickTree(int size):sums_(size, 0)&#123;&#125;; // n + 1 void update(int index, int delta) &#123; while (index &lt; sums_.size()) &#123; sums_[index] += delta; index += lowBit(index); &#125; &#125; int query(int index) &#123; int res = 0; while (index &gt; 0) &#123; res += sums_[index]; index -= lowBit(index); &#125; return res; &#125;private: static inline int lowBit(int i) &#123; return i &amp; (-i); &#125; vector&lt;int&gt; sums_;&#125;; 307 solution12345678910111213141516171819202122class NumArray &#123;public: NumArray(vector&lt;int&gt;&amp; nums):nums_(move(nums)), tree_(nums_.size() + 1)&#123; // index start from 1 for (int i = 0; i &lt; nums_.size(); ++i) tree_.update(i + 1, nums_[i]); &#125; void update(int index, int val) &#123; tree_.update(index + 1, val - nums_[index]); nums_[index] = val; &#125; int sumRange(int left, int right) &#123; return tree_.query(right + 1) - tree_.query(left); &#125;private: vector&lt;int&gt; nums_; fenwickTree tree_;&#125;; 315 solution123456789101112131415161718192021222324// 5 2 6 1 -&gt; 2 1 1 0// 1 6 2 5 -&gt; 0 1 1 2// 1 2 5 6class Solution &#123;public: vector&lt;int&gt; countSmaller(vector&lt;int&gt;&amp; nums) &#123; set&lt;int&gt; oSet(nums.cbegin(), nums.cend()); unordered_map&lt;int, int&gt; ranks; int i = 0; // 树状数组是从1开始的 for (const auto&amp; num : oSet) ranks[num] = ++i; vector&lt;int&gt; ans; fenwickTree tree(oSet.size() + 1); for (auto it = nums.rbegin(); it != nums.rend(); ++it) &#123; ans.push_back(tree.query(ranks[*it] - 1)); tree.update(ranks[*it], 1); &#125; return &#123;ans.crbegin(), ans.crend()&#125;; &#125;&#125;; referencehttps://www.youtube.com/watch?v=WbafSgetDDk leetcode307 leetcode315","categories":[],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://riverferry.site/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"keywords":[]},{"title":"线段树 segm tree","slug":"2021-05-01-线段树","date":"2021-05-01T00:00:00.000Z","updated":"2022-09-12T16:24:32.292Z","comments":true,"path":"2021-05-01-线段树/","link":"","permalink":"https://riverferry.site/2021-05-01-%E7%BA%BF%E6%AE%B5%E6%A0%91/","excerpt":"线段树（英语：Segment tree）是一种二叉树形数据结构，1977年由Jon Louis Bentley发明，用以存储区间或线段，并且允许快速查询结构内包含某一点的所有区间。一个包含n个区间的线段树，空间复杂度为O(n)，查询的时间复杂度则为O(logn + k)，其中k是符合条件的区间数量。","text":"线段树（英语：Segment tree）是一种二叉树形数据结构，1977年由Jon Louis Bentley发明，用以存储区间或线段，并且允许快速查询结构内包含某一点的所有区间。一个包含n个区间的线段树，空间复杂度为O(n)，查询的时间复杂度则为O(logn + k)，其中k是符合条件的区间数量。 code123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104typedef struct SEGMENT_NODE&#123; int start; int end; int sum; // can be max/min SEGMENT_NODE* left; SEGMENT_NODE* right; SEGMENT_NODE(int input_start = 0, int input_end = 0, int input_sum = 0, SEGMENT_NODE* input_left = nullptr, SEGMENT_NODE* input_right = nullptr): start(input_start), end(input_end), sum(input_sum), left(input_left), right(input_right)&#123;&#125;; ~SEGMENT_NODE() &#123; delete left; delete right; left = right = nullptr; &#125;;&#125; segmentNode;class segmentTree&#123; private: unique_ptr&lt;segmentNode&gt; root_; segmentNode* buildTree(int start, int end, vector&lt;int&gt;&amp; nums); void updateTree(segmentNode* node, int index, int value); int querySum(segmentNode* node, int start, int end); public: explicit segmentTree(vector&lt;int&gt;&amp; nums) &#123; if (!nums.empty()) root_.reset(buildTree(0, nums.size() - 1, nums)); &#125;; void updateTree(int index, int value); int querySum(int start, int end);&#125;;segmentNode* segmentTree::buildTree(int start, int end, vector&lt;int&gt;&amp; nums)&#123; if (start == end) return new segmentNode(start, end, nums[start]); auto mid = start + (end - start) / 2; auto left = buildTree(start, mid, nums); auto right = buildTree(mid + 1, end, nums); return new segmentNode(start, end, left-&gt;sum + right-&gt;sum, left, right);&#125;void segmentTree::updateTree(int index, int value)&#123; updateTree(root_.get(), index, value);&#125;void segmentTree::updateTree(segmentNode* node, int index, int value)&#123; if (node == nullptr) return; if (index == node-&gt;start &amp;&amp; index == node-&gt;end) &#123; node-&gt;sum = value; return; &#125; auto mid = node-&gt;start + (node-&gt;end - node-&gt;start) / 2; if (index &lt;= mid) updateTree(node-&gt;left, index, value); else updateTree(node-&gt;right, index, value); node-&gt;sum = (node-&gt;left != nullptr ? node-&gt;left-&gt;sum : 0) + (node-&gt;right != nullptr ? node-&gt;right-&gt;sum : 0); return;&#125;int segmentTree::querySum(int start, int end)&#123; if (root_ == nullptr || start &gt; end || start &lt; 0 || end &gt; root_-&gt;end) return 0; return querySum(root_.get(), start, end);&#125;int segmentTree::querySum(segmentNode* node, int start, int end)&#123; if (node == nullptr) return 0; if (start == node-&gt;start &amp;&amp; end == node-&gt;end) return node-&gt;sum; auto mid = node-&gt;start + (node-&gt;end - node-&gt;start) / 2; if (end &lt;= mid) return querySum(node-&gt;left, start, end); else if (start &gt; mid) return querySum(node-&gt;right, start, end); else return querySum(node-&gt;left, start, mid) + querySum(node-&gt;right, mid + 1, end);&#125; 307 solution12345678910111213141516class NumArray &#123;public: NumArray(vector&lt;int&gt;&amp; nums):segTree_(nums) &#123; &#125; void update(int index, int val) &#123; segTree_.updateTree(index, val); &#125; int sumRange(int left, int right) &#123; return segTree_.querySum(left, right); &#125;private: segmentTree segTree_;&#125;; referencehttps://www.youtube.com/watch?v=rYBtViWXYeI leetcode307","categories":[],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://riverferry.site/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"keywords":[]},{"title":"when goroutine quit","slug":"2021-03-17-when-goroutine-quit","date":"2021-03-17T00:00:00.000Z","updated":"2022-09-12T16:24:32.292Z","comments":true,"path":"2021-03-17-when-goroutine-quit/","link":"","permalink":"https://riverferry.site/2021-03-17-when-goroutine-quit/","excerpt":"","text":"demo1234567891011121314151617181920212223242526272829303132333435363738394041func main() &#123; defer func() &#123; fmt.Println(&quot;main defer&quot;) &#125;() go func() &#123; defer fmt.Println(&quot;one defer&quot;) go func() &#123; defer fmt.Println(&quot;two defer&quot;) f2, err := os.OpenFile(&quot;log2&quot;, os.O_WRONLY|os.O_CREATE, 0666) if err != nil &#123; panic(&quot;open err&quot;) &#125; write := bufio.NewWriter(f2) defer f2.Close() for &#123; write.WriteString(&quot;two here\\n&quot;) write.Flush() time.Sleep(2 * time.Second) &#125; &#125;() f1, err := os.OpenFile(&quot;log1&quot;, os.O_WRONLY|os.O_CREATE, 0666) if err != nil &#123; panic(&quot;open err&quot;) &#125; write := bufio.NewWriter(f1) defer f1.Close() for i := 1; i &lt; 3; i++ &#123; write.WriteString(&quot;one here\\n&quot;) write.Flush() time.Sleep(1 * time.Second) &#125; &#125;() time.Sleep(10 * time.Second) fmt.Println(&quot;main exit&quot;)&#125; output123one defermain exitmain defer log112one hereone here log212345two heretwo heretwo heretwo heretwo here conclusions main routine quit, all other routine quit a routine(not main) quit, child routine unaffected use channel/context to exit other routine","categories":[],"tags":[{"name":"golang","slug":"golang","permalink":"https://riverferry.site/tags/golang/"}],"keywords":[]},{"title":"2A raft leader election","slug":"2021-03-10-2A raft leader election","date":"2021-03-10T00:00:00.000Z","updated":"2022-09-12T16:24:32.292Z","comments":true,"path":"2021-03-10-2A raft leader election/","link":"","permalink":"https://riverferry.site/2021-03-10-2A%20raft%20leader%20election/","excerpt":"","text":"2A Introduction Part 2A Implement Raft leader election and heartbeats (AppendEntries RPCs with no log entries). The goal for Part 2A is for a single leader to be elected, for the leader to remain the leader if there are no failures, and for a new leader to take over if the old leader fails or if packets to/from the old leader are lost. Run go test -run 2A -race to test your 2A code. You can’t easily run your Raft implementation directly; instead you should run it by way of the tester, i.e. go test -run 2A -race.Follow the paper’s Figure 2. At this point you care about sending and receiving RequestVote RPCs, the Rules for Servers that relate to elections, and the State related to leader election,Add the Figure 2 state for leader election to the Raft struct in raft.go. You’ll also need to define a struct to hold information about each log entry.Fill in the RequestVoteArgs and RequestVoteReply structs. Modify Make() to create a background goroutine that will kick off leader election periodically by sending out RequestVote RPCs when it hasn’t heard from another peer for a while. This way a peer will learn who is the leader, if there is already a leader, or become the leader itself. Implement the RequestVote() RPC handler so that servers will vote for one another.To implement heartbeats, define an AppendEntries RPC struct (though you may not need all the arguments yet), and have the leader send them out periodically. Write an AppendEntries RPC handler method that resets the election timeout so that other servers don’t step forward as leaders when one has already been elected.Make sure the election timeouts in different peers don’t always fire at the same time, or else all peers will vote only for themselves and no one will become the leader.The tester requires that the leader send heartbeat RPCs no more than ten times per second.The tester requires your Raft to elect a new leader within five seconds of the failure of the old leader (if a majority of peers can still communicate). Remember, however, that leader election may require multiple rounds in case of a split vote (which can happen if packets are lost or if candidates unluckily choose the same random backoff times). You must pick election timeouts (and thus heartbeat intervals) that are short enough that it’s very likely that an election will complete in less than five seconds even if it requires multiple rounds.The paper’s Section 5.2 mentions election timeouts in the range of 150 to 300 milliseconds. Such a range only makes sense if the leader sends heartbeats considerably more often than once per 150 milliseconds. Because the tester limits you to 10 heartbeats per second, you will have to use an election timeout larger than the paper’s 150 to 300 milliseconds, but not too large, because then you may fail to elect a leader within five seconds.You may find Go’s rand useful.You’ll need to write code that takes actions periodically or after delays in time. The easiest way to do this is to create a goroutine with a loop that calls time.Sleep(); (see the ticker() goroutine that Make() creates for this purpose). Don’t use Go’s time.Timer or time.Ticker, which are difficult to use correctly.The Guidance page has some tips on how to develop and debug your code.If your code has trouble passing the tests, read the paper’s Figure 2 again; the full logic for leader election is spread over multiple parts of the figure.Don’t forget to implement GetState().The tester calls your Raft’s rf.Kill() when it is permanently shutting down an instance. You can check whether Kill() has been called using rf.killed(). You may want to do this in all loops, to avoid having dead Raft instances print confusing messages.Go RPC sends only struct fields whose names start with capital letters. Sub-structures must also have capitalized field names (e.g. fields of log records in an array). The labgob package will warn you about this; don’t ignore the warnings. My CodeMake1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677//// the service or tester wants to create a Raft server. the ports// of all the Raft servers (including this one) are in peers[]. this// server&#x27;s port is peers[me]. all the servers&#x27; peers[] arrays// have the same order. persister is a place for this server to// save its persistent state, and also initially holds the most// recent saved state, if any. applyCh is a channel on which the// tester or service expects Raft to send ApplyMsg messages.// Make() must return quickly, so it should start goroutines// for any long-running work.//// todo add contextfunc Make(peers []*labrpc.ClientEnd, me int, persister *Persister, applyCh chan ApplyMsg) *Raft &#123; log.Println(&quot;begin make.., me &quot;, me) rf := &amp;Raft&#123;&#125; rf.peers = peers rf.persister = persister rf.me = me rf.hasLeader = false rf.refreshCh = make(chan struct&#123;&#125;) rf.heartCh = make(chan struct&#123;&#125;) // Your initialization code here (2A, 2B, 2C). go func() &#123; for &#123; // rand time 300-400 ms rand.Seed(time.Now().UTC().UnixNano()) randtime := rand.Intn(100) + 300 timeout := time.After(time.Duration(randtime) * time.Millisecond) select &#123; // update log or leader // case ch := &lt;-applyCh: // &#123; // if ch.CommandValid == true &#123; // rf.lastApplied = ch.CommandIndex // &#125; // &#125; // refresh timeout case &lt;-rf.refreshCh: // begin elect case &lt;-timeout: &#123; if rf.killed() &#123; return &#125; go rf.startElection(me) &#125; // begin heartbeat case &lt;-rf.heartCh: &#123; if rf.killed() &#123; return &#125; // The tester requires that the leader send heartbeat RPCs no more than ten times per second. for num, _ := range peers &#123; // heartbeat if num != me &#123; go rf.heartBeatOne(num) &#125; &#125; &#125; &#125; &#125; &#125;() // initialize from state persisted before a crash rf.readPersist(persister.ReadRaftState()) return rf&#125; startElection123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566func (rf *Raft) startElection(me int) &#123; var count int = len(rf.peers) // become candidater log.Println(&quot;me become candidater &quot;, me) rf.mu.Lock() rf.hasLeader = false rf.currentTerm++ rf.votenum = 1 rf.isLeader = false rf.mu.Unlock() for num, _ := range rf.peers &#123; if num != me &#123; var args RequestVoteArgs var reply RequestVoteReply rf.mu.Lock() // already has leader if rf.hasLeader == true &#123; log.Println(&quot;break elect, hasleader, who = &quot;, me) rf.mu.Unlock() break &#125; args.Term = rf.currentTerm args.CandidateId = me lognum := len(rf.log) if lognum &gt; 0 &#123; args.LastLogIndex = rf.log[lognum-1].Index args.LastLogTerm = rf.log[lognum-1].Term &#125; rf.mu.Unlock() go func(server int) &#123; ret := rf.sendRequestVote(server, &amp;args, &amp;reply) if ret != true &#123; return &#125; rf.mu.Lock() defer rf.mu.Unlock() // become follower if reply.Term &gt; rf.currentTerm &#123; log.Println(&quot;me become follower &quot;, me) rf.isLeader = false return &#125; if reply.VoteGranted == true &#123; rf.votenum++ &#125; log.Println(&quot;votenum count/2 me &quot;, rf.votenum, count/2, me) // become leader if rf.votenum &gt; count/2 &#123; log.Println(&quot;become leader me&quot;, me) rf.hasLeader = true if !rf.isLeader &#123; rf.isLeader = true rf.heartCh &lt;- struct&#123;&#125;&#123;&#125; &#125; &#125; &#125;(num) &#125; &#125;&#125; heartBeatOne123456789101112131415161718192021222324252627282930313233func (rf *Raft) heartBeatOne(num int) &#123; for &#123; var req AppendEntriesReq var rsp AppendEntriesRsp rf.mu.Lock() rf.refreshCh &lt;- struct&#123;&#125;&#123;&#125; if !rf.hasLeader || !rf.isLeader || rf.killed() &#123; rf.mu.Unlock() break &#125; req.Term = rf.currentTerm req.LeaderId = rf.me rf.mu.Unlock() ret := rf.sendAppendEntries(num, &amp;req, &amp;rsp) if ret != true &#123; log.Println(&quot;sendAppendEntries err, server = me = &quot;, num, rf.me) &#125; // expired rf.mu.Lock() if rsp.Term &gt; rf.currentTerm &#123; rf.isLeader = false rf.mu.Unlock() break &#125; rf.mu.Unlock() time.Sleep(150 * time.Millisecond) &#125;&#125; RequestVote1234567891011121314151617181920212223242526272829303132333435363738394041//// example RequestVote RPC handler.//func (rf *Raft) RequestVote(args *RequestVoteArgs, reply *RequestVoteReply) &#123; // Your code here (2A, 2B). //1. Reply false if term &lt; currentTerm (§5.1) //2. If votedFor is null or candidateId, and candidate’s log is at //least as up-to-date as receiver’s log, grant vote (§5.2, §5.4) if rf.killed() &#123; reply.VoteGranted = false return &#125; rf.mu.Lock() if args.Term &lt; rf.currentTerm &#123; reply.VoteGranted = false &#125; else if args.Term &gt; rf.currentTerm &#123; reply.VoteGranted = true &#125; else &#123; // args.Term == rf.currentTerm // one term only vote one server if rf.votedFor == 0 || rf.votedFor == args.CandidateId &#123; loglen := len(rf.log) if loglen == 0 &#123; reply.VoteGranted = true &#125; else if args.LastLogTerm &gt; rf.log[loglen-1].Term || (args.LastLogTerm == rf.log[loglen-1].Term &amp;&amp; args.LastLogIndex &gt;= rf.log[loglen-1].Index) &#123; reply.VoteGranted = true &#125; &#125; &#125; if reply.VoteGranted == true &#123; log.Println(&quot;me vote him &quot;, rf.me, args.CandidateId) rf.votedFor = args.CandidateId rf.isLeader = false &#125; reply.Term = rf.currentTerm rf.mu.Unlock()&#125; AppendEntries123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657// Receiver implementation:// 1. Reply false if term &lt; currentTerm (§5.1)// 2. Reply false if log doesn’t contain an entry at prevLogIndex// whose term matches prevLogTerm (§5.3)// 3. If an existing entry conflicts with a new one (same index// but different terms), delete the existing entry and all that// follow it (§5.3)// 4. Append any new entries not already in the log// 5. If leaderCommit &gt; commitIndex, set commitIndex = min(leaderCommit, index of last new entry)func (rf *Raft) AppendEntries(req *AppendEntriesReq, rsp *AppendEntriesRsp) &#123; if rf.killed() &#123; rsp.Success = false return &#125; rf.mu.Lock() defer func() &#123; rsp.Term = rf.currentTerm rf.mu.Unlock() &#125;() // expired if req.Term &lt; rf.currentTerm &#123; rsp.Success = false return &#125; // heartbeat if len(req.Entries) == 0 &#123; rf.hasLeader = true rf.currentTerm = req.Term rf.isLeader = false rf.refreshCh &lt;- struct&#123;&#125;&#123;&#125; rsp.Success = true return &#125; if len(rf.log) &gt; req.PrevLogIndex &amp;&amp; rf.log[req.PrevLogIndex].Term != req.PrevLogTerm &#123; rsp.Success = false return &#125; rsp.Success = true for _, value := range req.Entries &#123; rf.log[value.Index] = value &#125; // why? if req.LeaderCommit &gt; rf.commitIndex &#123; if req.LeaderCommit &lt; req.Entries[len(req.Entries)-1].Index &#123; rf.commitIndex = req.LeaderCommit &#125; else &#123; rf.commitIndex = req.Entries[len(req.Entries)-1].Index &#125; &#125;&#125; test12345678#! &#x2F;bin&#x2F;shfor((i&#x3D;1;i&lt;&#x3D;500;i++));doecho &quot;---------------------$i&quot; &gt;&gt;2a.loggo test -run 2A -race 2&gt;&amp;1 &gt;&gt;2a.logecho &quot;&quot;done; 123456789101112131415161718192021222324252627282930313233343536373839404142grep PASS 2a.log | wc -l500ok pathname 7.480sok pathname 7.453sok pathname 7.463sok pathname 7.581sok pathname 7.587sok pathname 7.534sok pathname 7.483sok pathname 7.667sok pathname 7.499sok pathname 7.520sok pathname 7.539sok pathname 7.475sok pathname 7.519sok pathname 7.657sok pathname 7.617sok pathname 7.728sok pathname 7.539sok pathname 8.254sok pathname 7.591sok pathname 7.618sok pathname 7.703sok pathname 8.075sok pathname 7.509sok pathname 7.644sok pathname 7.381sok pathname 7.607sok pathname 7.616sok pathname 7.646sok pathname 7.571sok pathname 7.443sok pathname 7.533sok pathname 7.552sok pathname 7.562sok pathname 8.243sok pathname 7.559sok pathname 8.128sok pathname 8.000sok pathname 7.654sok pathname 7.579s","categories":[],"tags":[{"name":"raft","slug":"raft","permalink":"https://riverferry.site/tags/raft/"}],"keywords":[]},{"title":"protobuf 整理和坑","slug":"2021-03-05-protobuf 整理和坑","date":"2021-03-05T00:00:00.000Z","updated":"2022-09-12T16:24:32.292Z","comments":true,"path":"2021-03-05-protobuf 整理和坑/","link":"","permalink":"https://riverferry.site/2021-03-05-protobuf%20%E6%95%B4%E7%90%86%E5%92%8C%E5%9D%91/","excerpt":"","text":"message12345678910111213141516&#x2F;&#x2F;teststr&#x3D;&quot;hello&quot;num&#x3D;10&#x2F;&#x2F;Amessage Test&#123; string Str &#x3D; 1;&#125;&#x2F;&#x2F;Bmessage Test&#123; string Str &#x3D; 1; uint32 Num &#x3D; 2;&#125; 1234567891011121314151617&#x2F;&#x2F;A0000 1e 00 00 00 60 0d cf d3 00 35 06 40 00 00 00 000010 00 00 00 00 00 00 00 00 00 00 00 01 00 00 00 000020 00 00 00 00 00 00 00 00 00 00 00 01 d7 f2 27 100030 fb 13 27 e9 60 69 1d 73 80 18 18 e3 00 3d 00 000040 01 01 08 0a 3f 92 b3 a7 3f 92 b3 a7 00 00 0c 000050 01 00 00 00 01 00 00 00 00 07 0a 05 68 65 6c 6c0060 6f&#x2F;&#x2F;B0000 1e 00 00 00 60 02 12 34 00 37 06 40 00 00 00 000010 00 00 00 00 00 00 00 00 00 00 00 01 00 00 00 000020 00 00 00 00 00 00 00 00 00 00 00 01 f9 7e 27 100030 99 7d 24 16 a6 e1 55 ff 80 18 18 e3 00 3f 00 000040 01 01 08 0a 40 30 23 50 40 30 23 50 00 00 0e 000050 01 00 00 00 01 00 00 00 00 09 0a 05 68 65 6c 6c0060 6f 10 0a 1234567891011tag&#x3D; field &lt;&lt; 3 | wire&#x2F;&#x2F;A1010 field&#x3D;1 wire&#x3D;207 0a 05 68 65 6c 6c 6f07(字节总数) 0a(tag&#x3D;10) 05(len&#x3D;5) 68 65 6c 6c 6f(value&#x3D;hello)&#x2F;&#x2F;B0001 0000 field&#x3D;2 wire&#x3D;009 0a 05 68 65 6c 6c 6f 10 0a09(字节总数) 0a(tag&#x3D;10) 05(len&#x3D;5) 68 65 6c 6c 6f(value&#x3D;hello) 10(tag&#x3D;16) 0a(value&#x3D;10) wire_type Type Meaning Used For 0 Varint int32, int64, uint32, uint64, sint32, sint64, bool, enum 1 64-bit fixed64, sfixed64, double 2 Length-delimited string, bytes, embedded messages, packed repeated fields 3 Start group groups (deprecated) 4 End group groups (deprecated) 5 32-bit fixed32, sfixed32, float demo code12345678910111213141516171819202122syntax = &quot;proto2&quot;;package data;message Test&#123; optional string Str = 1; optional uint64 Num = 2; optional ENUMDATATYPE Data = 3;&#125;message Test2&#123; optional string str = 1;&#125;enum ENUMDATATYPE&#123; DATA_UNKONW = -1; DATA_ZERO = 0; DATA_ONE = 1; DATA_TWO = 2;&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243int main()&#123; data::Test tt; cout &lt;&lt; tt.ParseFromArray(nullptr, 0) &lt;&lt; endl; //1 // tt.set_str(&quot;hello&quot;); tt.set_num(10); cout &lt;&lt; tt.has_data() &lt;&lt; endl; //0 string str1; tt.SerializeToString(&amp;str1); /* 0x60e988: 0x10 0x0a 0x00 0x00 0x00 0x00 0x00 0x00 0x60e990: 0xa0 0xea 0x60 0x00 0x00 0x00 0x00 0x00 */ tt.set_data(data::DATA_UNKONW); cout &lt;&lt; tt.has_data() &lt;&lt; endl; //1 string str2; tt.SerializeToString(&amp;str2); /* 0x60eaa8: 0x10 0x0a 0x18 0xff 0xff 0xff 0xff 0xff 0x60eab0: 0xff 0xff 0xff 0xff 0x01 0x00 0x00 0x00 */ tt.set_data(data::DATA_ONE); cout &lt;&lt; tt.has_data() &lt;&lt; endl; //1 string str3; tt.SerializeToString(&amp;str3); /* 0x60ea18: 0x10 0x0a 0x18 0x01 0x00 0x00 0x00 0x00 0x60ea20: 0xf0 0xe8 0x60 0x00 0x00 0x00 0x00 0x00 */ data::Test tt2; tt2.ParseFromString(str3); cout &lt;&lt; tt2.DebugString() &lt;&lt; endl; /* Num: 10 Data: DATA_ONE */ return 0;&#125; specify default123456message Test&#123; optional string Str &#x3D; 1; optional uint64 Num &#x3D; 2; optional ENUMDATATYPE Data &#x3D; 3 [default &#x3D; DATA_ONE];&#125; 123456789101112&#x2F;&#x2F;str1str1.data() -&gt; $1 &#x3D; data::DATA_ONE0x60eaa8: 0x10 0x0a 0x00 0x00 0x00 0x00 0x00 0x000x60eab0: 0x60 0xed 0x60 0x00 0x00 0x00 0x00 0x00&#x2F;&#x2F;str20x616618: 0x10 0x0a 0x18 0xff 0xff 0xff 0xff 0xff0x616620: 0xff 0xff 0xff 0xff 0x01 0x00 0x00 0x00&#x2F;&#x2F;str30x60e988: 0x10 0x0a 0x18 0x01 0x00 0x00 0x00 0x000x60e990: 0xa0 0xea 0x60 0x00 0x00 0x00 0x00 0x00 update proto123456789101112131415161718192021222324message TestNew&#123; optional string Str &#x3D; 1; optional uint64 Num &#x3D; 2; optional ENUMDATATYPENEW Data &#x3D; 3; optional uint64 neww &#x3D; 4;&#125;enum ENUMDATATYPE&#123; DATA_UNKONW &#x3D; -1; DATA_ZERO &#x3D; 0; DATA_ONE &#x3D; 1; DATA_TWO &#x3D; 2;&#125;enum ENUMDATATYPENEW&#123; NEW_DATA_UNKONW &#x3D; -1; NEW_DATA_ZERO &#x3D; 0; NEW_DATA_ONE &#x3D; 1; NEW_DATA_TWO &#x3D; 2; NEW_DATA_NEW &#x3D; 3;&#125; 12345678910111213141516171819int main()&#123; data::Test tt1; data::TestNew tt2; tt2.set_str(&quot;hello&quot;); tt2.set_num(10); tt2.set_data(data::NEW_DATA_NEW); tt2.set_neww(200); cout &lt;&lt; tt2.DebugString() &lt;&lt; endl; string str; tt2.SerializeToString(&amp;str); tt1.ParseFromString(str); cout &lt;&lt; tt1.DebugString() &lt;&lt; endl; cout &lt;&lt; tt1.has_data() &lt;&lt; endl; return 0;&#125; 1234567891011Str: &quot;hello&quot;Num: 10Data: NEW_DATA_NEWneww: 200Str: &quot;hello&quot;Num: 103: 34: 2000 referenceproto编译安装 proto序列化原理 protobuf 中 enum 类型默认值的一个坑 protobuf message","categories":[],"tags":[{"name":"proto","slug":"proto","permalink":"https://riverferry.site/tags/proto/"}],"keywords":[]},{"title":"proxy_pass return rewrite try_file","slug":"2021-02-28-proxy-pass-return","date":"2021-02-28T00:00:00.000Z","updated":"2022-09-12T16:24:32.292Z","comments":true,"path":"2021-02-28-proxy-pass-return/","link":"","permalink":"https://riverferry.site/2021-02-28-proxy-pass-return/","excerpt":"","text":"dns www.riverferry.site 34.92.9.255nginx.org 3.125.197.172 nginx.conf12345678910111213141516171819server &#123; listen 0.0.0.0:8888; server_name www.riverferry.site; location &#x2F; &#123; proxy_pass http:&#x2F;&#x2F;nginx.org; &#125;&#125; server &#123; listen 0.0.0.0:9999; server_name www.riverferry.site; location &#x2F; &#123; return 301 http:&#x2F;&#x2F;nginx.org; &#125;&#125; proxy_pass return rewrite和return的区别 rewrite regex URL [flag]; 详情见Creating NGINX Rewrite Rules the first argument, regex, means that NGINX Plus and NGINX rewrite the URL only if it matches the specified regular expression (in addition to matching the server or location directive). The additional test means NGINX must do more processing. A second difference is that the rewrite directive can return only code 301 or 302. To return other codes, you need to include a return directive after the rewrite directive (see the example below). And finally the rewrite directive does not necessarily halt NGINX’s processing of the request as return does, and it doesn’t necessarily send a redirect to the client. Unless you explicitly indicate (with flags or the syntax of the URL) that you want NGINX to halt processing or send a redirect, it runs through the entire configuration looking for directives that are defined in the Rewrite module (break, if, return, rewrite, and set), and processes them in order. If a rewritten URL matches a subsequent directive from the Rewrite module, NGINX performs the indicated action on the rewritten URL (often rewriting it again). try_files try_files file … uri; In the following example, NGINX serves a default GIF file if the file requested by the client doesn’t exist. When the client requests (for example) http://www.domain.com/images/image1.gif, NGINX first looks for image1.gif in the local directory specified by the root or alias directive that applies to the location (not shown in the snippet). If image1.gif doesn’t exist, NGINX looks for image1.gif/, and if that doesn’t exist, it redirects to /images/default.gif. That value exactly matches the second location directive, so processing stops and NGINX serves that file and marks it to be cached for 30 seconds. 1234567location &#x2F;images&#x2F; &#123; try_files $uri $uri&#x2F; &#x2F;images&#x2F;default.gif;&#125;location &#x3D; &#x2F;images&#x2F;default.gif &#123; expires 30s;&#125;","categories":[],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://riverferry.site/tags/nginx/"}],"keywords":[]},{"title":"http cache","slug":"2021-02-25-http-cache","date":"2021-02-25T00:00:00.000Z","updated":"2022-09-12T16:24:32.292Z","comments":true,"path":"2021-02-25-http-cache/","link":"","permalink":"https://riverferry.site/2021-02-25-http-cache/","excerpt":"","text":"强制刷新 后退前进 重新加载","categories":[],"tags":[],"keywords":[]},{"title":"c++ volatile  atomic","slug":"2021-02-24-c++ volatile atomic","date":"2021-02-24T00:00:00.000Z","updated":"2022-09-12T16:24:32.292Z","comments":true,"path":"2021-02-24-c++ volatile atomic/","link":"","permalink":"https://riverferry.site/2021-02-24-c++%20volatile%20atomic/","excerpt":"最早接触valotile是在程序员的自我修养看到的，当时似懂非懂。这篇文章也挂在blog快一年了，今天重新查找资料，才算看明白了个大概。特此记录，毕竟是应用开发者，到此为止了","text":"最早接触valotile是在程序员的自我修养看到的，当时似懂非懂。这篇文章也挂在blog快一年了，今天重新查找资料，才算看明白了个大概。特此记录，毕竟是应用开发者，到此为止了 定义和区别 volatile是作用在单线程下，针对特定内存使用的。atomic是c++11提供的原子类操作 原子性 可见性 有序性 禁用优化 atomic cas实现 缓存一致性实现 内存屏障实现 不支持 volatile 不支持 不支持 不支持 支持 有序性123456x = y;a = b;// 可能被调整为a = b;x = y; 禁用优化：123456789101112131415161718192021//--------------int a = b;a = b;int c = 10;c = 20;//可能会被编译期优化为int a = b;int c = 20;//--------------std::atomic&lt;int&gt; y(x.load()); // 读取xy.store(x.load()); // 再次读取x//可能被优化为//导致x的变化不可知register = x.load(); // 将x读入寄存器std::atomic&lt;int&gt; y(register); // 用寄存器值初始化yy.store(register); // 将寄存器值保存至y 总结 atomic和volatile是完全不同的东西。 atomic可用在多线程中，对小数据进行原子操作，是安全的 volatile用于特殊内存防止编译器级别的优化，atomic用于普通内存，优化没有副作用，如果是特殊内存就用volatile,如果并且是多线程，可以叠加atomic使用 可以搭配一起使用，atomic并不能取代volatile的作用，volatile也没有atomic的功能 reference谈谈 C/C++ 中的 volatile Memory Model: 从多处理器到高级语言 GCC 原子操作中 Acquire/Release/Consume/Relaxed 内存模型 ending","categories":[],"tags":[{"name":"c++","slug":"c","permalink":"https://riverferry.site/tags/c/"}],"keywords":[]},{"title":"http basis","slug":"2021-02-24-http basis","date":"2021-02-24T00:00:00.000Z","updated":"2022-09-12T16:24:32.292Z","comments":true,"path":"2021-02-24-http basis/","link":"","permalink":"https://riverferry.site/2021-02-24-http%20basis/","excerpt":"","text":"概念http(HyperText transfer protocol)是超文本传输协议 超文本： 文字，音频，视频等传输：不同于路由协议，隧道协议，传输协议用于两方交换数据协议：符合rfc规范的应用层协议 相关技术 web服务器 爬虫 cdn html/webservice/waf 报文 请求1234request line: method + URI + versionhead: k&#x2F;vCRLFbody 响应1234status line: version + status code + reasonhead: k&#x2F;vCRLFbody 常用头通用字段Data:通用字段，但一般放在响应头，代表报文创建时间 请求字段host: 请求消息必带字段，代表了ip地址下的具体哪台主机，可用于路由重定向 User-Agent: 请求字段，描述客户端，比如chrome,实际作用不大 响应字段server:响应字段，代表web服务器软件和版本，也可以随便写一个来隐藏服务器软件 实体字段content-lenght:实体字段，代表body的长度，如果不带content-length则表示报文是不定长的，chunked类型 methodGET 读取下载数据 //幂等 HEAD 获取数据元信息 //幂等 POST 提交数据,偏向create,实际上创建修改都基本用POST //非幂等 PUT 和POST差不多，偏向update,实际多用POST替代 //幂等 DELETE 删除数据 //幂等 CONNECT 建立隧道，webf服务器可以因此作为代理 OPTIONS 列出可选方法 TRACE 追踪请求-响应的传输路径 uri schema :// user:passwd@ host:port path ?query #fragment https://www.nginx.com/resources/library/web-application-security/?utm_medium=nginxorg&amp;utm_source=homepagehero&amp;utm_campaign=ww-nx_sec&amp;utm_content=eb&amp;_ga=2.158505918.527586210.1614136337-596008434.1614136337 https://github.com/GHScan/TechNotes/blob/master/2017/Memory_Model.md#%E7%BC%96%E8%AF%91%E5%99%A8%E4%B8%AD%E7%9A%84%E4%BC%98%E5%8C%96%E6%8A%80%E6%9C%AF 上面的#代表锚点，直接到页面的一个标签处。因为有中文，这里也做了转义 状态码1xx提示信息，代表中间状态 101：切换协议 2xx成功信息 204：响应里面没有body 206: 响应是分段传输的一部分 3xx重定向 301: 永久重定向 302：临时重定向 304：缓存重定向 4xx客户端错误 400：格式错误 404：未找到 403：禁止访问 5xx服务器错误 503：服务器忙 数据类型和编码http是超文本传输协议，支持文本，视音频等格式，所以需要带上文件类型，因为数据可能被压缩，也要带上压缩格式，文件类型符合MIME协议 text text/html 超文本文档 text/plain 纯文本 text/css 样式表 audio audio/mpeg video video/mp4 image image/gif image/jpeg application application/pdf application/json encoding gzip deflate br 语言和字符集 en-US en-GB zh-CN utf-8 gbk 内容协商12345client serverAccept: text&#x2F;plain,application&#x2F;pdf Content-Type: text&#x2F;plainAccept-Encoding: gzip, deflate, br Content-Encoding: gzipAccept-Language: zh-CN Content-Language: zh-CNAccept-Charset: gbk, utf-8 Content-Type: text&#x2F;plain; charset&#x3D;utf-8 分段和范围感觉不重要，不记录了 长连接Connection: keep-alive 表示长连接 Connection: close 关闭连接 队头阻塞因为http是请求-应答模式，一条连接上，前一个请求阻塞了，会影响后面的请求，也就是队头阻塞 解决办法： 请求方并发多个连接，一般浏览器是开6个 响应方开启多主机，域名分片 cookie cookie可以用来记录客户端的状态 Expire/Max-Age: 表示cookie的过期时间 HttpOnly: 表示cookie只适用于http协议，防止脚本攻击 Secure: 表示cookie智能通过https协议传输，但cookie本身是明文的 SameSite: 表示cookie只用于本站，防止跨站攻击 Priority: 表示cookie移除时的优先级 http特点灵活可扩展head支持自定义字段 可靠传输下层是tcp/ip 应用层协议在应用层协议中(ftp,ssh)表现突出 请求应答契合c/s, b/s架构 无状态因为请求应答，两次连接彼此独立，不会记录请求方的状态，但可以通过cookie来实现有状态 流程浏览器输入 http://nginx.org/ 123456查dns三次握手Get &#x2F; HTTP&#x2F;1.1 &#x2F;&#x2F;拿index.htmlGet &#x2F;nginx.png HTTP&#x2F;1.1 &#x2F;&#x2F;拿网站图标,index里面的超链接GET &#x2F;favicon.ico HTTP&#x2F;1.1 &#x2F;&#x2F;拿浏览器那个小图标挥手","categories":[],"tags":[],"keywords":[]},{"title":"[译文]Paxos Made Simple","slug":"2021-02-20-Paxos-Made-Simple","date":"2021-02-20T00:00:00.000Z","updated":"2022-09-12T16:24:32.292Z","comments":true,"path":"2021-02-20-Paxos-Made-Simple/","link":"","permalink":"https://riverferry.site/2021-02-20-Paxos-Made-Simple/","excerpt":"original paper here","text":"original paper here 1 IntroductionThe Paxos algorithm for implementing a fault-tolerant distributed system has been regarded as difficult to understand perhaps because the original presentation was Greek to many readers [5]. In fact, it is among the simplest and most obvious of distributed algorithms. At its heart is a consensus algorithm—the “synod” algorithm of [5]. The next section shows that this consensus algorithm follows almost unavoidably from the properties we want it to satisfy. The last section explains the complete Paxos algorithm, which is obtained by the straightforward application of consensus to the state machine approach for building a distributed system—an approach that should be well-known, since it is the subject of what is probably the most often-cited article on the theory of distributed systems [4]. todo 2 The Consensus Algorithm2.1 The ProblemAssume a collection of processes that can propose values. A consensus algorithm ensures that a single one among the proposed values is chosen. If no value is proposed, then no value should be chosen. If a value has been chosen, then processes should be able to learn the chosen value. The safety requirements for consensus are: todo Only a value that has been proposed may be chosen, Only a single value is chosen, and A process never learns that a value has been chosen unless it actually has been. todo We won’t try to specify precise liveness requirements. However, the goal is to ensure that some proposed value is eventually chosen and, if a value has been chosen, then a process can eventually learn the value. todo We let the three roles in the consensus algorithm be performed by three classes of agents: proposers, acceptors, and learners. In an implementation, a single process may act as more than one agent, but the mapping from agents to processes does not concern us here. todo Assume that agents can communicate with one another by sending messages. We use the customary asynchronous, non-Byzantine model, in which: todo Agents operate at arbitrary speed, may fail by stopping, and may restart. Since all agents may fail after a value is chosen and then restart, a solution is impossible unless some information can be remembered by an agent that has failed and restarted. todo Messages can take arbitrarily long to be delivered, can be duplicated, and can be lost, but they are not corrupted. todo 2.2 Choosing a ValueThe easiest way to choose a value is to have a single acceptor agent. A proposer sends a proposal to the acceptor, who chooses the first proposed value that it receives. Although simple, this solution is unsatisfactory because the failure of the acceptor makes any further progress impossible. So, let’s try another way of choosing a value. Instead of a single acceptor, let’s use multiple acceptor agents. A proposer sends a proposed value to a set of acceptors. An acceptor may accept the proposed value. The value is chosen when a large enough set of acceptors have accepted it. How large islarge enough? To ensure that only a single value is chosen, we can let a large enough set consist of any majority of the agents. Because any two majorities have at least one acceptor in common, this works if an acceptor can accept at most one value. (There is an obvious generalization of a majority that has been observed in numerous papers, apparently starting with [3].) In the absence of failure or message loss, we want a value to be chosen even if only one value is proposed by a single proposer. This suggests the requirement: todo P1. An acceptor must accept the first proposal that it receives. todo But this requirement raises a problem. Several values could be proposed by different proposers at about the same time, leading to a situation in which every acceptor has accepted a value, but no single value is accepted by a majority of them. Even with just two proposed values, if each is accepted by about half the acceptors, failure of a single acceptor could make it impossible to learn which of the values was chosen. P1 and the requirement that a value is chosen only when it is acceptedby a majority of acceptors imply that an acceptor must be allowed to accept more than one proposal. We keep track of the different proposals that an acceptor may accept by assigning a (natural) number to each proposal, so a proposal consists of a proposal number and a value. To prevent confusion, we require that different proposals have different numbers. How this is2 achieved depends on the implementation, so for now we just assume it. A value is chosen when a single proposal with that value has been accepted by a majority of the acceptors. In that case, we say that the proposal (as well as its value) has been chosen. We can allow multiple proposals to be chosen, but we must guarantee that all chosen proposals have the same value. By induction on the proposal number, it suffices to guarantee: todo P2. If a proposal with value v is chosen, then every higher-numbered proposal that is chosen has value v. todo Since numbers are totally ordered, condition P2 guarantees the crucial safety property that only a single value is chosen. todo To be chosen, a proposal must be accepted by at least one acceptor. So, we can satisfy P2 by satisfying: todo P2a. If a proposal with value v is chosen, then every higher-numbered proposal accepted by any acceptor has value v. todo We still maintain P1 to ensure that some proposal is chosen. Because communication is asynchronous, a proposal could be chosen with some particular acceptor c never having received any proposal. Suppose a new proposer “wakes up” and issues a higher-numbered proposal with a different value. P1 requires c to accept this proposal, violating P2a. Maintaining both P1and P2a requires strengthening P2a to: todo P2b. If a proposal with value v is chosen, then every higher-numbered proposal issued by any proposer has value v. todo Since a proposal must be issued by a proposer before it can be accepted by an acceptor, P2b implies P2a, which in turn implies P2. todo To discover how to satisfy P2b, let’s consider how we would prove that it holds. We would assume that some proposal with number m and value v is chosen and show that any proposal issued with number n &gt; m also has value v. We would make the proof easier by using induction on n, so we can prove that proposal number n has value v under the additional assumption that every proposal issued with a number in m . .(n − 1) has value v, where i . . j denotes the set of numbers from i through j. For the proposal numbered m to be chosen, there must be some set C consisting of a majority of acceptors such that every acceptor in C accepted it. Combining this with the induction assumption, the hypothesis that m is chosen implies: 3 Every acceptor in C has accepted a proposal with number in m . .(n − 1), and every proposal with number in m . .(n − 1) accepted by any acceptor has value v. todo Since any set S consisting of a majority of acceptors contains at least one member of C , we can conclude that a proposal numbered n has value v by ensuring that the following invariant is maintained: todo P2c. For any v and n, if a proposal with value v and number n is issued, then there is a set S consisting of a majority of acceptors such that either (a) no acceptor in S has accepted any proposal numbered less than n, or (b) v is the value of the highest-numbered proposal among all proposals numbered less than n accepted by the acceptors in S. todo We can therefore satisfy P2b by maintaining the invariance of P2c. todo To maintain the invariance of P2c , a proposer that wants to issue a proposal numbered n must learn the highest-numbered proposal with number less than n, if any, that has been or will be accepted by each acceptor in some majority of acceptors. Learning about proposals already accepted is easy enough; predicting future acceptances is hard. Instead of trying to predict the future, the proposer controls it by extracting a promise that there won’t be any such acceptances. In other words, the proposer requests that the acceptors not accept any more proposals numbered less than n. This leads to the following algorithm for issuing proposals. todo A proposer chooses a new proposal number n and sends a request to each member of some set of acceptors, asking it to respond with: (a) A promise never again to accept a proposal numbered less than n, and(b) The proposal with the highest number less than n that it has accepted, if any. I will call such a request a prepare request with number n todo If the proposer receives the requested responses from a majority of the acceptors, then it can issue a proposal with number n and value v, where v is the value of the highest-numbered proposal among the responses, or is any value selected by the proposer if the responders reported no proposals. todo A proposer issues a proposal by sending, to some set of acceptors, a request that the proposal be accepted. (This need not be the same set of acceptors that responded to the initial requests.) Let’s call this an accept request. todo This describes a proposer’s algorithm. What about an acceptor? It can receive two kinds of requests from proposers: prepare requests and accept requests. An acceptor can ignore any request without compromising safety. So, we need to say only when it is allowed to respond to a request. It can always respond to a prepare request. It can respond to an accept request,accepting the proposal, iff it has not promised not to. In other words: todo P1a. An acceptor can accept a proposal numbered n iff it has not responded to a prepare request having a number greater than n. todo Observe that P1a subsumes P1. We now have a complete algorithm for choosing a value that satisfies the required safety properties—assuming unique proposal numbers. The final algorithm is obtained by making one small optimization. Suppose an acceptor receives a prepare request numbered n, but it has already responded to a prepare request numbered greater than n, thereby promising not to accept any new proposal numbered n. There is then no reason for the acceptor to respond to the new prepare request, since it will not accept the proposal numbered n that the proposer wants to issue. Sowe have the acceptor ignore such a prepare request. We also have it ignore a prepare request for a proposal it has already accepted. With this optimization, an acceptor needs to remember only the highestnumbered proposal that it has ever accepted and the number of the highestnumbered prepare request to which it has responded. Because P2c must be kept invariant regardless of failures, an acceptor must remember this information even if it fails and then restarts. Note that the proposer canalways abandon a proposal and forget all about it—as long as it never tries to issue another proposal with the same number. Putting the actions of the proposer and acceptor together, we see that the algorithm operates in the following two phases. Phase 1. (a) A proposer selects a proposal number n and sends a prepare request with number n to a majority of acceptors. (b) If an acceptor receives a prepare request with number n greater than that of any prepare request to which it has already responded, then it responds to the request with a promise not to accept any more proposals numbered less than n and with the highest-numbered proposal (if any) that it has accepted. Phase 2. (a) If the proposer receives a response to its prepare requests (numbered n) from a majority of acceptors, then it sends an accept request to each of those acceptors for a proposal numbered n with a value v, where v is the value of the highest-numbered proposal among the responses, or is any value if the responses reported no proposals. (b) If an acceptor receives an accept request for a proposal numbered n, it accepts the proposal unless it has already responded to a prepare request having a number greater than n. A proposer can make multiple proposals, so long as it follows the algorithm for each one. It can abandon a proposal in the middle of the protocol at any time. (Correctness is maintained, even though requests and/or responses for the proposal may arrive at their destinations long after the proposal was abandoned.) It is probably a good idea to abandon a proposal if someproposer has begun trying to issue a higher-numbered one. Therefore, if an acceptor ignores a prepare or accept request because it has already received a prepare request with a higher number, then it should probably inform the proposer, who should then abandon its proposal. This is a performance optimization that does not affect correctness. 2.3 Learning a Chosen ValueTo learn that a value has been chosen, a learner must find out that a proposal has been accepted by a majority of acceptors. The obvious algorithm is to have each acceptor, whenever it accepts a proposal, respond to all learners, sending them the proposal. This allows learners to find out about a chosen value as soon as possible, but it requires each acceptor to respondto each learner—a number of responses equal to the product of the number of acceptors and the number of learners. The assumption of non-Byzantine failures makes it easy for one learner to find out from another learner that a value has been accepted. We can have the acceptors respond with their acceptances to a distinguished learner, which in turn informs the other learners when a value has been chosen. This approach requires an extra round for all the learners to discover the chosen value. It is also less reliable, since the distinguished learner could fail. But it requires a number of responses equal only to the sum of the number of acceptors and the number of learners. More generally, the acceptors could respond with their acceptances to some set of distinguished learners, each of which can then inform all the learners when a value has been chosen. Using a larger set of distinguished learners provides greater reliability at the cost of greater communication complexity. Because of message loss, a value could be chosen with no learner ever finding out. The learner could ask the acceptors what proposals they have accepted, but failure of an acceptor could make it impossible to know whether or not a majority had accepted a particular proposal. In that case, learners will find out what value is chosen only when a new proposal is chosen. If a learner needs to know whether a value has been chosen, it can have a proposer issue a proposal, using the algorithm described above. 2.4 ProgressIt’s easy to construct a scenario in which two proposers each keep issuing a sequence of proposals with increasing numbers, none of which are ever chosen. Proposer p completes phase 1 for a proposal number n1. Another proposer q then completes phase 1 for a proposal number n2 &gt; n1. Proposer p’s phase 2 accept requests for a proposal numbered n1 are ignored becausethe acceptors have all promised not to accept any new proposal numbered less than n2. So, proposer p then begins and completes phase 1 for a new proposal number n3 &gt; n2, causing the second phase 2 accept requests of proposer q to be ignored. And so on. To guarantee progress, a distinguished proposer must be selected as the only one to try issuing proposals. If the distinguished proposer can communicate successfully with a majority of acceptors, and if it uses a proposal with number greater than any already used, then it will succeed in issuing a proposal that is accepted. By abandoning a proposal and trying again if it learns about some request with a higher proposal number, the distinguished proposer will eventually choose a high enough proposal number. If enough of the system (proposer, acceptors, and communication network) is working properly, liveness can therefore be achieved by electing a single distinguished proposer. The famous result of Fischer, Lynch, and Patterson [1] implies that a reliable algorithm for electing a proposer must use either randomness or real time—for example, by using timeouts. However,safety is ensured regardless of the success or failure of the election. 2.5 The ImplementationThe Paxos algorithm [5] assumes a network of processes. In its consensus algorithm, each process plays the role of proposer, acceptor, and learner. The algorithm chooses a leader, which plays the roles of the distinguished proposer and the distinguished learner. The Paxos consensus algorithm is precisely the one described above, where requests and responses are sent as ordinary messages. (Response messages are tagged with the corresponding proposal number to prevent confusion.) Stable storage, preserved during failures, is used to maintain the information that the acceptor must remember. An acceptor records its intended response in stable storage before actually sending the response. All that remains is to describe the mechanism for guaranteeing that no two proposals are ever issued with the same number. Different proposers choose their numbers from disjoint sets of numbers, so two different proposers never issue a proposal with the same number. Each proposer remembers (in stable storage) the highest-numbered proposal it has tried to issue,and begins phase 1 with a higher proposal number than any it has already used. 3 Implementing a State MachineA simple way to implement a distributed system is as a collection of clients that issue commands to a central server. The server can be described as a deterministic state machine that performs client commands in some sequence. The state machine has a current state; it performs a step by taking as input a command and producing an output and a new state. For example, the clients of a distributed banking system might be tellers, and the state-machine state might consist of the account balances of all users. A withdrawal would be performed by executing a state machine command that decreases an account’s balance if and only if the balance is greater than the amount withdrawn, producing as output the old and new balances. An implementation that uses a single central server fails if that server fails. We therefore instead use a collection of servers, each one independently implementing the state machine. Because the state machine is deterministic, all the servers will produce the same sequences of states and outputs if they all execute the same sequence of commands. A client issuing a command can then use the output generated for it by any server. To guarantee that all servers execute the same sequence of state machine commands, we implement a sequence of separate instances of the Paxos consensus algorithm, the value chosen by the i th instance being the ith state machine command in the sequence. Each server plays all the roles (proposer, acceptor, and learner) in each instance of the algorithm. For now, I assume that the set of servers is fixed, so all instances of the consensus algorithm use the same sets of agents. In normal operation, a single server is elected to be the leader, which acts as the distinguished proposer (the only one that tries to issue proposals) in all instances of the consensus algorithm. Clients send commands to the leader, who decides where in the sequence each command should appear. If the leader decides that a certain client command should be the 135thcommand, it tries to have that command chosen as the value of the 135th instance of the consensus algorithm. It will usually succeed. It might fail because of failures, or because another server also believes itself to be the leader and has a different idea of what the 135th command should be. But the consensus algorithm ensures that at most one command can be chosen as the 135th one. Key to the efficiency of this approach is that, in the Paxos consensus algorithm, the value to be proposed is not chosen until phase 2. Recall that, after completing phase 1 of the proposer’s algorithm, either the value to be proposed is determined or else the proposer is free to propose any value. I will now describe how the Paxos state machine implementation works during normal operation. Later, I will discuss what can go wrong. I consider what happens when the previous leader has just failed and a new leader has been selected. (System startup is a special case in which no commands have yet been proposed.) The new leader, being a learner in all instances of the consensus algorithm, should know most of the commands that have already been chosen. Suppose it knows commands 1–134, 138, and 139—that is, the values chosen in instances 1–134, 138, and 139 of the consensus algorithm. (We will see later how such a gap in the command sequence could arise.) It then executes phase 1 of instances 135–137 and of all instances greater than 139. (I describe below how this is done.) Suppose that the outcome of these executions determine the value to be proposed in instances 135 and 140, but leaves the proposed value unconstrained in all other instances. The leader then executes phase 2 for instances 135 and 140, thereby choosing commands135 and 140. The leader, as well as any other server that learns all the commands the leader knows, can now execute commands 1–135. However, it can’t execute commands 138–140, which it also knows, because commands 136 and 137 have yet to be chosen. The leader could take the next two commands requested by clients to be commands 136 and 137. Instead, we let it fill the gap immediately by proposing, as commands 136 and 137, a special “noop” command that leaves the state unchanged. (It does this by executing phase 2 of instances 136 and 137 of the consensus algorithm.) Once these no-op commands have been chosen commands 138–140 can be executed. Commands 1–140 have now been chosen. The leader has also completed phase 1 for all instances greater than 140 of the consensus algorithm, and it is free to propose any value in phase 2 of those instances. It assigns command number 141 to the next command requested by a client, proposing it as the value in phase 2 of instance 141 of the consensus algorithm. It proposes the next client command it receives as command 142, and so on. The leader can propose command 142 before it learns that its proposed command 141 has been chosen. It’s possible for all the messages it sent in proposing command 141 to be lost, and for command 142 to be chosen before any other server has learned what the leader proposed as command 141. When the leader fails to receive the expected response to its phase 2 messages in instance 141, it will retransmit those messages. If all goes well, its proposed command will be chosen. However, it could fail first, leaving a gap in the sequence of chosen commands. In general, suppose a leader can get α commands ahead—that is, it can propose commands i + 1 through i +α after commands 1 through i are chosen. A gap of up to α−1 commands could then arise. A newly chosen leader executes phase 1 for infinitely many instances of the consensus algorithm—in the scenario above, for instances 135–137 and all instances greater than 139. Using the same proposal number for all instances, it can do this by sending a single reasonably short message to the other servers. In phase 1, an acceptor responds with more than a simple OK only if it has already received a phase 2 message from some proposer. (In the scenario, this was the case only for instances 135 and 140.) Thus, a server (acting as acceptor) can respond for all instances with a single reasonably short message. Executing these infinitely many instances of phase 1 therefore poses no problem. Since failure of the leader and election of a new one should be rare events, the effective cost of executing a state machine command—that is, of achieving consensus on the command/value—is the cost of executing only phase 2 of the consensus algorithm. It can be shown that phase 2 of the Paxos consensus algorithm has the minimum possible cost of any algorithmfor reaching agreement in the presence of faults [2]. Hence, the Paxos algorithm is essentially optimal. This discussion of the normal operation of the system assumes that there is always a single leader, except for a brief period between the failure of the current leader and the election of a new one. In abnormal circumstances, the leader election might fail. If no server is acting as leader, then no new commands will be proposed. If multiple servers think they are leaders, then they can all propose values in the same instance of the consensus algorithm, which could prevent any value from being chosen. However, safety is preserved—two different servers will never disagree on the value chosen as the ith state machine command. Election of a single leader is needed only to ensure progress. If the set of servers can change, then there must be some way of determining what servers implement what instances of the consensus algorithm. The easiest way to do this is through the state machine itself. The current set of servers can be made part of the state and can be changed with ordinary state-machine commands. We can allow a leader to get α commands ahead by letting the set of servers that execute instance i + α of the consensus algorithm be specified by the state after execution of the i th state machine command. This permits a simple implementation of an arbitrarily sophisticated reconfiguration algorithm. References[1] Michael J. Fischer, Nancy Lynch, and Michael S. Paterson. Impossibility of distributed consensus with one faulty process. Journal of the ACM, 32(2):374–382, April 1985. [2] Idit Keidar and Sergio Rajsbaum. On the cost of fault-tolerant consensus when there are no faults—a tutorial.TechnicalReport MIT-LCS-TR-821, Laboratory for Computer Science, Massachusetts Institute Technology, Cambridge, MA, 02139, May 2001. also published in SIGACT News 32(2) (June 2001). [3] Leslie Lamport. The implementation of reliable distributed multiprocess systems. Computer Networks, 2:95–114, 1978. [4] Leslie Lamport. Time, clocks, and the ordering of events in a distributed system. Communications of the ACM, 21(7 :558–565, July 1978. [5] Leslie Lamport. The part-time parliament. ACM Transactions on Computer Systems, 16(2):133–169, May 1998. 其他资料","categories":[],"tags":[],"keywords":[]},{"title":"[译文]The Design of a Practical System for Fault-Tolerant VirtualMachines","slug":"2021-02-12-The-Design-of-a-Practical-System-for-Fault-Tolerant-Virtual-Machines","date":"2021-02-12T00:00:00.000Z","updated":"2022-09-12T16:24:32.291Z","comments":true,"path":"2021-02-12-The-Design-of-a-Practical-System-for-Fault-Tolerant-Virtual-Machines/","link":"","permalink":"https://riverferry.site/2021-02-12-The-Design-of-a-Practical-System-for-Fault-Tolerant-Virtual-Machines/","excerpt":"又挖了个坑，还是个大坑，不知道两天能挖完不。愚公竟是我自己？","text":"又挖了个坑，还是个大坑，不知道两天能挖完不。愚公竟是我自己？ AbstractWe have implemented a commercial enterprise-grade system for providing fault-tolerant virtual machines, based on the approach of replicating the execution of a primary virtual machine (VM) via a backup virtual machine on another server. We have designed a complete system in VMware vSphere 4.0 that is easy to use, runs on commodity servers, and typically reduces performance of real applications by less than 10%. Our method for replicating VM execution is similar to that described in Bressoud [3], but we have made a number of significant design changes that greatly improve performance. In addition, an easy-to-use, commercial system that automatically restores redundancy after failure requires many additional components beyond replicated VM execution. We have designed and implemented these extra components and addressed many practical issues encountered in supporting VMs running enterprise applications. In this paper, we describe our basic design, discuss alternate design choices and a number of the implementation details, and provide an evaluation of our performance for both micro-benchmarks and real applications. 我们已经实现了一个支持容错虚拟机的商用企业级系统，基于通过在另一个服务器上的备份虚拟机复制执行主虚拟机的方法。我们已经在VMware vSphere 4.0上实现了一个易于使用的完整的系统，这个系统运行在商用服务器上，并且通常会降低实际应用的性能少于10%.我们复制VM执行的方法和Bressoud描述的是相似的，但是我们做了很多重要的设计选择来极大的提高了性能。另外，一个在故障后能自动恢复冗余的易于使用的商用系统需要许多在复制的虚拟机上的额外组件。我们已经设计并实现了这些额外的组件，并且也遇到了一些实际的问题在支持虚拟机运行企业应用的时候。在这篇文章，我们会描述我们的基础设计，并讨论替代的选择和许多实现的细节，也提供了在micro-benchmarks和实际应用上的性能评估。 Key Words and Phrases: virtual machines, fault tolerance, deterministic replay 关键词和短语：虚拟机，容错，确定性重放 1 IntroductionA common approach to implementing fault-tolerant servers is the primary/backup approach [1], where the execution of a primary server is replicated by a backup server. Given that the primary and backup servers execute identically, the backup server can take over serving client requests without any interruption or loss of state if the primary server fails. One method for replicating servers is sometimes referred to as the state-machine approach [13]. The idea is to model the servers as deterministic state machines that are kept in sync by starting them from the same initial state and ensuring that they receive the same input requests in the same order. Since most servers or services have some operations that are not deterministic, extra coordination must be used to ensure that a primary and backup are kept in sync. 一个常用的实现容错服务的方法是主/备份，即主服务上的运行在备份服务上复制运行。如果主服务故障了，备份服务能够接管客户端的请求，而没有任何中断或状态的丢失。复制服务的方法也称为状态机方法。思想是将服务器建模为确定性状态机，通过按照相同初始化状态启动和以相同的顺序接受相同的输入请求来保持同步。因为大多数的服务器或者服务都有一些不确定性的操作，必须通过额外的协作来保证主备之间的同步。 Implementing coordination to ensure deterministic execution of physical servers [14] is difficult, particularly as processor frequencies increase and clock synchronization becomes more difficult. In contrast, a virtual machine (VM) running on top of a hypervisor is an excellent platform for implementing the primary/backup approach. A VM can be considered a well-defined state machine whose operations are the operations of the machine being virtualized (including all its devices). As with physical servers, VMs have some non-deterministic operations (e.g. reading a time-of-day clock or delivery of an interrupt), and so extra information must be sent to the backup to ensure that it is kept in sync. Since the hypervisor has full control over the execution of a VM, including delivery of all inputs, the hypervisor is able to capture all the necessary information about non-deterministic operations on the primary VM and to replay these operations correctly on the backup VM. 实现协作来保证物理服务器的完全确定性执行是困难的，特别是随着处理器频率增加和时钟同步变的困难。作为对比，运行在虚拟机监视器顶层的虚拟机是实现主/备份方法的极好的平台。VM可以被认为是良好定义的状态机，其操作是虚拟化(包括所有设备)的机器的操作。和物理服务器一样，VM也有一些不确定的操作(例如读取一个时钟时间或者中断传递),并且这些额外信息必须发送给备份机来保证主从同步。因为虚拟机监视器对于虚拟机执行有完全的控制权，包括输入数据的传递，所以虚拟机监视器能够捕获所有主虚拟机上涉及的非确定性操作的有效信息，然后在备份虚拟机上正确的重放这些操作。 A system of replication based on virtual machines can replicate individual VMs, allowing some VMs to be replicated and fault-tolerant, while other VMs are not replicated. In addition, technology based on VMs does not require hardware modifications, allowing the system to ride the hardware performance improvement curve of newer microprocessors. A system based on replicated execution of physical servers requires hardware modifications and thus often lags behind the performance curve. Yet another advantage of virtual machines for this application is the possibility of physical separation of the primary and the backup:for example, the replicated virtual machines can be run on physical machines distributed across a campus, which provides more reliability than a primary/backup system running in the same building. 基于虚拟机的备份系统可以备份单个VM,这允许在一些Vm不被备份的时候，还有部分Vm会被备份和容错。另外，基于的Vm的即使不需要修改硬件，这让系统能够驾驭新的微处理器来改进硬件性能。运行在物理服务器上的备份系统需要修改硬件，因此经常滞后于性能曲线。虚拟机对于应用的另一个优点是能够物理分离主机和备机：比如，备份的虚拟机可以运行在园区内分离的物理机上，这提供了比运行在同一建筑下的主备机更好的可靠性。 We have implemented fault-tolerant VMs using the primary/backup approach on the VMware vSphere 4.0 platform, which runs fully virtualized x86 virtual machines in a highly efficient manner. Since VMware vSphere implements a complete x86 virtual machine that can run all operating systems and applications that run on an x86 platform, we are automatically able to provide fault tolerance for any x86 operating systems and applications. The base technology that allows us to record the execution of a primary and ensure that the backup executes identically is known as deterministic replay [15]. VMware vSphere Fault Tolerance (FT) is based on deterministic replay, but adds in the necessary extra protocols and functionality to build a complete fault-tolerant system. In addition to providing hardware fault tolerance, our system restores redundancy by automatically starting a new backup virtual machine on any available server in the local cluster. At this time, the production versions of both deterministic replay and VMware FT support only uni-processor VMs. Recording and replaying the execution of a multi-processor VM is still work in progress, with significant performance issues because nearly every access to shared memory can be a non-deterministic operation. 我们已经在VMware vSphere4.0平台上使用主/备份的方法实现了容错虚拟机，可以高效运行在完全虚拟化的x86平台的虚拟机上。因为Vmware vSphere实现了可以运行所有基于X86平台的操作系统和应用的x86虚拟机，所以我们能够提供对于所有x86的操作系统，应用的容错能力。基础的技术让我们能够记录主机的执行并确保备机相同的执行，这称之为确定性重放。Vmware vSphere的容错是基于确定性重放的，但是为了建立一个完整的容错系统增加了必要的额外的协议和功能。另外为了提供硬件容错，我们的系统能够通过在本地集群的任何可用服务器上开启一个新的虚拟机来自动的回复冗余。现在，确定性重放和VMware FT的版本仅支持单处理器的虚拟机。记录并重放多处理器的虚拟机的执行仍在开发中，一个很重要的性能问题是几乎每一个对于共享内存的访问都会是一个不确定性的操作。 Bressoud [3] describes a prototype implementation of fault-tolerant VMs for the HP PARISC platform. Our approach is similar, but we have made some fundamental changes for performance reasons and investigated a number of design alternatives. In addition, we have had to design and implement many additional components in the system and deal with a number of practical issues to build a complete system that is efficient and usable by customers running enterprise applications. Similar to most other practical systems discussed, we only attempt to deal with fail-stop failures [12], which are server failures that can be detected before the failing server causes an incorrect externally visible action. Bressoud描述了对于HP PARISC平台的容错虚拟机的原型实现。这和我们的方法是相似的，但出于性能原因我们做出了一些根本改变并调查了一系列的可替代方案。另外，为了建立一个能够由顾客运行在企业应用上的高效可以用的完整系统，我们设计并实现了许多额外的系统组件，并且处理了一系列的实际问题。和讨论的大多数其他的实际系统相似，我们只尝试解决fail-stop故障，fail-stop故障是服务器故障可以在故障的服务器引起不正确的外部不可见行为之前被检测到。 The rest of the paper is organized as follows. First, we describe our basic design and detail our fundamental protocols that ensure that no data is lost if a backup VM takes over after a primary VM fails. Then, we describe in detail many of the practical issues that must be addressed to build a correct, robust, fully-functioning, and automated system. We also describe several design choices that arise for implementing fault-tolerant VMs and discuss the tradeoffs in these choices. Next, we give performance results for our implementation for some benchmarks and some real enterprise applications. Finally, we describe related work and conclude. 这篇论文的其余部分安排如下。首先，我们描述了我们的基础设计并详细介绍我们的基础协议，基础协议确保主机故障后由备机接管的时候没有数据丢失。然后，我们详细描述为建立一个正确的，健壮的，完整功能的，自动的系统必然会遇到的问题。我们还会描述一些为实现容错虚拟机会遇到的一些设计选择，讨论对这些选择的权衡。接着，我们提供我们的实现在一些benchmarks和一些实际企业应用上的性能表现。最后，我们会介绍相关的工作和结论。 2 Basic FT DesignFigure 1 shows the basic setup of our system for fault-tolerant VMs. For a given VM for which we desire to provide fault tolerance (the primary VM), we run a backup VM on a different physical server that is kept in sync and executes identically to the primary virtual machine, though with a small time lag. We say that the two VMs are in virtual lockstep. The virtual disks for the VMs are on shared storage (such a Fibre Channel or iSCSI disk array), and therefore accessible to the primary and backup VM for input and output. (We will discuss a design in which the primary and backup VM have separate non-shared virtual disks in Section 4.1.) Only the primary VM advertises its presence on the network, so all network inputs come to the primary VM. Similarly, all other inputs (such as keyboard and mouse) go only to the primary VM. 图1展示了我们容错虚拟机系统的基础设置。给定一个我们想要用来提供容错的虚拟机(成为主机)，我们会在不同的物理服务器上运行一个备机，备机通过和主机一样的执行来保持同步，不过会有一点延迟。我们称主机和备机是帧同步的。虚拟机的虚拟磁盘在共享存储上(比如光纤通道或者iSCSI磁盘阵列)，因此主机和备机访问共享存储用于输入和输出。(我们将在4.1节讨论，主机和备机在不同的非共享的虚拟磁盘上的设计)。只有主机参与网络交互，所以所有通过网络的输入都发给了主机。类似的，所有其他的输入(比如键盘或者鼠标)也只发给了主机。 All input that the primary VM receives is transmitted to the backup VM via a network connection known as the logging channel. For server workloads, the dominant input traffic is network and disk. Additional information, as discussed below in Section 2.1, is transmitted as necessary to ensure that the backup VM executed non-deterministic operations in the same way as the primary VM. The end result is that the backup VM always executes identically to the primary VM. However, the outputs of the backup VM are always dropped by the hypervisor, so only the primary produces actual outputs that are returned to clients. As described in Section 2.2, the primary and backup VM must follow a specific protocol, including explicit acknowledgments by the backup VM, in order to ensure that no data is lost if the primary fails. 所有主机接收的输入会被传输给备机，通过称为日志通道的网络连接。对于服务器工作负载，主要的输入流量来自网络和磁盘。我们在2.1节的下面部分将要讨论的额外信息必要时也会被传输给备机，来确保备机以和主机相同的方式运行不确定性操作。所以最后备机总是和主机以相同的方式运行。然而，备机的输出总是会被虚拟机管理程序丢弃，所以只有主机会产生实际的返回给客户端的输出。如2.2节描述的，主机和备机必须遵从特定的协议，包括备机的显式确认，为了保证主机故障的时候没有数据丢失。 A crucial issue that is not discussed much in previous work is the actual process of determining quickly whether a primary or backup VM has failed. Our system uses a combination of heartbeating between the relevant servers and monitoring of the traffic on the logging channel. In addition, we must ensure that only one of the primary or backup VM takes over execution, even if there is a split-brain situation where the primary and backup servers have lost communication with each other. 一个前面没有过多讨论的关键问题是快速判断哪个主机，备机故障的处理过程。我们的系统使用相关服务器和日志通道上流量监控程序的心跳包的关联。另外，我们必须确保只有一个主机或备机接管执行，即使在主机和备机失联导致脑裂的情况。 In the following sections, we provide more details on several important areas. In Section 2.1, we give some details on the deterministic replay technology that ensures that primary and backup VMs are kept in sync via the information sent over the logging channel. In Section 2.2, we describe a fundamental rule of our FT protocol that ensures that no data is lost if the primary fails. In Section 2.3, we describe our methods for detecting and responding to a failure in a correct fashion. 在下面的章节中，我们提供对于几个重要领域更多的细节。在2.1节，我们描述对于确定性重放技术的更多细节，确定性重放即使保证主机和备机通过日志通道发送信息来保持同步。在2.2节，我们描述我们容错协议的基础规则，容错协议保证主机故障的时候没有数据丢失。在2.3节，我们描述我们以正确方式来检测和响应故障的方法。 2.1 Record-Replay ImplementationAs we have mentioned, replicating servers (or VMs) can be modeled as the replication of deterministic state machines. If two deterministic state machines are started in the same initial state and provided the exact same inputs in the same order, then they will go through the same sequences of states and produce the same outputs. In the simplest case, one state machine is the primary, and the other is the backup. If all the inputs go to the primary, then the inputs can be distributed to the backup from the primary via a logging channel. A useful physical computer, when considered as a state machine, has a broad set of inputsranging from a keyboard device to network input received from a client. In addition, nondeterministic events like virtual interrupts, and non-deterministic operations like reading the clock cycle counter from the processor, affect the state machine. This presents three challenges to a practical hypervisor capable of running any operating system that can run on a physical machine: (1) correctly capturing all the input and non-determinism necessary to ensure deterministic execution of a backup virtual machine, (2) correctly applying the inputs and non-determinism to the backup virtual machine, and (3) doing so in a manner that doesn’t degrade performance. 如前所述，备份服务器(或备份虚拟机)可以被建模为确定性状态机的备份。如果两个确定性状态机以相同的初始状态启动并提供相同次序的完全相同的输入，则它们将经过相同的状态顺序并产生相同的输出。在最简单的情况，一个状态机是主，另一个是备。如果所有的输入都到达主，则输出可通过日志通道从主分发给备机。一个有用的物理计算机，作为状态机的时候，有广泛的输入范围，从键盘设备到来自客户端的网络输入。另外，不确定的事件比如虚拟中断，和不确定性操作像是从处理器读取时钟周期计数器，会影响状态机。这给实际的虚拟机管理程序在物理机上运行任何操作系统的能力带来了3个挑战：(1) 正确的捕获所有输入和必要的不确定性来保证备机的确定性执行(2) 正确的应用输入和不确定性给备机(3) 以不降低性能的方式进行 VMware deterministic replay [15] provides exactly this functionality for x86 virtual machines on the VMware vSphere platform. Deterministic replay allows the inputs of a VM and all possible non-determinism associated with the VM execution to be recorded via a stream of log entries written to a log file. The VM execution may be replayed later exactly by reading the log entries from the file. Non-deterministic state transitions can either result from explicit operations executed by the VM that have non-deterministic results (such as reading the time-of-day clock), or asynchronous events (such as interrupts) which create non-determinism because the point at which they interrupt the dynamic instruction stream affects the virtual machine execution. Vmware确定性重放正是为VMware vSphere平台上的x86虚拟机提供了此功能。确定性重放允许虚拟的输入和所有与虚拟机执行相关联的可能的不确定性能够通过写到日志文件的日志项的流记录下来。通过读取日志文件的日志项，可以在稍后准确的回访虚拟机的执行。不确定性状态转换可能是由有不确定性结果(比如读取time-of-day的时钟)的虚拟机的显式操作导致，也可能由异步的事件(比如中断)导致。这两种会导致不确定状态是因为它们打断动态指令流的时候会影响虚拟机的执行。 For non-deterministic operations, sufficient information must be logged to allow the operation to be reproduced with the same state change and output when replaying. For nondeterministic events such as timer interrupts or IO completion interrupts, the exact instruction at which the event occurred must also be recorded. During replay, the event must be delivered at the exact same point in the instruction stream. VMware deterministic replay implements an efficient event recording and event delivery mechanism that employs various techniques, including the use of hardware performance counters developed in conjunctionwith AMD [2] and Intel [8]. 对于不确定性操作，充足的信息必须被日记记录下来，来让重放的时候操作可以按照相同的状态改变和输出被重置。对于不确定性的事件比如时钟中断或者IO完成中断，还必须记录事件发生的确切指令。在重放期间，必须在指令流的同一时间点传递事件。VMware确定性重放实现了一个有效的事件记录和事件传递机制，该机制使用了多种技术，包括由amd和intel联合开发的硬件性能计数器。 Bressoud [3] mentions dividing the execution of VM into epochs, where non-deterministic events such as interrupts are only delivered at the end of an epoch. The notion of epoch seems to be used as a batching mechanism because it is too expensive to deliver each interrupt separately at the exact instruction where it occurred. However, our event delivery mechanism is efficient enough that VMware deterministic replay has no need to use epochs. The occurrence of each interrupt is recorded and logged as it occurs and efficiently delivered at the appropriate instruction while being replayed. Bressoud提到了将虚拟机的执行分为epochs(阶段？时期？)，不确定性事件比如中断只在最后的epoch传递。epoch被用于批处理机制，因为在中断发生的时候分别传递每一个中断在对应的指令是代价很高的。然而，我们的事件传递机制是足够有效的，所以VMware确定性重放不需要使用epochs.每一个中断的发生都可以被记录并写到日志，并有效的传递给适当的指令，在重放的时候。 2.2 FT ProtocolFor VMware FT, we use deterministic replay to produce the necessary log entries to record the execution of the primary VM, but instead of writing the log entries to disk, we send them to the backup VM via the logging channel. The backup VM replays the entries in real time, and hence executes identically to the primary VM. However, we must augment the logging entries with a strict FT protocol on the logging channel in order to ensure that we achieve fault tolerance. Our fundamental requirement is the following: 对于VMware容错，我们使用确定性重放来产生必要的日志项纪录主机的执行，但是不是将日志项写入磁盘，而是通过日志通道将日志项发送给备机。备机实时回放日志项，因此备机可以和主机有相同的执行。但是，为了容错，我们必须通过在日志通道上的严格的容错协议。基础协议有下面这些要求： Output Requirement: if the backup VM ever takes over after a failure of the primary, the backup VM will continue executing in a way that is entirely consistent with all outputs that the primary VM has sent to the external world. 输出要求： 如果备机在主机故障后接管，备机将以和主机已经发送发送给外部世界输出完全一致性的继续运行。 Note that after a failover occurs (i.e. the backup VM takes over after the failure of the primary VM), the backup VM will likely start executing quite differently from the way the primary VM would have continued executing, because of the many non-deterministic events happening during execution. However, as long as the backup VM satisfies the Output Requirement, no state or data is lost during a failover to the backup VM, and the clients will notice no interruption or inconsistency in their service. 注意，在故障转移发生(备机在主机故障后接管)之后，备机可能以和主机继续执行的方式完全不同的方式启动执行，因为许多不确定性事件在执行期间发生。然而，只要备机满足输出要求，就不会有任何状态和数据在故障转移给备机的时候丢失，并且客户端不会看到服务端有中断和不一致性的现象。 The Output Requirement can be ensured by delaying any external output (typically a network packet) until the backup VM has received all information that will allow it to replay execution at least to the point of that output operation. One necessary condition is that the backup VM must have received all log entries generated prior to the output operation. These log entries will allow it to execute up to the point of the last log entry. However, suppose a failure were to happen immediately after the primary executed the output operation. The backup VM must know that it must keep replaying up to the point of the output operation and only “go live” (stop replaying and take over as the primary VM, as described in Section 2.3) at that point. If the backup were to go live at the point of the last log entry before the output operation, some non-deterministic event (e.g. timer interrupt delivered to the VM) might change its execution path before it executed the output operation. 输出要求可以通过延迟所有外部输出(通常是网络包)直到备机已经接受了所有信息(允许备机重放到至少输出操作的时刻)的时候。一个必要的条件是备机必须已经接收了所有的输出操作事先生成的日志项。这些日志项能够让备机执行到最后的日志项的时刻。然而，如果一个故障在主机执行输出操作的时候立刻发生。备机必须知道它必须一直重放到输出操作的时刻然后在那个时刻仅仅上线(停止重放并接管主机，像2.3节描述的那样)。如果备机在输出操作之前的最后的日志项的时刻上线，一些不确定性事件(比如传递给虚拟机的时钟中断)可能改变执行路径，在执行输出操作之前。 Given the above constraints, the easiest way to enforce the Output Requirement is to create a special log entry at each output operation. Then, the Output Requirement may be enforced by this specific rule: 鉴于上面的约束，执行输出要求的最简单方式是对每一个输出操作创建一个特殊的日志项。然后，输出要求可以通过这些特殊的规则被执行： Output Rule: the primary VM may not send an output to the external world, until the backup VM has received and acknowledged the log entry associated with the operation producing the output. 输出规则：主机直到备机接收被确认了和产生输出相关联的日志项的时候，才发送输出给外部世界。 If the backup VM has received all the log entries, including the log entry for the outputproducing operation, then the backup VM will be able to exactly reproduce the state of the primary VM at that output point, and so if the primary dies, the backup will correctly reach a state that is consistent with that output. Conversely, if the backup VM takes over without receiving all necessary log entries, then its state may quickly diverge such that it is inconsistent with the primary’s output. The Output Rule is in some ways analogous to the approach described in [11], where an “externally synchronous” IO can actually be buffered, as long as it is actually written to disk before the next external communication. 如果备机已经接收了所有的日志项，包括输出产生操作的日志项，那么备机将能够准确的重现在该输出点上的主机的状态，即使主机宕了，备机仍能够正确的达到和该输出一致的状态。相反，如果备机在没有接收到所有必要的日志项的时候就接管了主机，则备机的状态可能很快偏离到和主机输出不一致的状态。输出规则在某些方面和[11]提到的方法是类似的，其中外部同步IO可以被缓冲，只要在下一次外部通信前写入磁盘。 Note that the Output Rule does not say anything about stopping the execution of the primary VM. We need only delay the sending of the output, but the VM itself can continue execution. Since operating systems do non-blocking network and disk outputs with asynchronous interrupts to indicate completion, the VM can easily continue execution and will not necessarily be immediately affected by the delay in the output. In contrast, previous work [3, 9] has typically indicated that the primary VM must be completely stopped prior to doing an output until the backup VM has acknowledged all necessary information from the primary VM. 注意输出规则没有说任何要通知主机执行的事情。我们只需要延迟发送输出，但是虚拟机可以继续执行。因为操作系统通过异步中断来非阻塞的表示网络和磁盘输出的完成，所以虚拟机只需要继续执行，并且不一定会立即受到输出延迟的影响。相反，先前的工作[3,9]通常表明在完成输出之前主机必须完全停止，直到备机已经确认了所有来自主机的必要信息。 As an example, we show a chart illustrating the requirements of the FT protocol in Figure 2. This figure shows a timeline of events on the primary and backup VMs. The arrows going from the primary line to the backup line represent the transfer of log entries, and the arrows going from the backup line to the primary line represent acknowledgments. Information on asynchronous events, inputs, and output operations must be sent to the backup as log entries and acknowledged. As illustrated in the figure, an output to the external world is delayed until the primary VM has received an acknowledgment from the backup VM that it has received the log entry associated with an output operation. Given that the Output Rule is followed, the backup VM will be able to take over in a state consistent with the primary’s last output. There will be no loss of state even if the primary has had a non-deterministic event since its last output. 作为例子，我们在图2中展示了一个图表说明容错协议的要求。该图展示了主机和备机上事件的时间线。主机线到备机线的箭头表示日志项的传输，备机线到主机线的箭头表示确认。异步事件的信息，输入，和输出操作都必须被发送给备机，以日志项的方式，然后由备机确认。如图中说明的那样，对于外部世界的输出会被延迟到主机已经接收到来自备机的确认信息，在备机收到和输出操作相关联的日志项的时候会进行确认。如果输出规则得以遵守，备机将能够以和主机最后输出一致性的状态进行接管。 As indicated in [3, 9], we can not guarantee that all outputs are produced exactly once in a failover situation. Without the use of transactions with two-phase commit when the primary intends to send an output, there is no way that the backup can determine if a primary crashed immediately before or after sending its last output. Fortunately, the network infrastructure (including the common use of TCP) is designed to deal with lost packets and identical (duplicate) packets. 如[3,9]所表示的，我们不能保证所有的输出都只被生成一次在故障转移的情况下。在主机尝试发送输出的时候不适用两阶段提交事务的话，就没有办法让备机判断主机是在崩溃之前还是之后发送了最后的输出。幸运的是，网络基础设施(包括常用的tcp)被设计为能够处理丢包和重包。 Note that incoming packets to the primary may also be lost during a failure of the primary and therefore won’t be delivered to the backup. However, incoming packets may be dropped for any number of reasons unrelated to server failure, so the network infrastructure, operating systems, and applications are all written to ensure that they can compensate for lost packets. 注意，传给主机的数据包在主机故障的时候也可能丢失因而不能被传递给备机。然而，传入的数据包可能出于一系列和服务器故障不相关的原因被丢弃，所以网络基础设施，操作系统和应用都被写入(意思应该是都要适配这个情况？ )来确保可以对丢失的包进行补偿 2.3 Detecting and Responding to FailureAs mentioned above, the primary and backup VMs must respond quickly if the other VM appears to have failed. If the backup VM fails, the primary VM will go live – that is, leave recording mode (and hence stop sending entries on the logging channel) and start executing normally. If the primary VM fails, the backup VM should similarly go live, but the process is a bit more complex. Because of its lag in execution, the backup VM will likely have a number of log entries that it has received and acknowledged, but have not yet been consumed because the backup VM hasn’t reached the appropriate point in its execution yet. The backup VM must continue replaying its execution from the log entries until it has consumed the last log entry. At that point, the backup VM will stop replaying mode and start executing as a normal VM. In essence, the backup VM has been promoted to the primary VM (and is now missing a backup VM). Since it is no longer a backup VM, the new primary VM will now produce output to the external world when the guest OS does output operations. During the transition to normal mode, there may be some device-specific operations needed to allow this output to occur properly. In particular, for the purposes of networking, VMware FT automatically advertises the MAC address of the new primary VM on the network, so that physical network switches will know on what server the new primary VM is located. In addition, the newly promoted primary VM may need to reissue some disk IOs (as described in Section 3.4). 如前面提到的那样，主机和备机必须在另一方故障的时候快速响应。如果备机故障，主机将会上线-指的是离开记录模式(因此停止在日志通道上发送日志项)并开始正常运行。如果主机故障，备机也会上线，但是处理会更加复杂一点。因为备机是延迟执行的，备机可能有一系列它已经接受和确认的的日志项，但是还没被消费完因为备机还没达到运行的合适时间点。备机必须继续重放来自日志项的运行知道消费完最后的日志项。然后备机将会停止重放模式然后开始正常运行，像普通虚拟机那样。本质上，备机已经被晋升为了主机(现在没有备机了)。因为已经不是备机了，新的主机将在guest os(运行在虚拟机上的操作系统)有输出操作的时候产生输出给外部世界。在过渡为正常模式的期间，可能会需要一些特定设备的操作来让输出正确发生。特别的，出于联网的目的，VMware容错会自动将新的主机的mac地址在网络进行通告，所以物理网络交换机将能够得知新的主机服务器的位置。另外，新的晋升的主机可能需要重发一些磁盘IO(像3.4节描述的那样) There are many possible ways to attempt to detect failure of the primary and backup VMs. VMware FT uses UDP heartbeating between servers that are running fault-tolerant VMs to detect when a server may have crashed. In addition, VMware FT monitors the logging traffic that is sent from the primary to the backup VM and the acknowledgments sent from the backup VM to the primary VM. Because of regular timer interrupts, the logging traffic should be regular and never stop for a functioning guest OS. Therefore, a halt in the flow of log entries or acknowledgments could indicate the failure of a VM or a networking problem. A failure is declared if heartbeating or traffic on the logging channel has stopped for longer than a specific timeout (on the order of a few seconds). 对于尝试检测主机和备机故障有许多可能的方式。VMware容错使用运行在容错虚拟机上的服务器间的udp心跳包来检测哪台服务器已经宕掉了。另外，VMware容错监控从主机发给备机的日志和从备机发送给主机的确认信息的流量。因为经常的时钟中断，日志流量应该是规律的并且永远不会在guest os上停止。因此，日志项和确认信息流的暂停可能表明虚拟机或者网络问题引起的故障。如果心跳包或者日志通道流量停止了超过指定的超时时间(大约几秒钟)则表明这是故障 However, any such failure detection method is susceptible to a split-brain problem. If the backup server stops receiving heartbeats from the primary server, that may indicate that the primary server has failed, or it may just mean that all network connectivity has been lost between still functioning servers. If the backup VM then goes live while the primary VM is actually still running, there will likely be data corruption and problems for the clients communicating with the VM. Hence, we must ensure that only one of the primary or backup VM goes live when a failure is detected. To avoid split-brain problems, we make use of the shared storage that is used to store the virtual disks of the VM. At the point where either a primary or backup VM wants to go live, it executes an atomic test-and-set operation on the shared storage. If the operation succeeds, the VM is allowed to go live. If the operation fails, then the other VM must have already gone live, so the current VM actually halts itself (“commits suicide”). If the VM cannot access the shared storage when trying to do the atomic operation, then it just waits until it can. Note that if shared storage is not accessible because of some failure in the storage network, then the VM would likely not be able to do useful work anyway because the virtual disks reside on the same shared storage. Thus, using shared storage to resolve split-brain situations does not introduce any extra unavailability. 然而，任何这类故障检测方法都容易收到脑裂问题的影响。如果备机停止从主机接收心跳包，可能意味着主机故障了，也可能只是因为仍在运行的服务器间的所有网络连接都丢失了。如果备机接着在主机仍旧运行的情况下上线，这可能引起数据损坏或者客户端与虚拟机通信的问题。因此，我们必须确保只有一台主机或备机上线，在故障被检测到的时候。为了避免脑裂的问题，我们使用用来存储虚拟机虚拟磁盘的共享存储。在主机或备机想上线的时候，在共享存储上执行一个原子的test-and-set锁指令。如果操作指令成功，则虚拟机可以上线。如果指令失败，则另外的虚拟机肯定仍在运行，所以当前的虚拟机实际上会结束运行(提交suicide).如果虚拟机无法访问共享存储，在尝试做原子操作指令的时候，只需要一直等到可以访问的时候。记住如果共享存储因为一些存储网络故障导致不能访问，那么虚拟机可能无论如何都不能正常工作，因为虚拟机磁盘也在共享存储上面。因此，使用共享存储来解决脑裂问题不会带来任何额外的不可用 One final aspect of the design is that once a failure has occurred and one of the VMs has gone live, VMware FT automatically restores redundancy by starting a new backup VM on another host. Though this process is not covered in most previous work, it is fundamental to making fault-tolerant VMs useful and requires careful design. More details are given in Section 3.1. 该设计的最后一个方面是一旦故障已经发生了并且其中一个虚拟机已经上线了，VMware容错会自动通过在另外主机上启动新的备机来恢复冗余。即使前面大部分没有提及这个过程，但是这一点对于实现有用的容错系统是基础的，并且需要仔细设计。更多的细节见3.1节。 2.4 Go-live PointsThe use of deterministic replay for fault tolerance purposes has driven us to add an interesting mechanism to our replay implementation. Because of network issues or the failure of the primary at any point, the stream of log entries being read and replayed by the backup can be terminated at any point. The possibility of termination at any point in the log can permeate the deterministic replay implementation, since each potential consumer of a log entry (such as a virtual device implementation) would need to check for and deal with the fact that an expected log entry is not available. For instance, given previous log entries and its current state, a virtual device implementation may expect a number of additional log entries about IO completions. The code that is replaying the device will have to be written to check for the end of the log stream, exit some possibly complex replaying code, and restore the device to a reasonable state so that the VM can go live. 为了容错使用的确定性重放驱使我们在我们的重放实现中增加了一种有趣的机制。因为会有网络问题以及主机故障可能发生在任何时刻，由备机正在读取或者重放的日志项流也可能在任何时刻终止。日志项在任何时刻终止的可能性会扩散到确定性重放的实现，因为每一个日志项(比如一个虚拟的设备实现)的潜在消费者都需要检查和处理所需日志不可用的问题。比如，给定一个之前的日志项和它现在的状态，虚拟设备实现可能需要一系列有关IO实现的额外的日志项。需要编写重放部分的代码来检查日志流的结束，退出一些可能复杂的重放代码，回复设备到合理的状态，使之可以在虚拟机上go live. To alleviate this burden on many components of the system, we have implemented go-live points. Any individual log entry can be marked as a go-live point. The idea is that a log entry that is marked as a go-live point represents the last log entry in a series of log entries necessary for replaying an instruction or a particular device operation. If a particular operation or instruction requires several log entries to be recorded, then only the last log entry would be marked as a go-live point. In practice, the hypervisor automatically marks the last new log entry as a go-live point when it has completed all event and device processing for a given instruction. 为了减轻系统上多数组件的负担，我们已经实现了go-live points.任何单个日志项都可以被标记为go-live points.思想是一个被标记为go-live point的日志项可以用来表示对于重放一个指令或者特别的设备操作必要的一系列日志项中的最后一个日志项。如果一个特别的操作或者指令需要一部分被记录的日志项，那么仅最后的日志项会被标记为go-live point.实际上，虚拟机管理程序会自动标记最后的一个新的日志项为go-live point,在它完成给定指令的所有事件和设备处理的时候。 Go-live points are used during replaying as follows. While all log entries read from the logging channel are buffered by the hypervisor on the virtual machine that is replaying, only the log entries up to the last go-live point are allowed to be consumed by the replaying (backup) VM. That is, the replaying VM will stall after consuming the last log entry tagged as a go-live point until another series of log entries containing a log entry with a go-live point has been fetched by the hypervisor. The result is that if there is a series of log entries associated with a device operation, the virtual device implementation can assume that all the needed log entries will be available if the first log entry is encountered. Thus, the virtual device implementation does not have to do all the extra checking and recovery code needed if the log entries could be terminated at any point. Similarly, whenever a single instruction executed on behalf of the virtual machine generates multiple log entries, the hypervisor of the replaying virtual machine begins the emulation of that instruction only if all the log entries necessary for completing the emulation of that instruction are available. The tagging scheme doesn’t introduce any significant delay of the replaying VM, since the hypervisor of the recording (primary) VM guarantees that last log entry of each single instruction emulation or a device operation is marked as a go-live point. Since the backup VM cannot be significantly delayed, the primary VM is also not affected by the use of go-live points. go-live points在重放期间的使用如下。当所有从日志通道读取的日志项都被虚拟机管理程序缓存在正在重放的虚拟机上。只有最后的go-live point之前的日志项可以被重放的备机消费。也就是说，正在重放的虚拟机在消费最后一个被标记为go-live point的日志项之后会停止运行直到一系列包含go-live point的日志项已经被虚拟机管理程序拉取。结果是如果有一系列和设备操作关联的日志项，如果虚拟设备实现遇到了第一个日志项，就可以假定所有需要的日志项都是可用的。因此，虚拟设备实现不需要做所有额外的检查和恢复代码，如果日志项可以在任何时刻终止。类似的，任何代表虚拟机执行的单个指令生成多个日志项的时候，重放虚拟机的虚拟机管理程序仅在所有的对于完成指令仿真有必要的日志项都是可用的时候，才开始指令的模拟。标记方案不会对正在重放的虚拟机带来任何明显的延迟，因此记录(primary)虚拟机的虚拟机管理程序保证每一个模拟指令或者设备操作的最后的日志项被标记为go-live point.因此备机不会有明显的延迟，主机也不会受到go-live point的影响。 3 Practical Implementation of FTSection 2 described our fundamental design and protocols for FT. However, to create a usable, robust, and automatic system, there are a great many other components that must be designed and implemented. 第2节描述了容错的基础设计和协议。但是为了创建一个可用的，健壮的自动化系统，还需要设计实现许多其他组件。 3.1 Starting and Restarting FT VMsOne of the biggest additional components that must be designed is the mechanism for starting a backup VM in the same state as a primary VM. This mechanism will also be used when restarting a backup VM after a failure has occurred. Hence, this mechanism must be usable for a running primary VM that is in an arbitrary state (i.e. not just starting up). In addition, we would prefer that the mechanism does not significantly disrupt the execution of the primary VM, since that will directly affect any current clients of the VM. 必须设计的最大的额外组件之一是以和主机相同的状态启动备机的机制。这个机制在故障发生重启备机的时候也会用到。因此，该机制对于运行任意状态(不仅仅是启动)的主机必须是可用的。另外，我们更希望该机制不会明显的打断主机的运行，因此这会影响到所有连接虚拟机的客户端。 For VMware FT, we adapted the existing VMotion functionality of VMware vSphere. VMware VMotion [10] allows the migration of a running VM from one server to another server with minimal disruption – VM pause times are typically less than a second. We created a modified form of VMotion that creates an exact running copy of a VM on a remote server, but without destroying the VM on the local server. That is, our modified FT VMotion clones a VM to a remote host rather than migrating it. The FT VMotion also sets up a logging channel, causes the source VM to enter logging mode as the primary, and the destination VM to enter replay mode as the new backup. Like normal VMotion, FT VMotion typically interrupts the execution of the primary VM by less than a second. Hence, enabling FT on a running VM is an easy, non-disruptive operation. 对于VMware容错系统，我们适配了VMware vSphere的现有Vmotion功能。VMware VMotion可以在最小化中断的代价下将运行的虚拟机从一台服务器迁移到另一台服务器-虚拟机的暂停时间通常小于1秒。我们创建了一个修改版的Vmotion，通过在远端服务器上创建一个精确的虚拟机的运行拷贝，而不需要摧毁本地服务器上的虚拟机。也就是说，修改版的容错Vmotion克隆一个虚拟机到远端服务器而不是迁移虚拟机。容错Vmotion也会建立一个日志通道，源虚拟机会作为主机进入日志模式，目的虚拟机作为新的备机进入重放模式。和普通版本的Vmotion一样，容错Vmotion通常打断主机的时间少于1秒。因此，在运行中虚拟机启用容错是简单，无中断的操作 Another aspect of starting a backup VM is choosing a server on which to run it. Faulttolerant VMs run in a cluster of servers that have access to shared storage, and so all VMs can typically run on any servers in the cluster. This flexibility allows VMware vSphere to restore FT redundancy even when one or more servers have failed. VMware vSphere implements a clustering service that maintains management and resource information. When a failure happens and a primary VM now needs a new backup VM to re-establish redundancy, the primary VM informs the clustering service that it needs a new backup. The clustering service determines the best server on which to run the backup VM based on resource allocations, usage, and other constraints. Then the clustering service automatically invokes an FT VMotion to create the new backup VM. Of course, there are many additional complexities, such as retrying if a first attempt to create a backup fails and automatically detecting when a server in the cluster becomes newly available. The end result is that VMware FT typically can re-establish VM redundancy within minutes of a server failure, all without any noticeable interruption in the execution of a fault-tolerant VM. 启动备机的另一个方面是选择哪台服务器来运行。容错虚拟机运行在访问共享存储的服务器集群上，因而所有的虚拟机是运行在集群中任意的服务器的。这种灵活性让VMware vSphere能够恢复容错冗余在一台或者多台服务器故障的时候。VMware vSphere实现了一个集聚服务来维护管理和资源信息。当故障发生而主机需要一个新的备机重建冗余的时候，主机会通知集聚服务它需要一个新的备机。集聚服务基于资源申请，使用和其他约束来选择运行备机的最佳服务器。然后集聚服务自动调用容错Vmotion来创建新的备机。当然，也有许多额外的复杂性，比如在第一次创建备机失败后的重试，和自动检测集群中服务器什么时候变为新的可用状态。最后的结果是VMware容错可以重建虚拟机冗余在服务器故障后几分钟，而不会对容错虚拟机执行有明显的打断。 3.2 Managing the Logging ChannelThere are a number of interesting implementation details in managing the traffic on the logging channel. In our implementation, the hypervisors maintain a large buffer for logging entries for the primary and backup VMs. As the primary VM executes, it produces log entries into the log buffer, and similarly, the backup VM consumes log entries from its log buffer. The contents of the primary’s log buffer are flushed out to the logging channel as soon as possible, and log entries are read into the backup’s log buffer from the logging channel as soon as they arrive. The backup sends acknowledgments back to the primary each time that it reads some log entries from the network into its log buffer. These acknowledgments allow VMware FT to determine when an output that is delayed by the Output Rule can be sent. Figure 3 illustrates this process. 管理日志通道的流量有一系列有趣的实现细节。在我们实现中，虚拟机管理程序维护了一个大的缓冲，保存了主机和备机的日志项。当主机运行的时候，会产生日志项到日志缓冲，类似的，备机从日志缓冲消费日志项。主机日志缓冲的内容会尽快刷到日志通道中，日志项写到日志缓冲后也会尽快读取到备机的日志缓冲中。备机发送确认信息给主机，在每一次通过网络读取一些日志项到日志缓冲的时候。这些确认信息让VMvare容错能够决定什么时候被输出规则延迟的输出可以被发送。图3说明了这个过程。 If the backup VM encounters an empty log buffer when it needs to read the next log entry, it will stop execution until a new log entry is available. Since the backup VM is not communicating externally, this pause will not affect any clients of the VM. Similarly, if the primary VM encounters a full log buffer when it needs to write a log entry, it must stop execution until log entries can be flushed out. This stop in execution is a natural flowcontrol mechanism that slows down the primary VM when it is producing log entries at too fast a rate. However, this pause can affect clients of the VM, since the primary VM will be completely stopped and unresponsive until it can log its entry and continue execution. Therefore, our implementation must be designed to minimize the possibility that the primary log buffer fills up. 如果备机在读取新的日志项的时候遇到了空的日志缓冲，则会停止运行知道日志项变为可用。因为备机不是在外部通信，这种暂停不会虚拟机的客户端有影响。相似的，如果主机在需要写入日志项的时候发现复制缓冲满了，也会停止运行知道日志项被清除了。主机的停止是自然的流控机制，可以在生成的日志项速率过快的时候降低速度。然而，这种暂停会影响虚拟机的客户端，因为主机会完全停止变为不响应知道可以写入日志继续运行的时候。因此，我们的实现必须设计为最小化主机日志缓冲满的可能性 One reason that the primary log buffer may fill up is because the bandwidth of the logging channel is too low to carry the volume of log entries being produced. While the bandwidth on the logging channel is typically not high (as seen in Section 5), we strongly recommend the use of a 1 Gbit/s network for the logging channel to avoid any possibility of a bottleneck. 主机日志缓冲满的一个原因是日志通道的带宽太小以至于无法承载正在生成的日志项的容量。因为日志通道的带宽通常不太高(见第5节)，我们强烈建议对于日志通道使用1Gbit/s的网络来避免网络瓶颈。 Another reason that the primary log buffer may fill up is because the backup VM is executing too slowly and therefore consuming log entries too slowly. In general, the backup VM must be able to replay an execution at roughly the same speed as the primary VM is recording the execution. Fortunately, the overhead of recording and replaying in VMware deterministic replay is roughly the same. However, if the server hosting the backup VM is heavily loaded with other VMs (and hence overcommitted on resources), the backup VM may not be able to get enough CPU and memory resources to execute as fast as the primary VM, despite the best efforts of the backup hypervisor’s VM scheduler. 主机缓冲满的另一个可能原因是备机执行过慢以至于消费日志项太慢。通常，备机必须能以和主机记录执行大致相同的速度重放执行。幸运的是，VMware确定性重放中记录和重放的负载是大致相同的。然而，如果承载备机的服务器也加载了其他的虚拟机(因此使用资源过渡)，备机可能无法获得足够的cpu和内存资源以和主机相同的速度执行，即使备机虚拟机管理程序的虚拟机调度器尽最大的努力 Beyond avoiding unexpected pauses if the log buffers fill up, there is another reason why we don’t wish the execution lag to become too large. If the primary VM fails, the backup VM must “catch up” by replaying all the log entries that it has already acknowledged before it goes live and starts communicating with the external world. The time to finish replaying is basically the execution lag time at the point of the failure. Hence, the time for the backup to go live is roughly equal to the failure detection time plus the current execution lag time. So, we don’t wish the execution lag time to be large (more than a second), since that will add significant time to the failover time (the time for the backup to go live). 除了避免在日志缓冲满时不希望的暂停，还有另外原因是我们不希望执行的滞后变得太大。如果主机故障了，备机必须通过重放所有的在上线并开始和外部世界通信前已经确认了的日志项来赶上主机。结束重放的时间基本上是故障点的执行滞后时间。因此，备机上线的时间大致等于故障检测时间加上当前执行滞后时间。所以，我们不希望执行滞后时间太大(超过1秒)，因为这将明显的增加故障转移的时间(备机上线的时间) Therefore, we have an additional mechanism to slow down the primary VM to prevent the backup VM from getting too far behind. In our protocol for sending and acknowledging log entries, we send additional information to determine the real-time execution lag between the primary and backup VMs. Typically the execution lag is less than 100 milliseconds. If the backup VM starts having a significant execution lag (say, more than 1 second), VMware FT starts slowing down the primary VM by informing the scheduler to give it a slightly smaller share of the CPU (initially by just a few percent). We use a slow feedback loop,which will try to gradually pinpoint the appropriate CPU share for the primary VM that will allow the backup VM to match its execution. If the backup VM continues to lag behind, we continue to gradually reduce the primary VM’s CPU share. Conversely, if the backup VM catches up, we gradually increase the primary VM’s CPU share until the backup VM returns to having a slight lag. 因此，我们有一个额外的机制来减慢主机的速度，避免备机落后太多。在发送和确认日志项的协议中，会发送额外的信息来决定实时的运行延迟，在主机和备机之间。通常执行延迟少于100毫秒。如果备机开始有了明显的执行延迟(比如超过1秒)，VMware容错会开始减慢主机的速度，通过通知调度器给主机更少的cpu份额(初始时只有百分之几)。我们使用一个慢反馈环，会逐渐的精确话对于主机的cpu份额来让备机匹配上主机的运行。如果备机仍旧落后，我们会继续降低主机的cpu份额。相反了，如果备机追上了主机，我们会逐渐的增加主机的cpu份额知道备机返回微小的延迟 Note that such slowdowns of the primary VM are very rare, and typically happen only when the system is under extreme stress. All the performance numbers of Section 5 include the cost of any such slowdowns. 注意对于主机的减速是很罕见的，通常只在系统处于极端压力的情况下发生。第5节的所有性能数字包含了这些减速的成本。 3.3 Operation on FT VMsAnother practical matter is dealing with the various control operations that may be applied to the primary VM. For example, if the primary VM is explicitly powered off, the backup VM should be stopped as well, and not attempt to go live. As another example, any resource management change on the primary (such as increased CPU share) should also be applied to the backup. For these kind of operations, special control entries are sent on the logging channel from the primary to the backup, in order to effect the appropriate operation on the backup. 另一个实际的问题是处理多种可能被应用于主机的控制操作。比如，当主机显式关机的时候，备机也应该关机，而不是尝试上线。另一个例子，主机上任何的资源管理改变(比如增加了cpu份额)也应该应用到备机。对于这些操作，特殊的控制项会通过日志通道从主机发送给备机，为了在备机上也应用适当的操作 In general, most operations on the VM should be initiated only on the primary VM. VMware FT then sends any necessary control entry to cause the appropriate change on the backup VM. The only operation that can be done independently on the primary and backup VM is VMotion. That is, the primary and backup VM can each be VMotioned independently to other hosts. Note that VMware FT ensures that neither VM is VMotioned to the server where the other VM is, since that situation would no longer provide fault tolerance. 通常，虚拟机的多数操作仅在主机上初始化。VMware容错会发送所有必要的控制项在备机上应用适当的变更。唯一可以在主机和备机上独立执行的操作是VMotion.也就是说，主机和备机可以分别独立的Vmotiond到其他主机。注意，VMware容错确保主机和备机都不会被VMotioned到对方所在的服务器上，因为这种情况下不再提供容错 VMotion of a primary VM adds some complexity over a normal VMotion, since the backup VM must disconnect from the source primary and re-connect to the destination primary VM at the appropriate time. VMotion of a backup VM has a similar issue, but adds an additional complexity. For a normal VMotion, we require that all outstanding disk IOs be quiesced (i.e. completed) just as the final switchover on the VMotion occurs. For a primary VM, this quiescing is easily handled by waiting until the physical IOs complete and delivering these completions to the VM. However, for a backup VM, there is no easy way to cause all IOs to be completed at any required point, since the backup VM must replay the primary VM’s execution and complete IOs at the same execution point. The primaryVM may be running a workload in which there are always disk IOs in flight during normal execution. VMware FT has a unique method to solve this problem. When a backup VM is at the final switchover point for a VMotion, it requests via the logging channel that the primary VM temporarily quiesce all of its IOs. The backup VM’s IOs will then naturally be quiesced as well at a single execution point as it replays the primary VM’s execution of the quiescing operation. 主机的Vmotion相对于普通Vmotion增加了一些复杂性，因为备机必须和源主机断开连接然后在合适的时间重新连接到目的主机。备机的VMtion有相同的问题，但是增加了额外的复杂性。对于普通的Vmotion,我们要求所有未完成的磁盘IO都暂停(即完成)就像VMotion上发生的最终切换。对于主机，这种暂停容易处理，可以一直等待直到物理IO完成并发送完成信息给虚拟机。然而，对于备机，没有简单的方法在任何需要的时间点让所有IO完成，因为备机必须重放主机的执行并且在相同的执行点完成IO.主机可以运行在总是有磁盘IO的工作负载上，在正常运行期间。VMware容错有独特的方法解决这个问题。当备机在VMotion的最终切换点的时候，它通过日志通道要求主机临时停止所有的IO.备机的IO也会在单独的执行点上自然的暂停，因为备机会重放主机暂停操作的执行命令 3.4 Implementation Issues for Disk IOsThere are a number of subtle implementation issues related to disk IO. First, given that disk operations are non-blocking and so can execute in parallel, simultaneous disk operations that access the same disk location can lead to non-determinism. Also, our implementation of disk IO uses DMA directly to/from the memory of the virtual machines, so simultaneous disk operations that access the same memory pages can also lead to non-determinism. Our solution is generally to detect any such IO races (which are rare), and force such racing disk operations to execute sequentially in the same way on the primary and backup. Interestingly, a single disk read operation can cause a race as well, since its scatter-gather array could reference the same block of memory multiple times, hence leaving the final contents of the memory block undetermined. Our solution is to detect this racing IO as well, and in this case ensure that the final contents of memory are sent on the logging channel, so the backup ends up with the same memory contents. 有一些和磁盘IO相关的细微的实现问题。首先，非阻塞的磁盘操作可以并行执行，因此对同一磁盘位置的同时访问可能导致不确定性。我们对磁盘IO的实现使用DMA直接读写虚拟机内存，所有对于相同内存页的同时访问也可能导致不确定性。我们的解决方案通常是检测所有这类IO竞争(是很罕见的)，然后强制这些竞争的磁盘操作以相同的方式在主机和备机上顺序执行。有趣的是，单个磁盘读取操作也可能造成竞争，因为散聚的阵列可能引用相同的内存块多次，而导致内存页的内容变得不确定性。我们的解决方案还是检测这些竞争，保证在这种情况下最后的内存内容会在日志通道上发送，这样备机可以以相同的内存内存结束。 Second, a disk operation can also race with a memory access by an application (or OS) in a VM, because the disk operations directly access the memory of a VM via DMA. For example, there could be a non-deterministic result if an application/OS in a VM is reading a memory block at the same time a disk read is occurring to that block. This situation is also unlikely, but we must detect it and deal with it if it happens. One solution is to set up page protection temporarily on pages that are targets of disk operations. The page protections result in a trap if the VM happens to make an access to a page that is also the target of an outstanding disk operation, and the VM can be paused until the disk operation completes. Because changing MMU protections on pages is an expensive operation, we choose instead to use bounce buffers. A bounce buffer is a temporary buffer that has the same size as the memory being accessed by a disk operation. A disk read operation is modified to read the specified data to the bounce buffer, and the data is copied to guest memory only as the IO completion is delivered. Similarly, for a disk write operation, the data to be sent is first copied to the bounce buffer, and the disk write is modified to write data from the bounce buffer. The use of the bounce buffer can slow down disk operations, but we have not seen it cause any noticeable performance differences. 第二，虚拟机上的应用程序(或操作系统)的有关内存访问的磁盘操作也可能产生竞争，因为磁盘操作直接通过DMA访问内存。比如，如果虚拟机中的应用程序/操作系统在同一时间读取一个正在发生磁盘读取的内存块可能会导致不确定性。这种情况也是类似的，但是我们必须检测并解决它在发生的时候。我们的解决方案是设置临时的页保护在由磁盘操作标记的页上。如果虚拟机碰巧对未完成磁盘操作的标记页进行访问则页保护最终会进入陷阱，虚拟机会被暂停直到磁盘操作完成。因为修改页上的MMU保护是昂贵的操作，所以我们使用了bounce buffers. Bounce buffer是和由磁盘操作正在访问的内存大小一致的临时缓冲。磁盘读操作被修改为在bounce buffer中读取特定数据，并且数据仅在IO操作完成并被传递的时候拷贝到虚拟机内存。类似的，对于磁盘写操作，将要被发送的数据会先拷贝到bounce buffer,磁盘写操作位被修改为写数据到bounce buffer. Bounce buffer的使用能够减慢磁盘操作，但是我们还没有看到任何明显的性能差异。 Third, there are some issues associated with disk IOs that are outstanding (i.e. not completed) on the primary when a failure happens, and the backup takes over. There is no way for the newly-promoted primary VM to be sure if the disk IOs were issued to the disk or completed successfully. In addition, because the disk IOs were not issued externally on the backup VM, there will be no explicit IO completion for them as the newly-promoted primary VM continues to run, which would eventually cause the guest operating system in the VM to start an abort or reset procedure. Therefore, we would like to ensure that a completion is sent to the VM for each pending IO. We could send an error completion that indicates that each IO failed, since it is acceptable to return an error even if the IO completed successfully. However, the guest OS might not respond well to errors from its local disk. Instead, we re-issue the IOs during the go-live process of the VM. Because we have eliminated all races and all IOs specify directly which memory and disk blocks are accessed, these disk operations can be re-issued even if they have already completed successfully (i.e. they are idempotent). 第三，当主机故障的时候在主机上可能会有一些未完成的和磁盘IO相关的问题，而备机进行了接管。对新提升的主机就没有办法确定磁盘IO被发布到磁盘还是已经成功完成。另外，因为磁盘IO没有在外部的备机进行发布，当新提升的主机继续运行的时候，不会有明确的IO完成，最终可能导致虚拟机的虚拟机操作系统开始终止或者重置程序。因此，我们希望确保对于每一个挂起的IO，完成信息被发送给虚拟机。我们可以发送错误完成信息来表明IO失败，因为即使IO成功完成，返回错误也是可接受的。然而，虚拟机操作系统可能不会从本地磁盘很好的响应错误。相反，我们在虚拟机go-live的过程重新发布IO。因为我们已经消除了所有的竞争并且所有的IO直接指定了要访问的内存和磁盘块，这些磁盘操作可以重新发布即使已经成功完成了（即是幂等的) 3.5 Implementation Issues for Network IOVMware vSphere provides many performance optimizations for VM networking. Many of these optimizations are based on the hypervisor asynchronously updating the state of the virtual machine’s network device. For example, receive buffers can be updated directly by the hypervisor while the VM is executing. Unfortunately these asynchronous updates to a VM’s state add non-determinism. Unless we can guarantee that all updates happen at the same point in the instruction stream on the primary and the backup, the backup’s execution can diverge from that of the primary. VMware vSphere对于虚拟机网络提供了许多性能优化。多数这些优化是基于虚拟机管理程序异步更新虚拟机网络设备的状态。比如，在虚拟机运行的时候接收缓冲区可以被虚拟机管理程序直接更新。不幸的是，这种对于虚拟机状态的异步更新增加了不确定性。除非我们能够保证所有的更新在主机和备机的指令流同时发生，否则备机的执行可能和主机不同 The biggest change to the networking emulation code for fault tolerance is the elimination of the asynchronous network optimizations. All updates to VM networking state must be done while the VM is not executing instructions so we can log the updates and replay the updates on the backup at the same point in the instruction stream. The code that asynchronously updates VM ring buffers with incoming packets has been modified to instead force the guest to trap to the hypervisor where it can log the updates and then apply them to the VM. Similarly, code that previously pulled packets out of transmit queues asynchronously has been disabled for FT and instead we require transmits to be done through a trap to the hypervisor (except as noted below). 对于容错的网络仿真代码的最大改变是消除了异步网络优化。所有对于虚拟机网络状态的更新必须在虚拟机不执行指令的时候完成，以便我们可以记录更新日志并在备机上指令流的同一点重放。异步更新虚拟机ring buffer的代码被修改为强制guest陷入到虚拟机管理程序，在虚拟机管理程序里可以更新然后应用更新日志带虚拟机。类似的，之前异步拉取传输队列的包的代码被容错禁用了，取而代之的我们要求通过陷入到虚拟机管理程序来完成传输(如下所示) The elimination of the asynchronous updates of the network device combined with the delaying of sending packets described in Section 2.2 has provided some performance challenges for networking. We’ve taken two approaches to improving VM network performance while running FT. First, we implemented clustering optimizations to reduce VM traps and interrupts. When we are streaming data at a sufficient bit rate, we are able to do one transmit trap per group of packets and, in the best case, zero traps, since we can transmit the packets as part of receiving new packets. Likewise, we can reduce the number of interrupts to the VM for incoming packets by only posting the interrupt for a group of packets. 网络设备异步更新的消除和2.2节描述的发送包的延迟，为网络的性能带来了挑战。我们已经使用两种方法来提高运行容错的虚拟机的网络性能。首先，我们实现了集群优化来江都虚拟机的陷入和中断。当我们以足够的比特率传输数据，我们可以对于每一组包进行一次传输陷入，最好的情况下是0陷入，因为我们将包作为新接收的包的一部分进行传输。同样的，我们通过对每一组包发送一次中断，来降低对于传入包的虚拟机的中断次数。 Our second performance optimization for networking involves reducing the delay for transmitted packets. As noted earlier, we have to delay all transmitted packets until we get an acknowledgment from the backup that it has received the appropriate log entries. The key to reducing the transmit delay is to reduce the time required to send a log message to the backup and get an acknowledgment. Our primary optimizations in this area involve ensuring that sending and receiving log entries and acknowledgments can all be done without any thread context switch. The VMware vSphere hypervisor allows functions to be registeredwith the TCP stack that will be called from a deferred-execution context (similar to a tasklet in Linux) whenever TCP data is received. This allows us to quickly handle any incoming log messages on the backup and any acknowledgments received by the primary without any thread context switches. In addition, when the primary VM enqueues a packet to be transmitted, we force an immediate log flush of the associated output log entry (as described in Section 2.2) by scheduling a deferred-execution context to do the flush. 我们对于网络的第二个性能优化涉及降低传输包的延迟。如前面提到的，我们必须延迟所有的传输包直到获取了备机的确认信息，在备机接受到合适的日志项。降低传输延迟的关键是降低要求的发送给备机的日志信息和获取更新的时间。我们在这个方面的主要优化设计确保发送接受日志项和确认信息都在不发生线程上下文切换的情况下完成。VMware vSphere虚拟机管理程序允许函数被注册为TCP栈，任何接收到tcp数据的时候，将在推迟执行上下文中调用(类似linux的软中断)。这允许我们在备机上快速处理所有的输入日志项和由主机收到的确认信息，而不会发生任何的线程上下文切换。另外，当主机将需要被传输的包入队，我们通过调度延迟执行上下文来将需要立即刷新的和输出日志项关联的日志进行刷新。 4 Design AlternativesIn our implementation of VMware FT, we have explored a number of interesting design alternatives. In this section, we explore some of these alternatives. 在我们VMware容错的实现中，我们已经探索了许多有趣的设计替代方案。在这一节，我们探索一部分替代方案 4.1 Shared vs. Non-shared DiskIn our default design, the primary and backup VMs share the same virtual disks. Therefore, the content of the shared disks is naturally correct and available if a failover occurs. Essentially, the shared disk is considered external to the primary and backup VMs, so any write to the shared disk is considered a communication to the external world. Therefore, only the primary VM does actual writes to the disk, and writes to the shared disk must be delayed in accordance with the Output Rule. The shared disk model is the one used in [3, 9, 7]. 在我们的缺省设计中，主机和备机共享相同的虚拟磁盘。因此，共享磁盘的内容在故障转移发生的时候自然是正确和可用的。基本上，共享磁盘被认为在主机和备机的外部，所以共享磁盘的写入是到外部世界的通信。因此，只有主机实际上写磁盘，共享磁盘的写入以和输出规则一致的方式进行延迟。共享磁盘模型在[3, 9, 7]中使用 An alternative design is for the primary and backup VMs to have separate (non-shared) virtual disks. In this design, the backup VM does do all disk writes to its virtual disks, and in doing so, it naturally keeps the contents of its virtual disks in sync with the contents of the primary VM’s virtual disks. Figure 4 illustrates this configuration. In the case of nonshared disks, the virtual disks are essentially considered part of the internal state of each VM. Therefore, disk writes of the primary do not have to be delayed according to the Output Rule. The non-shared design is quite useful in cases where shared storage is not accessible to the primary and backup VMs. This may be the case because shared storage is unavailable or too expensive, or because the servers running the primary and backup VMs are far apart (“long-distance FT”). One disadvantage of the non-shared design is that the two copies of the virtual disks must be explicitly synced up in some manner when fault tolerance is first enabled. In addition, the disks can get out of sync after a failure, so they must be explicitly resynced when the backup VM is restarted after a failure. That is, FT VMotion must not only sync the running state of the primary and backup VMs, but also their disk state. 对于主机和备机的一个替代设计是使用单独(非共享)的虚拟磁盘。在这种设计中，备机将所有的写写到自己的虚拟磁盘，这样做可以自然的保持备机的虚拟磁盘和主机的虚拟磁盘保持同步。图4说明了这种配置。对于非共享磁盘的情况，每个虚拟磁盘本质上被认为是每个虚拟机的内部状态的一部分。因此，主机的磁盘写不用根据输出规则做延迟。在共享存储对于主机和备机不可访问的时候非共享的设计是相当有用的。可能是因为共享存储不可用或太昂贵，或是因为运行主机和备机的服务器相距很远(远距离的容错)。非共享设计的一个缺点是在容错第一次启用的时候，虚拟磁盘的两份拷贝必须显式同步。另外，磁盘可能会在故障发生后脱离同步，所以在故障发生后虚拟机重启的时候，磁盘必须被显式的重新同步。也就是说，容错VMotion必须不光同步主机和备机的运行状态，也要同步磁盘的状态。 In the non-shared-disk configuration, there may be no shared storage to use for dealing with a split-brain situation. In this case, the system could use some other external tiebreaker, such as a third-party server that both servers can talk to. If the servers are part of a cluster with more than two nodes, the system could alternatively use a majority algorithm based on cluster membership. In this case, a VM would only be allowed to go live if it is running on a server that is part of a communicating sub-cluster that contains a majority of the original nodes. 在非共享磁盘的配置下，可能没有可用的共享存储对于解决脑裂的情况。在这种情况下，系统可以使用一些其他的外部的”决胜局”,比如主机和备机都可以进行通信的第三方服务器。如果服务器是超过两个节点的集群的一部分，系统可以替代性的使用基于集群成员的多数派算法。在这种情况下，如果虚拟机运行在一个属于包含多数原始节点的通信子集群的一部分的服务器上，将仅仅被允许上线。 4.2 Executing Disk Reads on the Backup VMIn our default design, the backup VM never reads from its virtual disk (whether shared or non-shared). Since the disk read is considered an input, it is natural to send the results of the disk read to the backup VM via the logging channel. 在我们的缺省设计中，备机绝不会从虚拟磁盘(不管共享还是非共享)进行读取.因为磁盘读被认为是一个输入，通过日志通道发送磁盘读的结果给备机是自然的。 An alternate design is to have the backup VM execute disk reads and therefore eliminate the logging of disk read data. This approach can greatly reduce the traffic on the logging channel for workloads that do a lot of disk reads. However, this approach has a number of subtleties. It may slow down the backup VM’s execution, since the backup VM must execute all disk reads and wait if they are not physically completed when it reaches the point in the VM execution where they completed on the primary. 一个替代的设计是让备机执行磁盘读，这样可以消除磁盘读的日志。这样可以极大的降低日志通道的流量，在有大量磁盘读的工作负载上。然而，这种方法有很多微妙之处。它可能会减慢备机的执行速度，因为备机必须执行所有的磁盘读，并且在达到主机上执行完成的执行点上等待磁盘读是否在物理上完成 Also, some extra work must be done to deal with failed disk read operations. If a disk read by the primary succeeds but the corresponding disk read by the backup fails, then the disk read by the backup must be retried until it succeeds, since the backup must get the same data in memory that the primary has. Conversely, if a disk read by the primary fails, then the contents of the target memory must be sent to the backup via the logging channel, since the contents of memory will be undetermined and not necessarily replicated by a successful disk read by the backup VM. 并且，必须做一些额外的工作来处理失败的磁盘读操作。如果主机的磁盘读成功了但是备机的磁盘读失败了，那么备机的磁盘读必须重试直到成功，因为备机必须在内存中获得和主机一样的数据。反过来，如果主机的磁盘读失败，必须通过日志通道将目的内存的内容发送给备机，因为内存的内容将会是不确定性的，并且备机的成功磁盘读可能是不必要的副本 Finally, there is a subtlety if this disk-read alternative is used with the shared disk configuration. If the primary VM does a read to a particular disk location, followed fairly soon by a write to the same disk location, then the disk write must be delayed until the backup VM has executed the first disk read. This dependence can be detected and handled correctly, but adds extra complexity to the implementation. 最后，替代方案的磁盘读和共享磁盘配置一起使用的行为是微妙的。如果主机读取了一个特定的磁盘位置，然后很快又有一个对于相同磁盘位置的写操作，则第二次磁盘写将被延迟到备机已经执行了第一次的磁盘读。这种依赖可以被检测到并进行正确的处理，但是对于实现增加了额外的复杂性。 In Section 5.1, we give some performance results indicating that executing disk reads on the backup can cause some slightly reduced throughput (1-4%) for real applications, but can also reduce the logging bandwidth noticeably. Hence, executing disk reads on the backup VM may be useful in cases where the bandwidth of the logging channel is quite limited. 在5.1节，我们提供的一些性能结果表明在备机上执行磁盘读会对应用程序的吞吐有轻微的降低(1-4%),但也会显著降低日志的带宽。因此，对于日志通道带宽受限的情况，在备机执行磁盘读是有用的。 5 Performance EvaluationIn this section, we do a basic evaluation of the performance of VMware FT for a number of application workloads and networking benchmarks. For these results, we run the primary and backup VMs on identical servers, each with eight Intel Xeon 2.8 Ghz CPUs and 8 Gbytes of RAM. The servers are connected via a 10 Gbit/s crossover network, though as will be seen in all cases, much less than 1 Gbit/s of network bandwidth is used. Both servers access their shared virtual disks from an EMC Clariion connected through a standard 4 Gbit/s Fibre Channel network. The client used to drive some of the workloads is connected to the serversvia a 1 Gbit/s network. The applications that we evaluate in our performance results are as follows. SPECJbb2005 is an industry-standard Java application benchmark that is very CPU- and memory-intensive and does very little IO. Kernel Compile is a workload that runs a compilation of the Linux kernel. This workload does some disk reads and writes, and is very CPU- and MMU-intensive, because of the creation and destruction of many compilation processes. Oracle Swingbench is a workload in which an Oracle 11g database is driven by the Swingbench OLTP (online transaction processing) workload. This workload does substantial disk and networking IO, and has eighty simultaneous database sessions. MS-SQL DVD Store is a workload in which a Microsoft SQL Server 2005 database is driven by the DVD Store benchmark, which has sixteen simultaneous clients. 5.1 Basic Performance ResultsTable 1 gives basic performance results. For each of the applications listed, the second column gives the ratio of the performance of the application when FT is enabled on the VM running the server workload vs. the performance when FT is not enabled on the same VM. For SPECJbb2005, Kernel Compile, Oracle Swingbench, and MS-SQL DVD Store, the performance measures are, respectively, business operations per second, compile time in seconds, transactions per second, and operations per second. The ratios are calculated so that a value less than 1 indicates that the FT workload is slower. Clearly, the overhead for enabling FT on these representative workloads is less than 10%. SPECJbb2005 is completely computebound and has no idle time, but performs well because it has minimal non-deterministic events beyond timer interrupts. The other workloads do disk IO and have some idle time, so some of the overhead of deterministic replay and the FT protocol may be hidden by the fact that the FT VMs have less idle time. However, the general conclusion is that VMware FT is able to support fault-tolerant VMs with a reasonable performance overhead. In the third column of the table, we give the average bandwidth of data sent on the logging channel when these applications are run. For these applications, the logging bandwidth is quite reasonable and easily satisfied by a 1 Gbit/s network. In fact, the low bandwidth requirements indicate that multiple FT workloads can share the same 1 Gbit/s network without any negative performance effects. For VMs that run common guest operating systems like Linux and Windows, we have found that the typical logging bandwidth while the guest OS is idle is 0.5-1.5 Mbits/sec. The “idle” bandwidth is largely the result of recording the delivery of timer interrupts. For a VM with an active workload, the logging bandwidth is dominated by the network and disk inputs that must be sent to the backup – the network packets that are received and the disk blocks that are read from disk. We have found that a useful heuristic for the network bandwidth is: FT logging bandwidth = 1 Mbit/s + 1.2 * (average disk read throughput [Mbits/s] + average network receives [Mbits/s]) The factor of 1.2 is a “fudge factor” that approximates the extra logging bandwidth needed for disk and network IOs aside from the input data, including the log entry headers and the extra entries for completion interrupts. Hence, the logging bandwidth can be much higher than those measured in Table 1 for applications that have very high network receive or disk read bandwidth. For these kinds of applications, the bandwidth of the logging channel could be a bottleneck, especially if there are other uses of the logging channel. The relatively low bandwidth needed over the logging channel for many real applications makes replay-based fault tolerance quite attractive for a long-distance configuration using non-shared disks. For long-distance configurations where the primary and backup might be separated by 1-100 kilometers, optical fiber can easily support bandwidths of 100-1000 Mbit/s with latencies of less than 10 milliseconds. For the applications in Table 1, a bandwidth of 100-1000 Mbit/s should be sufficient for good performance. Note, however, that the extra round-trip latency between the primary and backup may cause network and disk outputs to be delayed by up to 20 milliseconds. The long-distance configuration will only be appropriate for applications whose clients can tolerate such an additional latency on each request. For two applications, we have measured the performance impact of executing disk reads on the backup VM (as described in Section 4.2) vs. sending disk read data over the logging channel. For Oracle Swingbench, throughput is about 4% slower when executing disk reads on the backup VM; for MS-SQL DVD Store, throughput is about 1% slower. Meanwhile, the logging bandwidth is decreased from 12 Mbits/sec to 3 Mbits/sec for Oracle Swingbench, and from 18 Mbits/sec to 8 Mbits/sec for MS-SQL DVD Store. Clearly, the bandwidth savings could be much greater for applications with much greater disk read bandwidth. As mentioned in Section 4.2, it is expected that the performance might be somewhat worse when disk reads are executed on the backup VM. However, for cases where the bandwidth of the logging channel is limited (for example, a long-distance configuration), executing disk reads on the backup VM may be useful. 5.2 Network BenchmarksNetworking benchmarks can be quite challenging for our system for a number of reasons. First, high-speed networking can have a very high interrupt rate, which requires the logging and replaying of asynchronous events at a very high rate. Second, benchmarks that receive packets at a high rate will cause a high rate of logging traffic, since all such packets must be sent to the backup via the logging channel. Third, benchmarks that send packets will be subject to the Output Rule, which delays the sending of network packets until the appropriate acknowledgment from the backup is received. This delay will increase the measured latency to a client. This delay could also decrease network bandwidth to a client, since network protocols (such as TCP) may have to decrease the network transmission rate as the roundtrip latency increases. Table 2 gives our results for a number of measurements made by the standard netperf benchmark. In all these measurements, the client VM and primary VM are connected via a 1 Gbit/s network. The first two rows give send and receive performance when the primary and backup hosts are connected by a 1 Gbit/s network. The third and fourth rows give the send and receive performance when the primary and backup servers are connected by a 10 Gbit/s network, which not only has higher bandwidth, but also lower latency than the 1 Gbit/s network. As a rough measure, the ping time between hypervisors for the 1 Gbit/s connection is about 150 microseconds, while the ping time for a 10 Gbit/s connection is about 90 microseconds. When FT is not enabled, the primary VM can achieve close (940 Mbit/s) to the 1 Gbit/s line rate for both transmits and receives. When FT is enabled for receive workloads, the logging bandwidth is very large, since all the incoming network packets must be sent on the logging channel. The logging channel can therefore become a bottleneck, as shown for the results for the 1 Gbit/s logging network. The effect is much less for the 10 Gbit/s logging network. When FT is enabled for transmit workloads, the logging bandwidth is significant since all the network interrupts must still be logged. However, the achievable network transmit bandwidths are higher than the network receive bandwidths. Overall, we see that FT can limit network bandwidths significantly at very high transmit and receive rates, but high absolute rates are still achievable. 6 Related WorkBressoud and Schneider [3] described the initial idea of implementing fault tolerance for virtual machines via software contained completely at the hypervisor level. They demonstrated the feasibility of keeping a backup virtual machine in sync with a primary virtual machine via a prototype for servers with HP PA-RISC processors. However, due to limitations of the PA-RISC architecture, they could not implement fully secure, isolated virtual machines. Also, they did not implement any method of failure detection or attempt to address any of the practical issues described in Section 3. More importantly, they imposed a numberof constraints on their FT protocol that were unnecessary. First, they imposed a notion of epochs, where asynchronous events are delayed until the end of a set interval. The notion of an epoch is unnecessary – they may have imposed it because they could not replay individual asynchronous events efficiently enough. Second, they required that the primary VM stop execution essentially until the backup has received and acknowledged all previous log entries. However, only the output itself (such as a network packet) must be delayed – the primary VM itself may continue executing. Bressoud [4] describes a system that implements fault tolerance in the operating system (Unixware), and therefore provides fault tolerance for all applications that run on that operating system. The system call interface becomes the set of operations that must be replicated deterministically. This work has similar limitations and design choices as the hypervisor-based work. Napper [9] and Friedman [7] describe implementations of fault-tolerant Java virtual machines. They follow a similar design to ours and Bressoud’s in sending information about inputs and non-deterministic operations on a logging channel. Like Bressoud, they do not appear to focus on detecting failure and re-establishing fault tolerance after a failure. In addition, their implementation is limited to providing fault tolerance for applications that run in a Java virtual machine. These systems attempt to deal with issues of multi-threaded Java applications, but require either that all data is correctly protected by locks or enforce a serialization on access to shared memory. Dunlap [6] describes an implementation of deterministic replay targeted towards debugging application software on a paravirtualized system. Our work supports arbitrary operating systems running inside virtual machines and implements fault tolerance support for these VMs, which requires much higher levels of stability and performance. Cully [5] describes an alternative approach for supporting fault-tolerant VMs and its implementation in a project called Remus. With this approach, the state of a primary VM is repeatedly checkpointed during execution and sent to a backup server, which collects the checkpoint information. The checkpoints must be executed very frequently (many times per second), since external outputs must be delayed until a following checkpoint has been sent and acknowledged. The advantage of this approach is that it applies equally well to uni-processor and multi-processor VMs. The main issue is that this approach has very high network bandwidth requirements to send the incremental changes to memory state at each checkpoint. The results for Remus presented in [5] show 100% to 225% slowdown for kernel compile and SPECweb benchmarks, when attempting to do 40 checkpoints per second using a 1 Gbit/s network connection for transmitting changes in memory state. There are a number of optimizations that may be useful in decreasing the required network bandwidth, but it is not clear that reasonable performance can be achieved with a 1 Gbit/s connection. In contrast, our record-replay based approach can achieve less than 10% overhead, typically with on the order of 10-50 Mbit/s bandwidth required between the primary and backup hosts. 7 Conclusion and Future WorkWe have designed and implemented an efficient and complete system in VMware vSphere that provides fault tolerance (FT) for virtual machines running on servers in a cluster. Our design is based on replicating the execution of a primary VM via a backup VM on another host using VMware deterministic replay. If the server running the primary VM fails, the backup VM takes over immediately with no interruption or loss of data. 我们已经在VMware vSphere上设计实现了一个有效的完整的系统，可对运行在服务器集群上的虚拟机提供容错。我们的设计基于，运行在另外主机上通过使用VMware确定性重放功能的备机复制主机的执行。如果运行主机的服务器故障，备机可以立即接管主机，没有中断，也不会丢失数据。 Overall, the performance of fault-tolerant VMs under VMware FT on commodity hardware is excellent, and shows less than 10% overhead for some typical applications. Most of performance cost of VMware FT comes from the overhead of using VMware deterministic replay to keep the primary and backup VMs in sync. The low overhead of VMware FT therefore derives from the efficiency of VMware deterministic replay. In addition, the logging bandwidth required to keep the primary and backup in sync is typically quite small, often less than 100 Mbit/s. Because the logging bandwidth is quite small in most cases, it seems feasible to implement configurations where the primary and backup VMs are separated by long distances (1-100 kilometers). 总体而言，VMware容错系统在商用硬件上的容错性能是出色的，对于一些典型应用的开销不到10%.多数VMware容错的性能开销来自保持主机备机间同步而使用的VMware确定性重放。VMware容错系统的低开销源自VMware确定性重放的效率。另外，用来保持主机备机间同步的日志带宽通常很小，一般低于100Mbit/s.因为日志带宽在大多数情况下很小，实现主机和备机远距离分布(1-100公里)看起来是可行的。 Our results with VMware FT have shown that an efficient implementation of faulttolerant VMs can be built upon deterministic replay. Such a system can transparently provide fault tolerance for VMs running any operating systems and applications with minimal overhead. However, for a system of fault-tolerant VMs to be useful for customers, it must also be robust, easy-to-use, and highly automated. A usable system requires many other components beyond replicated execution of VMs. In particular, VMware FT automatically restores redundancy after a failure, by finding an appropriate server in the local cluster and creating a new backup VM on that server. By addressing all the necessary issues, we have demonstrated a system that is usable for real applications in customer’s datacenters. 我们对VMware容错系统的研究结果表明，通过确定性重放技术能够高效的实现虚拟机容错。这样的系统可以透明的对运行在任何操作系统和应用上的虚拟机提供容错，以最小化开销。然而，对于一个对用户有用的容错虚拟机来说，他还必须是健壮的，易于使用，并且高自动化的。一个可用的系统除了复制虚拟机执行外，还需要很多其他的组件。特别的，VMware容错系统可以在故障后自动恢复冗余，通过在本地集群中寻找合适的服务器然后创建一个新的备机。通过解决所有必要的问题，我们证明了对客户数据中心上实际应用程序可用的系统 In the future, we are interested in investigating the performance characteristics of the long-distance FT configurations mentioned above. We are also interested in extending our system to deal with partial hardware failure. By partial hardware failure, we mean a partial loss of functionality or redundancy in a server that doesn’t cause corruption or loss of data. An example would be the loss of all network connectivity to the VM, or the loss of a redundantpower supply in the physical server. If a partial hardware failure occurs on a server running a primary VM, in many cases (but not all) it would be advantageous to fail over to the backup VM immediately. Such a failover could immediately restore full service for a critical VM, and ensure that the VM is quickly moved off of a potentially unreliable server. 今后，我们有兴趣调查前面提到的远距离容错配置的性能特征。我们也有兴趣扩展我们的系统来解决部分硬件。所谓的部分硬件故障，说的是服务器中部分功能缺失或冗余，不会导致数据的损坏或丢失。比如虚拟机的所有网络连接的丢失，或者物理服务器中冗余电源的丢失。如果部分硬件故障发生在运行主机的服务器上，在大多数情况(不是所有情况)下对于故障立即转移到备机是有利的。故障转移可以让关键的虚拟机恢复完整服务，并确保虚拟机从潜在不可靠的服务器中快速移出 AcknowledgmentsWe would like to thank Krishna Raja, who generated many of the performance results. There were numerous people involved in the implementation of VMware FT. Core implementors of deterministic replay and the base FT functionality included Lan Huang, Eric Lowe, Slava Malyugin, Alex Mirgorodskiy, Boris Weissman, and Min Xu. In addition, there are many other people involved in the higher-level management of FT in VMware vCenter and in implementation issues related to specific virtual devices besides network and disk. Karyn Ritter did an excellent job managing much of the work. References[1] Alsberg, P., and Day, J. A Principle for Resilient Sharing of Distributed Resources. In Proceedings of the Second International Conference on Software Engineering (1976), pp. 627–644. [2] AMD Corporation. AMD64 Architecture Programmer’s Manual. Sunnyvale, CA. [3] Bressoud, T., and Schneider, F. Hypervisor-based Fault Tolerance. In Proceedings of SOSP 15 (Dec. 1995). [4] Bressoud, T. C. TFT: A Software System for Application-Transparent Fault Tolerance. In Proceedings of the Twenty-Eighth Annual International Symposium on FaultTolerance Computing (June 1998), pp. 128–137. [5] Cully, B., Lefebvre, G., Meyer, D., Feeley, M., Hutchison, N., and Warfield, A. Remus: High Availability via Asynchronous Virtual Machine Replication. In Proceedings of the Fifth USENIX Symposium on Networked Systems Design and Implementation (Apr. 2008), pp. 161–174. [6] Dunlap, G. W., King, S. T., Cinar, S., Basrai, M., and Chen, P. M. ReVirt: Enabling Intrusion Analysis through Virtual Machine Logging and Replay. In Proceedings of the 2002 Symposium on Operating Systems Design and Implementation (Dec. 2002). [7] Friedman, R., and Kama, A. Transparent Fault-Tolerant Java Virtual Machine. In Proceedings of Reliable Distributed System (Oct. 2003), pp. 319–328. [8] Intel Corporation. IntelAˆR 64 and IA-32 Architectures Software Developer’s Manuals. Santa Clara, CA. [9] Napper, J., Alvisi, L., and Vin, H. A Fault-Tolerant Java Virtual Machine. In Proceedings of the International Conference on Dependable Systems and Networks (June 2002), pp. 425–434. [10] Nelson, M., Lim, B.-H., and Hutchins, G. Fast Transparent Migration for Virtual Machines. In Proceedings of the 2005 Annual USENIX Technical Conference (Apr. 2005). [11] Nightingale, E. B., Veeraraghavan, K., Chen, P. M., and Flinn, J. Rethink the Sync. In Proceedings of the 2006 Symposium on Operating Systems Design andImplementation (Nov. 2002). [12] Schlicting, R., and Schneider, F. B. Fail-stop Processors: An Approach to Designing Fault-tolerant Computing Systems. ACM Computing Surveys 1, 3 (Aug.1983), 222–238. [13] Schneider, F. B. Implementing fault-tolerance services using the state machine approach: A tutorial. ACM Computing Surveys 22, 4 (Dec. 1990), 299–319. [14] Stratus Technologies. Benefit from Stratus Continuing Processing Technology: Automatic 99.999% Uptime for Microsoft Windows Server Environments. At http://www.stratus.com/pdf/whitepapers/continuous-processing-for-windows.pdf, June 2009. [15] Xu, M., Malyugin, V., Sheldon, J., Venkitachalam, G., and Weissman, B. ReTrace: Collecting Execution Traces with Virtual Machine Deterministic Replay. InProceedings of the 2007 Workshop on Modeling, Benchmarking, and Simulation (June 2007). 原文","categories":[],"tags":[],"keywords":[]},{"title":"[译文]The Google File System","slug":"2021-01-26-The-Google-File-System","date":"2021-01-26T00:00:00.000Z","updated":"2022-09-12T16:24:32.291Z","comments":true,"path":"2021-01-26-The-Google-File-System/","link":"","permalink":"https://riverferry.site/2021-01-26-The-Google-File-System/","excerpt":"original paper here","text":"original paper here ABSTRACTWe have designed and implemented the Google File System, a scalable distributed file system for large distributed data-intensive applications. It provides fault tolerance while running on inexpensive commodity hardware, and it delivers high aggregate performance to a large number of clients. 概览我们已经设计并实现了GFS,一个针对大的分布式数据密集型应用的可扩展的分布式文件系统。它提供了运行在廉价的商用硬件上的容错处理，和对大量客户端的高的聚合性能。 While sharing many of the same goals as previous distributed file systems, our design has been driven by observations of our application workloads and technological environment, both current and anticipated, that reflect a marked departure from some earlier file system assumptions. This has led us to reexamine traditional choices and explore radically different design points. 尽管和以前的文件系统有着很多相同的目标，而我们的设计是由对于现在和将来的应用工作量和技术环境的观察驱动的，这些反应出和早期文件系统假设的明显不同。这让我们重新审视传统的选择并开始探索和原来完全不同的设计要点。 The file system has successfully met our storage needs. It is widely deployed within Google as the storage platform for the generation and processing of data used by our service as well as research and development efforts that require large data sets. The largest cluster to date provides hundreds of terabytes of storage across thousands of disks on over a thousand machines, and it is concurrently accessed by hundreds of clients. 文件系统已经成功满足我们的存储需求。GFS作为存储平台广泛部署在谷歌内部，用来生成和处理我们的服务数据以及需要大数据集的研究和开发的数据。上千台机器组成的集群通过上千台磁盘提供了数百Tb的数据，并且可以并行的访问上百个客户端。 In this paper, we present file system interface extensions designed to support distributed applications, discuss many aspects of our design, and report measurements from both micro-benchmarks and real world use. 在这篇论文中，我们呈现支持分布式应用的扩展的文件系统接口，讨论我们设计许多方面，并报告基于mocro-benchmarks和真实世界使用的测试数据。 1. INTRODUCTIONWe have designed and implemented the Google File System (GFS) to meet the rapidly growing demands of Google’s data processing needs. GFS shares many of the same goals as previous distributed file systems such as performance, scalability, reliability, and availability. However, its design has been driven by key observations of our application workloads and technological environment, both current and anticipated, that reflect a marked departure from some earlier file system design assumptions. We have reexamined traditional choices and explored radically different points in the design space. 我们已经设计并实现了GFS来解决谷歌迅速增长的数据处理需求。GFS和以前的分布式文件系统有许多相同的目标，比如性能，扩展性，可靠性，可用性。然而，GFS是基于我们对现在和以后的应用负载以及技术环境的观察来设计的，这反映出和早期文件系统设计的假设完全不同。我们重新审视了传统的选择并开始探索和原来完全不同的设计方式。 First, component failures are the norm rather than the exception. The file system consists of hundreds or even thousands of storage machines built from inexpensive commodity parts and is accessed by a comparable number of client machines. The quantity and quality of the components virtually guarantee that some are not functional at any given time and some will not recover from their current failures. We have seen problems caused by application bugs, operating system bugs, human errors, and the failures of disks, memory, connectors, networking, and power supplies. Therefore, constant monitoring, error detection, fault tolerance, and automatic recovery must be integral to the system. 第一，组件故障是正常现象，而非异常。文件系统由成百上千通过廉价商用部件组成的存储机器构成，并被许多客户机访问。组件的数量和质量实际上保证了，在一定的时间有些是不可用的，并且有一些不能从自身的错误中恢复。我们已经遇见了很多问题：应用bug,操作系统bug,人为错误，磁盘/内存/连接器的故障，网络和电源的错误。因此，持续监控，错误检测，容错，和自动恢复对于系统来说是必不可少的。 Second, files are huge by traditional standards. Multi-GB files are common. Each file typically contains many application objects such as web documents. When we are regularly working with fast growing data sets of many TBs comprising billions of objects, it is unwieldy to manage billions of approximately KB-sized files even when the file system could support it. As a result, design assumptions and parameters such as I/O operation and blocksizes have to be revisited. 第二，按传统标椎看现在的文件是很大的。数GB的文件很常见。每个文件通常都包括许多应用对象，比如网页文档。当我们定期处理快速增长的包含数十亿对象的数据集合，即使文件系统支持这样的量级，管理起来也是很笨重的。所以，必须重新设计假设条件和参数的值，比如I/O操作和块大小。 Third, most files are mutated by appending new data rather than overwriting existing data. Random writes within a file are practically non-existent. Once written, the files are only read, and often only sequentially. A variety of data share these characteristics. Some may constitute large repositories that data analysis programs scan through. Some may be data streams continuously generated by running applications. Some may be archival data. Some may be intermediate results produced on one machine and processed on another, whether simultaneously or later in time. Given this access pattern on huge files, appending becomes the focus of performance optimization and atomicity guarantees, while caching data blocks in the client loses its appeal. 第三，大多数文件的变化都是通过追加新数据而不是覆盖原始数据进行的。文件内的随机写几乎不存在。一旦写入，文件就是只读的，通常都是顺序读。许多数据都有这种特性。可能是数据分析程序扫描用的数据仓库，可能是运行中程序连续生成的数据流，可能是档案数据。可能是一台机器产生的中间结果，同时会稍后被另一台机器处理。鉴于对大型文件的这种访问方式，追加写成为了性能优化和原子性保证的重点，相应的在客户端缓存数据块便失去了吸引力。 Fourth, co-designing the applications and the file system API benefits the overall system by increasing our flexibility .For example, we have relaxed GFS’s consistency model to vastly simplify the file system without imposing an onerous burden on the applications. We have also introduced an atomic append operation so that multiple clients can append concurrently to a file without extra synchronization between them. These will be discussed in more details later in the paper. 第四，应用程序和文件系统api共同设计可以提高整个系统的灵活性。例如，我们放宽了GFS的一致性模型来极大的简化文件系统，避免给应用程序带来繁重的负担。我们也介绍了原子追加写的方式可以让多个客户端能够并行的追加写而不需要进行额外的同步。论文的后面会对这些细节进行更多的讨论。 Multiple GFS clusters are currently deployed for different purposes. The largest ones have over 1000 storage nodes, over 300 TB of diskstorage, and are heavily accessed by hundreds of clients on distinct machines on a continuous basis. 目前已经部署了多个GFS集群，出于不同的目的。最大的一个包含超过1000个节点，超过300TB的磁盘存储，并且连续不断的被分布在不同机器上的数百个客户端大量访问。 2. DESIGN OVERVIEW2.1 AssumptionsIn designing a file system for our needs, we have been guided by assumptions that offer both challenges and opportunities. We alluded to some key observations earlier and now lay out our assumptions in more details. 在设计满足我们需求的文件系统的时候，我们需要以挑战和机遇并存的假设为指引。前面我们已经提过了一些关键的观察点，现在将阐述关于假设更多的细节。 The system is built from many inexpensive commodity components that often fail. It must constantly monitor itself and detect, tolerate, and recover promptly from component failures on a routine basis. 系统是由许多容易出故障的廉价组件构成的。必须对系统进行持续的监控，检测，容错，以及及时的从组件故障中恢复。 The system stores a modest number of large files. We expect a few million files, each typically 100 MB or larger in size. Multi-GB files are the common case and should be managed efficiently. Small files must be supported, but we need not optimize for them. 文件系统存储了适量的大文件。我们预计有几百万个文件，每个通常为100m或者更大。数Gb的文件是常见的情况，这应该能够有效的管理。小文件必须支持，但我们不需要对小文件进行优化。 The workloads primarily consist of two kinds of reads: large streaming reads and small random reads. In large streaming reads, individual operations typically read hundreds of KBs, more commonly 1 MB or more. Successive operations from the same client often read through a contiguous region of a file. A small random read typically reads a few KBs at some arbitrary offset. Performance-conscious applications often batch and sort their small reads to advance steadily through the file rather than go backand forth. 工作负载主要包含两种读取：大的流式读取和小的随机读取。对于大的流式读取，个人操作通常读取几百kbs，更常见的是1m或者更多。同一客户端的连续读取通常读取的是文件的连续区域。小的随机读取通常在任意偏移位置读取几kbs的数据。注重性能表现的程序通常对于小的读取进行批处理和排序来稳定的向前读取文件，而不是来回切换的读取。 The workloads also have many large, sequential writes that append data to files. Typical operation sizes are similar to those for reads. Once written, files are seldom modified again. Small writes at arbitrary positions in a file are supported but do not have to be efficient. 工作负载也包含许多大的连续的顺序追加写。这些写操作通常和读取操作的大小是相似的。一旦写入，文件很少会被修改。小的随机写需要支持，但不需要保证效率。 The system must efficiently implement well-defined semantics for multiple clients that concurrently append to the same file. Our files are often used as producer-consumer queues or for many-way merging. Hundreds of producers, running one per machine, will concurrently append to a file. Atomicity with minimal synchronization overhead is essential. The file may be read later, or a consumer may be reading through the file simultaneously. 文件系统必须对多个客户端在同一个文件追加写实现定义良好的语义。文件通常作为生产者消费者队列或用于多路合并。数百个生产者，每个机器运行一个，将并发追加写到文件。原子性和最小化的同步开销是必要的。文件可能稍后被读取，也可能同时被一个消费者读取。 High sustained bandwidth is more important than low latency. Most of our target applications place a premium on processing data in bulkat a high rate, while few have stringent response time requirements for an individual read or write. 高持续性的带宽比低延迟更加重要。大多数的目标应用程序更加重视高速率的处理大的数据，而不会对单个的读或写的响应时间有严格要求。 2.2 InterfaceGFS provides a familiar file system interface, though it does not implement a standard API such as POSIX. Files are organized hierarchically in directories and identified by pathnames. We support the usual operations to create, delete, open, close, read, and write files. GFS提供了熟悉的文件系统接口，即使它没有实现像POSIX那样的标椎API.文件在目录中有组织的分层，通过路径标识。我们支持常用的操作，像是create/delete/open/close/read/write. Moreover, GFS has snapshot and record append operations. Snapshot creates a copy of a file or a directory tree at low cost. Record append allows multiple clients to append data to the same file concurrently while guaranteeing the atomicity of each individual client’s append. It is useful for implementing multi-way merge results and producerconsumer queues that many clients can simultaneously append to without additional locking. We have found these types of files to be invaluable in building large distributed applications. Snapshot and record append are discussed further in Sections 3.4 and 3.3 respectively. 此外，GFS有快照和记录追加机制。快照以低成本创建文件或目录树的拷贝。记录追加机制允许多个客户端并行的追加写数据到相同的文件并保证了每一个追加写的原子性。这对于实现多路合并以及生产者消费者队列是有用的，多个客户端可以同时追加写而不需要额外的锁操作。我们发现这种文件类型对于建立大型分布式应用是非常有价值的。快照和记录追加将在3.4和3.3节进行更多的讨论。 2.3 ArchitectureA GFS cluster consists of a single master and multiple chunkservers and is accessed by multiple clients, as shown in Figure 1. Each of these is typically a commodity Linux machine running a user-level server process. It is easy to run both a chunkserver and a client on the same machine, as long as machine resources permit and the lower reliability caused by running possibly flaky application code is acceptable. 架构GFS集群由一个master和多个chunkservers组成并被多个客户端访问，如图1所示。master/chunkserver通常都是运行在商用linux机器的用户级进程。可以将chunkserver和客户端运行在相同的机器，只要机器资源允许，并且可以接受运行不稳定程序可能带来的低可靠性。 Files are divided into fixed-size chunks. Each chunk is identified by an immutable and globally unique 64 bit chunk handle assigned by the master at the time of chunk creation. Chunkservers store chunks on local disks as Linux files and read or write chunkdata specified by a chunk handle and byte range. For reliability, each chunk is replicated on multiple chunkservers. By default, we store three replicas, though users can designate different replication levels for different regions of the file namespace. 文件被分割为固定大小的chunks。每个chunk由一个固定且全局的64bit chunk handle组成，chunk handle在chunk创建的时候由master分配。chunkserver将chunks存储在磁盘中，以文件的方式，并根据chunkhandle和字节大小读取或写入chunkdata.为了可靠性，每个chunk会在多个chunkserver进行备份。缺省情况下，会保存3份拷贝，用户也可以为文件命名空间的不同区域指定不同的复制级别。 The master maintains all file system metadata. This includes the namespace, access control information, the mapping from files to chunks, and the current locations of chunks. It also controls system-wide activities such as chunk lease management, garbage collection of orphaned chunks, and chunk migration between chunkservers. The master periodically communicates with each chunkserver in HeartBeat messages to give it instructions and collect its state. master维护所有文件系统的元数据。包括命名空间，访问控制信息，文件到chunks的映射，chunks的当前位置。master还控制整个系统的活动，比如chunk的租约管理，孤儿chunk的垃圾回收，以及多个chunkservers间的chunk迁移。master定期的和每个chunkserver通过心跳包进行保活，也通过心跳包给chunkserver发送指示和收集chunkserver的状态信息。 GFS client code linked into each application implements the file system API and communicates with the master and chunkservers to read or write data on behalf of the application. Clients interact with the master for metadata operations, but all data-bearing communication goes directly to the chunkservers. We do not provide the POSIX API and therefore need not hookinto the Linux vnode layer. GFS中链接到应用程序的client实现了文件系统API,和master/chunkserver进行通信，代替应用来读取和写入数据。client和master通信来进行元数据操作，但是承载的数据由client和chunkserver直接传输。我们没有提供POSIX API接口，因此client代码不需要嵌入到linux的vnode层。 Neither the client nor the chunkserver caches file data. Client caches offer little benefit because most applications stream through huge files or have working sets too large to be cached. Not having them simplifies the client and the overall system by eliminating cache coherence issues. (Clients do cache metadata, however.) Chunkservers need not cache file data because chunks are stored as local files and so Linux’s buffer cache already keeps frequently accessed data in memory. clinet和chunkserver都不缓存文件数据。client缓存作用很小，因为大多数用于都是通过大文件进行流式存储或者数据集太大根本就无法缓存。没有缓存让client和整个系统变得简单，因为消除了缓存的一致性问题(但实际上client会缓存元数据)。chunkservers不需要缓存文件数据因为chunks是存储在磁盘的本地文件，而linux的buffer cache层已经缓存了频繁访问的数据在内存。 2.4 Single MasterHaving a single master vastly simplifies our design and enables the master to make sophisticated chunk placement and replication decisions using global knowledge. However, we must minimize its involvement in reads and writes so that it does not become a bottleneck. Clients never read and write file data through the master. Instead, a client asks the master which chunkservers it should contact. It caches this information for a limited time and interacts with thechunkservers directly for many subsequent operations. 只有一个master极大的简化了我们的设计，也使得master可以根据掌握的全局信息来决定chunk和副本的位置。但是，必须最小化master对于读和写的参与以避免master成为瓶颈。clients不会从master直接读取文件数据。而是向master询问它应该和哪一个chunkserver进行联系。client会缓存这些元数据的信息在有限的时间内，然后直接和相应的chunkservers进行通信，进行相应的操作。 Let us explain the interactions for a simple read with reference to Figure 1. First, using the fixed chunksize, the client translates the file name and byte offset specified by the application into a chunk index within the file. Then, it sends the master a request containing the file name and chunk index. The master replies with the corresponding chunk handle and locations of the replicas. The client caches this information using the file name and chunkindex as the key. 让我们参考图1解释下一次读流程的交互过程。首先，通过固定的chanksize,客户端将应用指定的文件名和字节偏移转换为chunk index.然后将文件名和chunk index发给Master。master回复chunk的handle和位置信息给客户端。客户端将这些信息缓存下来，key是文件名和chunk index. The client then sends a request to one of the replicas, most likely the closest one. The request specifies the chunk handle and a byte range within that chunk. Further reads of the same chunk require no more client-master interaction until the cached information expires or the file is reopened. In fact, the client typically asks for multiple chunks in the same request and the master can also include the information for chunks immediately following those requested. This extra information sidesteps several future client-master interactions at practically no extra cost. 然后客户端发送请求给其中一个副本，最可能是离得最近的那个。请求指定了chunk的句柄和chunk内的字节范围。在客户端缓存失效或者文件被reopen之前，请求相同的chunk，客户端都不再需要和master进行交互。事实上，客户端通常一次请求多个chunks, master也会在请求到来后携带多个chunks的信息给客户端。这些额外的信息减少了以后客户端和master之间的交互，并且没有额外的代价。 2.5 Chunk SizeChunksize is one of the key design parameters. We have chosen 64 MB, which is much larger than typical file system blocksizes. Each chunk replica is stored as a plain Linux file on a chunkserver and is extended only as needed. Lazy space allocation avoids wasting space due to internal fragmentation, perhaps the greatest objection against such a large chunksize. chunksize是一个关键的设计参数。我们选择了比一般的文件系统块大得多的64M.每个chunk的副本以普通linux文件的方式存储在chunkserver,只有在需要的时候才扩展。这种惰性空间分配避免了内部碎片造成的空间浪费，这些碎片最大可能有一个chunksize那么大(?这里英文不是很理解)。 A large chunksize offers several important advantages. First, it reduces clients’ need to interact with the master because reads and writes on the same chunk require only one initial request to the master for chunklocation information. The reduction is especially significant for our workloads because applications mostly read and write large files sequentially. Even for small random reads, the client can comfortably cache all the chunklocation information for a multi-TB working set. Second, since on a large chunk, a client is more likely to perform many operations on a given chunk, it can reduce network overhead by keeping a persis-tent TCP connection to the chunkserver over an extended period of time. Third, it reduces the size of the metadata stored on the master. This allows us to keep the metadata in memory, which in turn brings other advantages that we will discuss in Section 2.6.1. 大的chunksize有几个重要的优点.首先，它减少了客户端和Master交互的需求，因为一个chunk上的读和写只需要客户端和master之间一次初始化请求，拿到chunk的位置信息就行了。也能减少我们的工作负载，因为应用几乎都是顺序的读写大文件，也因此客户端可以在一个指定的chunk执行更多的操作，通过和chunkserver保持tcp长连接，也能减少网络负载。第三，可以减少master存储的元数据。这使得master可以加个元数据缓存在内存中，并带来其他的优先，具体我们将在2.6.1节再进行讨论。 On the other hand, a large chunksize, even with lazy space allocation, has its disadvantages. A small file consists of a small number of chunks, perhaps just one. The chunkservers storing those chunks may become hot spots if many clients are accessing the same file. In practice, hot spots have not been a major issue because our applications mostly read large multi-chunkfiles sequentially. 另一方面，大的chunk size,即使是惰性空间分配，也有它的缺点。一个小的文件由少量的chunks组成，也可能只有一个chunk.如果许多客户端都访问相同的文件，chunkserver存储的这些chunks就可能成为热点数据。实际上，热点并不是主要的问题，因为应用程序基本上都是顺序访问大的多chunks组成的文件。 However, hot spots did develop when GFS was first used by a batch-queue system: an executable was written to GFS as a single-chunkfile and then started on hundreds of machines at the same time. The few chunkservers storing this executable were overloaded by hundreds of simultaneous requests. We fixed this problem by storing such executables with a higher replication factor and by making the batchqueue system stagger application start times. A potential long-term solution is to allow clients to read data from other clients in such situations. 然而，热点数据被批队列系统第一次使用的时候出现了：一个单chunk的可执行文件被写入GFS,然后在数百台机器上同时执行。存储这个可执行文件的几个chunkservers被同一时间收到的数百条请求搞过载了。我们已经解决了这个问题，通过给这个可执行文件更高的拷贝因子并且让批队列系统错开启动时间。一个潜在的长期的解决方案是允许客户端在这种场景下可以从其他的客户端读取数据。 2.6 MetadataThe master stores three major types of metadata: the file and chunk namespaces, the mapping from files to chunks, and the locations of each chunk’s replicas. All metadata is kept in the master’s memory. The first two types (namespaces and file-to-chunkmapping) are also kept persistent by logging mutations to an operation log stored on the master’s local disk and replicated on remote machines. Using a log allows us to update the master state simply, reliably, and without risking inconsistencies in the event of a master crash. The master does not store chunk location information persistently. Instead, it asks each chunkserver about its chunks at master startup and whenever a chunkserver joins the cluster. master存储3种主要的元数据类型：文件和chunk的命名空间，文件到chunks的映射关系，每个chunk的副本的位置。所有的元数据在master中缓存。前两种(文件和chunk的命名空间，文件到chunks的映射关系)的变化信息也被记录到保存在master本地磁盘的操作日志中，日志也会备份在其他机器上。使用日志让我们可以简单的更新master的状态，变得可靠，不用冒master奔溃引起的不一致的风险。master也不是固定的存储这些元数据，master启动的时候会取询问每一个chunkserver他们的chunks的信息，并且有新的chunkserver加入的时候也会去询问。 2.6.1 In-Memory Data StructuresSince metadata is stored in memory, master operations are fast. Furthermore, it is easy and efficient for the master to periodically scan through its entire state in the background. This periodic scanning is used to implement chunk garbage collection, re-replication in the presence of chunkserver failures, and chunk migration to balance load and diskspace usage across chunkservers. Sections 4.3 and 4.4 will discuss these activities further. 因为元数据存储在内存中，所以master的操作很快。此外，这使得master在后台扫描所有的状态变得简单有效。持续的扫描是为了进行chunk的垃圾回收，chunkserver故障时的重新复制，以及为了平衡负载和磁盘使用情况在chunkservers间进行的chunk迁移。第4.3和4.4节将更讨论这些活动。 One potential concern for this memory-only approach is that the number of chunks and hence the capacity of the whole system is limited by how much memory the master has. This is not a serious limitation in practice. The master maintains less than 64 bytes of metadata for each 64 MB chunk. Most chunks are full because most files contain many chunks, only the last of which may be partially filled. Similarly, the file namespace data typically requires less then 64 bytes per file because it stores file names compactly using prefix compression. 对于这种只使用内存保存的方法有一个潜在的问题，就是chunks的数量，以及整个系统的容量受到master的内存大小的限制。但实际上这不是严重的限制。每个64M大小的块在master中对应的元数据大小少于64字节，因为多数文件都是包含多个块的，只有最后的块可能是部分填充的。并且，master中存储的单个命名空间数据也是少于64字节的，因为文件名使用前缀压缩算法保存。 If necessary to support even larger file systems, the cost of adding extra memory to the master is a small price to pay for the simplicity, reliability, performance, and flexibility we gain by storing the metadata in memory. 如果要支持更大的文件系统，给master增加更多内存的代价，远小于存储到内存中带来的易用性，可靠性，高性能，可维护性带来的好处。我们将这些元数据保存在内存中而获益。 2.6.2 Chunk LocationsThe master does not keep a persistent record of which chunkservers have a replica of a given chunk. It simply polls chunkservers for that information at startup. The master can keep itself up-to-date thereafter because it controls all chunk placement and monitors chunkserver status with regular HeartBeat messages. master并不会持久性的保存这些记录(一个指定的chunk的拷贝在哪些chunkservers上)。master在启动时轮训所以的chunservers来获取这些信息。master控制所有chunk的位置并且通过定时的心跳包来监控chunkserver的状态，所以master存储的信息总是最新的。 We initially attempted to keep chunk location information persistently at the master, but we decided that it was much simpler to request the data from chunkservers at startup, and periodically thereafter. This eliminated the problem of keeping the master and chunkservers in sync as chunkservers join and leave the cluster, change names, fail, restart, and so on. In a cluster with hundreds of servers, these events happen all too often. 我们一开始尝试在master中持久性的保存chunk的位置信息，但是我们发现master在启动以及启动后定期的向chunkserver请求这些数据会更加简单。这也解决了master和chunkserver保持同步的问题，有新加入的chunkserver，有退出的chunkserver,chunkserver的重命名，故障，重启，等等。在一个有数百台机器的集群中，这是经常发生的。 Another way to understand this design decision is to realize that a chunkserver has the final word over what chunks it does or does not have on its own disks. There is no point in trying to maintain a consistent view of this information on the master because errors on a chunkserver may cause chunks to vanish spontaneously (e.g., a disk may go bad and be disabled) or an operator may rename a chunkserver. 另一种理解这种设计的方式是意识到chunkserver对chunks要不要保存在自己的磁盘中有最终的决定权。持久性的保存这些信息在master中没有意义，因为一些错误可能导致部分chunks消失(比如磁盘故障或者不可用)或者有操作可能重新命名了chunkserver. 2.6.3 Operation LogThe operation log contains a historical record of critical metadata changes. It is central to GFS. Not only is it the only persistent record of metadata, but it also serves as a logical time line that defines the order of concurrent operations. Files and chunks, as well as their versions (see Section 4.5), are all uniquely and eternally identified by the logical times at which they were created. 操作日志保留了关键元数据变更的历史记录。这是GFS的核心。不仅仅因为操作日志是唯一持久化保存的元数据记录，也因为它记录了并发操作的逻辑时间线。对于文件，chunks,以及它们的版本(见4.5节)，都是在他们创建的时候通过逻辑时间唯一且永久的定义的。 Since the operation log is critical, we must store it reliably and not make changes visible to clients until metadata changes are made persistent. Otherwise, we effectively lose the whole file system or recent client operations even if the chunks themselves survive. Therefore, we replicate it on multiple remote machines and respond to a client operation only after flushing the corresponding log record to disk both locally and remotely. The master batches several logrecords together before flushing there by reducing the impact of flushing and replication on overall system throughput. 因为操作日志十分重要，所以我们必须可靠的对齐进行存储，直到元数据持久化之后再将变化对客户端可见。否则，我们可能会丢失整个文件系统或最近的客户端操作，即使chunkserver还是运行的。因此，我们再其他机器上对元数据进行备份，仅当数据在本地和其他机器上落盘后才响应给客户端。master在刷盘前会批处理一些日志记录来减少刷盘拷贝对于整个系统吞吐量的影响。 The master recovers its file system state by replaying the operation log. To minimize startup time, we must keep the log small. The master checkpoints its state whenever the log grows beyond a certain size so that it can recover by loading the latest checkpoint from local disk and replaying only the limited number of log records after that. The checkpoint is in a compact B-tree like form that can be directly mapped into memory and used for namespace lookup without extra parsing. This further speeds up recovery and improves availability. master通过重放操作日志可以恢复自身的文件系统。为了最小化启动时间，我们必须让日志比较小。当日志增长到超过一个固定的大小master会检查自身状态，为了实现从磁盘加载最近的检查点的时候只重放检查点后的有限的记录。检查点保存在类似B-tree的结构，可以直接映射到内存用于命名空间的查找而不需要额外的解析。这进一步加快了恢复速度并提高了可用性。 Because building a checkpoint can take a while, the master’s internal state is structured in such a way that a new checkpoint can be created without delaying incoming mutations. The master switches to a new log file and creates the new checkpoint in a separate thread. The new checkpoint includes all mutations before the switch. It can be created in a minute or so for a cluster with a few million files. When completed, it is written to diskboth locally and remotely. 因为建立一个检查点需要一些时间，所以master内部状态的结构化是以这种方式：一个新的检查点被创建，没有延迟处理传入的变化。master切换到一个新的日志文件然后在一个分离的线程中创建新的检查点。新的检查点包含了切换前的所有变化。对于几百万的文件可以在一分钟左右创建完成。完成的时候，已经同时写入了本地和其他机器上的磁盘。 Recovery needs only the latest complete checkpoint and subsequent log files. Older checkpoints and log files can be freely deleted, though we keep a few around to guard against catastrophes. A failure during checkpointing does not affect correctness because the recovery code detects and skips incomplete checkpoints. 恢复只需要最近的完成的检查点和其后的日志文件。老的检查点和日志文件可以被删除，即使我们会保存一些来保证容灾的处理。创建检查点期间发生的故障并不影响正确性，因为恢复的代码会检查并跳过未完成的检查点。 2.7 Consistency ModelGFS has a relaxed consistency model that supports our highly distributed applications well but remains relatively simple and efficient to implement. We now discuss GFS’s guarantees and what they mean to applications. We also highlight how GFS maintains these guarantees but leave the details to other parts of the paper. GFS有相对宽松的一致性模型，能够很好的支持我们的高分布式的应用且实现起来相对的简单和有效。我们现在讨论GFS的一致性保证，以及其对于应用程序的意义。我们也会重点讨论GFS如何提供一致性保证但是将细节留在其他部分讨论。 2.7.1 Guarantees by GFSFile namespace mutations (e.g., file creation) are atomic. They are handled exclusively by the master: namespace locking guarantees atomicity and correctness (Section 4.1); the master’s operation log defines a global total order of these operations (Section 2.6.3). 文件命名空间的变化(比如文件创建)是原子的。这些只由master来处理：命名空间锁保证了原子性和正确性(4.1节)；master的操作日志定义了全局的所有这些操作的顺序(2.6.3)。 The state of a file region after a data mutation depends on the type of mutation, whether it succeeds or fails, and whether there are concurrent mutations. Table 1 summarizes the result. A file region is consistent if all clients will always see the same data, regardless of which replicas they read from. A region is defined after a file data mutation if it is consistent and clients will see what the mutation writes in its entirety. When a mutation succeeds without interference from concurrent writers, the affected region is defined (and by implication consistent): all clients will always see what the mutation has written. Concurrent successful mutations leave the region undefined but consistent: all clients see the same data, but it may not reflect what any one mutation has written. Typically, it consists of mingled fragments from multiple mutations. A failed mutation makes the region inconsistent (hence also undefined): different clients may see different data at different times. We describe below how our applications can distinguish defined regions from undefined regions. The applications do not need to further distinguish between different kinds of undefined regions. 文件区域在数据变化后的状态取决于变化的类型，而不管是成功或失败，或者是不是并行的变更。表1概述了这种结果。如果所有的客户端都总是能看到相同的数据，不管它读取的是哪个副本,那么这个文件区域就是一致性的。如果它是一致性的并且客户端总是能读取所有变化写入的数据，那么区域A在文件变化后是已定义的。当一个变更在没有并发写干扰下成功执行，受影响的区域是已定义的(也是含义一致的):所有客户端都总能看到写入的变更。并行的成功变更导致区域是未定义但一致性的：所有客户端看到相同的数据，但是看不出是哪一个写入的变更。通常，由多个变更的碎片混杂在一起组成。一个失败的变更会导致区域成为非一致性(也是未定义的)：不同的客户端在不同的时间可能会看到不同的数据。我们在下面描述我们的应用程序如何区别已定义德和未定义的区域。程序并不需要更多的区分不同种类的未定义的区域。 Data mutations may be writes or record appends. A write causes data to be written at an application-specified file offset. A record append causes data (the “record”) to be appended atomically at least once even in the presence of concurrent mutations, but at an offset of GFS’s choosing (Section 3.3). (In contrast, a “regular” append is merely a write at an offset that the client believes to be the current end of file.) The offset is returned to the client and marks the beginning of a defined region that contains the record. In addition, GFS may insert padding or record duplicates in between. They occupy regions considered to be inconsistent and are typically dwarfed by the amount of user data. 写入和追加记录会引起数据变化。写入是将数据写入文件中应用指定的偏移位置。记录追加将数据原子性的追加至少一次，即使是在并行的情况下，但是是追加的位置是GFS选择的(3.3节)。(而常规的追加写是仅仅写到客户端人为的当前文件的末尾) 偏移位置会返回给客户端然后标记这块记录所在的已定义区域的起始位置。除此之外，GFS可能会插入padding或者重复的记录数据。他们会占据被认为是不一致的区域，这通常比用户数据小得多。 After a sequence of successful mutations, the mutated file region is guaranteed to be defined and contain the data written by the last mutation. GFS achieves this by (a) applying mutations to a chunk in the same order on all its replicas (Section 3.1), and (b) using chunkversion numbers to detect any replica that has become stale because it has missed mutations while its chunkserver was down (Section 4.5). Stale replicas will never be involved in a mutation or given to clients asking the master for chunk locations. They are garbage collected at the earliest opportunity. 在一系列变更之后，变化的文件区域可以保证是已定义的，并且包含最后一次变更写入的数据。GFS是通过这两点来实现的：a 按顺序将对chunk的变更应用到chunk的所有副本(3.1节)，b 使用chunk版本号来检测因为chunkserver挂掉而丢失变更从而已经过期的副本。过期的副本不会算入变更，在客户端向master请求chunk位置的时候也会过滤掉已经过期的副本。这些过期的副本会被尽可能早的进行垃圾回收。 Since clients cache chunk locations, they may read from a stale replica before that information is refreshed. This window is limited by the cache entry’s timeout and the next open of the file, which purges from the cache all chunk information for that file. Moreover, as most of our files are append-only, a stale replica usually returns a premature end of chunk rather than outdated data. When a reader retries and contacts the master, it will immediately get current chunk locations. 因为客户端缓存了chunk的位置信息，在缓存数据刷新前可能会从已经过期的副本上读取。这种情况会受到一些约束，缓存项超过超期时间或者文件被重新打开，都会清除掉对应文件的所有缓存位置信息。并且，大多数的文件都是追加写入的，已过期的副本通常会返回早期的chunk的尾部信息而不是已经过期的数据。当reader重试然后和master进行沟通，将会立刻获得最新的chunk的位置信息。 Long after a successful mutation, component failures can of course still corrupt or destroy data. GFS identifies failed chunkservers by regular handshakes between master and all chunkservers and detects data corruption by checksumming (Section 5.2). Once a problem surfaces, the data is restored from valid replicas as soon as possible (Section 4.3). A chunk is lost irreversibly only if all its replicas are lost before GFS can react, typically within minutes. Even in this case, it becomes unavailable, not corrupted: applications receive clear errors rather than corrupt data. 成功变更很久之后，组件故障也还是可能损坏和破坏数据.GFS通过master和所有chunkserver进行定期的握手来检测故障的chunkserver,并通过校验和检查数据是否已损坏。一单问题发生，会尽快的从有效的副本恢复。chunk的丢失不可逆转的情况只发生在，GFS反应前所有的chunk的副本都丢失了，反应时间通常在几分钟内。即使在这种情况下，数据是不可用的，而不是已损坏的：应用程序可以接受到明确的错误信息而不是收到已损坏的数据。 2.7.2 Implications for ApplicationsGFS applications can accommodate the relaxed consistency model with a few simple techniques already needed for other purposes: relying on appends rather than overwrites, checkpointing, and writing self-validating, self-identifying records. GFS应用程序可以通过一些其他的简单技术来适应这种宽松的一致性模型：追加写而不是覆盖写，检查点，写入自验证，自标识的记录。 Practically all our applications mutate files by appending rather than overwriting. In one typical use, a writer generates a file from beginning to end. It atomically renames the file to a permanent name after writing all the data, or periodically checkpoints how much has been successfully written. Checkpoints may also include application-level checksums. Readers verify and process only the file region up to the last checkpoint, which is known to be in the definedstate. Regardless of consistency and concurrency issues, this approach has served us well. Appending is far more efficient and more resilient to application failures than random writes. Checkpointing allows writers to restart incrementally and keeps readers from processing successfully written file data that is still incomplete from the application’s perspective. 实际上我们的应用程序修改文件都是通过追加写而不是随机写。一种典型的情况是，一个write从头到尾写一个文件。所有数据写完的时候会原子性的重命名文件，或者定期的检查有多少成功写入了。检查点可能包含应用级别的校验和。reader校验并处理到上一次检查点之间文件范围的数据，这些数据都是已定义的状态。忽视一致性和并行的问题，这种方式工作的很好。追加写相比于随机写，要非常的高效并且对于应用故障也更有弹性。检查点允许writer可以渐进的重新启动，并阻止reader读取已经写入的数据，这些数据在应用角度来看是不完整的。 In the other typical use, many writers concurrently append to a file for merged results or as a producer-consumer queue. Record append’s append-at-least-once semantics preserves each writer’s output. Readers deal with the occasional padding and duplicates as follows. Each record prepared by the writer contains extra information like checksums so that its validity can be verified. A reader can identify and discard extra padding and record fragments using the checksums. If it cannot tolerate the occasional duplicates (e.g., if they would trigger non-idempotent operations), it can filter them out using unique identifiers in the records, which are often needed anyway to name corresponding application entities such as web documents. These functionalities for record I/O (except duplicate removal) are in library code shared by our applications and applicable to other file interface implementations at Google. With that, the same sequence of records, plus rare duplicates, is always delivered to the record reader. 另外一种典型的情况是，多个writers并行的追加写用于合并文件或者用于生产者消费者队列。记录追加写的”至少追加写一次“语义保留了每一个write的输出。reader处理偶尔的padding和重复。writer写记录之前都会加入额外的信息(比如校验和)确保记录可以被验证有效性。reader可以通过校验和识别并忽略额外的填充和记录碎片信息。如果不能容忍偶尔的重复数据(比如可能触发了非幂等的操作)，也可以通过唯一标识来过滤记录，这通常需要命名相应的程序项，比如web文档。这些记录IO(不包含重复的删除)的功能都在我们程序共享的库代码中，并且对于谷歌已实现的其他文件接口也是适用的。这样一来，相同的记录顺序，加上罕见的重复，总是会呈现给记录的reader. 3. SYSTEM INTERACTIONSWe designed the system to minimize the master’s involvement in all operations. With that background, we now describe how the client, master, and chunkservers interact to implement data mutations, atomic record append, and snapshot. 我们设计这个系统是要最小化master和各种操作的相关性。在这个背景之下，我们现在描述client,master,chunkserver之间如何交互以实现数据的变更，原子记录的写入，和快照。 3.1 Leases and Mutation OrderA mutation is an operation that changes the contents or metadata of a chunk such as a write or an append operation. Each mutation is performed at all the chunk’s replicas. We use leases to maintain a consistent mutation order across replicas. The master grants a chunk lease to one of the replicas, which we call the primary. The primary picks a serial order for all mutations to the chunk. All replicas follow this order when applying mutations. Thus, the global mutation order is defined first by the lease grant order chosen by the master, and within a lease by the serial numbers assigned by the primary. 变更指的是文本或者元信息的chunk被修改的操作，例如覆盖写或者追加写。每一个变更都在chunk的所有副本上生效。我们使用租约来保持多个副本之间变更的一致性。master分配一个租约给其中我们称之为primary的副本。primaru会为该chunk的所有变更选择一个顺序。应用变更的时候所有副本都基于这个顺序。因此，master一开始会分配租约分配顺序来定义全局的变更顺序，每一个租约内部的顺序由parimary分配 The lease mechanism is designed to minimize management overhead at the master. A lease has an initial timeout of 60 seconds. However, as long as the chunk is being mutated, the primary can request and typically receive extensions from the master indefinitely. These extension requests and grants are piggybacked on the HeartBeat messages regularly exchanged between the master and all chunkservers. The master may sometimes try to revoke a lease before it expires (e.g., when the master wants to disable mutations on a file that is being renamed). Even if the master loses communication with a primary, it can safely grant a newlease to another replica after the old lease expires. 租约机制旨在最小化master的管理开销。每个租约有一个初始化的60s的超时时间。但是只要chunk正在变更，primary就可以向master申请无限期的延长租约时间，通常还会收到一些扩展的信息。扩展信息和租约分配都是带在master和所有的chunkserver之间定期的心跳包里面。master有时候可能会尝试在租约过期之前进行撤销(例如，master想要对一个重命名的文件禁用变更)。即使master丢失了primary的信息，它也可以在这个primary过期之后，分配一个新的租约给另一个副本。 In Figure 2, we illustrate this process by following the control flow of a write through these numbered steps. 在图2中，我们按照下面编号的步骤说明一个写控制流的过程。 The client asks the master which chunkserver holds the current lease for the chunk and the locations of the other replicas. If no one has a lease, the mastergrants one to a replica it chooses (not shown). 1 客户端向master询问哪一个chunkserver有chunk的当前租约，以及其他副本所在的位置。如果没有chunkserver拥有租约，master会选择一个副本分配租约。(这里没有展示) The master replies with the identity of the primary and the locations of the other (secondary) replicas. The client caches this data for future mutations. It needs to contact the master again only when the primary becomes unreachable or replies that it no longer holds a lease. 2 master回复primary的标识和其他副本的位置。客户端为以后的变更缓存这个数据。只有当primary变得不可访问或者primary回复说它不再拥有租约了，客户端才需要再次和master联系。 The client pushes the data to all the replicas. A client can do so in any order. Each chunkserver will store the data in an internal LRU buffer cache until the data is used or aged out. By decoupling the data flow from the control flow, we can improve performance by scheduling the expensive data flow based on the network topology regardless of which chunkserver is the primary. Section 3.2 discusses this further. 3 客户端推送数据给所有副本。客户端可以按照任意顺序推送。chunkserver会将数据存储在LRU的缓存中，知道数据被数据或者过期。通过对数据流和控制流进行解耦，我们提高在网络拓扑上调度数据的性能，而不用管primary在哪一个chunkserver上。3.2节将讨论更多 Once all the replicas have acknowledged receiving the data, the client sends a write request to the primary. The request identifies the data pushed earlier to all of the replicas. The primary assigns consecutive serial numbers to all the mutations it receives, possibly from multiple clients, which provides the necessary serialization. It applies the mutation to its own local state in serial number order. 一旦所有的副本都确认收到了数据，客户端会发送一个写请求给primary.请求中标识了之前推送给所有副本的数据。primary为它接受的可能来自多个客户端的所有变更，分配连续的序列号，这提供了必要的序列化。primary会按照序列号的顺序应用变更到自己的本地状态。 The primary forwards the write request to all secondary replicas. Each secondary replica applies mutations in the same serial number order assigned by the primary. primary传递写请求给所有其他次要的的副本。每一个次要的副本按照primary分配的序列号的顺序应用变更。 The secondaries all reply to the primary indicating that they have completed the operation. 所有次要的副本回复给primary表明自己已经完成了变更 The primary replies to the client. Any errors encountered at any of the replicas are reported to the client. In case of errors, the write may have succeeded at the primary and an arbitrary subset of the secondary replicas. (If it had failed at the primary, it would not have been assigned a serial number and forwarded.) The client request is considered to have failed, and the modified region is left in an inconsistent state. Our client code handles such errors by retrying the failed mutation. It will make a few attempts at steps (3) through (7) before falling backto a retry from the beginning of the write. 7 primary回复client.任何副本发生任何错误都会报告给客户端。错误发生的时候，primary或者其他副本的一部分可能已经成功写入了。(如果primary失败了，它就不会分配序列号也不会传递写请求)。客户端请求被认为是处理失败的，修改的区域也变为了不一致的状态。我们的客户端通过对错误的变更进行重试来处理这种错误。在开始写返回到重试前，可能会在3-7阶段进行一些尝试。 If a write by the application is large or straddles a chunk boundary, GFS client code breaks it down into multiple write operations. They all follow the control flow described above but may be interleaved with and overwritten by concurrent operations from other clients. Therefore, the shared file region may end up containing fragments from different clients, although the replicas will be identical because the individual operations are completed successfully in the same order on all replicas. This leaves the file region in consistent but undefined state as noted in Section 2.7. 如果应用程序的写操作很大或者跨块边界，GFS客户端代码会将其拆分为多个写操作。他们都按照前面描述的控制流程执行，但可能会在来自多个客户端的并行操作的覆盖写之间交错。因此，共享的文件区域最终可能包含了来自不同客户端的片段，但是所有副本最终都是一致的，因为每个副本的操作都是按照相同的顺序成功完成的。这导致文件区域是一致性但未定义的状态，如2.7节所述 3.2 Data FlowWe decouple the flow of data from the flow of control to use the network efficiently. While control flows from the client to the primary and then to all secondaries, data is pushed linearly along a carefully picked chain of chunkservers in a pipelined fashion. Our goals are to fully utilize each machine’s network bandwidth, avoid network bottlenecks and high-latency links, and minimize the latency to push through all the data. 我们解耦了数据流和控制流，为了高效使用网络。当控制从客户端流向primary然后流向其他所有的副本，数据以流水线的方式沿着chunkservers之间选择的链路线性的推送。我们的目标是充分利用每天机器的网络带宽，避免网络瓶颈和高延迟的链接，以及最小化推送所有数据的延迟。 To fully utilize each machine’s networkbandwidth, the data is pushed linearly along a chain of chunkservers rather than distributed in some other topology (e.g., tree). Thus, each machine’s full outbound bandwidth is used to transfer the data as fast as possible rather than divided among multiple recipients. 为了充分利用每台机器的网络带宽，数据在chunkservers之间按链路线性推送而不是以其他的拓扑结构(例如tree)分布.因此，每台机器的所有出站带宽都被用来尽可能快的传输数据，而不会其中一些接受者分掉。 To avoid network bottlenecks and high-latency links (e.g., inter-switch links are often both) as much as possible, each machine forwards the data to the “closest” machine in the networktopology that has not received it. Suppose the client is pushing data to chunkservers S1 through S4. It sends the data to the closest chunkserver, say S1. S1 forwards it to the closest chunkserver S2 through S4 closest to S1, say S2. Similarly, S2 forwards it to S3 or S4, whicheveris closer to S2, and so on. Our networktopology is simple enough that “distances” can be accurately estimated from IP addresses. 为了尽可能的避免网络瓶颈和高延迟的链接(例如交换机通常两者都是)，每一台机器传输数据给还没有接收数据的在网络拓扑中离自己最近的机器。加入客户端推送数据从chunkserver的S1到S4.客户端发送数据给最近的chunkserver,比如s1,s1传输数据给s4到s1之间最近的s2.相似的，s2传输数据给s4-s2之间离s2最近的s3或者s4,以此类推。我们的网络拓扑足够简单，距离可以通过ip地址进行准确的估算。 Finally, we minimize latency by pipelining the data transfer over TCP connections. Once a chunkserver receives some data, it starts forwarding immediately. Pipelining is especially helpful to us because we use a switched network with full-duplex links. Sending the data immediately does not reduce the receive rate. Without network congestion, the ideal elapsed time for transferring B bytes to R replicas is B/T + RL where T is the network throughput and L is latency to transfer bytes between two machines. Our network links are typically 100 Mbps (T), and L is far below 1 ms. Therefore, 1 MB can ideally be distributed in about 80 ms. 最后，我们通过以流水线的方式传输数据在tcp传输数据中最小化延迟。一旦chunkserver受到一些数据，就会立即开始传输。流水线对我们特别有用，因为我们使用全双工的交换网络。立即发送数据不会影响接受速率。在没有网络拥塞的情况下，传输B字节到R个副本的理想时间是 B/T + RL,其中T是网络吞吐量，L是两台机器间传输数据的延迟。我们的网络连接通常是100Mbps(T), L远小于1ms.因此1Mb的数据理想情况下只需要80ms就可以分布式的传输完 3.3 Atomic Record AppendsGFS provides an atomic append operation called record append. In a traditional write, the client specifies the offset at which data is to be written. Concurrent writes to the same region are not serializable: the region may end up containing data fragments from multiple clients. In a record append, however, the client specifies only the data. GFS appends it to the file at least once atomically (i.e., as one continuous sequence of bytes) at an offset of GFS’s choosing and returns that offset to the client. This is similar to writing to a file opened in O_APPEND mode in Unix without the race conditions when multiple writers do so concurrently. GFS提供了一个称为record append的追加写操作。传统的写入，客户端会给要写的文件指定一个偏移量。并行的写入同一区域不是串行的：被写区域最终可能包含了不同客户端的片段。然而对于record append,客户端只指定数据。GFS至少原子性的追加写一次(如一个连续的顺序流)在一个由GFS选择的偏移位置，然后返回偏移位置给客户端。这和unix中的O_APPEND方式很相似，当多个并行的写没有竞争情况的时候。 Record append is heavily used by our distributed applications in which many clients on different machines append to the same file concurrently. Clients would need additional complicated and expensive synchronization, for example through a distributed lock manager, if they do so with traditional writes. In our workloads, such files often serve as multiple-producer/single-consumer queues or contain merged results from many different clients. record append在我们的分布式应用中广泛使用，这些应用里会有不同机器上的多个客户端并行的向同一个文件写入数据。如果使用传统的覆盖写，客户端会引入额外的复杂和昂贵的同步操作，比如通过分布式锁管理器。在我们的工作中，前面说的这些文件通常被用于多个生产者/单个消费者的队列或者用于保留来自多个不同客户端的合并结果。 Record append is a kind of mutation and follows the control flow in Section 3.1 with only a little extra logic at the primary. The client pushes the data to all replicas of the last chunk of the file Then, it sends its request to the primary. The primary checks to see if appending the record to the current chunk would cause the chunk to exceed the maximum size (64 MB). If so, it pads the chunk to the maximum size, tells secondaries to do the same, and replies tothe client indicating that the operation should be retried on the next chunk. (Record append is restricted to be at most one-fourth of the maximum chunksize to keep worst case fragmentation at an acceptable level.) If the record fits within the maximum size, which is the common case, the primary appends the data to its replica, tells the secondaries to write the data at the exact offset where it has, and finally replies success to the client. record append是变更的一种，遵循3.1节的控制流，只是在primary中有一些额外的逻辑。客户端推送数据给直到最后一个chunk给予回复信息，然后客户端发送请求给primary. primary会检查追加写这些记录到当前的chunk是否会让chunk超过最大大小(64M).如果超过了，就将超过的信息写入新的chunk并填充到最大值，然后告诉所有次要的副本也这样做，然后回复客户端指示其需要在下一个chunk上进行重试。(record append被限制最多为chunksize最大值的1/4,来保证最坏情况下数据碎片仍在可接受的程度) 如果记录刚好在最大值内，这是最常见的情况，则primary会追加写数据到自己的回复，告诉所有其他次要的副本在同样的偏移位置写入，并最终回复成功响应给客户端。 If a record append fails at any replica, the client retries the operation. As a result, replicas of the same chunk may contain different data possibly including duplicates of the same record in whole or in part. GFS does not guarantee that all replicas are bytewise identical. It only guarantees that the data is written at least once as an atomic unit. This property follows readily from the simple observation that for the operation to report success, the data must have been written at the same offset on all replicas of some chunk. Furthermore, after this, all replicas are at least as long as the end of record and therefore any future record will be assigned a higher offset or a different chunk even if a different replica later becomes the primary. In terms of our consistency guarantees, the regions in which successful record append operations have written their data are defined (hence consistent), whereas intervening regions are inconsistent (hence undefined). Our applications can deal with inconsistent regions as we discussed in Section 2.7.2. 如果任何一个回复的record append失败了，客户端都会重试。最终，同一个chunk的多个回复可能包含了不同的数据，这些不同的数据可能包含了部分或者整个记录的重复数据。GFS不保证所有的副本每个字节都相同。GFS只保证数据被原子性的至少写入一次。这种属性可以从对于成功操作报告的观察简单的得出，数据必须在每个副本都写入相同的偏移位置。而且之后所有的副本都至少到达了记录的结尾因此以后的记录都将会被分配更大的偏移位置或者在不同的chunk上，即使primary变为了别的副本也是这样。在我们一致性保证下，record append成功写入数据的区域是已定义的(也是一致性的)，而介入其间的区域是非一致性的(也即未定义的)。我们的应用可以处理这种非一致性的区域，如2.7.2讨论的那样。 3.4 SnapshotThe snapshot operation makes a copy of a file or a directory tree (the “source”) almost instantaneously, while minimizing any interruptions of ongoing mutations. Our users use it to quickly create branch copies of huge data sets (and often copies of those copies, recursively), or to checkpoint the current state before experimenting with changes that can later be committed or rolled back easily. 快照可以瞬间创建文件或目录的拷贝，能够最小化对于进行中变更的影响。我们的用户能够使用快照快速的创建对于大数据集的拷贝分支(通常递归的对拷贝再进行拷贝)，或者在测试修改能否稍后提交或者回滚之前检查当前的状态。 Like AFS [5], we use standard copy-on-write techniques to implement snapshots. When the master receives a snapshot request, it first revokes any outstanding leases on the chunks in the files it is about to snapshot. This ensures that any subsequent writes to these chunks will require an interaction with the master to find the lease holder. This will give the master an opportunity to create a new copy of the chunk first. 和AFS一样，我们使用标椎写时拷贝技术来实现快照。当master接收到快照请求，它首先撤销快照涉及文件对应的chunks上未完成的租约。这样确保了随后的对这些chunks的写都将和master交互去获取租约持有者。这将给master一个机会可以闯将一个chunk的新的拷贝。 After the leases have been revoked or have expired, the master logs the operation to disk. It then applies this log record to its in-memory state by duplicating the metadata for the source file or directory tree. The newly created snapshot files point to the same chunks as the source files. 在租约被撤销或者过期之后，master记录操作日志到磁盘。通过复制源文件或目录树的元数据，master将日志记录应用到内存中状态。新创建的快照文件和源文件指向相同的chunks. The first time a client wants to write to a chunk C after the snapshot operation, it sends a request to the master to find the current lease holder. The master notices that the reference count for chunk C is greater than one. It defers replying to the client request and instead picks a new chunk handle C’. It then asks each chunkserver that has a current replica of C to create a new chunk called C’. By creating the new chunk on the same chunkservers as the original, we ensure that the data can be copied locally, not over the network(our disks are about three times as fast as our 100 Mb Ethernet links). From this point, request handling is no different from that for any chunk: the master grants one of the replic as a lease on the new chunkC’ and replies to the client, which can write the chunk normally, not knowing that it has just been created from an existing chunk. 在快照之后客户端第一次想要对chunk c进行写入，会先发送请求给master来查找当前租约的持有者。master注意到chunk c的引用大于 1的话，会推迟回复给client响应，而是先选择一个新的chunk句柄 C’.然后master要求每一个chunk c的副本所在chunkserver都创建一个新的chunk c’.通过在和原来chunk c相同的chunkserver上创建新的chunk,我们可以确保数据是在本地进行拷贝的，而不经过网络(我们磁盘的读写速度是我们100M以太网的3倍)。基于这点，对于任何chunk的请求都是一样的：master对chunk c’的的一个副本分配租约然后回复给客户端，客户端可以正常的写入数据，而不知道写入的chunk其实是刚刚从原来的chunk新创建的。 4. MASTER OPERATIONThe master executes all namespace operations. In addition, it manages chunk replicas throughout the system: it makes placement decisions, creates new chunks and hence replicas, and coordinates various system-wide activities to keep chunks fully replicated, to balance load across all the chunkservers, and to reclaim unused storage. We now discuss each of these topics. master执行所有命名空间的操作。并且，它管理整个系统上chunk的副本：决定chunk的位置，创建新的chunk和副本，协调整个系统范围的各种活动来保证chunk的完整复制，通过chunkservers来做负载均衡，回收未使用的存储。现在我们分别来讨论这些主题 4.1 Namespace Management and LockingMany master operations can take a long time: for example, a snapshot operation has to revoke chunkserver leases on all chunks covered by the snapshot. We do not want to delay other master operations while they are running. Therefore, we allow multiple operations to be active and use locks over regions of the namespace to ensure proper serialization. 有许多的master操作都需要很长的处理时间：比如，一个快照操作需要撤销快照覆盖的所有chunks的租约。我们不想在快照执行的时候延迟其他的master操作。因此，我们允许多个master操作处于活动状态，通过命名空间锁来保证正确的顺序。 Unlike many traditional file systems, GFS does not have a per-directory data structure that lists all the files in that directory. Nor does it support aliases for the same file or directory (i.e, hard or symbolic links in Unix terms). GFS logically represents its namespace as a lookup table mapping full pathnames to metadata. With prefix compression, this table can be efficiently represented in memory. Each node in the namespace tree (either an absolute file name or an absolute directory name) has an associated read-write lock. 和许多传统的文件系统不同的是，GFS没有per-directory的数据结构来列出目录下所有的文件。它也不支持对于文件和目录的别称(想unix中的硬链接，软连接).GFS逻辑上将命名空间表示为所有路径名到元数据的查找表。通过前缀压缩，命名空间表可以高效的保存在内存中。每一个命名空间树的节点(绝对的文件名或者绝对的目录名)都有一个相关联的读写锁。 Each master operation acquires a set of locks before it runs. Typically, if it involves /d1/d2/…/dn/leaf, it will acquire read-locks on the directory names /d1, /d1/d2, …, /d1/d2/…/dn, and either a read lockor a write lock on the full pathname /d1/d2/…/dn/leaf. Note that leaf may be a file or directory depending on the operation. 每个master操作在运行前都需要一组锁。通常，包含/d1/d2/…/dn/leaf的情况,master会在名录名为d1, /d1/d2, … /d1/d2/…/dn的地方分别获取读锁，在完整路径名/d1/d2/…/dn/leaf获取一个读锁或写锁。记住叶子节点可能是文件或者目录，这取决于操作。 We now illustrate how this locking mechanism can prevent a file /home/user/foo from being created while /home/user is being snapshotted to /save/user. The snapshot operation acquires read lock s on /home and /save, and write locks on /home/user and /save/user. The file creation acquires read locks on /home and /home/user, and a write lockon /home/user/foo. The two operations will be serialized properly because they try to obtain conflicting locks on /home/user. File creation does not require a write lock on the parent directory because there is no “directory”, or inode-like, data structure to be protected from modification.The read lock on the name is sufficient to protect the parent directory from deletion. 我们现在说明锁机制如何保护/home/user被快照到/save/user的时候，/home/user/foo不被创建。快照操作获取/home和/save的读锁，以及/home/user和/save/user的写锁。文件创建获取/hoem和/home/user的读锁，以及/home/user/foo的写锁。两个操作可以正确顺序的执行因为他们获取/home/user的锁会冲突。文件创建不需要获取父目录的写锁因为没有目录或者inode节点的数据结构需要保护。创建文件获取父目录的读锁就足够保护父目录不被删除了。 One nice property of this locking scheme is that it allows concurrent mutations in the same directory. For example, multiple file creations can be executed concurrently in the same directory: each acquires a read lock on the directory name and a write lock on the file name. The read lock on the directory name suffices to prevent the directory from being deleted, renamed, or snapshotted. The write locks on file names serialize attempts to create a file with the samename twice. 锁方案的一个好处是可以允许对于相同目录的并行变更。比如，同一目录下多个文件创建操作可以并行处理：每个操作都获取目录名的读锁以及文件名的写锁。目录名的读锁足够保护目录不被删除，重命名，或者快照。文件名的写锁保证两次对一个文件的相同重命名是顺序执行的。 Since the namespace can have many nodes, read-write lock objects are allocated lazily and deleted once they are not in use. Also, locks are acquired in a consistent total order to prevent deadlock: they are first ordered by level in the namespace tree and lexicographically within the same level. 因为命名空间有很多节点，读写锁对象是懒分配并在不被使用的时候删除。而且锁是按一致性的顺序来获取的以防止死锁的发生：锁先按在命名空间树中的层级排序，然后在相同层级内按字段序排序。 4.2 Replica PlacementA GFS cluster is highly distributed at more levels than one. It typically has hundreds of chunkservers spread across many machine racks. These chunkservers in turn may be accessed from hundreds of clients from the same or different racks. Communication between two machines on different racks may cross one or more network switches. Additionally, bandwidth into or out of a rack may be less than the aggregate bandwidth of all the machines within the rack. Multi-level distribution presents a unique challenge to distribute data for scalability, reliability, and availability. GFS集群是多层级高分布式的。通常由分布在多个机架上的数百台机器组成。chunkserver反过来可能被一个或者多个机架上的数百台机器访问。不同机架上的两台机器通信可能会经过一个或者多个网络交换机。另外，进出一个机架的带宽可能少于这台机架上所有机器的总带宽。多层级分布给分布式数据的可扩展性，可靠性，可用性带来了特别的挑战。 The chunk replica placement policy serves two purposes: maximize data reliability and availability, and maximize networkbandwidth utilization. For both, it is not enough to spread replicas across machines, which only guards against disk or machine failures and fully utilizes each machine’s networkbandwidth. We must also spread chunk replicas across racks. This ensures that some replicas of a chunk will survive and remain available even if an entire rack is damagedor offline (for example, due to failure of a shared resource like a network switch or power circuit). It also means that traffic, especially reads, for a chunk can exploit the aggregate bandwidth of multiple racks. On the other hand, write traffic has to flow through multiple racks, a tradeoff we make willingly. chunk的副本放置的策略出于两个目的：最大化数据的可靠性和可用性，以及最大化网络带宽的利用率。出于这两个目的，仅仅将副本分布在机器间是不够的，这样只能应对磁盘和机器的故障，以及可以充分利用每台机器的带宽。我们也需要将副本分布在不同的机架上。这可以确保即使整个机架损坏或者离线了(比如网络交换机或者电源电路这些共享资源故障了)仍有一些副本保留下来可用。这也意味着流量，尤其是读流量，对于chunk来说能够利用多台机架的总带宽。另一方面，写流量要穿过多个机架，这是我们乐意做的折中。 4.3 Creation, Re-replication, RebalancingChunk replicas are created for three reasons: chunk creation, re-replication, and rebalancing. chunk副本的创建出于3个原因：chunk的创建，重复制，再平衡。 When the master creates a chunk, it chooses where to place the initially empty replicas. It considers several factors. (1) We want to place new replicas on chunkservers with below-average diskspace utilization. Over time this will equalize disk utilization across chunkservers. (2) We want to limit the number of “recent” creations on each chunkserver. Although creation itself is cheap, it reliably predicts imminent heavy write traffic because chunks are created when demanded by writes, and in our append-once-read-many workload they typically become practically read-only once they have been completely written. (3) As discussed above, we want to spread replicas of a chunkacross racks. 当master创建chunk的时候，他会选择一个位置来初始化空的副本。会基于几个因素来考虑：(1) 我们会想放置一个新的副本在一个磁盘利用率低于平均值的chunkserver上。随着时间的推移能够均衡各个chunkservers的磁盘利用率。(2) 我们想限制每个chunkserver近期创建的chunk的数量。即使创建操作本身代价很小，但能够预测到很快会有大量的写流量，因为chunks就是因为写操作而创建的，对于我们append-once-read-many，通常在写入完成的时候工作负载就变成只读的了。(3) 如前面讨论的，我们想将副本分布在不同的机架上。 The master re-replicates a chunk as soon as the number of available replicas falls below a user-specified goal. This could happen for various reasons: a chunkserver becomes unavailable, it reports that its replica may be corrupted, one of its disks is disabled because of errors, or the replication goal is increased. Each chunk that needs to be re-replicated is prioritized based on several factors. One is how far it is from its replication goal. For example, we give higher priority to a chunk that has lost two replicas than to a chunkthat has lost only one. In addition, we prefer to first re-replicate chunks for live files as opposed to chunks that belong to recently deleted files (see Section 4.4). Finally, to minimize the impact of failures on running applications, we boost the priority of any chunk that is blocking client progress. 当可用的chunk副本数量低于用户指定的值,master会马上对chunk进行重复制。这种情况的发生有多种原因：一个chunkserver不可访问，chunkserver报告了一个副本损坏了，一个磁盘因为错误而不可用，或者复制的目标被提高了。每个需要再复制的chunk会基于几个因素增加优先级。一个因素是看距离副本完成的目标还有多远。比如，我们会给一个丢失了两份副本的chunk更高的优先级，相对于只丢失了一个副本的chunk.另外，我们更愿意给一个文件存在的chunk更高的优先级，而不是相反给文件被删除的chunk更高的优先级(见4.4节)。最后，为了最小化对于运行期程序的影响，我们会提高所有客户端阻塞中的chunk的优先级。 The master picks the highest priority chunk and “clones” it by instructing some chunkserver to copy the chunk data directly from an existing valid replica. The new replica is placed with goals similar to those for creation: equalizing diskspace utilization, limiting active clone operations on any single chunkserver, and spreading replicas across racks. To keep cloning traffic from overwhelming client traffic, the master limits the numbers of active clone operations both for the cluster and for each chunkserver. Additionally, each chunkserver limits the amount of bandwidth it spends on each clone operation by throttling its read requests to the source chunkserver. master选择最高优先级的chunk,通过指示一些chunkserver直接从现有的有效的副本处拷贝数据来对这个chunk进行clone.新的副本的放置和前面说的创建有相似的目标：均衡磁盘利用率，限制单个chunkserver上活动的clone操作的数量，将副本分布在不同机架。为了防止clone的流量挤占过多客户端的流量，master限制了整个集群和单个chunkserver上活动的clone的数量。另外，每个chunkserver限制了clone操作对于源chunkserver的读请求的流量。 Finally, the master rebalances replicas periodically: it examines the current replica distribution and moves replicas for better disk space and load balancing. Also through this process, the master gradually fills up a new chunkserver rather than instantly swamps it with new chunks and the heavy write traffic that comes with them. The placement criteria for the new replica are similar to those discussed above. In addition, the master must also choose which existing replica to remove. In general, it prefers to remove those on chunkservers with below-average free space so as to equalize diskspace usage. 最后，master定期对副本进行再平衡：master检查当前副本的分布然后对其移动为了更好的磁盘空间使用和负载均衡。同样通过这个过程，master逐渐的填充新的chunkserver,而不是一下子通过新的chunks和随之而来的大的写入流量进行填充。新的副本的放置策略和前面说的一样。另外，master必须选择一个已存在的副本移除。总的来说，master更可能一出一个空间磁盘低于平均值的chunkserver来均衡磁盘的使用率。 4.4 Garbage CollectionAfter a file is deleted, GFS does not immediately reclaim the available physical storage. It does so only lazily during regular garbage collection at both the file and chunklevels. We find that this approach makes the system much simpler and more reliable. 文件被删除之后，GFS不会立即回收可用的物理存储。仅在文件和块级别的常规垃圾回收期间才这样做。我们发现这能够提高系统的易用性和可靠性。 4.4.1 MechanismWhen a file is deleted by the application, the master logs the deletion immediately just like other changes. However instead of reclaiming resources immediately, the file is just renamed to a hidden name that includes the deletion timestamp. During the master’s regular scan of the file system namespace, it removes any such hidden files if they have existed for more than three days (the interval is configurable). Until then, the file can still be read under the new, special name and can be undeleted by renaming it back to normal. When the hidden file is removed from the namespace, its inmemory metadata is erased. This effectively severs its links to all its chunks. 当一个文件被应用程序删除，master会和对待其他变化一样，立即将删除操作记录到日志。然而文件只是被重命名为包含删除时间戳的隐藏名称，而不是立即回收资源。在master定期扫描文件系统命名空间的时候，master会真正移除已经存在超过三天(内部可配置)的隐藏文件.在这之前，文件仍可以通过新的特殊名称来访问，也可以通过重命名来将其恢复成正常文件。当隐藏文件从命名空间移除，它在内存中的元数据也会被删除。这会影响到所有和它关联的chunks. In a similar regular scan of the chunk namespace, the master identifies orphaned chunks (i.e., those not reachable from any file) and erases the metadata for those chunks. In a HeartBeat message regularly exchanged with the master, each chunkserver reports a subset of the chunks it has, and the master replies with the identity of all chunks that are no longer present in the master’s metadata. The chunkserver is free to delete its replicas of such chunks. 在对chunk命名空间的类似定期扫描中，master会识别孤立的chunks(那些无法被任何文件访问的)然后删除这些chunks的元数据。在定期和master交换的心跳包中，每个chunkserver会上报自身所含chunks的一个子集，然后master将回复元数据已经不存在的chunks的标识给chunkserver. chunkserver可以删除这些chunks的副本数据。 4.4.2 DiscussionAlthough distributed garbage collection is a hard problem that demands complicated solutions in the context of programming languages, it is quite simple in our case. We can easily identify all references to chunks: they are in the file-to-chunk mappings maintained exclusively by the master. We can also easily identify all the chunk replicas: they are Linux files under designated directories on each chunkserver. Any such replica not known to the master is “garbage.” 即使分布式垃圾回收是个很难的问题，在编程语言上下文中这需要复杂的解决方案，但我们遇到的情况却很简单。我们可以容易的识别所有chunks的引用信息：它们只保留在master中file-to-chunk的映射里。我们也可以轻易的识别所有chunks的副本：它们是每个chunkserver指定目录下的linux文件。任何master不能识别的副本都是垃圾信息。 The garbage collection approach to storage reclamation offers several advantages over eager deletion. First, it is simple and reliable in a large-scale distributed system where component failures are common. Chunk creation may succeed on some chunkservers but not others, leaving replicas that the master does not know exist. Replica deletion messages may be lost, and the master has to remember to resend them across failures, both its own and the chunkserver’s. Garbage collection provides a uniform and dependable way to clean up any replicas not known to be useful. Second, it merges storage reclamation into the regular background activities of the master, such as the regular scans of namespaces and handshakes with chunkservers. Thus, it is done in batches and the cost is amortized. Moreover, it is done only when the master is relatively free. The master can respond more promptly to client requests that demand timely attention. Third, the delay in reclaiming storage provides a safety net against accidental, irreversible deletion. 存储回收的垃圾回收方法相比直接删除有几个优点。首先，这对于组件经常故障的大规模分布式系统来说更加简单和可靠。chunk创建可能在部分chunkservers成功，在部分上失败，因此有部分master不知道的副本。副本删除信息可能丢失，因此master必须记住这些并在在故障发生的时候重新发送，不管是master自身还是chunkserver发生故障。垃圾回收提高了统一和可靠的方式清理那些master不知道的副本。第二，master将存储回收和其他master的后台活动进行合并，比如定期的命名空间扫描和与chunkservers间的握手。因此，这是批量完成的，成本可以摊销。并且，这些活动只在master空闲的时候执行。所以master可以迅速的对客户端要求立即关注的请求进行回复。第三，存储回收的延迟给偶然和不可逆的删除操作提供了安全网。 In our experience, the main disadvantage is that the delay sometimes hinders user effort to fine tune usage when storage is tight. Applications that repeatedly create and delete temporary files may not be able to reuse the storage right away. We address these issues by expediting storage reclamation if a deleted file is explicitly deleted again. We also allow users to apply different replication and reclamation policies to different parts of the namespace. For example, users can specify that all the chunks in the files within some directory tree are to be stored without replication, and any deleted files are immediately and irrevocably removed from the file system state. 根据我们的经验，这种存储回收的延迟主要的缺点是在存储紧张的时候，阻碍了用户对于存储使用调整的努力。重复创建和删除临时文件的应用程序可能不能立即重用存储。我们通过，在删除的文件被再次显示删除的时候，加快存储回收来解决这些问题。我们也允许用户对命名空间下不同部分应用不同的拷贝和回收的策略。比如，用户可以指定一些目录树中文件的所有都被无副本的保存，也可以指定删除的文件被立即不可撤销的从系统中删除。 4.5 Stale Replica DetectionChunk replicas may become stale if a chunkserver fails and misses mutations to the chunk while it is down. For each chunk, the master maintains a chunk version number to distinguish between up-to-date and stale replicas. chunk的副本可能因为chunkserver故障或者在chunkserver故障期间丢失了chunk的变更信息，而过期。对于这些chunk,master保留了chunk的版本号来区别最新的和过期的副本。 Whenever the master grants a new lease on a chunk, it increases the chunk version number and informs the up-to-date replicas. The master and these replicas all record the new version number in their persistent state. This occurs before any client is notified and therefore before it can start writing to the chunk. If another replica is currently unavailable, its chunk version number will not be advanced. The master will detect that this chunkserver has a stale replica when the chunkserver restarts and reports its set of chunks and their associated version numbers. If the master sees a version number greater than the one in its records, the master assumes that it failed when granting the lease and so takes the higher version to be up-to-date. 每当master给chunk分配新租约的时候，都会增加chunk的版本号并通知最新的副本。master和这些副本都会持续的记录新的版本号。因为这发生在客户端收到通知前，因此也在chunk被写之前。如果另一个副本变得不可用。它的chunk版本号将不会提前。master可以检测到这些过期副本所在的chunkservers，当chunkserver重启和报告自身chunk的子集以及相关联的版本号的时候。如果master看到一个比自己更大的版本号的时候，master会假定在分配租约的时候失败了，因此会将高的版本号置位最新的版本号。 The master removes stale replicas in its regular garbage collection. Before that, it effectively considers a stale replica not to exist at all when it replies to client requests for chunk information. As another safeguard, the master includes the chunk version number when it informs clients which chunkserver holds a lease on a chunk or when it instructs a chunkserver to read the chunk from another chunkserver in a cloning operation. The client or the chunkserver verifies the version number when it performs the operation so that it is always accessing up-to-date data. master在定期的垃圾回收中移除过期的副本。在那之前，当master回复客户端关于chunk信息请求的时候，master会当这些过期副本实际并不存在一样。另一种安全保障是，当master通知客户端哪个chunkserver持有租约，或者在clone操作中指示一个chunkserver从其他chunkserver读取数据的时候，master发送的信息都会携带chunk的版本号。客户端或者chunkserver都会验证版本号当它们执行操作的时候，因此他们总是访问最新数据。 5. FAULT TOLERANCE AND DIAGNOSISOne of our greatest challenges in designing the system is dealing with frequent component failures. The quality and quantity of components together make these problems more the norm than the exception: we cannot completely trust the machines, nor can we completely trust the disks. Component failures can result in an unavailable system or, worse, corrupted data. We discuss how we meet these challenges and the tools we have built into the system to diagnose problems when they inevitably occur 我们在设计系统时遇到的最大挑战之一是处理频繁的组件故障。组件的质量和数量加在一起使得这些问题的出现更像是正常情况而非异常：我们不会完全相信机器，也不会完全指望磁盘。组件故障可能导致系统不可用，或者更糟的情况使数据损坏。我们会讨论我们遇到的挑战，以及我们已经内置到系统的工具，可以工具可以诊断那些不可避免发生的问题 5.1 High AvailabilityAmong hundreds of servers in a GFS cluster, some are bound to be unavailable at any given time. We keep the overall system highly available with two simple yet effective strategies: fast recovery and replication. 在GFS集群的数百台服务器中，在任意给定时间一定会有部分机器不可用。我们通过两种简单但有效的策略来提高整个系统的高可用性：快速恢复和复制。 5.1.1 Fast RecoveryBoth the master and the chunkserver are designed to restore their state and start in seconds no matter how they terminated. In fact, we do not distinguish between normal and abnormal termination; servers are routinely shut down just by killing the process. Clients and other servers experience a minor hiccup as they time out on their outstanding requests, reconnect to the restarted server, and retry. Section 6.2.2 reports observed startup times. master和chunkserver都被设计成在任何终止情况都可以在数秒内重启并恢复状态。事实上，我们并不区分正常和异常的终止；通过杀掉进程就可以正常的关闭服务端。客户端和其他的服务端在他们未完成的请求超时的时候会经历短暂的停顿，然后重新连接重启的服务端，并重试。6.2.2节报告了观察的启动时间 5.1.2 Chunk ReplicationAs discussed earlier, each chunk is replicated on multiple chunkservers on different racks. Users can specify different replication levels for different parts of the file namespace. The default is three. The master clones existing replicas as needed to keep each chunk fully replicated as chunkservers go offline or detect corrupted replicas through checksum verification (see Section 5.2). Although replication has served us well, we are exploring other forms of cross-server redundancy such as parity or erasure codes for our increasing readonly storage requirements. We expect that it is challenging but manageable to implement these more complicated redundancy schemes in our very loosely coupled system because our traffic is dominated by appends and reads rather than small random writes. 如前面讨论的那样，每个chunk都被复制到不同机架上的多个chunkservers.用户可以为文件命名空间的不同部分指定不同的复制级别。缺省级别是3.master clone已存在的副本为了在chunkserver离线或者通过校验码(见5.2节)检查到有损坏的副本的情况下，chunk也能被完全复制。即使副本工作的很好，我们仍在探索其他的跨服务器冗余的形式，比如parity(奇偶码？)或者纠删码，来应对我们日益增加的只读存储请求。我们认为在我们非常松散的耦合系统上实现更加复杂的冗余方案是有挑战性但可管理的，因为我们的流量主要是追加写和读操作，而不是小的随机写 5.1.3 Master ReplicationThe master state is replicated for reliability. Its operation log and checkpoints are replicated on multiple machines. A mutation to the state is considered committed only after its log record has been flushed to disk locally and on allmaster replicas. For simplicity, one master process remains in charge of all mutations as well as background activities such as garbage collection that change the system internally. When it fails, it can restart almost instantly. If its machine or disk fails, monitoring infrastructure outside GFS starts a new master process elsewhere with the replicated operation log. Clients use only the canonical name of the master (e.g. gfs-test), which is a DNS alias that can be changed if the master is relocated to another machine. 为了可靠性，master的状态会被复制。其操作日志和检查点会被复制到多台机器。一个状态的变更只有在日志记录被写到本地磁盘以及所有master的副本的时候才会提交。为了简单起见，一个master仍然处理所有的变更和后台活动，比如会在内部修改系统的垃圾回收。master失败的时候，几乎总是可以立即重启。如果是机器或者磁盘故障，GFS外部的监控基础设施会通过操作日志副本信息在别处启动一个新的master.客户端仅仅使用master的规范名称(如gfs-test),这其实是一个dns别名，会随着master迁移到另一台机器的时候跟着变化 Moreover, “shadow” masters provide read-only access to the file system even when the primary master is down. They are shadows, not mirrors, in that they may lag the primary slightly, typically fractions of a second. They enhance read availability for files that are not being actively mutated or applications that do not mind getting slightly stale results. In fact, since file content is read from chunkservers, applications do not observe stale file content. What could be stale within short windows is file metadata, like directory contents or access control information. 另外，shwdow master提供了文件系统的只读访问，即使在primary master挂掉的时候。他们是影子而不是镜子，shodow master可能会轻微落后于primary master,通常少于一秒。shadows master对于不经常变化或应用程序不介意获取稍微过期的结果的情况下，能够提高文件的读可用性。事实上，因为文件内容是从chunkservers读取的，应用程序观察不到过期的文件内容。会在短窗口期内过期的是文件元数据，像是目录内容或者访问控制信息 To keep itself informed, a shadow master reads a replica of the growing operation log and applies the same sequence of changes to its data structures exactly as the primary does. Like the primary, it polls chunkservers at startup (and in frequently thereafter) to locate chunk replicas and exchanges frequent handshake messages with them to monitor their status. It depends on the primary master only for replica location updates resulting from the primary’s decisions to create and delete replicas. 为了保持同步，shadow master读取不断增长的操作日志的副本并按照和primary master相同的顺序将变更应用到自己的数据结构。像primary一样，shadow在启动阶段(随后会频繁的)轮训chunkservers来定位副本的位置，并频繁的通过和客户端的握手报文来监控客户端的状态。shadows master仅仅依赖与primary master对于副本位置的更新，master创建和删除副本的时候会导致副本位置更新。 5.2 Data IntegrityEach chunkserver uses checksumming to detect corruption of stored data. Given that a GFS cluster often has thousands of disks on hundreds of machines, it regularly experiences disk failures that cause data corruption or loss on both theread and write paths. (See Section 7 for one cause.) We can recover from corruption using other chunk replicas, but it would be impractical to detect corruption by comparing replicas across chunkservers. Moreover, divergent replicas may be legal: the semantics of GFS mutations, in particular atomic record append as discussed earlier, does not guarantee identical replicas. Therefore, each chunkserver must independently verify the integrity of its own copy by maintaining checksums. 每个chunkserver使用校验和来检测存储数据是否损坏。一个通常包含上百台机器，数千个磁盘的GFS集群，经常遇到磁盘故障对于读和写造成的数据损坏或丢失(见第七节中的一个原因)。我们可以使用chunk副本来恢复损坏数据，但是通过比较不同chunkservers的副本来检测损坏数据是不切实际的。不同的副本也不能是合法的：GFS变更的语义，尤其对于我们前面讨论的原子记录追加写，并不保证完全相同的副本。因此，每个chunkserver必须独立验证自己的副本的完整性，通过维护校验和 A chunk is broken up into 64 KB blocks. Each has a corresponding 32 bit checksum. Like other metadata, checksums are kept in memory and stored persistently with logging, separate from user data. 每个chunk被分为64kb大小的块。每个块有相应的32位的校验和。和其他元数据一样，校验和保存在内存中并通过日志进行持久化，并和用户数据分离。 For reads, the chunkserver verifies the checksum of data blocks that overlap the read range before returning any data to the requester, whether a client or another chunkserver. Therefore chunkservers will not propagate corruptions to other machines. If a block does not match the recorded checksum, the chunkserver returns an error to the requestor and reports the mismatch to the master. In response, the requestor will read from other replicas, while the master will clone the chunk from another replica. After a valid new replica is in place, the master instructs the chunkserver that reported the mismatch to delete its replica. 对于读请求，chunkserver在返回任何数据给请求方之前，会对这次读请求重叠的范围内的数据验证校验和，不管请求方是客户端还是chunkserver.因此每个chunkserver都不会传递损坏数据给其他的机器。如果某个块和记录的校验和不匹配，chunkserver会返回错误给请求方并报告匹配无效给master.作为回应，请求方会从另一个副本处读取，同时master会在另一个副本处clone这个chunk.在一个新的副本被放置后，master会指示之前那个报告了匹配无效的chunkserver删除无效的副本。 Checksumming has little effect on read performance for several reasons. Since most of our reads span at least a few blocks, we need to read and checksum only a relatively small amount of extra data for verification. GFS client code further reduces this overhead by trying to align reads at checksum block boundaries. Moreover, checksum lookups and comparison on the chunkserver are done without any I/O, and checksum calculation can often be overlapped with I/Os. 出于几个原因，校验和对读取性能的影响很小。因为我们大多数的读取都至少跨了几个块，因此我们只需要读取并对少量相关的额外数据进行验证。GFS的客户端代码通过尝试对校验和边缘进行对齐更加减少了读取的开销。此外，校验和在chunkserver上查找和比较是不涉及IO操作的，并且校验和的计算经常喝IO是重叠的。 Checksum computation is heavily optimized for writes that append to the end of a chunk(as opposed to writes that overwrite existing data) because they are dominant in our workloads. We just incrementally update the checksum for the last partial checksum block, and compute new checksums for any brand new checksum blocks filled by the append. Even if the last partial checksum block is already corrupted and we fail to detect it now, the new checksum value will not match the stored data, and the corruption will be detected as usual when the block is next read. 校验和的计算对于chunk的追加写进行了极大的优化(相对于覆盖写)因为我们工作中主要是追加写。我们只需要对最后部分的校验和块进行增量更新校验和，然后对于任何通过追加写添加的权限的校验和块重新计算新的校验和。即使最后部分的校验和块已经损坏了并且我们正在尝试的检测也失败了，新的校验和后面也不会和存储的数据匹配成功，当损坏的块下次被读取的时候将会向通常那样被检测到 In contrast, if a write overwrites an existing range of the chunk, we must read and verify the first and last blocks of the range being overwritten, then perform the write, and finally compute and record the new checksums. If we do not verify the first and last blocks before overwriting them partially, the new checksums may hide corruption that exists in the regions not being overwritten. 相反，如果写操作覆盖了chunk的现有范围，我们必须读取并验证被覆盖范围中第一个和最后一个块，然后再执行写操作，最终计算并记录新的校验和。如果我们不验证第一个和最后一个块在部分写之前，那么新的校验和可能会隐藏掉存在于没有被覆盖写的区域中的损坏数据。 During idle periods, chunkservers can scan and verify the contents of inactive chunks. This allows us to detect corruption in chunks that are rarely read. Once the corruption is detected, the master can create a new uncorrupted replica and delete the corrupted replica. This prevents an inactive but corrupted chunk replica from fooling the master into thinking that it has enough valid replicas of a chunk. 在处理期间，chunkserver可以扫描并验证不活跃的chunks的内容。这允许我们检查这些chunks中很少被读取的损坏的数据。一旦校测到损坏数据，master可以创建新的未损坏的副本，然后删除掉损坏的副本。这阻止了不活跃但已损坏的chunk的副本让master误以为它头足够数量的有效的chunk的副本。 5.3 Diagnostic ToolsExtensive and detailed diagnostic logging has helped immeasurably in problem isolation, debugging, and performance analysis, while incurring only a minimal cost. Without logs, it is hard to understand transient, non-repeatable interactions between machines. GFS servers generate diagnostic logs that record many significant events (such as chunkservers going up and down) and all RPC requests and replies. These diagnostic logs can be freely deleted without affecting the correctness of the system. However, we try to keep these logs around as far as space permits. 广泛和详细的诊断日志能够极大的帮助我们对于问题的分解，调试，和性能分析，只需要很小的代价。没有这些日志，将很难理解不同机器间短暂又不可重复的交互。GFS服务端生成诊断日志记录了许多重要的事件(比如chunskerver的启动和关闭)以及RPC的请求和回复。这些诊断日志可以自由的删除而不会影响系统的正确性。但是，在空间允许的情况下我们会尝试保留这些日志 The RPC logs include the exact requests and responses sent on the wire, except for the file data being read or written. By matching requests with replies and collating RPC records on different machines, we can reconstruct the entire interaction history to diagnose a problem. The logs also serve as traces for load testing and performance analysis. RPC日志包含了线上精确的请求和响应，除了读和写的文件数据。通过匹配记录在不同机器上的请求和响应，我们能够重建整个交互历史来诊断问题。日志也用于负载测试已经性能分析的跟踪 The performance impact of logging is minimal (and far outweighed by the benefits) because these logs are written sequentially and asynchronously. The most recent events are also kept in memory and available for continuous online monitoring. 日志的性能影响是很小的(带来的好处远胜于这点影响)，因为这些日志是异步顺序写的。大多数最近的时间也保存在内存中，可用于线上持续的监控 6. MEASUREMENTSIn this section we present a few micro-benchmarks to illustrate the bottlenecks inherent in the GFS architecture and implementation, and also some numbers from real clusters in use at Google. 6.1 Micro-benchmarksWe measured performance on a GFS cluster consisting of one master, two master replicas, 16 chunkservers, and 16 clients. Note that this configuration was set up for ease of testing. Typical clusters have hundreds of chunkservers and hundreds of clients. All the machines are configured with dual 1.4 GHz PIII processors, 2 GB of memory, two 80 GB 5400 rpm disks, and a 100 Mbps full-duplex Ethernet connection to an HP 2524 switch. All 19 GFS server machines are connected to one switch, and all 16 client machines to the other. The two switches are connected with a 1 Gbps link. 6.1.1 ReadsN clients read simultaneously from the file system. Each client reads a randomly selected 4 MB region from a 320 GB file set. This is repeated 256 times so that each client ends up reading 1 GB of data. The chunkservers taken together have only 32 GB of memory, so we expect at most a 10% hit rate in the Linux buffer cache. Our results should be close to cold cache results. Figure 3(a) shows the aggregate read rate for N clients and its theoretical limit. The limit peaks at an aggregate of 125 MB/s when the 1 Gbps linkbetween the two switches is saturated, or 12.5 MB/s per client when its 100 Mbps networkinterface gets saturated, whichever applies. The observed read rate is 10 MB/s, or 80% of the per-client limit, when just one client is reading. The aggregate read rate reaches 94 MB/s, about 75% of the 125 MB/s linklimit, for 16 readers, or 6 MB/s per client. The efficiency drops from 80% to 75% because as the number of readers increases, so does the probability that multiple readers simultaneously read from the same chunkserver. 6.1.2 WritesN clients write simultaneously to N distinct files. Each client writes 1 GB of data to a new file in a series of 1 MB writes. The aggregate write rate and its theoretical limit are shown in Figure 3(b). The limit plateaus at 67 MB/s because we need to write each byte to 3 of the 16 chunk servers, each with a 12.5 MB/s input connection. The write rate for one client is 6.3 MB/s, about half of the limit. The main culprit for this is our networkstack. It does not interact very well with the pipelining scheme we use for pushing data to chunkreplicas. Delays in propagating data from one replica to another reduce the overall write rate. Aggregate write rate reaches 35 MB/s for 16 clients (or 2.2 MB/s per client), about half the theoretical limit. As in the case of reads, it becomes more likely that multiple clients write concurrently to the same chunkserver as the number of clients increases. Moreover, collision is more likely for 16 writers than for 16 readers because each write involves three different replicas. Writes are slower than we would like. In practice this has not been a major problem because even though it increases the latencies as seen by individual clients, it does not significantly affect the aggregate write bandwidth delivered by the system to a large number of clients. 6.1.3 Record AppendsFigure 3(c) shows record append performance. N clients append simultaneously to a single file. Performance is limited by the networkbandwidth of the chunkservers that store the last chunkof the file, independent of the number of clients. It starts at 6.0 MB/s for one client and drops to 4.8 MB/s for 16 clients, mostly due to congestion and variances in networktransfer rates seen by different clients. Our applications tend to produce multiple such files concurrently. In other words, N clients append to M shared files simultaneously where both N and M are in the dozens or hundreds. Therefore, the chunkserver network congestion in our experiment is not a significant issue in practice because a client can make progress on writing one file while the chunkservers for another file are busy. 6.2 Real World ClustersWe now examine two clusters in use within Google that are representative of several others like them. Cluster A is used regularly for research and development by over a hundred engineers. A typical taskis initiated by a human user and runs up to several hours. It reads through a few MBs to a few TBs of data,transforms or analyzes the data, and writes the results backto the cluster. Cluster B is primarily used for production data processing. The tasks last muchlonger and continuously generate and process multi-TB data sets with only occasional human intervention. In both cases, a single “task” consists of many processes on many machines reading and writing many files simultaneously. 6.2.1 StorageAs shown by the first five entries in the table, both clusters have hundreds of chunkservers, support many TBs of disk space, and are fairly but not completely full. “Used space” includes all chunkreplicas. Virtually all files are replicated three times. Therefore, the clusters store 18 TB and 52 TB of file data respectively. The two clusters have similar numbers of files, though B has a larger proportion of dead files, namely files which were deleted or replaced by a new version but whose storage have not yet been reclaimed. It also has more chunks because its files tend to be larger. 6.2.2 MetadataThe chunkservers in aggregate store tens of GBs of metadata, mostly the checksums for 64 KB blocks of user data. The only other metadata kept at the chunkservers is the chunkversion number discussed in Section 4.5. The metadata kept at the master is much smaller, only tens of MBs, or about 100 bytes per file on average. This agrees with our assumption that the size of the master’s memory does not limit the system’s capacity in practice. Most of the per-file metadata is the file names stored in a prefix-compressed form. Other metadata includes file ownership and permissions, mapping from files to chunks, and each chunk’s current version. In addition, for each chunk we store the current replica locations and a reference count for implementing copy-on-write. Each individual server, both chunkservers and the master, has only 50 to 100 MB of metadata. Therefore recovery is fast: it takes only a few seconds to read this metadata from diskbefore the server is able to answer queries. However, the master is somewhat hobbled for a period – typically 30 to 60 seconds – until it has fetched chunklocation information from all chunkservers. 6.2.3 Read and Write RatesTable 3 shows read and write rates for various time periods. Both clusters had been up for about one weekwhen these measurements were taken. (The clusters had been restarted recently to upgrade to a new version of GFS.) The average write rate was less than 30 MB/s since the restart. When we tookthese measurements, B was in the middle of a burst of write activity generating about 100 MB/s of data, which produced a 300 MB/s networkload because writes are propagated to three replicas. Figure 3: Aggregate Throughputs. Top curves show theoretical limits imposed by our networktopology. Bottom curves show measured throughputs. They have error bars that show 95% confidence intervals, which are illegible in some cases because of low variance in measurements. The read rates were much higher than the write rates. The total workload consists of more reads than writes as we have assumed. Both clusters were in the middle of heavy read activity. In particular, A had been sustaining a read rate of 580 MB/s for the preceding week. Its network configuration can support 750 MB/s, so it was using its resources efficiently. Cluster B can support peakread rates of 1300 MB/s, but its applications were using just 380 MB/s. 6.2.4 Master LoadTable 3 also shows that the rate of operations sent to the master was around 200 to 500 operations per second. The master can easily keep up with this rate, and therefore is not a bottleneckfor these workloads. In an earlier version of GFS, the master was occasionally a bottleneckfor some workloads. It spent most of its time sequentially scanning through large directories (which contained hundreds of thousands of files) looking for particular files. We have since changed the master data structures to allow efficient binary searches through the namespace. It can now easily support many thousands of file accesses per second. If necessary, we could speed it up further by placing name lookup caches in front of the namespace data structures. 6.2.5 Recovery TimeAfter a chunkserver fails, some chunks will become underreplicated and must be cloned to restore their replication levels. The time it takes to restore all such chunks depends on the amount of resources. In one experiment, we killed a single chunkserver in cluster B. The chunkserver had about 15,000 chunks containing 600 GB of data. To limit the impact on running applications and provide leeway for scheduling decisions, our default parameters limit this cluster to 91 concurrent clonings (40% of the number of chunkservers) where each clone operation is allowed to consume at most 6.25 MB/s (50 Mbps). All chunks were restored in 23.2 minutes, at an effective replication rate of 440 MB/s. In another experiment, we killed two chunkservers each with roughly 16,000 chunks and 660 GB of data. This double failure reduced 266 chunks to having a single replica. These 266 chunks were cloned at a higher priority, and were all restored to at least 2x replication within 2 minutes, thus putting the cluster in a state where it could tolerate another chunkserver failure without data loss. 6.3 Workload BreakdownIn this section, we present a detailed breakdown of the workloads on two GFS clusters comparable but not identical to those in Section 6.2. Cluster X is for research and development while cluster Y is for production data processing. 6.3.1 Methodology and CaveatsThese results include only client originated requests so that they reflect the workload generated by our applications for the file system as a whole. They do not include interserver requests to carry out client requests or internal background activities, such as forwarded writes or rebalancing. Statistics on I/O operations are based on information heuristically reconstructed from actual RPC requests logged by GFS servers. For example, GFS client code may breaka read into multiple RPCs to increase parallelism, from which we infer the original read. Since our access patterns are highly stylized, we expect any error to be in the noise. Explicit logging by applications might have provided slightly more accurate data, but it is logistically impossible to recompile and restart thousands of running clients to do so and cumbersome to collect the results from as many machines. One should be careful not to overly generalize from our workload. Since Google completely controls both GFS and its applications, the applications tend to be tuned for GFS, and conversely GFS is designed for these applications. Such mutual influence may also exist between general applications and file systems, but the effect is likely more pronounced in our case. 6.3.2 Chunkserver WorkloadTable 4 shows the distribution of operations by size. Read sizes exhibit a bimodal distribution. The small reads (under 64 KB) come from seek-intensive clients that look up small pieces of data within huge files. The large reads (over 512 KB) come from long sequential reads through entire files. A significant number of reads return no data at all in cluster Y. Our applications, especially those in the production systems, often use files as producer-consumer queues. Producers append concurrently to a file while a consumer reads the end of file. Occasionally, no data is returned when the consumer outpaces the producers. Cluster X shows this less often because it is usually used for short-lived data analysis tasks rather than long-lived distributed applications. Write sizes also exhibit a bimodal distribution. The large writes (over 256 KB) typically result from significant buffering within the writers. Writers that buffer less data, checkpoint or synchronize more often, or simply generate less data account for the smaller writes (under 64 KB). As for record appends, cluster Y sees a much higher percentage of large record appends than cluster X does because our production systems, which use cluster Y, are more aggressively tuned for GFS. Table 5 shows the total amount of data transferred in operations of various sizes. For all kinds of operations, the larger operations (over 256 KB) generally account for most of the bytes transferred. Small reads (under 64 KB) do transfer a small but significant portion of the read data because of the random seekworkload. 6.3.3 Appends versus WritesRecord appends are heavily used especially in our production systems. For cluster X, the ratio of writes to record appends is 108:1 by bytes transferred and 8:1 by operation counts. For cluster Y, used by the production systems, the ratios are 3.7:1 and 2.5:1 respectively. Moreover, these ratios suggest that for both clusters record appends tend to be larger than writes. For cluster X, however, the overall usage of record append during the measured period is fairlylow and so the results are likely skewed by one or two applications with particular buffer size choices. As expected, our data mutation workload is dominated by appending rather than overwriting. We measured the amount of data overwritten on primary replicas. This approximates the case where a client deliberately overwrites previous written data rather than appends new data. For cluster X, overwriting accounts for under 0.0001% of bytes mutated and under 0.0003% of mutation operations. For cluster Y, the ratios are both 0.05%. Although this is minute, it is still higher than we expected. It turns out that most of these overwrites came from client retries due to errors or timeouts. They are not part of the workload per se but aconsequence of the retry mechanism. 6.3.4 Master WorkloadTable 6 shows the breakdown by type of requests to the master. Most requests askfor chunklocations (FindLocation) for reads and lease holder information (FindLeaseLocker) for data mutations. Clusters X and Y see significantly different numbers of Delete requests because cluster Y stores production data sets that are regularly regenerated and replaced with newer versions. Some of this difference is further hidden in the difference in Open requests because an old version of a file may be implicitly deleted by being opened for write from scratch (mode “w” in Unix open terminology). FindMatchingFiles is a pattern matching request that supports “ls” and similar file system operations. Unlike other requests for the master, it may process a large part of the namespace and so may be expensive. Cluster Y sees it much more often because automated data processing tasks tend to examine parts of the file system to understand global application state. In contrast, cluster X’s applications are under more explicit user control and usually know the names of all needed files in advance. 7. EXPERIENCESIn the process of building and deploying GFS, we have experienced a variety of issues, some operational and some technical. 在构建和部署GFS的过程中，我们遇到了许多问题，一些操作方面的，一些是技术方面的。 Initially, GFS was conceived as the backend file system for our production systems. Over time, the usage evolved to include research and development tasks. It started with little support for things like permissions and quotas but now includes rudimentary forms of these. While production systems are well disciplined and controlled, users sometimes are not. More infrastructure is required to keep users from interfering with one another. 最初，GFS被构思为我们生产系统的后台文件系统。随着时间的推移，它也被用于研究和开发任务。GFS最开始很少支持权限和配额，但现在已经有了基础的支持。生产系统是被约束和控制的，但用户间有时候却不是这样。需要更多的基础设施来防止用户间相互干扰。 Some of our biggest problems were disk and Linux related. Many of our disks claimed to the Linux driver that they supported a range of IDE protocol versions but in fact responded reliably only to the more recent ones. Since the protocol versions are very similar, these drives mostly worked, but occasionally the mismatches would cause the drive and the kernel to disagree about the drive’s state. This would corrupt data silently due to problems in the kernel. This problem motivated our use of checksums to detect data corruption, while concurrently we modified the kernel to handle these protocol mismatches. 一些我们遇到的最大问题是磁盘和linux相关的。我们的许多磁盘都声称它们支持一系列IDE协议版本的linux驱动，但实际上只有最新的一些才有好的反应。因为协议版本是非常相似的，这些驱动大多数时间都能正常工作，但是偶发的不匹配会造成磁驱动和内核对于驱动的状态产生分歧。这将会因为内核的问题导致数据被默默损坏。这些问题促使我们使用校验和来检测数据损坏，同时我们已经修改了内核代码来解决协议不匹配问题 Earlier we had some problems with Linux 2.2 kernels due to the cost of fsync(). Its cost is proportional to the size of the file rather than the size of the modified portion. This was a problem for our large operation logs especially before we implemented checkpointing. We worked around this for a time by using synchronous writes and eventually migrated to Linux 2.4. 早先在linux2.2版本，我们有一些fsync的开销导致的问题。fsync的开销和文件大小成比例而不是和修改部分的大小成比例。这对于我们的大的操作日志是个问题，特别是在我们实现检查点之前。有一段时间我们通过同步写并最终升级到linxu2.4版本来解决这个问题 Another Linux problem was a single reader-writer lock which any thread in an address space must hold when it pages in from disk(reader lock) or modifies the address space in an mmap() call (writer lock). We saw transient timeouts in our system under light load and looked hard for resource bottlenecks or sporadic hardware failures. Eventually, we found that this single lock blocked the primary network thread from mapping new data into memory while the disk threads were paging in previously mapped data. Since we are mainly limited by the networkinterface rather than by memory copy bandwidth, we worked around this by replacing mmap() with pread() at the cost of an extra copy. Despite occasional problems, the availability of Linux code has helped us time and again to explore and understand system behavior. When appropriate, we improve the kernel and share the changes with the open source community. 另一个linux系统造成的问题是，任何地址空间的线程必须持有的单个读写锁，在它从磁盘分页时是读锁，通过mmap修改地址空间是写锁。我们看到我们的系统在低负载下会出现短暂的超时，并且很难寻找文件瓶颈或者零散的硬件故障。最终，我们发现是因为单个锁阻塞了主要的网络线程映射新的数据到内存，在磁盘线程正在对先前已映射数据进行分页的时候。因为我们主要受到网络接口的限制而不是内存拷贝带宽的限制，所以我们通过用pread代替mmap解决了这个问题，以额外的拷贝为代价。尽管有偶发的问题发生，linux代码的可用性已经帮助我们很多次了，在我们探索和理解系统行为上。在合适的时候，我们会改进内核并将共享修改的代码给开源社区 8. RELATED WORKLike other large distributed file systems such as AFS [5], GFS provides a location independent namespace which enables data to be moved transparently for load balance or fault tolerance. Unlike AFS, GFS spreads a file’s data across storage servers in a way more akin to xFS [1] and Swift [3] in order to deliver aggregate performance and increased fault tolerance. As disks are relatively cheap and replication is simpler than more sophisticated RAID [9] approaches, GFS currently uses only replication for redundancy and so consumes more raw storage than xFS or Swift. In contrast to systems like AFS, xFS, Frangipani [12], and Intermezzo [6], GFS does not provide any caching below the file system interface. Our target workloads have little reuse within a single application run because they either stream through a large data set or randomly seekwithin it and read small amounts of data each time. Some distributed file systems like Frangipani, xFS, Minnesota’s GFS[11] and GPFS [10] remove the centralized server and rely on distributed algorithms for consistency and management. We opt for the centralized approach in order to simplify the design, increase its reliability, and gain flexibility. In particular, a centralized master makes it much easier to implement sophisticated chunkplacement and replication policies since the master already has most of the relevant information and controls how it changes. We address fault tolerance by keeping the master state small and fully replicated on other machines. Scalability and high availability (for reads) are currently provided by our shadow master mechanism. Updates to the master state are made persistent by appending to a write-ahead log. Therefore we could adapt a primary-copy scheme like the one in Harp [7] to provide high availability with stronger consistency guarantees than our current scheme. We are addressing a problem similar to Lustre [8] in terms of delivering aggregate performance to a large number of clients. However, we have simplified the problem significantly by focusing on the needs of our applications rather than building a POSIX-compliant file system. Additionally, GFS assumes large number of unreliable components and so fault tolerance is central to our design. GFS most closely resembles the NASD architecture [4]. While the NASD architecture is based on network-attached diskdrives, GFS uses commodity machines as chunkservers, as done in the NASD prototype. Unlike the NASD work, our chunkservers use lazily allocated fixed-size chunks rather than variable-length objects. Additionally, GFS implements features such as rebalancing, replication, and recovery that are required in a production environment. Unlike Minnesota’s GFS and NASD, we do not seek to alter the model of the storage device. We focus on addressing day-to-day data processing needs for complicated distributed systems with existing commodity components. The producer-consumer queues enabled by atomic record appends address a similar problem as the distributed queues in River [2]. While River uses memory-based queues distributed across machines and careful data flow control, GFS uses a persistent file that can be appended to concurrently by many producers. The River model supports m-to-n distributed queues but lacks the fault tolerance that comes with persistent storage, while GFS only supports m-to-1 queues efficiently. Multiple consumers can read the same file, but they must coordinate to partition the incoming load. 9. CONCLUSIONSThe Google File System demonstrates the qualities essential for supporting large-scale data processing workloads on commodity hardware. While some design decisions are specific to our unique setting, many may apply to data processing tasks of a similar magnitude and cost consciousness. GFS证明了其支持在商用硬件上的大规模数据处理工作的基础特性。虽然它的一些设计决策是针对于我们的独特设置，但是多数都可以用于类似的量和开销的处理任务。 We started by reexamining traditional file system assumptions in light of our current and anticipated application workloads and technological environment. Our observations have led to radically different points in the design space. We treat component failures as the norm rather than the exception, optimize for huge files that are mostly appended to (perhaps concurrently) and then read (usually sequentially), and both extend and relax the standard file system interface to improve the overall system. 我们首先根据我们现在和预期的应用程序工作负载和技术环境，重新审视了传统文件系统的假设。我们的这些观察导致我们在设计空间上有完全不同的观点。我们认为组件故障是正常情况，而非异常，对于大文件的优化大多是通过追加写(可能并行的)然后读取(通常是顺序读)，我们通过扩展和放宽标椎文件系统接口来提高整个系统 Our system provides fault tolerance by constant monitoring, replicating crucial data, and fast and automatic recovery. Chunk replication allows us to tolerate chunkserver failures. The frequency of these failures motivated a novel online repair mechanism that regularly and transparently repairs the damage and compensates for lost replicas as soon as possible. Additionally, we use checksumming to detect data corruption at the disk or IDE subsystem level, which becomes all too common given the number of disks in the system. 我们的系统通过持续监控，复制关键数据，以及快速和原子的恢复来实现容错。chunk的副本存在允许我们容忍chunkserver发生故障。这些频繁发生的故障促使我们采用了新颖的在线修复机制，一种可以定期透明的对丢失的副本进行尽可能块的修复和补偿。另外，我们使用校验和来检测磁盘上损坏的数据或者检查IDE子系统的级别，这在系统给定磁盘数量的时候很常见。 Our design delivers high aggregate throughput to many concurrent readers and writers performing a variety of tasks. We achieve this by separating file system control, which passes through the master, from data transfer, which passes directly between chunkservers and clients. Master involvement in common operations is minimized by a large chunk size and by chunk leases, which delegates authority to primary replicas in data mutations. This makes possible a simple, centralized master that does not become a bottleneck. We believe that improvements in our networking stack will lift the current limitation on the write throughput seen by an individual client. 我们的设计对于多个并行的reader和writer的运行中的多种任务呈现出高聚合吞吐。我们通过分离传递给Master的文件系统控制信息，和直接在chunskervers于客户端见传输的数据，来实现。通过大的chunk大小参数和chunk的租约机制来最小化master参与到常用操作中，通过在数据变更的时候将权限委托给primaey副本。这使得简单，集中的master不会成为瓶颈。我们相信我们网络栈的提高将会改进现在对于单个客户端写吞吐量的限制 GFS has successfully met our storage needs and is widely used within Google as the storage platform for research and development as well as production data processing. It is an important tool that enables us to continue to innovate and attack problems on the scale of the entire web. GFS已经成功的实现了我们的存储需求并作为存储平台在谷歌内部广泛使用，用于研究和开发以及生产数据的处理。它是个重要的工具，对于能够使我们在整个网络规模上继续进行创建和解决问题 ACKNOWLEDGMENTSWe wish to thankthe following people for their contributions to the system or the paper. Brain Bershad (our shepherd) and the anonymous reviewers gave us valuable comments and suggestions. Anurag Acharya, Jeff Dean, and David desJardins contributed to the early design. Fay Chang worked on comparison of replicas across chunkservers. Guy Edjlali worked on storage quota. Markus Gutschke worked on a testing frameworkand security enhancements. David Kramer worked on performance enhancements. Fay Chang, Urs Hoelzle, Max Ibel, Sharon Perl, Rob Pike, and Debby Wallach commented on earlier drafts of the paper. Many of our colleagues at Google bravely trusted their data to a new file system and gave us useful feedback. Yoshka helped with early testing. REFERENCES[1] Thomas Anderson, Michael Dahlin, Jeanna Neefe, David Patterson, Drew Roselli, and Randolph Wang. Serverless networkfile systems. In Proceedings of the15th ACM Symposium on Operating System Principles, pages 109–126, Copper Mountain Resort, Colorado, December 1995. [2] Remzi H. Arpaci-Dusseau, Eric Anderson, Noah Treuhaft, David E. Culler, Joseph M. Hellerstein, David Patterson, and Kathy Yelick. Cluster I/O with River: Making the fast case common. In Proceedings of the Sixth Workshop on Input/Output in Parallel and Distributed Systems (IOPADS ’99), pages 10–22, Atlanta, Georgia, May 1999. [3] Luis-Felipe Cabrera and Darrell D. E. Long. Swift: Using distributed diskstriping to provide high I/O data rates. Computer Systems, 4(4):405–436, 1991. [4] Garth A. Gibson, David F. Nagle, Khalil Amiri, Jeff Butler, Fay W. Chang, Howard Gobioff, Charles Hardin, ErikRiedel, David Rochberg, and Jim Zelenka. A cost-effective, high-bandwidth storage architecture. In Proceedings of the 8th Architectural Support for Programming Languages and Operating Systems, pages 92–103, San Jose, California, October 1998. [5] John Howard, Michael Kazar, Sherri Menees, David Nichols, Mahadev Satyanarayanan, Robert Sidebotham, and Michael West. Scale and performance in a distributed file system. ACM Transactions on Computer Systems, 6(1):51–81, February 1988. [6] InterMezzo. http://www.inter-mezzo.org, 2003. [7] Barbara Liskov, Sanjay Ghemawat, Robert Gruber, Paul Johnson, Liuba Shrira, and Michael Williams. Replication in the Harp file system. In 13th Symposium on Operating System Principles, pages 226–238, Pacific Grove, CA, October 1991. [8] Lustre. http://www.lustreorg, 2003. [9] David A. Patterson, Garth A. Gibson, and Randy H. Katz. A case for redundant arrays of inexpensive disks (RAID). In Proceedings of the 1988 ACM SIGMODInternational Conference on Management of Data, pages 109–116, Chicago, Illinois, September 1988. [10] FrankSchmuckand Roger Haskin. GPFS: A shared-diskfile system for large computing clusters. In Proceedings of the First USENIX Conference on Fileand Storage Technologies, pages 231–244, Monterey, California, January 2002. [11] Steven R. Soltis, Thomas M. Ruwart, and Matthew T. O’Keefe. The Gobal File System. In Proceedings of the Fifth NASA Goddard Space Flight Center Conferenceon Mass Storage Systems and Technologies, College Park, Maryland, September 1996. [12] Chandramohan A. Thekkath, Timothy Mann, and Edward K. Lee. Frangipani: A scalable distributed file system. In Proceedings of the 16th ACM Symposiumon Operating System Principles, pages 224–237, Saint-Malo, France, October 1997. 参考其他翻译","categories":[],"tags":[],"keywords":[]},{"title":"[译文]MapReduce: Simplified Data Processing on Large Clusters","slug":"2021-01-21-MapReduce-Simplified-Data-Processing-on-Large-Clusters","date":"2021-01-21T00:00:00.000Z","updated":"2022-09-12T16:24:32.289Z","comments":true,"path":"2021-01-21-MapReduce-Simplified-Data-Processing-on-Large-Clusters/","link":"","permalink":"https://riverferry.site/2021-01-21-MapReduce-Simplified-Data-Processing-on-Large-Clusters/","excerpt":"尝试翻译一下，会大量参考翻译软件和其他翻译文章，纯自学，无其他用途。参考文章在文末，原文在此: MapReduce: Simplified Data Processing on Large Clusters 翻译的工作量超出了预期，让我产生了投入回报比的疑惑，这种积累需要很长时期的沉淀，而目前我的重点应该是内容而不是语言的形式。所以后面应该会依赖于对翻译文章的搜索以及各种翻译软件的使用。英文水平提高待日后再提上日程吧。","text":"尝试翻译一下，会大量参考翻译软件和其他翻译文章，纯自学，无其他用途。参考文章在文末，原文在此: MapReduce: Simplified Data Processing on Large Clusters 翻译的工作量超出了预期，让我产生了投入回报比的疑惑，这种积累需要很长时期的沉淀，而目前我的重点应该是内容而不是语言的形式。所以后面应该会依赖于对翻译文章的搜索以及各种翻译软件的使用。英文水平提高待日后再提上日程吧。 AbstractMapReduce is a programming model and an associated implementation for processing and generating large data sets. Users specify a map function that processes a key/value pair to generate a set of intermediate key/value pairs, and a reduce function that merges all intermediate values associated with the same intermediate key. Many real world tasks are expressible in this model, as shown in the paper. MapReduce一种编程模型，和处理，生成大数据库集的相关实现。用户指定一个map函数，处理k/v pair并生成中间的k/v pair,以及一个reduce函数来合并所有相同的中间key对应的中间value.很多真实世界的任务都可以通过这个模型表示，如本文描述的那样。 Programs written in this functional style are automatically parallelized and executed on a large cluster of commodity machines. The run-time system takes care of the details of partitioning the input data, scheduling the program’s execution across a set of machines, handling machine failures, and managing the required inter-machine communication. This allows programmers without any experience with parallel and distributed systems to easily utilize the resources of a large distributed system. 用MapReduce这种函数风格实现的程序能够自动实现并行化，可以运行在大的商用集群中。运行时系统负责一些细节：划分输入数据，调度程序在一组机器上执行，处理机器故障，管理内部机器间的交流请求。这使毫无并行以及分布式经验的程序员能够很容易的利用一个大的分布式系统的资源。 Our implementation of MapReduce runs on a large cluster of commodity machines and is highly scalable: a typical MapReduce computation processes many terabytes of data on thousands of machines. Programmers find the system easy to use: hundreds of MapReduce programs have been implemented and upwards of one thousand MapReduce jobs are executed on Google’s clusters every day. 我们对MapReduce的实现可在大的商业集群上运行并有很好的扩展性：一个典型的在数千台机器上处理TB级数据的MapReduce计算。谷歌程序员觉得这种系统很容易使用：已经有数百个MapReduce被实现，谷歌的集群上每天运行一千个mapReduce作业 1 IntroductionOver the past five years, the authors and many others at Google have implemented hundreds of special-purpose computations that process large amounts of raw data, such as crawled documents, web request logs, etc., to compute various kinds of derived data, such as inverted indices, various representations of the graph structure of web documents, summaries of the number of pages crawled per host, the set of most frequent queries in a given day, etc. Most such computations are conceptually straightforward. However, the input data is usually large and the computations have to be distributed across hundreds or thousands of machines in order to finish in a reasonable amount of time. The issues of how to parallelize the computation, distribute the data, and handle failures conspire to obscure the original simple computation with large amounts of complex code to deal with these issues. 过去5年，笔者和许多谷歌人员已经实现了数百个用于特定用途的计算过程，包括处理大量的原始数据(比如抓取的文档，web请求日志等)，处理各种衍生数据(如反向索引，各种网页文档中图结构的表示,单台主机抓取网页数量概要，指定日期top频次查询的集合等)。大多数这类计算在概念上是直截了当的。然而输入数据通常很大，需要成百上千台机器通过分布式计算以在合理时间内完成。解决并行计算，分布式数据，错误处理这些问题引入了大量复杂的代码将原本简单的计算变得晦涩难懂。 As a reaction to this complexity, we designed a new abstraction that allows us to express the simple computations we were trying to perform but hides the messy details of parallelization, fault-tolerance, data distribution and load balancing in a library. Our abstraction is inspired by the map and reduce primitives present in Lisp and many other functional languages. We realized thatmost of our computations involved applying a map operation to each logical “record” in our input in order to compute a set of intermediate key/value pairs, and then applying a reduce operation to all the values that shared the same key, in order to combine the derived data appropriately. Our use of a functional model with userspecified map and reduce operations allows us to parallelize large computations easily and to use re-execution as the primary mechanism for fault tolerance. 作为对这种复杂性的回应，我们设计了一个新的抽象，允许我们将计算进行简单的表达，而隐藏对于并行，容错，分布式计算，负载均衡这些复杂的细节。我们实现的抽象，受到了当下Lisp等函数式语言的启发。我们意识到大多数的计算都涉及到对于每一个输入的逻辑数据的map操作从而计算出一个中间的k/v pair的集合，然后对于所有相同key的value,进行reduce操作,从而适当的合并这些衍生的数据。使用这种通过用户指定map reduce操作的函数模型让我们可以很容易的将大型计算并行化，并且以恢复执行作为容错的机制。 The major contributions of this work are a simple and powerful interface that enables automatic parallelization and distribution of large-scale computations, combined with an implementation of this interface that achieves high performance on large clusters of commodity PCs. 这份工作主要的贡献是提供一个简单而强大的接口，能够自动实现并行化和大规模分布式计算。结合这些接口的实现能够在大的商用pc集群中有很好的表现。 Section 2 describes the basic programming model and gives several examples. Section 3 describes an implementation of the MapReduce interface tailored towards our cluster-based computing environment. Section 4 describes several refinements of the programming model that we have found useful. Section 5 has performance measurements of our implementation for a variety of tasks. Section 6 explores the use of MapReduce within Google including our experiences in using it as the basis for a rewrite of our production indexing system. Section 7 discusses related and future work. 第二部分描述了简单的程序模型并提供了几个例子。第三部分描述了对于我们基础计算集群环境上量身定制的MapReduce接口的实现。第四部分描述了几种我们已经发现的有用的程序模型的细化。第五部分展示了我们的实现对于各种各样任务的数据表现。第六部分探索了谷歌内部基于MapReduce改写我们的索引系统中的经验。第七部分讨论了相关的和未来的工作。 2 Programming ModelThe computation takes a set of input key/value pairs, and produces a set of output key/value pairs. The user of the MapReduce library expresses the computation as two functions: Map and Reduce. 计算过程使用一个输入的k/v pair集合，产出一个输出的k/v pair集合。MapReduce库的用户通过map和reduce函数来使用。 Map, written by the user, takes an input pair and produces a set of intermediate key/value pairs. The MapReduce library groups together all intermediate values associated with the same intermediate key I and passes them to the Reduce function. map函数由用户实现，使用一个输入的pair然后产出一个中间的kv pair.MapReduce库对所有有相同key的中间值进行组合然后传递给reduce函数。 The Reduce function, also written by the user, accepts an intermediate key I and a set of values for that key. It merges together these values to form a possibly smaller set of values. Typically just zero or one output value is produced per Reduce invocation. The intermediate values are supplied to the user’s reduce function via an iterator. This allows us to handle lists of values that are too large to fit in memory. reduce函数也由用户实现，接受一个中间的key和该key对应的value的集合，合并这些值并构造出一个更小的值得集合。典型的o或1作为reduce函数每次执行的输出。中间值通过迭代器提供给用户的reduce函数。这允许我们处理哪些太大以至于不能保存在内存中的以链表保存的值。 2.1 ExampleConsider the problem of counting the number of occurrences of each word in a large collection of documents. The user would write code similar to the following pseudo-code: 思考统计一个大的文档中单词出现次数的问题。用户可以很简单的写出如下的伪代码。 12345678910111213map(String key, String value): &#x2F;&#x2F; key: document name &#x2F;&#x2F; value: document contents for each word w in value: EmitIntermediate(w, &quot;1&quot;);reduce(String key, Iterator values): &#x2F;&#x2F; key: a word &#x2F;&#x2F; values: a list of counts int result &#x3D; 0; for each v in values: result +&#x3D; ParseInt(v); Emit(AsString(result)); The map function emits each word plus an associated count of occurrences (just ‘1’ in this simple example). The reduce function sums together all counts emitted for a particular word. map函数发射每一个单词加上关联的次数(本例中是1)。reduce函数统计所有发出的特定单词的次数。 In addition, the user writes code to fill in a mapreduce specification object with the names of the input and output files, and optional tuning parameters. The user then invokes the MapReduce function, passing it the specification object. The user’s code is linked together with the MapReduce library (implemented in C++). Appendix A contains the full program text for this example. 除此之外，用户实现代码用输入输出文件名和可选的调优参数填充特定的mapreduce函数。然后传递特定的对象并执行MapReduce函数。用户的代码和MapReduce库链接起来(用c++实现)。附录A包含完整的此实例的代码。 2.2 TypesEven though the previous pseudo-code is written in terms of string inputs and outputs, conceptually the map and reduce functions supplied by the user have associated types: 即使前面伪代码里面用string作为输入和输出，概念上用户提供的map和reduce函数是和类型关联的： 12map (k1,v1) → list(k2,v2)reduce (k2,list(v2)) → list(v2) I.e., the input keys and values are drawn from a different domain than the output keys and values. Furthermore, the intermediate keys and values are from the same domain as the output keys and values. 输入的k/v和输出的k/v来自不同的域。此外，中间的k/v和输出的k/v来自同一域。 Our C++ implementation passes strings to and from the user-defined functions and leaves it to the user code to convert between strings and appropriate types. 我们的c++实现传递string到用户定义的函数，用户代码将string和相应的类型进行转换。 2.3 More ExamplesHere are a few simple examples of interesting programs that can be easily expressed as MapReduce computations. 这里有一些简单有趣的程序可以容易的用于MapRedece计算 Distributed Grep: The map function emits a line if it matches a supplied pattern. The reduce function is an identity function that just copies the supplied intermediate data to the output. 分布式grep: map函数如果匹配到特定模式则发射一行。reduce函数复制中间数据到输出。 Count of URL Access Frequency: The map function processes logs of web page requests and outputs (URL, 1). The reduce function adds together all values for the same URL and emits a (URL, total count) pair. 统计url访问频率：map函数处理网页输入和输出日志(url, 1). reduce函数把所有相同url的值加起来然后发射(url, total count)pair. Reverse Web-Link Graph: The map function outputs (target, source) pairs for each link to a target URL found in a page named source. The reduce function concatenates the list of all source URLs associated with a given target URL and emits the pair: (target, list(source)) 反向web链接图：map函数对于source页中每一个指向target的链接都输出一个(target, source)pair. reduce函数将所有和给定target相关联的source串联成链表然后发送：(target, list(source)) pair. Term-Vector per Host: A term vector summarizes the most important words that occur in a document or a set of documents as a list of (word, frequency) pairs. The map function emits a (hostname, term vector) pair for each input document (where the hostname is extracted from the URL of the document). The reduce function is passed all per-document term vectors for a given host. It adds these term vectors together, throwing away infrequent terms, and then emits a final (hostname, term vector) pair. 每台主机的关键词向量： 关键词向量概括了一个或一组文档中出现的最重要的单词，形如(word, frequency) pair的链表。map函数对于每一个输入数据(其中hostname是从文档的Url中提取的)发射(hostname, term vector)pair. 给定主机的所有关键词向量都会传递给reduce函数。reduce函数将这些关键词向量相加，去掉频率较低的关键词，然后发射最终的(hostname, term vector) pair. Inverted Index: The map function parses each document, and emits a sequence of (word, document ID) pairs. The reduce function accepts all pairs for a given word, sorts the corresponding document IDs and emits a (word, list(document ID)) pair. The set of all output pairs forms a simple inverted index. It is easy to augment this computation to keep track of word positions. 反向索引(倒排索引)：map函数解析每一个文件，然后发射一个有序的(word, document id)pair. reduce函数接收所有给定单词的所有pairs,对document ids进行排序然后发射(word, list(document id))pair.所有输出的pairs组成一个简单的反向索引。通过扩展这个计算来跟踪单词位置是很容易的。 Distributed Sort: The map function extracts the key from each record, and emits a (key, record) pair. The reduce function emits all pairs unchanged. This computation depends on the partitioning facilities described in Section 4.1 and the ordering properties described in Section 4.2. 分布式排序：map函数从每一个记录中提取key,然后发射(key, record) pair. reduce函数发射所有未改变的pairs.这个计算依赖于4.1节描述的划分机制以及4.2节描述的排序性质。 3 ImplementationMany different implementations of the MapReduce interface are possible. The right choice depends on the environment. For example, one implementation may be suitable for a small shared-memory machine, another for a large NUMA multi-processor, and yet another for an even larger collection of networked machines. 许多不同MapReduce接口的实现都是可能的。正确的选择依赖于环境。例如，有的实现可能适合一个小的共享内存机器，有的适合大的NUMA多处理器，也有的适合大的网络机器集合 This section describes an implementation targeted to the computing environment in wide use at Google: 这个部分描述的实现主要针对谷歌使用的计算环境： large clusters of commodity PCs connected together with switched Ethernet [4]. In our environment: 大集群的商用pc机通过以太网连接在一起，在我们的环境中： (1) Machines are typically dual-processor x86 processors running Linux, with 2-4 GB of memory per machine. (1) 每台机器都是典型的基于x86架构的运行在linux下的2-4g内存的配置 (2) Commodity networking hardware is used – typically either 100 megabits/second or 1 gigabit/second at the machine level, but averaging considerably less in overall bisection bandwidth. (2) 使用商用的网络硬件-在机器层面上通常是100mb/s或者1g/s，但平均下来少于整体带宽一般的速度。 (3) A cluster consists of hundreds or thousands of machines, and therefore machine failures are common. (3) 成百上千机器组成的集群，所以机器故障会很常见 (4) Storage is provided by inexpensive IDE disks attached directly to individual machines. A distributed file system [8] developed in-house is used to manage the data stored on these disks. The file system uses replication to provide availability and reliability on top of unreliable hardware. (4) 廉价IDE磁盘嵌入到个人机作为存储。内部开发的文件系统用来管理这些存储在磁盘的数据。文件系统使用复制来保证在不可靠的硬件上提供可用性，可靠性 (5) Users submit jobs to a scheduling system. Each job consists of a set of tasks, and is mapped by the scheduler to a set of available machines within a cluster. (5) 用户提交作业到调度系统。每个作业由一组任务组成，通过调度器映射到集群中一组可用的机器。 3.1 Execution OverviewThe Map invocations are distributed across multiple machines by automatically partitioning the input data into a set of M splits. The input splits can be processed in parallel by different machines. Reduce invocations are distributed by partitioning the intermediate key space into R pieces using a partitioning function (e.g., hash(key) mod R). The number of partitions (R) and the partitioning function are specified by the user. 通过自动化的将输入数据分割成M块的集合，map调用可以在多台机器上分布式执行。输入数据可以通过不同的机器并行处理。reduce通过分割函数(eg., hash(key) mod R)分割中间数据成R块来分布式调用。R的数量和分割函数由用户指定 Figure 1 shows the overall flow of a MapReduce operation in our implementation. When the user program calls the MapReduce function, the following sequence of actions occurs (the numbered labels in Figure 1 correspond to the numbers in the list below): 图一展示了实现的MapReduce操作的总体流程。用户调用MapReduce函数的时候，会发生下面的行为(图一的标号和下面列表的数字对应) The MapReduce library in the user program first splits the input files into M pieces of typically 16 megabytes to 64 megabytes (MB) per piece (controllable by the user via an optional parameter). It then starts up many copies of the program on a cluster of machines. MapReduce库在用户程序中首先分割输入数据成典型的16m-64m(用户通过可选参数指定)大小的M片，然后在集群中启动多个程序的副本 One of the copies of the program is special – the master. The rest are workers that are assigned work by the master. There are M map tasks and R reduce tasks to assign. The master picks idle workers and assigns each one a map task or a reduce task. 其中一个副本程序时特殊的-主节点。其余的工作节点通过主节点分配工作。一共有m个map任务和r个reduce任务需要分配。主节点选择一个idle的工作节点执行map或者reduce任务 A worker who is assigned a map task reads the contents of the corresponding input split. It parses key/value pairs out of the input data and passes each pair to the user-defined Map function. The intermediate key/value pairs produced by the Map function are buffered in memory. 被分配map任务的worker(工作节点)读取相应输入块的内容。worker解析输入文件成k/v pair然后发给用户定义的map函数。map函数生成中间的k/v pair并缓存在内存中 Periodically, the buffered pairs are written to local disk, partitioned into R regions by the partitioning function. The locations of these buffered pairs on the local disk are passed back to the master, who is responsible for forwarding these locations to the reduce workers. 缓存的pair会定期的写入本地磁盘，通过分割函数分割到R个块。存在本地磁盘的缓存pairs将被传递给master,由master负责传递给reduce workers When a reduce worker is notified by the master about these locations, it uses remote procedure calls to read the buffered data from the local disks of the map workers. When a reduce worker has read all intermediate data, it sorts it by the intermediate keys so that all occurrences of the same key are grouped together. The sorting is needed because typically many different keys map to the same reduce task. If the amount of intermediate data is too large to fit in memory, an external sort is used. 当reduce work收到master发来的位置通知信息，会通过rpc从map workers读取缓存的pairs. reduce读取完所有的中间数据后，将对所有的中间keys进行排序分组。之所以排序是因为通常多个不同的keys会映射到同一个reduce task. 如果中间数据太大以至于内存放不下，则会使用外部排序 The reduce worker iterates over the sorted intermediate data and for each unique intermediate key encountered, it passes the key and the corresponding set of intermediate values to the user’s Reduce function. The output of the Reduce function is appended to a final output file for this reduce partition. reduce worker迭代的对唯一的中间keys进行排序统计， 传递key和相应的value到用户的Reduce函数。 Reduce函数输出会追加到该reduce work的最终输出文件。 When all map tasks and reduce tasks have been completed, the master wakes up the user program. At this point, the MapReduce call in the user program returns back to the user code. 当所有的map和reduce task处理完成， master会唤醒用户程序。 然后MapReduce调用结束返回到用户代码 After successful completion, the output of the mapreduce execution is available in the R output files (one per reduce task, with file names as specified by the user). Typically, users do not need to combine these R output files into one file – they often pass these files as input to another MapReduce call, or use them from another distributed application that is able to deal with input that is partitioned into multiple files. 成功执行后，MapReduce将输出写入到R个输出文件(每一个reduce任务都有一个由用户指定的文件名)。 通常用户不需要合并这R个文件到一个文件中-一般会将这些文件作为输入传递给其他的MapReduce调用， 或者使用那些能够处理以多个文件作为输入的分布式程序 3.2 Master Data StructuresThe master keeps several data structures. For each map task and reduce task, it stores the state (idle, in-progress, or completed), and the identity of the worker machine (for non-idle tasks). master有几种数据结构。对于每一个map任务和reduce任务，master会保存状态(idle, in-progress, or completed)，对于非空闲的任务还会保存任务的ID The master is the conduit through which the location of intermediate file regions is propagated from map tasks to reduce tasks. Therefore, for each completed map task, the master stores the locations and sizes of the R intermediate file regions produced by the map task. Updates to this location and size information are received as map tasks are completed. The information is pushed incrementally to workers that have in-progress reduce tasks. 主节点是map任务将中间文件的位置信息传递给reduce任务的渠道。因此，对于每一个完成的map任务，master保存其R个中间文件(map task生成的)的位置和大小。map任务完成的时候会受到更新位置和大小的通知。这些信息会逐步推送给处于in-progress状态的reduce worker. 3.3 Fault ToleranceSince the MapReduce library is designed to help process very large amounts of data using hundreds or thousands of machines, the library must tolerate machine failures gracefully. 因为MapReduce库是设计用来通过数千台机器处理非常大的数据，所以该库必须能够优雅的处理机器故障。 Worker FailureThe master pings every worker periodically. If no response is received from a worker in a certain amount of time, the master marks the worker as failed. Any map tasks completed by the worker are reset back to their initial idle state, and therefore become eligible for scheduling on other workers. Similarly, any map task or reduce task in progress on a failed worker is also reset to idle and becomes eligible for rescheduling. master定时ping所有的worker(工作节点).如果没有在一定的时间内收到响应，master会标记这些work为failed状态。这个工作节点的所有已完成任务都会被重置为初始的idle状态，其他工作节点就可以处理这些任务了。类似的，任何一个故障的worker中未完成的map或reduce任务，也会被置为idle状态，等待重新调度 Completed map tasks are re-executed on a failure because their output is stored on the local disk(s) of the failed machine and is therefore inaccessible. Completed reduce tasks do not need to be re-executed since their output is stored in a global file system. 已完成的map任务遇到错误会重新执行，因为输出保存在故障机器的本地磁盘中所以是不可访问的。已完成的reduce task不需要从新执行，因为输出存储在公共的文件系统中。 When a map task is executed first by worker A and then later executed by worker B (because A failed), all workers executing reduce tasks are notified of the reexecution. Any reduce task that has not already read the data from worker A will read the data from worker B. 当一个map task一开始在worker a执行然后在worker b执行(因为work a)故障了，所有执行reduce task的worker都被收到通知。任何还没有从worker a读取数据的reduce task都会从work b开始读取数据。 MapReduce is resilient to large-scale worker failures. For example, during one MapReduce operation, network maintenance on a running cluster was causing groups of 80 machines at a time to become unreachable for several minutes. The MapReduce mastersimply re-executed the work done by the unreachable worker machines, and continued to make forward progress, eventually completing the MapReduce operation. MapReduce能够弹性处理大规模工作节点故障。比如，网络维护导致80台机器同时持续几分钟不可访问。MapReduce会重新执行网络不可达的worker，然后继续向前执行，最终完成所有的MapReduce操作。 Master FailureIt is easy to make the master write periodic checkpoints of the master data structures described above. If the master task dies, a new copy can be started from the last checkpointed state. However, given that there is only a single master, its failure is unlikely; therefore our current implementation aborts the MapReduce computation if the master fails. Clients can check for this condition and retry the MapReduce operation if they desire. master可以很容易的将前面描述的数据结构写成checkpoint。如果master task失败了，可以从最新的checkpoint开始新的程序副本。然而，给定的只有一台主节点,它也不太可能失败。所以现在的MapReduce没有实现对于master fails的处理。如果客户端需要的话，可以自己检查这种情况然后重新尝试MapReduce操作。 Semantics in the Presence of FailuresWhen the user-supplied map and reduce operators are deterministic functions of their input values, our distributed implementation produces the same output as would have been produced by a non-faulting sequential execution of the entire program. 当用户提供的map和reduce函数对于输入值是确定的，我们的分布式实现和非故障顺序执行的结果是一样的。 We rely on atomic commits of map and reduce task outputs to achieve this property. Each in-progress task writes its output to private temporary files. A reduce task produces one such file, and a map task produces R such files (one per reduce task). When a map task completes, the worker sends a message to the master and includes the names of the R temporary files in the message. If the master receives a completion message for an already completed map task, it ignores the message. Otherwise, it records the names of R files in a master data structure. 我们依靠原子提交map/reduce任务的输出来实现这个性质。所有in-grogress task将输出写入到自己私有的临时文件中。每个reduce task只生成一个这种文件，每个map task生成r个这种文件(每个reduce一个)。当一个map task完成的时候，会发送包含R个文件名称的消息给master。如果master从一个已经完成了的map task收到一个完成消息，会忽视掉。否则，会记录R个文件的文件名在master的数据结构中。 When a reduce task completes, the reduce worker atomically renames its temporary output file to the final output file. If the same reduce task is executed on multiple machines, multiple rename calls will be executed for the same final output file. We rely on the atomic rename operation provided by the underlying file system to guarantee that the final file system state contains just the data produced by one execution of the reduce task. 当reduce任务完成的时候，reduce工作节点会原子的将临时输出文件重命名为最终的输出文件。当相同的reduce任务在多台机器上执行，多个相同的对于最终输出文件的重命名调用会被执行。我们依赖底层文件系统提供的原子重命名操作来保证最终的文件系统仅包含一个reduce任务执行产生的数据。 The vast majority of our map and reduce operators are deterministic, and the fact that our semantics are equivalent to a sequential execution in this case makes it very easy for programmers to reason about their program’s behavior. When the map and/or reduce operators are nondeterministic, we provide weaker but still reasonable semantics. In the presence of non-deterministic operators, the output of a particular reduce task R1 is equivalent to the output for R1 produced by a sequential execution of the non-deterministic program. However, the output for a different reduce task R2 may correspond to the output for R2 produced by a different sequential execution of the non-deterministic program. 绝大多数map和reduce操作都是确定性的，这在语义上和顺序执行是相等的，都很容易去解释程序的行为。当map或者reduce操作是不确定的时候我们提供较弱但仍旧合理的语义。对于不确定性操作，一个reduce任务R1的输出等价于一个不确定性的顺序执行的R1的输出。然而一个不同的reduce任务R2的输出可能和另外的不确定程序顺序执行下的输出R2相符。 Consider map task M and reduce tasks R1 and R2. Let e(Ri) be the execution of Ri that committed (there is exactly one such execution). The weaker semantics arise because e(R1) may have read the output produced by one execution of M and e(R2) may have read the output produced by a different execution of M. 考虑map任务M和reduce任务R1,R2. 让e(Ri)表示Ri的已提交的执行(只执行一次)。此时弱语义生效，因为e(R1)可能读取了M的输出，而e(R2)可能读取了M的另一个输出。 3.4 LocalityNetwork bandwidth is a relatively scarce resource in our computing environment. We conserve network bandwidth by taking advantage of the fact that the input data (managed by GFS [8]) is stored on the local disks of the machines that make up our cluster. GFS divides each file into 64 MB blocks, and stores several copies of each block (typically 3 copies) on different machines. The MapReduce master takes the location information of the input files into account and attempts to schedule a map task on a machine that contains a replica of the corresponding input data. Failing that, it attempts to schedule a map task near a replica of that task’s input data (e.g., on a worker machine that is on the same network switch as the machine containing the data). When running large MapReduce operations on a significant fraction of the workers in a cluster, most input data is read locally and consumes no network bandwidth. 局部性网络带宽在我们的计算环境中是相对稀缺的资源。事实上我们利用将输入数据(通过GFS管理)存储在组成集群的机器的本地磁盘中从而节省了带宽。GFS将每个文件切割成64M大小的块，每块复制几份(通常是3份)存储到不同的机器。考虑到MapReduce master中保存了输入文件的位置信息，可以调用存储了输入数据的机器来执行map task.如果失败了，会接着尝试调度靠近存储输入数据备份的机器(比如和存储数据的机器在同一网关的其他机器)。当一个集群中大部分worker在运行一个大的MapReduce操作的时候，大多数输入数据都是本都读取的，而不消耗带宽。 3.5 Task GranularityWe subdivide the map phase into M pieces and the reduce phase into R pieces, as described above. Ideally, M and R should be much larger than the number of worker machines. Having each worker perform many different tasks improves dynamic load balancing, and also speeds up recovery when a worker fails: the many map tasks it has completed can be spread out across all the other worker machines. 任务粒度将map细分为M个阶段，reudce细分为R个阶段。理想情况下，M和R的总数远大于机器的worker数。每个worker都运行许多不同的任务从而提供了动态负载均衡，并且加速了worker故障的恢复：失败节点已经完成的map tasks可以扩散到到所有其他的worker中 There are practical bounds on how large M and R can be in our implementation, since the master must make O(M + R) scheduling decisions and keeps O(MR) state in memory as described above. (The constant factors for memory usage are small however: the O(MR) piece of the state consists of approximately one byte of data per map task/reduce task pair.) 在我们的实现中,M和R有实际的上限，因为如前面所讲那样，master必须对O(M+R)做出调度决策，并存储O(M x R)的状态在内存中。(然后内存使用的常数项很小：O(M x R)个状态中每个map/reduce任务对只需要一个字节的数据) Furthermore, R is often constrained by users because the output of each reduce task ends up in a separate output file. In practice, we tend to choose M so that each individual task is roughly 16 MB to 64 MB of input data (so that the locality optimization described above is most effective), and we make R a small multiple of the number of worker machines we expect to use. We often perform MapReduce computations with M = 200000 and R = 5000, using 2000 worker machines. 此外，R通常由用户指定，因为每一个reduce task的输出最终都保存在一个单独的输出文件中。在实践中，我们倾向于这样选择M，即将每个单独的任务都是16-64m大小的输入数据(这样前面说的局部性优化是最有效的) 因为每一个单独的任务的输入文件大小是16到64M(因为地区优化是最有效的)，并且我们选择R为我们希望使用的工作节点机器的小数倍。我们通常使用M=200000,R=5000,使用2000个worker机器来进行MapReduce计算。 3.6 Backup TasksOne of the common causes that lengthens the total time taken for a MapReduce operation is a “straggler”: a machine that takes an unusually long time to complete one of the last few map or reduce tasks in the computation. Stragglers can arise for a whole host of reasons. For example, a machine with a bad disk may experience frequent correctable errors that slow its read performance from 30 MB/s to 1 MB/s. The cluster scheduling system may have scheduled other tasks on the machine, causing it to execute the MapReduce code more slowly due to competition for CPU, memory, local disk, or network bandwidth. A recent problem we experienced was a bug in machine initialization code that caused processor caches to be disabled: computations on affected machines slowed down by over a factor of one hundred. 备份任务延长MapReduce操作总时间的常见原因之一是“落后者”：在计算中一台机器需要不正常的大量时间才能完成最后的几个map或者reduce任务。落后者的出现有很多原因。比如，一台机器磁盘损坏可能造成频繁的校正错误从而导致读取速度从30m/s变慢到1m/s.集群调度系统可能已经调度了其他任务在这台机器，因为需要竞争Cpu,内存，本地磁盘，网络带宽进而使得MapReduce变得更慢。我们最近遇到的一个机器初始化代码的bug造成缓存不可用：受影响的机器的计算速度下降了100倍 We have a general mechanism to alleviate the problem of stragglers. When a MapReduce operation is close to completion, the master schedules backup executions of the remaining in-progress tasks. The task is marked as completed whenever either the primary or the backup execution completes. We have tuned this mechanism so that it typically increases the computational resources used by the operation by no more than a few percent. We have found that this significantly reduces the time to complete large MapReduce operations. As an example, the sort program described in Section 5.3 takes 44% longer to complete when the backup task mechanism is disabled. 我们有一个一般的机制来减轻落后者的问题：当一个MapReduce操作接近完成的时候，master调度其他in-progress的tasks备份执行。不管是主要的还是备份的执行完成，task都会被master标记为已完成。我们已经调整了该机制使得其增加的计算资源不超过百分之几。我们发现这样显著的降低了完成大的MapReduce操作的时间。作为例子，5.3部分的排序程序在备份任务机制被禁用的情况下多消耗44%的时间。 4 RefinementsAlthough the basic functionality provided by simply writing Map and Reduce functions is sufficient for most needs, we have found a few extensions useful. These are described in this section. 细化尽管map reduce函数提供的基础功能已经足够使用了，我们还发现了一些有用的扩展，会在这部分描述。 4.1 Partitioning FunctionThe users of MapReduce specify the number of reduce tasks/output files that they desire (R). Data gets partitioned across these tasks using a partitioning function on the intermediate key. A default partitioning function is provided that uses hashing (e.g. “hash(key) mod R”). This tends to result in fairly well-balanced partitions. In some cases, however, it is useful to partition data by some other function of the key. For example, sometimes the output keys are URLs, and we want all entries for a single host to end up in the same output file. To support situations like this, the user of the MapReduce library can provide a special partitioning function. For example, using “hash(Hostname(urlkey)) mod R” as the partitioning function causes all URLs from the same host toend up in the same output file. MapReduce的用户可以指定他们想要的reduce tasks/output文件的数量(R).数据被划分函数通过中间key进行划分。我们提供了一个缺省的划分函数hash.这通常会生成成很好平衡性的划分。然而某些情况，其他的划分函数会更加有效。比如，有些时候输出的keys是URLs,我们希望某个主机的所有项最终都在相同的输出文件中。为了支持这种情况，MapReduce的用户可以指定一个特别的划分函数。比如使用hash(Hostname(urlkey)) mod R作为分区函数，这样所有相同主机的URLs都会在相同的输出文件。 4.2 Ordering GuaranteesWe guarantee that within a given partition, the intermediate key/value pairs are processed in increasing key order. This ordering guarantee makes it easy to generate a sorted output file per partition, which is useful when the output file format needs to support efficient random access lookups by key, or users of the output find it convenient to have the data sorted. 我们保证在一个给定的分区内，中间的k/v pairs按照递增key的顺序处理。这种有序保证了每一个分区生成排序的输出文件变得容易，当输出文件格式需要指出按key随机有效访问，或者需要输出数据有序的时候用户会发现这很方便。 4.3 Combiner FunctionIn some cases, there is significant repetition in the intermediate keys produced by each map task, and the userspecified Reduce function is commutative and associative. A good example of this is the word counting example in Section 2.1. Since word frequencies tend to follow a Zipf distribution, each map task will produce hundreds or thousands of records of the form &lt;the, 1&gt;. All of these counts will be sent over the network to a single reduce task and then added together by the Reduce function to produce one number. We allow the user to specify an optional Combiner function that does partial merging of this data before it is sent over the network. 合并函数某些情况下，每一个map task生成的中间key有大量重复，并且用户指定的reduce函数可进行交换组合。一个好的例子是2.1节的单词统计例子，因为单词频率分布倾向于Zipf分布，每一个map task从&lt;the, 1&gt;中都会生成成百上千个记录。所有这些次数会通过网络发送给一个简单的reduce task，通过一个reduce函数加起来生成一个总数。我们允许用户指定一个可选的Combiner函数，在发送之前进行部分合并。 The Combiner function is executed on each machine that performs a map task. Typically the same code is used to implement both the combiner and the reduce functions. The only difference between a reduce function and a combiner function is how the MapReduce library handles the output of the function. The output of a reduce function is written to the final output file. The output of a combiner function is written to an intermediate file that will be sent to a reduce task. Combiner函数在任意机器上作为map task运行。典型的combiner和reduce函数使用相同的代码实现。Combiner和Reduce函数的区别是MapReduce库如何处理输出数据。MapReduce函数的输出数据写在最终的输出文件。Combiner函数的输出数据写在中间文件然后发送给reduce task. Partial combining significantly speeds up certain classes of MapReduce operations. Appendix A contains an example that uses a combiner. 部分合并能够显著加快各种MapReduce操作。附录A有一个使用combiner的例子。 4.4 Input and Output TypesThe MapReduce library provides support for reading input data in several different formats. For example, “text” mode input treats each line as a key/value pair: the key is the offset in the file and the value is the contents of the line. Another common supported format stores a sequence of key/value pairs sorted by key. Each input type implementation knows how to split itself into meaningful ranges for processing as separate map tasks (e.g. text mode’s range splitting ensures that range splits occur only at line boundaries). Users can add support for a new input type by providing an implementation of a simple reader interface, though most users just use one of a small number of predefined input types. MapReduce库提供了几种不同的格式来读取输入文件。比如，文本模式的输入文件的每一行作为一个k/v pair:key是在文件中的偏移，value是每一行的内容。另一种支持的格式存储了按照key排序的k/v pairs.每一种输入类型都应该知道如何分割为有意义的范围来让每个单独的map task处理(例如，文本模式下范围分割确保在每一行的行边界进行分割)。用户可以通过提供一个简单的读接口来增加新的输入类型，即使大多数用户只使用少数预定义的输入类型。 A reader does not necessarily need to provide data read from a file. For example, it is easy to define a reader that reads records from a database, or from data structures mapped in memory. 一个reader不一定要从文件中读取。比如，一个简单实现的reader可以从数据库，或者映射到内存的数据结构读取。 In a similar fashion, we support a set of output types for producing data in different formats and it is easy foruser code to add support for new output types. 类似的方式，我们支持一组输出类型来生成不同格式的数据，用户编码增加新的输出类型很容易。 4.5 Side-effectsIn some cases, users of MapReduce have found it convenient to produce auxiliary files as additional outputs from their map and/or reduce operators. We rely on the application writer to make such side-effects atomic and idempotent. Typically the application writes to a temporary file and atomically renames this file once it has been fully generated. We do not provide support for atomic two-phase commits of multiple output files produced by a single task. Therefore, tasks that produce multiple output files with cross-file consistency requirements should be deterministic. This restriction has never been an issue in practice. 边界效应某些情况，MapReduce用户发现从他们的map reduce操作生成一些额外的辅助文件很有用。我们依赖应用编写者确保边界效应是原子的和幂等的。通常应用编写者会写到临时文件然后等完整生成的时候进行重命名。我们不支持一个task生成的多个输出文件的自动两阶段提交。因此，生成的多个输出文件的跨文件一致性要求必须是确定性的。这种限制在实践中还没出过问题。 4.6 Skipping Bad RecordsSometimes there are bugs in user code that cause the Map or Reduce functions to crash deterministically on certain records. Such bugs prevent a MapReduce operation from completing. The usual course of action is to fix the bug, but sometimes this is not feasible; perhaps the bug is in a third-party library for which source code is unavailable. Also, sometimes it is acceptable to ignore a few records, for example when doing statistical analysis on a large data set. We provide an optional mode of execution where the MapReduce library detects which records cause deterministic crashes and skips these records in order to make forward progress. 跳过坏记录某些时候，用户代码的bug会在固定的记录上必然的崩溃。这些bug阻止了MapReduce操作的完成。通常的行动方针是修复bug,但有时是不可行的。或许bug来源于第三方库不可读的代码。或者，有时候忽视少数记录也是可接受的，比如统计分析大数据集合的时候。我们提供了一个可选的执行模式当MapReduce库检测到记录会造成确定性的崩溃则跳过这些记录来让程序继续运行。 Each worker process installs a signal handler that catches segmentation violations and bus errors. Before invoking a user Map or Reduce operation, the MapReduce library stores the sequence number of the argument in a global variable. If the user code generates a signal, the signal handler sends a “last gasp” UDP packet that contains the sequence number to the MapReduce master. When the master has seen more than one failure on a particular record, it indicates that the record should be skipped when it issues the next re-execution of the corresponding Map or Reduce task. 每一个worker进程都注册了信号处理函数来捕捉分段错误和bus错误。调用用户map reduce函数之前，MapReduce库在全局变量中存储了参数的顺序。如果用户代码产生了信号，信号处理函数发送包含最终序列号的udp报文给MapReduce主节点。当master发现在特定的记录上出现多次错误，表示当下一次记录重新执行map reduce的时候应该被跳过。 4.7 Local ExecutionDebugging problems in Map or Reduce functions can be tricky, since the actual computation happens in a distributed system, often on several thousand machines, with work assignment decisions made dynamically by the master. To help facilitate debugging, profiling, and small-scale testing, we have developed an alternative implementation of the MapReduce library that sequentially executes all of the work for a MapReduce operation on the local machine. Controls are provided to the user so that the computation can be limited to particular map tasks. Users invoke their program with a special flag and can then easily use any debugging or testing tools they find useful (e.g. gdb). Map Reduce函数的调试问题是棘手的，因为实际的计算发生在分布式系统，通常包括数千台机器，由master动态决定工作的分配。为了便于调试，分析，和小规模测试，我们开发了MapReduce库的另一实现，可在本地机器上顺序执行所有MapReduce操作。提供给用户的控制权使得计算可以被限制在部分的map tasks.用户可以通过特殊的标记调用程序，然后就可以很容易的使用任何他们觉得有用的调试和测试工具(比如gdb) 4.8 Status InformationThe master runs an internal HTTP server and exports a set of status pages for human consumption. The status pages show the progress of the computation, such as how many tasks have been completed, how many are in progress, bytes of input, bytes of intermediate data, bytes of output, processing rates, etc. The pages also contain links to the standard error and standard output files generated by each task. The user can use this data to predict how long the computation will take, and whether or not more resources should be added to the computation. These pages can also be used to figure out when the computation is much slower than expected. master运行一个内部的http服务，可以将状态导出为网页供用户使用。状态页展示了计算的进度，比如已完成的任务数，处理中的任务数，输入数据大小，中间数据的大小，输出数据大小，处理速度等。页面还包含了指向每个task任务的标准错误和标椎输出文件的链接。用户可以使用这些数据预测计算需要多久，是否需要增加更多的计算资源。这些页面也可以被用来计算什么时间计算是低于预期的。 In addition, the top-level status page shows which workers have failed, and which map and reduce tasks they were processing when they failed. This information is useful when attempting to diagnose bugs in the user code. 另外，最高等级的状态页显示了哪些workers失败了，以及失败的时候有哪些map和reduce task在执行。这些信息在你调试用户代码中的Bug时将会很有用。 4.9 CountersThe MapReduce library provides a counter facility to count occurrences of various events. For example, user code may want to count total number of words processed or the number of German documents indexed, etc. MapReduce库提供了一个计数器机制来统计各种事件的发生。比如，用户代码可能希望统计所有被处理的单词的总数或者德语文档索引的总数等。 To use this facility, user code creates a named counter object and then increments the counter appropriately in the Map and/or Reduce function. For example: 要使用这个机制，用户代码需要在Map/Reduce函数创建一个命名的计数器对象然后适当的增加该值。比如： 12345678Counter* uppercase;uppercase &#x3D; GetCounter(&quot;uppercase&quot;);map(String name, String contents): for each word w in contents: if (IsCapitalized(w)): uppercase-&gt;Increment(); EmitIntermediate(w, &quot;1&quot;); The counter values from individual worker machines are periodically propagated to the master (piggybacked on the ping response). The master aggregates the counter values from successful map and reduce tasks and returns them to the user code when the MapReduce operation is completed. The current counter values are also displayed on the master status page so that a human can watch the progress of the live computation. When aggregating counter values, the master eliminates the effects of duplicate executions of the same map or reduce task to avoid double counting. (Duplicate executions can arise from our use of backup tasks and from re-execution of tasks due to failures.) 每个机器的计数值会定期的传播给master(带在ping响应中)。master会汇总成功的map和reduce的计数值并在MapReduce操作成功完成的时候返回给用户代码。这些信息也可以显示在master的状态页中，让用户能够看到实时的计算进展。在汇总这些值的时候，master会消除相同map/reduce重复执行造成的冲突的影响。(冲突会在用户使用备份任务或者任务失败导致的重新执行这些情况下发生) Some counter values are automatically maintained by the MapReduce library, such as the number of input key/value pairs processed and the number of output key/value pairs produced. 一些计数值会由MapReduce库自动维护，比如输入k/v pairs处理的数量，输出的k/v pairs生成的数量。 Users have found the counter facility useful for sanity checking the behavior of MapReduce operations. For example, in some MapReduce operations, the user code may want to ensure that the number of output pairs produced exactly equals the number of input pairs processed, or that the fraction of German documents processed is within some tolerable fraction of the total number of documents processed. 用户发现计数机制对于MapReduce操作的智能检查非常有用。比如，对于一些MapReduce操作，用户代码可能希望生成的输出k/v pairs的数量等于处理的输入的pairs，或者已处理的德语文档的比例在所有已处理文档比例的可接受范围内。 5 PerformanceIn this section we measure the performance of MapReduce on two computations running on a large cluster of machines. One computation searches through approximately one terabyte of data looking for a particular pattern. The other computation sorts approximately one terabyte of data. 这部分我们测试MapReduce运行在大集群中的两种计算能力。一种计算用于查找大约1T大小的数据来寻找特定的模式，另一种计算对大约1T的数据进行排序。 These two programs are representative of a large subset of the real programs written by users of MapReduce – one class of programs shuffles data from one representation to another, and another class extracts a small amount of interesting data from a large data set. 这两种程序是用户编写的MapReduce程序的的代表。– 一种程序将数据从一种表示形式转换成另一种形式，另一种从大的数据集中提取一小部分感兴趣的数据。 5.1 Cluster ConfigurationAll of the programs were executed on a cluster that consisted of approximately 1800 machines. Each machine had two 2GHz Intel Xeon processors with HyperThreading enabled, 4GB of memory, two 160GB IDE disks, and a gigabit Ethernet link. The machines were arranged in a two-level tree-shaped switched network with approximately 100-200 Gbps of aggregate bandwidth available at the root. All of the machines were in the same hosting facility and therefore the round-trip time between any pair of machines was less than a millisecond. 集群配置所有的程序都在大约1800台机器组成的集群上运行。每台机器都有启用了超线程的2GHz的intel xeon处理器，4G内存，两个160g的IDE磁盘，一个千兆的以太网连接。这些机器排列在两层的树形交换机中，根部拥有100-200G的带宽。所有的机器都在相同的托管设施中，任何两台机器的往返时间都在1ms之内。 Out of the 4GB of memory, approximately 1-1.5GB was reserved by other tasks running on the cluster. The programs were executed on a weekend afternoon, when the CPUs, disks, and network were mostly idle. 除了4G内存外，还有1-1.5G的内存保留给了集群上其他的task使用。程序在周末的下午执行，此时cpu,磁盘和网络大多处于闲置状态。 5.2 GrepThe grep program scans through 10^10 100-byte records, searching for a relatively rare three-character pattern (the pattern occurs in 92,337 records). The input is split into approximately 64MB pieces (M = 15000), and the entire output is placed in one file (R = 1). grep程序扫描10^10个100字节的记录，寻找比较罕见的3个字符组成的模式(模式在92337个记录中出现)。输入数据被分为64m左右的块(M=15000), 整个输出都包含在一个文件内(R=1) Figure 2 shows the progress of the computation over time. The Y-axis shows the rate at which the input data is scanned. The rate gradually picks up as more machines are assigned to this MapReduce computation, and peaks at over 30 GB/s when 1764 workers have been assigned. As the map tasks finish, the rate starts dropping and hits zero about 80 seconds into the computation. The entire computation takes approximately 150 seconds from start to finish. This includes about a minute of startup overhead. The overhead is due to the propagation of the program to all worker machines, and delays interacting with GFS to open the set of 1000 input files and to get the information needed for the locality optimization. 图2显示了随着时间推移的计算进度。Y轴是输入数据的扫描速度。随着被分配给MapReduce计算的机器数增多速度开始增高，当被分配1764个workers的时候达到30g/s.等到map tasks完成的时候，速度在80秒内逐渐下降到0.整个计算从开始到结束花费大概150s。这包含了一分钟的启动花销。花销是因为程序在所有机器上的传播，以及和GFS互动而打开的1000个输入文件和为了局部优化获取数据造成的。 5.3 SortThe sort program sorts 10^10 100-byte records (approximately 1 terabyte of data). This program is modeled after the TeraSort benchmark [10]. sort程序对大约1T数据进行排序，该程序模仿了TeraSort benchmark。 The sorting program consists of less than 50 lines of user code. A three-line Map function extracts a 10-byte sorting key from a text line and emits the key and the original text line as the intermediate key/value pair. We used a built-in Identity function as the Reduce operator. This functions passes the intermediate key/value pair unchanged as the output key/value pair. The final sorted output is written to a set of 2-way replicated GFS files (i.e., 2 terabytes are written as the output of the program). 排序程序由不到50行用户代码组成。map函数一共3行，它从文本行中提取排序的key然后发送key和原始的文本行到中间的k/v pairs.我们使用内置的函数实现reduce操作。该函数传递未改动的中间k/v pair作为输出的k/v pair.最终的结果写到一组2路复制的GFS文件中 As before, the input data is split into 64MB pieces (M = 15000). We partition the sorted output into 4000 files (R = 4000). The partitioning function uses the initial bytes of the key to segregate it into one of R pieces. 和前面一样，输入数据被分为64m大小的块。(M=15000) 我们划分有序的输出到4000个文件中(R=4000)。划分函数根据key的首字节将其划分到一个R文件中。 Our partitioning function for this benchmark has builtin knowledge of the distribution of keys. In a general sorting program, we would add a pre-pass MapReduce operation that would collect a sample of the keys and use the distribution of the sampled keys to compute splitpoints for the final sorting pass. 此次测试中我们的划分函数已经内建了key分布的知识。在一般的排序程序中，我们会预先添加MapReduce操作，收集key的样本，并使用key抽样的分布来计算最终输出文件的划分点。 Figure 3 (a) shows the progress of a normal execution of the sort program. The top-left graph shows the rate at which input is read. The rate peaks at about 13 GB/s and dies off fairly quickly since all map tasks finish before 200 seconds have elapsed. Note that the input rate is less than for grep. This is because the sort map tasks spend about half their time and I/O bandwidth writing intermediate output to their local disks. The corresponding intermediate output for grep had negligible size. 图3展示了排序程序正常执行的过程。左上角图显示了输入数据读取的速度。速度高峰的时候达到13g/s然后在200秒快速降下去。注意这里的输入速度远小于grep.因为排序的map任务写中间文件到磁盘花费了一半的时间和I/O带宽。而grep的中间输出数据非常小。 The middle-left graph shows the rate at which data is sent over the network from the map tasks to the reduce tasks. This shuffling starts as soon as the first map task completes. The first hump in the graph is for the first batch of approximately 1700 reduce tasks (the entire MapReduce was assigned about 1700 machines, and each machine executes at most one reduce task at a time). Roughly 300 seconds into the computation, some of these first batch of reduce tasks finish and we start shuffling data for the remaining reduce tasks. All of the shuffling is done about 600 seconds into the computation. 左边中间的图显示了map任务通过网络给reduce任务发送数据的速度。在第一个map任务完成的时候快速变化。图中第一个驼峰是大约1700个reduce任务批量运行的时候(整个MapReduce被分配了1700台机器，每台机器都同时间运行最多一个reduce任务)。计算大概300秒，一些reduce任务已经完成了并开始向其他的reduce任务传递(改组？)数据。所有的传送在600秒结束。 The bottom-left graph shows the rate at which sorted data is written to the final output files by the reduce tasks. There is a delay between the end of the first shuffling period and the start of the writing period because the machines are busy sorting the intermediate data. The writes continue at a rate of about 2-4 GB/s for a while. All of the writes finish about 850 seconds into the computation. Including startup overhead, the entire computation takes 891 seconds. This is similar to the current best reported result of 1057 seconds for the TeraSort benchmark [18]. 左边底部的图显示了reduce任务将排序数据写到最终输出文件的速度。在第一次传输数据和开始写入数据之间有一个延迟，因为这会机器正忙于对中间数据进行排序。写数据保持2-4G/s的速度一段时间。850秒的时候所有写操作结束。算上启动开销，整个计算需要891秒。这和TeraSort报告的最新测试数据1057秒很接近。 A few things to note: the input rate is higher than the shuffle rate and the output rate because of our locality optimization – most data is read from a local disk and bypasses our relatively bandwidth constrained network. The shuffle rate is higher than the output rate because the output phase writes two copies of the sorted data (we make two replicas of the output for reliability and availability reasons). We write two replicas because that is the mechanism for reliability and availability provided by our underlying file system. Network bandwidth requirements for writing data would be reduced if the underlying file system used erasure coding [14] rather than replication. 一些要注意的事：输入数据的速度是高于传输数据和输出数据的因为局部性优化-绕开了带宽受限的网络。传输速度高于输出数据是因为写输出阶段要对排序数据写两份拷贝(我们通过对输出数据写两份拷贝来实现可靠性和可用性)。写两份拷贝是底层文件系统对可靠性和可用性提供的机制。如果底层文件系统使用删除代码而不是复制，写数据的带宽将会降低。 5.4 Effect of Backup TasksIn Figure 3 (b), we show an execution of the sort program with backup tasks disabled. The execution flow is similar to that shown in Figure 3 (a), except that there is a very long tail where hardly any write activity occurs. After 960 seconds, all except 5 of the reduce tasks are completed. However these last few stragglers don’t finish until 300 seconds later. The entire computation takes 1283 seconds, an increase of 44% in elapsed time. 备份任务的影响图3b显示了，禁用备份任务下排序程序的运行。和图3a看起来很相似。除了尾部有非常长的时间几乎没有写操作发生。960秒后，只有5个reduce任务还没有完成。但这几个落后者直到300秒后才全部完成。整个计算花了1283秒，比之前多了44%的时间。 5.5 Machine FailuresIn Figure 3 (c), we show an execution of the sort program where we intentionally killed 200 out of 1746 worker processes several minutes into the computation. The underlying cluster scheduler immediately restarted new worker processes on these machines (since only the processes were killed, the machines were still functioning properly). 机器故障图3c中,显示的是我们故意杀掉1746个工作节点中的200个节点达几分钟时排序程序的执行。底层集群调度器马上在这些机器上重启了新的工作节点。(进程被杀掉了，机器还在正常运行) The worker deaths show up as a negative input rate since some previously completed map work disappears (since the corresponding map workers were killed) and needs to be redone. The re-execution of this map work happens relatively quickly. The entire computation finishes in 933 seconds including startup overhead (just an increase of 5% over the normal execution time). 工作节点挂掉显示为负的输入速度，因为之前已经完成的一些map任务消失了(相应的工作节点被杀掉了)需要重新完成。重新执行这些map任务会很快发生。整个计算过程包含启动开销一共花了933秒(只比正常的执行时间多了5%) 6 ExperienceWe wrote the first version of the MapReduce library in February of 2003, and made significant enhancements to it in August of 2003, including the locality optimization, dynamic load balancing of task execution across worker machines, etc. Since that time, we have been pleasantly surprised at how broadly applicable the MapReduce library has been for the kinds of problems we work on.It has been used across a wide range of domains within Google, including: large-scale machine learning problems, clustering problems for the Google News and Froogle products, extraction of data used to produce reports of popular queries (e.g. Google Zeitgeist), extraction of properties of web pages for new experiments and products (e.g. extraction of geographical locations from a large corpus of web pages for localized search), and large-scale graph computations. https://blog-1254238374.cos.ap-hongkong.myqcloud.com/blog/Snipaste_2021-01-21_14-42-41.jpg Figure 4 shows the significant growth in the number of separate MapReduce programs checked into our primary source code management system over time, from 0 in early 2003 to almost 900 separate instances as of late September 2004. MapReduce has been so successful because it makes it possible to write a simple program and run it efficiently on a thousand machines in the course of half an hour, greatly speeding up the development and prototyping cycle. Furthermore, it allows programmers who have no experience with distributed and/or parallel systems to exploit large amounts of resources easily. At the end of each job, the MapReduce library logs statistics about the computational resources used by the job. In Table 1, we show some statistics for a subset of MapReduce jobs run at Google in August 2004. 经验 6.1 Large-Scale IndexingOne of our most significant uses of MapReduce to date has been a complete rewrite of the production indexing system that produces the data structures used for the Google web search service. The indexing system takes as input a large set of documents that have been retrieved by our crawling system, stored as a set of GFS files. The raw contents for these documents are more than 20 terabytes of data. The indexing process runs as a sequence of five to ten MapReduce operations. Using MapReduce (instead of the ad-hoc distributed passes in the prior version of the indexing system) has provided several benefits: 大规模索引我们对于MapReduce的最重要的一个使用是完全重写了生产环境索引系统，它用来生成谷歌网络搜索服务需要的数据结构。索引系统以我们爬取系统抓取的很多文档集合作为输入，存储为一组GFS文件。这些文件中的原始内容超过20Tb.索引系统以5-20个MapReduce程序运行。使用MapReduce(而不是老版本索引系统中的ad-hoc)带来了几点好处： The indexing code is simpler, smaller, and easier to understand, because the code that deals with fault tolerance, distribution and parallelization is hidden within the MapReduce library. For example, the size of one phase of the computation dropped from approximately 3800 lines of C++ code to approximately 700 lines when expressed using MapReduce. 索引代码简单，代码量小，容易理解，因为处理容错，分布式和并行化的代码隐藏在了MapReduce的库里面。比如，其中一个阶段的计算在使用了MapReduce后代码量从3800行C++代码降低到只需要700行。 The performance of the MapReduce library is good enough that we can keep conceptually unrelated computations separate, instead of mixing them together to avoid extra passes over the data. This makes it easy to change the indexing process. For example, one change that took a few months to make in our old indexing system took only a few days to implement in the new system. MapReduce的性能足够好，我们可以把概念上无关的计算分离，而不需要为了避免额外传输数据将其混杂在一起。这让修改索引进程变得容易，以前修改老的索引系统需要几个月的时间，而在现在新实现的索引系统上只需要几天时间。 The indexing process has become much easier to operate, because most of the problems caused by machine failures, slow machines, and networking hiccups are dealt with automatically by the MapReduce library without operator intervention. Furthermore, it is easy to improve the performance of the indexing process by adding new machines to the indexing cluster. 索引系统更容易去操作，因为大多数机器故障，机器执行缓慢，网络中断问题都可以由MapReduce库自动处理而不需要额外介入。此外，通过增加集群中的机器数可以很容易的提高索引进程的性能。 7 Related WorkMany systems have provided restricted programming models and used the restrictions to parallelize the computation automatically. For example, an associative function can be computed over all prefixes of an N element array in log N time on N processors using parallel prefix computations [6, 9, 13]. MapReduce can be considered a simplification and distillation of some of these modelsbased on our experience with large real-world computations. More significantly, we provide a fault-tolerant implementation that scales to thousands of processors. In contrast, most of the parallel processing systems have only been implemented on smaller scales and leave the details of handling machine failures to the programmer. Bulk Synchronous Programming [17] and some MPI primitives [11] provide higher-level abstractions that make it easier for programmers to write parallel programs. A key difference between these systems and MapReduce is that MapReduce exploits a restricted programming model to parallelize the user program automatically and to provide transparent fault-tolerance. Our locality optimization draws its inspiration from techniques such as active disks [12, 15], where computation is pushed into processing elements that are close to local disks, to reduce the amount of data sent across I/O subsystems or the network. We run on commodity processors to which a small number of disks are directly connected instead of running directly on disk controllerprocessors, but the general approach is similar. Our backup task mechanism is similar to the eager scheduling mechanism employed in the Charlotte System [3]. One of the shortcomings of simple eager scheduling is that if a given task causes repeated failures, the entire computation fails to complete. We fix some instances of this problem with our mechanism for skipping bad records. The MapReduce implementation relies on an in-house cluster management system that is responsible for distributing and running user tasks on a large collection of shared machines. Though not the focus of this paper, the cluster management system is similar in spirit to other systems such as Condor [16]. The sorting facility that is a part of the MapReduce library is similar in operation to NOW-Sort [1]. Source machines (map workers) partition the data to be sorted and send it to one of R reduce workers. Each reduce worker sorts its data locally (in memory if possible). Of course NOW-Sort does not have the user-definable Map and Reduce functions that make our library widely applicable. River [2] provides a programming model where processes communicate with each other by sending data over distributed queues. Like MapReduce, the River system tries to provide good average case performance even in the presence of non-uniformities introduced byheterogeneous hardware or system perturbations. River achieves this by careful scheduling of disk and networktransfers to achieve balanced completion times. MapReduce has a different approach. By restricting the programming model, the MapReduce framework is able to partition the problem into a large number of finegrained tasks. These tasks are dynamically scheduledon available workers so that faster workers process more tasks. The restricted programming model also allows us to schedule redundant executions of tasks near the end of the job which greatly reduces completion time in the presence of non-uniformities (such as slow or stuck workers). BAD-FS [5] has a very different programming model from MapReduce, and unlike MapReduce, is targeted to the execution of jobs across a wide-area network. However, there are two fundamental similarities. (1) Both systems use redundant execution to recover from data loss caused by failures. (2) Both use locality-aware scheduling to reduce the amount of data sent across congested network links. TACC [7] is a system designed to simplify construction of highly-available networked services. Like MapReduce, it relies on re-execution as a mechanism for implementing fault-tolerance. 相关工作… 8 ConclusionsThe MapReduce programming model has been successfully used at Google for many different purposes. We attribute this success to several reasons. First, the model is easy to use, even for programmers without experience with parallel and distributed systems, since it hides the details of parallelization, fault-tolerance, locality optimization, and load balancing. Second, a large variety of problems are easily expressible as MapReduce computations. For example, MapReduce is used for the generation of data for Google’s production web search service, for sorting, for data mining, for machine learning, and many other systems. Third, we have developed an implementation of MapReduce that scales to large clusters of machines comprising thousands of machines. The implementation makes efficient use of these machine resources and therefore is suitable for use on many of the large computational problems encountered at Google. 结论MapReduce编程模型在谷歌内部已经成功的用于很多不同的用途。我们将其成功归结于几个方面。首先，该模型易于使用，即使对于没有并行和分布式经验的程序员，因为模型隐藏了并行化，容错，局部优化和负载均衡的细节。其次，很多种类的问题都可以方便的表示为MapReduce模型。比如，MapReduce被用于谷歌网络搜索服务的数据生成，排序，数据挖掘，和用于机器学习以及其他的系统。第三，我们已经开发了MapReduce的实现，可以扩展到数千台机器组成的大规模集群中。该实现可以高效利用机器资源，因此适用于谷歌遇到的的许多大的计算问题。 We have learned several things from this work. First, restricting the programming model makes it easy to parallelize and distribute computations and to make such computations fault-tolerant. Second, network bandwidth is a scarce resource. A number of optimizations in our system are therefore targeted at reducing the amount of data sent across the network: the locality optimization allows us to read data from local disks, and writing a single copy of the intermediate data to local disk saves network bandwidth. Third, redundant execution can be used to reduce the impact of slow machines, and to handle machine failures and data loss. 从这项工作中我们学到了一些东西。首先，约束编程模型使得并行以及分布式计算，以及计算容错，变得简单。其次，网络带宽是稀缺资源。我们系统因此针对通过网络传输大量数据做了一些优化：局部性优化允许我们从本地磁盘读取数据，写一份中间数据到本地磁盘也节省了带宽。第三，冗余执行可以降低慢机器造成的影响，以及处理机器故障和数据丢失。 AcknowledgementsJosh Levenberg has been instrumental in revising and extending the user-level MapReduce API with a number of new features based on his experience with using MapReduce and other people’s suggestions for enhancements. MapReduce reads its input from and writes its output to the Google File System [8]. We would like to thank Mohit Aron, Howard Gobioff, Markus Gutschke, David Kramer, Shun-Tak Leung, and Josh Redstone for their work in developing GFS. We would also like to thank Percy Liang and Olcan Sercinoglu for their work in developing the cluster management system used by MapReduce. Mike Burrows, Wilson Hsieh, Josh Levenberg, Sharon Perl, Rob Pike, and Debby Wallach provided helpful comments on earlier drafts of this paper. The anonymous OSDI reviewers, and our shepherd, Eric Brewer, provided many useful suggestions of areas where the paper could be improved. Finally, we thank all the users of MapReduce within Google’s engineering organization for providing helpful feedback, suggestions, and bug reports. 致谢… References[1] Andrea C. Arpaci-Dusseau, Remzi H. Arpaci-Dusseau, David E. Culler, Joseph M. Hellerstein, and David A. Patterson. High-performance sorting on networks of workstations. In Proceedings of the 1997 ACM SIGMOD International Conference on Management of Data, Tucson, Arizona, May 1997. [2] Remzi H. Arpaci-Dusseau, Eric Anderson, Noah Treuhaft, David E. Culler, Joseph M. Hellerstein, David Patterson, and Kathy Yelick. Cluster I/O with River: Making the fast case common. In Proceedings of the Sixth Workshop on Input/Output in Parallel and DistributedSystems (IOPADS ’99), pages 10–22, Atlanta, Georgia, May 1999. [3] Arash Baratloo, Mehmet Karaul, Zvi Kedem, and Peter Wyckoff. Charlotte: Metacomputing on the web. In Proceedings of the 9th International Conference on Parallel and Distributed Computing Systems, 1996. [4] Luiz A. Barroso, Jeffrey Dean, and Urs Holzle. ¨ Web search for a planet: The Google cluster architecture. IEEE Micro, 23(2):22–28, April 2003. [5] John Bent, Douglas Thain, Andrea C.Arpaci-Dusseau, Remzi H. Arpaci-Dusseau, and Miron Livny. Explicit control in a batch-aware distributed file system. In Proceedings of the 1st USENIX Symposium on Networked Systems Design and Implementation NSDI, March 2004. [6] Guy E. Blelloch. Scans as primitive parallel operations. IEEE Transactions on Computers, C-38(11), November [7] Armando Fox, Steven D. Gribble, Yatin Chawathe, Eric A. Brewer, and Paul Gauthier. Cluster-based scalable network services. In Proceedings of the 16th ACM Symposium on Operating System Principles, pages 78– 91, Saint-Malo, France, 1997. [8] Sanjay Ghemawat, Howard Gobioff, and Shun-Tak Leung. The Google file system. In 19th Symposium on Operating Systems Principles, pages 29–43, Lake George, New York, 2003. [9] S. Gorlatch. Systematic efficient parallelization of scan and other list homomorphisms. In L. Bouge, P. Fraigniaud, A. Mignotte, and Y. Robert, editors, Euro-Par’96. Parallel Processing, Lecture Notes in Computer Science 1124, pages 401–408. Springer-Verlag, 1996. [10] Jim Gray. Sort benchmark home page. http://research.microsoft.com/barc/SortBenchmark/. [11] William Gropp, Ewing Lusk, and Anthony Skjellum. Using MPI: Portable Parallel Programming with the Message-Passing Interface. MIT Press, Cambridge, MA, [12] L. Huston, R. Sukthankar, R. Wickremesinghe, M. Satyanarayanan, G. R. Ganger, E. Riedel, and A. Ailamaki. Diamond: A storage architecture for early discard in interactive search. In Proceedings of the 2004 USENIX File and Storage Technologies FAST Conference, April 2004. [13] Richard E. Ladner and Michael J. Fischer. Parallel prefix computation. Journal of the ACM, 27(4):831–838, 1980. [14] Michael O. Rabin. Efficient dispersal of information for security, load balancing and fault tolerance. Journal ofthe ACM, 36(2):335–348, 1989. [15] Erik Riedel, Christos Faloutsos, Garth A. Gibson, and David Nagle. Active disks for large-scale data processing. IEEE Computer, pages 68–74, June 2001. [16] Douglas Thain, Todd Tannenbaum, and Miron Livny. Distributed computing in practice: The Condor experience. Concurrency and Computation: Practice and Experience, 2004. [17] L. G. Valiant. A bridging model for parallel computation. Communications of the ACM, 33(8):103–111, 1997. [18] Jim Wyllie. Spsort: How to sort a terabyte quickly. http://alme1.almaden.ibm.com/cs/spsort.pdf. A Word FrequencyThis section contains a program that counts the number of occurrences of each unique word in a set of input files specified on the command line. 这部分是一个统计由命令行指定的输入文件集合中每一个唯一的单词出现次数的统计程序。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182#include &quot;mapreduce/mapreduce.h&quot;// User’s map functionclass WordCounter : public Mapper &#123;public: virtual void Map(const MapInput&amp; input) &#123; const string&amp; text = input.value(); const int n = text.size(); for (int i = 0; i &lt; n; ) &#123; // Skip past leading whitespace while ((i &lt; n) &amp;&amp; isspace(text[i])) i++; // Find word end int start = i; while ((i &lt; n) &amp;&amp; !isspace(text[i])) i++; if (start &lt; i) Emit(text.substr(start,i-start),&quot;1&quot;); &#125; &#125;&#125;;REGISTER_MAPPER(WordCounter);// User’s reduce functionclass Adder : public Reducer &#123; virtual void Reduce(ReduceInput* input) &#123; // Iterate over all entries with the // same key and add the values int64 value = 0; while (!input-&gt;done()) &#123; value += StringToInt(input-&gt;value()); input-&gt;NextValue(); &#125; // Emit sum for input-&gt;key() Emit(IntToString(value));&#125;&#125;;REGISTER_REDUCER(Adder);int main(int argc, char** argv) &#123; ParseCommandLineFlags(argc, argv); MapReduceSpecification spec; // Store list of input files into &quot;spec&quot; for (int i = 1; i &lt; argc; i++) &#123; MapReduceInput* input = spec.add_input(); input-&gt;set_format(&quot;text&quot;); input-&gt;set_filepattern(argv[i]); input-&gt;set_mapper_class(&quot;WordCounter&quot;); &#125; // Specify the output files: // /gfs/test/freq-00000-of-00100 // /gfs/test/freq-00001-of-00100 // ... MapReduceOutput* out = spec.output(); out-&gt;set_filebase(&quot;/gfs/test/freq&quot;); out-&gt;set_num_tasks(100); out-&gt;set_format(&quot;text&quot;); out-&gt;set_reducer_class(&quot;Adder&quot;); // Optional: do partial sums within map // tasks to save network bandwidth out-&gt;set_combiner_class(&quot;Adder&quot;); // Tuning parameters: use at most 2000 // machines and 100 MB of memory per task spec.set_machines(2000); spec.set_map_megabytes(100); spec.set_reduce_megabytes(100); // Now run it MapReduceResult result; if (!MapReduce(spec, &amp;result)) abort(); // Done: ’result’ structure contains info // about counters, time taken, number of // machines used, etc. return 0;&#125; 参考https://www.bbsmax.com/A/KE5Q0Nq3JL/","categories":[],"tags":[],"keywords":[]},{"title":"hash in redis","slug":"2020-11-07-hash in redis","date":"2020-11-07T00:00:00.000Z","updated":"2022-09-12T16:24:32.289Z","comments":true,"path":"2020-11-07-hash in redis/","link":"","permalink":"https://riverferry.site/2020-11-07-hash%20in%20redis/","excerpt":"以前整理过一篇hash,后来git rebase不小心给丢了，重新补一下，part1是基础概念，part2是redis里面的字典实现，对照分析","text":"以前整理过一篇hash,后来git rebase不小心给丢了，重新补一下，part1是基础概念，part2是redis里面的字典实现，对照分析 part1 hash 哈希函数加密函数 可用于数据加密，比如vpn代理传输就常见aes。其他加密函数:md5,sha 唯一标识 数据校验 利用哈希函数相同的key hash后的值是相同的这一特性可用于作为元素的唯一标识，比如Md5标记一个版本，文件。 散列函数 java中hashmap的散列函数 1234567891011121314151617int hash(Object key) &#123; int h = key.hashCode()； //无符号右移 return (h ^ (h &gt;&gt;&gt; 16)) &amp; (capitity -1); //capicity 表示散列表的大小&#125;public int hashCode() &#123; int var1 = this.hash; if(var1 == 0 &amp;&amp; this.value.length &gt; 0) &#123; char[] var2 = this.value; for(int var3 = 0; var3 &lt; this.value.length; ++var3) &#123; var1 = 31 * var1 + var2[var3]; &#125; this.hash = var1; &#125; return var1;&#125; hashcode就是对字符进行进制计算得到整数。hash函数生成对应桶的索引。h是int,32位，这里右移16位然后异或是为了更加随机吧左右参合在一起增加点随机性()，然后桶的大小是2的倍数，所以capitity-1就是桶的大小，&amp;就类似%，效率更高。 负载均衡 利用hash函数的随机性和唯一性去映射一个端，作为负载均衡的策略。 一致性哈希就是用一个环来让扩容或者恢复影响变小，可以参考这篇文章：一致性哈希算法的理解与实践以后有时间单独分析下。 装载因子装载因子=哈希表的元素个数/桶的大小 如果是开放寻址法，装载因子要小于1 拉链法装载因子大于1很正常，也不宜太大 java中hashmap的装载因子是0.75 可以用红黑树(java hashmap中链表长度大于n就用红黑树，小于m退化成链表)或者跳表去拉链，避免链表过长效率太低。 散列冲突开放寻址法 易序列化，利于cpu缓存删除麻烦，冲突代价高，装载因子不能太大浪费时间&lt;1 拉链法 装载因子高&gt;10也ok，额外存放指针对小对象来说就有点浪费内存,cpu不友好 扩容迁移装载因子过大的时候就要考虑扩容了，一般都是扩成原来的2倍大小。像redis本来就是2个ht.扩容就是给ht[1]申请空间，赋地址。然后慢慢迁移。 分批次迁移,redis里面增删改查操作都会让rehash右移一个桶，这样慢慢迁移。并且还有定时函数(这部分就不看了)处理，保证在没有操作的时候，迁移也会进行。 LRU 缓存淘汰算法Lru缓存淘汰可以用双链表实现，但是双链表查找是O(n),速度太慢了，可以将hash和双链表结合起来实现。 part2 redis dict struct1234567891011121314151617181920212223242526272829303132333435363738typedef struct dict &#123; dictType *type; void *privdata; dictht ht[2]; long rehashidx; /* rehashing not in progress if rehashidx == -1 */ unsigned long iterators; /* number of iterators currently running */&#125; dict;//函数指针typedef struct dictType &#123; uint64_t (*hashFunction)(const void *key); void *(*keyDup)(void *privdata, const void *key); void *(*valDup)(void *privdata, const void *obj); int (*keyCompare)(void *privdata, const void *key1, const void *key2); void (*keyDestructor)(void *privdata, void *key); void (*valDestructor)(void *privdata, void *obj);&#125; dictType;//哈希表结构，新旧各一个/* This is our hash table structure. Every dictionary has two of this as we * implement incremental rehashing, for the old to the new table. */typedef struct dictht &#123; dictEntry **table; unsigned long size; unsigned long sizemask; //size-1 unsigned long used;&#125; dictht;typedef struct dictEntry &#123; void *key; union &#123; void *val; uint64_t u64; int64_t s64; double d; &#125; v; struct dictEntry *next;&#125; dictEntry; 创建1234567891011121314151617181920212223242526272829303132/* Create a new hash table */dict *dictCreate(dictType *type, void *privDataPtr)&#123; dict *d = zmalloc(sizeof(*d)); _dictInit(d,type,privDataPtr); return d;&#125;/* Initialize the hash table */int _dictInit(dict *d, dictType *type, void *privDataPtr)&#123; _dictReset(&amp;d-&gt;ht[0]); _dictReset(&amp;d-&gt;ht[1]); d-&gt;type = type; d-&gt;privdata = privDataPtr; d-&gt;rehashidx = -1; d-&gt;iterators = 0; return DICT_OK;&#125;/* Reset a hash table already initialized with ht_init(). * NOTE: This function should only be called by ht_destroy(). */static void _dictReset(dictht *ht)&#123; ht-&gt;table = NULL; ht-&gt;size = 0; ht-&gt;sizemask = 0; ht-&gt;used = 0;&#125; 比较简单，没啥说的 添加123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111/* Add an element to the target hash table */int dictAdd(dict *d, void *key, void *val)&#123; dictEntry *entry = dictAddRaw(d,key,NULL); if (!entry) return DICT_ERR; dictSetVal(d, entry, val); return DICT_OK;&#125;/* Low level add or find: * This function adds the entry but instead of setting a value returns the * dictEntry structure to the user, that will make sure to fill the value * field as he wishes. * * This function is also directly exposed to the user API to be called * mainly in order to store non-pointers inside the hash value, example: * * entry = dictAddRaw(dict,mykey,NULL); * if (entry != NULL) dictSetSignedIntegerVal(entry,1000); * * Return values: * * If key already exists NULL is returned, and &quot;*existing&quot; is populated * with the existing entry if existing is not NULL. * * If key was added, the hash entry is returned to be manipulated by the caller. */dictEntry *dictAddRaw(dict *d, void *key, dictEntry **existing)&#123; long index; dictEntry *entry; dictht *ht; //rehash未完成，添加的时候step一步 分批次迁移 if (dictIsRehashing(d)) _dictRehashStep(d); /* Get the index of the new element, or -1 if * the element already exists. */ //计算桶的索引，如果key已经存在了返回-1，冲突的情况不返回-1 if ((index = _dictKeyIndex(d, key, dictHashKey(d,key), existing)) == -1) return NULL; /* Allocate the memory and store the new entry. * Insert the element in top, with the assumption that in a database * system it is more likely that recently added entries are accessed * more frequently. */ ht = dictIsRehashing(d) ? &amp;d-&gt;ht[1] : &amp;d-&gt;ht[0]; entry = zmalloc(sizeof(*entry)); //如果没有冲突，则next指向的是Null,否则指向的是原来的头结点 entry-&gt;next = ht-&gt;table[index]; ht-&gt;table[index] = entry; ht-&gt;used++; /* Set the hash entry fields. */ dictSetKey(d, entry, key); return entry;&#125;/* This function performs just a step of rehashing, and only if there are * no safe iterators bound to our hash table. When we have iterators in the * middle of a rehashing we can&#x27;t mess with the two hash tables otherwise * some element can be missed or duplicated. * * This function is called by common lookup or update operations in the * dictionary so that the hash table automatically migrates from H1 to H2 * while it is actively used. */static void _dictRehashStep(dict *d) &#123; if (d-&gt;iterators == 0) dictRehash(d,1);&#125;/* Returns the index of a free slot that can be populated with * a hash entry for the given &#x27;key&#x27;. * If the key already exists, -1 is returned * and the optional output parameter may be filled. * * Note that if we are in the process of rehashing the hash table, the * index is always returned in the context of the second (new) hash table. */static long _dictKeyIndex(dict *d, const void *key, uint64_t hash, dictEntry **existing)&#123; unsigned long idx, table; dictEntry *he; if (existing) *existing = NULL; /* Expand the hash table if needed */ if (_dictExpandIfNeeded(d) == DICT_ERR) return -1; for (table = 0; table &lt;= 1; table++) &#123; idx = hash &amp; d-&gt;ht[table].sizemask; /* Search if this slot does not already contain the given key */ he = d-&gt;ht[table].table[idx]; while(he) &#123; if (key==he-&gt;key || dictCompareKeys(d, key, he-&gt;key)) &#123; if (existing) *existing = he; return -1; &#125; he = he-&gt;next; &#125; if (!dictIsRehashing(d)) break; &#125; return idx;&#125;#define dictSetKey(d, entry, _key_) do &#123; \\ if ((d)-&gt;type-&gt;keyDup) \\ (entry)-&gt;key = (d)-&gt;type-&gt;keyDup((d)-&gt;privdata, _key_); \\ else \\ (entry)-&gt;key = (_key_); \\&#125; while(0) dictAddRaw _dictKeyIndex _dictExpandIfNeeded插入的时候会判断是否需要扩容 扩容1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556/* Expand the hash table if needed */static int _dictExpandIfNeeded(dict *d)&#123; /* Incremental rehashing already in progress. Return. */ if (dictIsRehashing(d)) return DICT_OK; /* If the hash table is empty expand it to the initial size. */ if (d-&gt;ht[0].size == 0) return dictExpand(d, DICT_HT_INITIAL_SIZE); /* If we reached the 1:1 ratio, and we are allowed to resize the hash * table (global setting) or we should avoid it but the ratio between * elements/buckets is over the &quot;safe&quot; threshold, we resize doubling * the number of buckets. */ //因为是链表法所以装载因子比较大 dict_force_resize_ratio=5 if (d-&gt;ht[0].used &gt;= d-&gt;ht[0].size &amp;&amp; (dict_can_resize || d-&gt;ht[0].used/d-&gt;ht[0].size &gt; dict_force_resize_ratio)) &#123; return dictExpand(d, d-&gt;ht[0].used*2); &#125; return DICT_OK;&#125;/* Expand or create the hash table */int dictExpand(dict *d, unsigned long size)&#123; /* the size is invalid if it is smaller than the number of * elements already inside the hash table */ if (dictIsRehashing(d) || d-&gt;ht[0].used &gt; size) return DICT_ERR; dictht n; /* the new hash table */ //基于初始化大小，每次2倍增长 unsigned long realsize = _dictNextPower(size); /* Rehashing to the same table size is not useful. */ if (realsize == d-&gt;ht[0].size) return DICT_ERR; /* Allocate the new hash table and initialize all pointers to NULL */ n.size = realsize; n.sizemask = realsize-1; //2的倍数，可以进制取模 n.table = zcalloc(realsize*sizeof(dictEntry*)); n.used = 0; /* Is this the first initialization? If so it&#x27;s not really a rehashing * we just set the first hash table so that it can accept keys. */ if (d-&gt;ht[0].table == NULL) &#123; d-&gt;ht[0] = n; return DICT_OK; &#125; /* Prepare a second hash table for incremental rehashing */ d-&gt;ht[1] = n; d-&gt;rehashidx = 0; return DICT_OK;&#125; 缩容12345678910111213141516171819202122int htNeedsResize(dict *dict) &#123; long long size, used; size = dictSlots(dict); used = dictSize(dict); //DICT_HT_INITIAL_SIZE=4 HASHTABLE_MIN_FILL=10 return (size &gt; DICT_HT_INITIAL_SIZE &amp;&amp; (used*100/size &lt; HASHTABLE_MIN_FILL));&#125;/* Resize the table to the minimal size that contains all the elements, * but with the invariant of a USED/BUCKETS ratio near to &lt;= 1 */int dictResize(dict *d)&#123; int minimal; if (!dict_can_resize || dictIsRehashing(d)) return DICT_ERR; minimal = d-&gt;ht[0].used; if (minimal &lt; DICT_HT_INITIAL_SIZE) minimal = DICT_HT_INITIAL_SIZE; return dictExpand(d, minimal);&#125; size&gt;DICT_HT_INITIAL_SIZE说明已经扩容过，并且装载因子也小于0.1的话，就缩容 查找1234567891011121314151617181920212223dictEntry *dictFind(dict *d, const void *key)&#123; dictEntry *he; uint64_t h, idx, table; //新旧哈希表都为空 if (d-&gt;ht[0].used + d-&gt;ht[1].used == 0) return NULL; /* dict is empty */ if (dictIsRehashing(d)) _dictRehashStep(d); //哈希函数计算 h = dictHashKey(d, key); for (table = 0; table &lt;= 1; table++) &#123; //取模，计算插入的桶的索引 idx = h &amp; d-&gt;ht[table].sizemask; he = d-&gt;ht[table].table[idx]; while(he) &#123; if (key==he-&gt;key || dictCompareKeys(d, key, he-&gt;key)) return he; he = he-&gt;next; &#125; if (!dictIsRehashing(d)) return NULL; &#125; return NULL;&#125; 迁移1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556/* Performs N steps of incremental rehashing. Returns 1 if there are still * keys to move from the old to the new hash table, otherwise 0 is returned. * * Note that a rehashing step consists in moving a bucket (that may have more * than one key as we use chaining) from the old to the new hash table, however * since part of the hash table may be composed of empty spaces, it is not * guaranteed that this function will rehash even a single bucket, since it * will visit at max N*10 empty buckets in total, otherwise the amount of * work it does would be unbound and the function may block for a long time. */int dictRehash(dict *d, int n) &#123; int empty_visits = n*10; /* Max number of empty buckets to visit. */ if (!dictIsRehashing(d)) return 0; while(n-- &amp;&amp; d-&gt;ht[0].used != 0) &#123; dictEntry *de, *nextde; /* Note that rehashidx can&#x27;t overflow as we are sure there are more * elements because ht[0].used != 0 */ assert(d-&gt;ht[0].size &gt; (unsigned long)d-&gt;rehashidx); while(d-&gt;ht[0].table[d-&gt;rehashidx] == NULL) &#123; d-&gt;rehashidx++; if (--empty_visits == 0) return 1; &#125; de = d-&gt;ht[0].table[d-&gt;rehashidx]; /* Move all the keys in this bucket from the old to the new hash HT */ while(de) &#123; uint64_t h; nextde = de-&gt;next; /* Get the index in the new hash table */ h = dictHashKey(d, de-&gt;key) &amp; d-&gt;ht[1].sizemask; //头插法 de-&gt;next = d-&gt;ht[1].table[h]; d-&gt;ht[1].table[h] = de; d-&gt;ht[0].used--; d-&gt;ht[1].used++; de = nextde; &#125; d-&gt;ht[0].table[d-&gt;rehashidx] = NULL; d-&gt;rehashidx++; &#125; //所有桶都迁移完成了 /* Check if we already rehashed the whole table... */ if (d-&gt;ht[0].used == 0) &#123; zfree(d-&gt;ht[0].table); d-&gt;ht[0] = d-&gt;ht[1]; _dictReset(&amp;d-&gt;ht[1]); d-&gt;rehashidx = -1; return 0; &#125; /* More to rehash... */ return 1;&#125; rehashidx是ht[0]迁移的桶的索引，进度。dictRehash函数的参数n是一次rehash需要迁移几个桶，链表的所有节点都一次迁移掉。 删除123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/* Remove an element, returning DICT_OK on success or DICT_ERR if the * element was not found. */int dictDelete(dict *ht, const void *key) &#123; return dictGenericDelete(ht,key,0) ? DICT_OK : DICT_ERR;&#125;/* Search and remove an element. This is an helper function for * dictDelete() and dictUnlink(), please check the top comment * of those functions. */static dictEntry *dictGenericDelete(dict *d, const void *key, int nofree) &#123; uint64_t h, idx; dictEntry *he, *prevHe; int table; if (d-&gt;ht[0].used == 0 &amp;&amp; d-&gt;ht[1].used == 0) return NULL; //删除也rehash一个桶 if (dictIsRehashing(d)) _dictRehashStep(d); h = dictHashKey(d, key); for (table = 0; table &lt;= 1; table++) &#123; idx = h &amp; d-&gt;ht[table].sizemask; he = d-&gt;ht[table].table[idx]; //单链表的删除 prevHe = NULL; while(he) &#123; if (key==he-&gt;key || dictCompareKeys(d, key, he-&gt;key)) &#123; /* Unlink the element from the list */ if (prevHe) prevHe-&gt;next = he-&gt;next; else d-&gt;ht[table].table[idx] = he-&gt;next; if (!nofree) &#123; dictFreeKey(d, he); dictFreeVal(d, he); zfree(he); &#125; d-&gt;ht[table].used--; return he; &#125; prevHe = he; he = he-&gt;next; &#125; if (!dictIsRehashing(d)) break; &#125; return NULL; /* not found */&#125; 更新12345678910111213141516171819202122232425262728/* Add or Overwrite: * Add an element, discarding the old value if the key already exists. * Return 1 if the key was added from scratch, 0 if there was already an * element with such key and dictReplace() just performed a value update * operation. */int dictReplace(dict *d, void *key, void *val)&#123; dictEntry *entry, *existing, auxentry; /* Try to add the element. If the key * does not exists dictAdd will succeed. */ entry = dictAddRaw(d,key,&amp;existing); if (entry) &#123; dictSetVal(d, entry, val); return 1; &#125; /* Set the new value and free the old one. Note that it is important * to do that in this order, as the value may just be exactly the same * as the previous one. In this context, think to reference counting, * you want to increment (set), and then decrement (free), and not the * reverse. */ auxentry = *existing; dictSetVal(d, existing, val); dictFreeVal(d, &amp;auxentry); return 0;&#125; 链表存的是地址，auxentry是原始数据，需要删掉。新的数据还在原来的位置existing插入。","categories":[],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://riverferry.site/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"redis","slug":"redis","permalink":"https://riverferry.site/tags/redis/"}],"keywords":[]},{"title":"redis sorted set","slug":"2020-11-06-redis-sorted-set","date":"2020-11-06T00:00:00.000Z","updated":"2022-09-12T16:24:32.288Z","comments":true,"path":"2020-11-06-redis-sorted-set/","link":"","permalink":"https://riverferry.site/2020-11-06-redis-sorted-set/","excerpt":"redis有序结合的命令部分熟悉","text":"redis有序结合的命令部分熟悉 BZPOPMAX BZPOPMAX key [key …] timeout 12345678910111213127.0.0.1:6379&gt; bzpopmax set2 set3 1 &#x2F;&#x2F;阻塞1s后返回nil(nil)(1.02s)127.0.0.1:6379&gt; bzpopmax set2 set3 0 &#x2F;&#x2F;set2和set3都是empty,timeout&#x3D;0永久阻塞 ^C127.0.0.1:6379&gt; bzpopmax set0 set1 0 &#x2F;&#x2F;set0和set1都是非空，返回set0的第一个max元素1) &quot;set0&quot;2) &quot;b&quot;3) &quot;20&quot;127.0.0.1:6379&gt; bzpopmax set2 set1 0 &#x2F;&#x2F;set2是空，set1非空，返回非空的set11) &quot;set1&quot;2) &quot;a&quot;3) &quot;1&quot; BZPOPMIN同上，一个最大一个最小 ZADDoptions XX 只更新已存在的成员，不新增 NX 不更新已经存在的成员，总是新增 LT 如果新的分数比原来的小则更新，不新增 //ver&gt;=6.2: Added the GT and LT options. GT 如果新的分数比原来的大则更新，不新增 //ver&gt;=6.2: Added the GT and LT options. CH 修改返回值为发生变化的成员个数(区别原来是返回新增的成员个数) INCR 类似ZINCRBY命令，增加成员的分数，只能增加一个成员 return value 默认返回新增的成员数量，不包括更新的 If the INCR option is specified, the return value will be Bulk string reply: The new score of member (a double precision floating point number) represented as string, or nil if the operation was aborted (when called with either the XX or the NX option). demo1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950127.0.0.1:6379&gt; ZADD set0 10 a 20 b(integer) 2127.0.0.1:6379&gt; ZADD set0 XX 11 a 30 c &#x2F;&#x2F;更新a,新增c失败(integer) 0127.0.0.1:6379&gt; ZRANGE set0 0 -1 WITHSCORES1) &quot;a&quot;2) &quot;11&quot;3) &quot;b&quot;4) &quot;20&quot;127.0.0.1:6379&gt; ZADD set0 NX 40 d 12 a &#x2F;&#x2F;新增d,更新a失败(integer) 1127.0.0.1:6379&gt; ZRANGE set0 0 -1 WITHSCORES1) &quot;a&quot;2) &quot;11&quot;3) &quot;b&quot;4) &quot;20&quot;5) &quot;d&quot;6) &quot;40&quot;127.0.0.1:6379&gt; ZADD set0 LT 10 a 21 b(error) ERR syntax error127.0.0.1:6379&gt; ZADD set0 LT 10 a &#x2F;&#x2F;当前版本不支持(error) ERR syntax error127.0.0.1:6379&gt; ZADD set0 CH 12 a 30 c &#x2F;&#x2F;变化变化的总数(integer) 2127.0.0.1:6379&gt; ZRANGE set0 0 -1 WITHSCORES1) &quot;a&quot;2) &quot;12&quot;3) &quot;b&quot;4) &quot;20&quot;5) &quot;c&quot;6) &quot;30&quot;7) &quot;d&quot;8) &quot;40&quot;127.0.0.1:6379&gt; ZADD set0 CH XX 11 a &#x2F;&#x2F;配合其他参数(integer) 1127.0.0.1:6379&gt; ZADD set0 XX 13 a &#x2F;&#x2F;区别老的返回值(integer) 0127.0.0.1:6379&gt; ZADD set0 50.1 e &#x2F;&#x2F;支持浮点数(integer) 1127.0.0.1:6379&gt; ZRANGE set0 0 -1 WITHSCORES 1) &quot;a&quot; 2) &quot;13&quot; 3) &quot;b&quot; 4) &quot;20&quot; 5) &quot;c&quot; 6) &quot;30&quot; 7) &quot;d&quot; 8) &quot;40&quot; 9) &quot;e&quot;10) &quot;50.100000000000001&quot; ZCARD返回key的元素个数，如果key不存在，返回0 123456127.0.0.1:6379&gt; zadd set1 1 a 2 b 3 c(integer) 3127.0.0.1:6379&gt; zcard set1(integer) 3127.0.0.1:6379&gt; zcard set10(integer) 0 ZCOUNT ZCOUNT key min max 12345678910127.0.0.1:6379&gt; zadd set7 1 a 3 b 3 c 4 d(integer) 4127.0.0.1:6379&gt; zcount set7 1 4(integer) 4127.0.0.1:6379&gt; zcount set7 [1 (4 &#x2F;&#x2F;不支持[(error) ERR min or max is not a float127.0.0.1:6379&gt; zcount set7 1 (4(integer) 3127.0.0.1:6379&gt; zcount set7 -inf +inf(integer) 4 ZINCRBY ZINCRBY key increment member 给元素的分数增加/递减 123456789101112131415127.0.0.1:6379&gt; zrange set7 0 -1 withscores1) &quot;a&quot;2) &quot;1&quot;3) &quot;b&quot;4) &quot;3&quot;5) &quot;c&quot;6) &quot;3&quot;7) &quot;d&quot;8) &quot;4&quot;127.0.0.1:6379&gt; zincrby set7 2 a&quot;3&quot;127.0.0.1:6379&gt; zincrby set7 -1 a&quot;2&quot;127.0.0.1:6379&gt; zincrby set7 5 e&quot;5&quot; ZINTERhttps://redis.io/commands/zinter ZINTERSTORE ZINTERSTORE destination numkeys key [key …] [WEIGHTS weight [weight …]] [AGGREGATE SUM|MIN|MAX] 取有序集合的交合到一个key中http://redis.cn/commands/zinterstore.html ZLEXCOUNT ZLEXCOUNT key min max 计算有序集合元素之间的元素数量，key的元素分数相同才有意义http://redis.cn/commands/zlexcount.html ZMSCOREhttps://redis.io/commands/zmscore ZPOPMAX弹出最大的值，默认1个，可加参数调整弹出的个数 1234567891011121314151617181920212223242526272829303132127.0.0.1:6379&gt; zrange set0 0 -1 withscores 1) &quot;a&quot; 2) &quot;16.010000000000002&quot; 3) &quot;b&quot; 4) &quot;20&quot; 5) &quot;g&quot; 6) &quot;70&quot; 7) &quot;g0&quot; 8) &quot;70&quot; 9) &quot;g1&quot;10) &quot;70&quot;11) &quot;g2&quot;12) &quot;70&quot;13) &quot;g3&quot;14) &quot;70&quot;127.0.0.1:6379&gt; zpopmax set01) &quot;g3&quot;2) &quot;70&quot;127.0.0.1:6379&gt; zpopmax set0 31) &quot;g2&quot;2) &quot;70&quot;3) &quot;g1&quot;4) &quot;70&quot;5) &quot;g0&quot;6) &quot;70&quot;127.0.0.1:6379&gt; zrange set0 0 -1 withscores1) &quot;a&quot;2) &quot;16.010000000000002&quot;3) &quot;b&quot;4) &quot;20&quot;5) &quot;g&quot;6) &quot;70&quot; ZPOPMIN同上，弹出最小的值，默认1个，可加参数调整弹出的个数 12345678910127.0.0.1:6379&gt; zpopmin set0 11) &quot;c&quot;2) &quot;1&quot;127.0.0.1:6379&gt; zpopmin set0 31) &quot;c1&quot;2) &quot;1&quot;3) &quot;c2&quot;4) &quot;1&quot;5) &quot;c3&quot;6) &quot;1&quot; ZRANGE ZRANGE key start stop [WITHSCORES] 返回一个区间的结果数组,strat从0开始，stop从zcard-1/-1开始,WITHSCORES结果带上score 结果按分数升序排列，相同分数的按key的字典正序排序 123456789101112131415161718192021222324252627282930313233343536373839404142127.0.0.1:6379&gt; zrange set1 0 3 withscores &#x2F;&#x2F;3大于右边界，退化成21) &quot;a&quot;2) &quot;1&quot;3) &quot;b&quot;4) &quot;2&quot;5) &quot;c&quot;6) &quot;3&quot;127.0.0.1:6379&gt; zrange set1 0 0 withscores1) &quot;a&quot;2) &quot;1&quot;127.0.0.1:6379&gt; zrange set1 0 2 withscores1) &quot;a&quot;2) &quot;1&quot;3) &quot;b&quot;4) &quot;2&quot;5) &quot;c&quot;6) &quot;3&quot;127.0.0.1:6379&gt; zrange set1 0 -1 withscores &#x2F;&#x2F;-1表示右边第一个值1) &quot;a&quot;2) &quot;1&quot;3) &quot;b&quot;4) &quot;2&quot;5) &quot;c&quot;6) &quot;3&quot;127.0.0.1:6379&gt; zrange set1 0 -2 withscores &#x2F;&#x2F;-2表示右边第二个值1) &quot;a&quot;2) &quot;1&quot;3) &quot;b&quot;4) &quot;2&quot;127.0.0.1:6379&gt; zrange set1 -1 -2 withscores &#x2F;&#x2F;左边-1就越界了(empty list or set)127.0.0.1:6379&gt; zrange set1 0 -1 withscores &#x2F;&#x2F;分数升序，字典正序 1) &quot;a&quot; 2) &quot;1&quot; 3) &quot;b&quot; 4) &quot;2&quot; 5) &quot;c&quot; 6) &quot;3&quot; 7) &quot;c1&quot; 8) &quot;3&quot; 9) &quot;c2&quot;10) &quot;3&quot; ZRANGEBYLEX ZRANGEBYLEX key min max [LIMIT offset count] 对分数相同的元素进行ascii排序，通过memcmp函数，如果key中元素分数不一致就不要用 min,max的使用 -表示最左边的元素，+表示最右边的元素 [是包含,(不包含 12345678910111213141516171819202122232425262728127.0.0.1:6379&gt; zadd set3 0 aaa 0 aba 0 abc 0 bbb 0 bcb 0 bcc 0 ccc(integer) 7127.0.0.1:6379&gt; zrangebylex set3 - + &#x2F;&#x2F;列出所有1) &quot;aaa&quot;2) &quot;aba&quot;3) &quot;abc&quot;4) &quot;bbb&quot;5) &quot;bcb&quot;6) &quot;bcc&quot;7) &quot;ccc&quot;127.0.0.1:6379&gt; zrangebylex set3 - + LIMIT 0 7 &#x2F;&#x2F;offset count1) &quot;aaa&quot;2) &quot;aba&quot;3) &quot;abc&quot;4) &quot;bbb&quot;5) &quot;bcb&quot;6) &quot;bcc&quot;7) &quot;ccc&quot;127.0.0.1:6379&gt; zrangebylex set3 - + LIMIT 1 21) &quot;aba&quot;2) &quot;abc&quot;127.0.0.1:6379&gt; zrangebylex set3 [a (b &#x2F;&#x2F;以a开头的1) &quot;aaa&quot;2) &quot;aba&quot;3) &quot;abc&quot;127.0.0.1:6379&gt; zrangebylex set3 [ab (ac &#x2F;&#x2F;以ab开头的1) &quot;aba&quot;2) &quot;abc&quot; ZRANGEBYSCORE ZRANGEBYSCORE key min max [WITHSCORES] [LIMIT offset count] ZRANGEBYSCORE和ZRANGE配合WITHSCORES还是有区别的. 12345678910111213141516171819202122232425262728293031127.0.0.1:6379&gt; zadd set4 1 a 2 b 3 c 4 d 5 e 6 f(integer) 6127.0.0.1:6379&gt; zrangebyscore set4 - + &#x2F;&#x2F;不支持这种格式(error) ERR min or max is not a float127.0.0.1:6379&gt; zrangebyscore set4 -inf +inf &#x2F;&#x2F;所有元素1) &quot;a&quot;2) &quot;b&quot;3) &quot;c&quot;4) &quot;d&quot;5) &quot;e&quot;6) &quot;f&quot;127.0.0.1:6379&gt; zrangebyscore set4 -inf +inf LIMIT 1 2 &#x2F;&#x2F;limit1) &quot;b&quot;2) &quot;c&quot;127.0.0.1:6379&gt; zrangebyscore set4 -inf +inf WITHSCORES LIMIT 1 2 &#x2F;&#x2F;withscores1) &quot;b&quot;2) &quot;2&quot;3) &quot;c&quot;4) &quot;3&quot;127.0.0.1:6379&gt; zrangebyscore set4 [1 [3 WITHSCORES LIMIT 1 2 &#x2F;&#x2F;不支持[(error) ERR min or max is not a float127.0.0.1:6379&gt; zrangebyscore set4 1 3 WITHSCORES LIMIT 1 21) &quot;b&quot;2) &quot;2&quot;3) &quot;c&quot;4) &quot;3&quot;127.0.0.1:6379&gt; zrangebyscore set4 (1 (3 WITHSCORES LIMIT 1 2(empty list or set)127.0.0.1:6379&gt; zrangebyscore set4 (1 (3 WITHSCORES &#x2F;&#x2F;支持(1) &quot;b&quot;2) &quot;2&quot; ZRANK ZRANK key member 返回元素按score的排名，从低到高，不存在的话返回nil 12345678127.0.0.1:6379&gt; zadd set5 1 a 2 b 3 c 4 d 5 e(integer) 5127.0.0.1:6379&gt; zrank set5 a(integer) 0127.0.0.1:6379&gt; zrank set5 b(integer) 1127.0.0.1:6379&gt; zrank set5 k(nil) ZREM ZREM key member [member …] remove元素，支持一次删除多个(ver&gt;=2.4),返回删除成功的元素个数 1234567891011121314151617181920127.0.0.1:6379&gt; zrange set5 0 -1 withscores 1) &quot;a&quot; 2) &quot;1&quot; 3) &quot;b&quot; 4) &quot;2&quot; 5) &quot;c&quot; 6) &quot;3&quot; 7) &quot;d&quot; 8) &quot;4&quot; 9) &quot;e&quot;10) &quot;5&quot;127.0.0.1:6379&gt; zrem set5 a b c o(integer) 3127.0.0.1:6379&gt; zrange set5 0 -1 withscores1) &quot;d&quot;2) &quot;4&quot;3) &quot;e&quot;4) &quot;5&quot;127.0.0.1:6379&gt; zrem set5 p(integer) 0 ZREMRANGEBYLEX ZREMRANGEBYLEX key min max rangeby只对分数相同的key有效 12345678910111213141516171819202122232425262728293031323334127.0.0.1:6379&gt; zrange set3 0 -1 withscores 1) &quot;aaa&quot; 2) &quot;0&quot; 3) &quot;aba&quot; 4) &quot;0&quot; 5) &quot;abc&quot; 6) &quot;0&quot; 7) &quot;bbb&quot; 8) &quot;0&quot; 9) &quot;bcb&quot;10) &quot;0&quot;11) &quot;bcc&quot;12) &quot;0&quot;13) &quot;ccc&quot;14) &quot;0&quot;127.0.0.1:6379&gt; zrangebylex set3 - +1) &quot;aaa&quot;2) &quot;aba&quot;3) &quot;abc&quot;4) &quot;bbb&quot;5) &quot;bcb&quot;6) &quot;bcc&quot;7) &quot;ccc&quot;127.0.0.1:6379&gt; zremrangebylex set3 [a (b &#x2F;&#x2F;删除以a开头的(integer) 3127.0.0.1:6379&gt; zrange set3 0 -1 withscores1) &quot;bbb&quot;2) &quot;0&quot;3) &quot;bcb&quot;4) &quot;0&quot;5) &quot;bcc&quot;6) &quot;0&quot;7) &quot;ccc&quot;8) &quot;0&quot; ZREMRANGEBYRANK ZREMRANGEBYRANK key start stop 删除按分数排名的区间 123456789101112131415161718192021222324252627127.0.0.1:6379&gt; zrange set4 0 -1 withscores 1) &quot;a&quot; 2) &quot;1&quot; 3) &quot;b&quot; 4) &quot;2&quot; 5) &quot;c&quot; 6) &quot;3&quot; 7) &quot;d&quot; 8) &quot;4&quot; 9) &quot;e&quot;10) &quot;5&quot;11) &quot;f&quot;12) &quot;6&quot;127.0.0.1:6379&gt; zremrangebyrank set4 0 2 &#x2F;&#x2F;删除前三个(integer) 3127.0.0.1:6379&gt; zrange set4 0 -1 withscores1) &quot;d&quot;2) &quot;4&quot;3) &quot;e&quot;4) &quot;5&quot;5) &quot;f&quot;6) &quot;6&quot;127.0.0.1:6379&gt; zremrangebyrank set4 -3 -2 &#x2F;&#x2F;删除倒数第2，3个(integer) 2127.0.0.1:6379&gt; zrange set4 0 -1 withscores1) &quot;f&quot;2) &quot;6&quot; ZREMRANGEBYSCORE ZREMRANGEBYSCORE key min max https://redis.io/commands/zremrangebyscore ZREVRANGE同上取反 ZREVRANGEBYLEX同上取反 ZREVRANGEBYSCORE同上取反 ZREVRANK同上取反 ZSCANZSCOREZUNIONZUNIONSTOREtime comlexityreference[1]https://redis.io/commands/zrangebylex [2]http://redis.cn/commands/zrangebyscore.html","categories":[],"tags":[],"keywords":[]},{"title":"skip-list in redis","slug":"2020-11-06-skip-list in redis","date":"2020-11-06T00:00:00.000Z","updated":"2022-09-12T16:24:32.288Z","comments":true,"path":"2020-11-06-skip-list in redis/","link":"","permalink":"https://riverferry.site/2020-11-06-skip-list%20in%20redis/","excerpt":"在计算机科学中，跳跃列表是一种数据结构。它使得包含n个元素的有序序列的查找和插入操作的平均时间复杂度都是O(log n)，优于数组的O(n)复杂度。快速的查询效果是通过维护一个多层次的链表实现的，且与前一层（下面一层）链表元素的数量相比，每一层链表中的元素的数量更少（见右下角示意图）。一开始时，算法在最稀疏的层次进行搜索，直至需要查找的元素在该层两个相邻的元素中间。这时，算法将跳转到下一个层次，重复刚才的搜索，直到找到需要查找的元素为止。跳过的元素的方法可以是随机性选择[2]或确定性选择[3]，其中前者更为常见。","text":"在计算机科学中，跳跃列表是一种数据结构。它使得包含n个元素的有序序列的查找和插入操作的平均时间复杂度都是O(log n)，优于数组的O(n)复杂度。快速的查询效果是通过维护一个多层次的链表实现的，且与前一层（下面一层）链表元素的数量相比，每一层链表中的元素的数量更少（见右下角示意图）。一开始时，算法在最稀疏的层次进行搜索，直至需要查找的元素在该层两个相邻的元素中间。这时，算法将跳转到下一个层次，重复刚才的搜索，直到找到需要查找的元素为止。跳过的元素的方法可以是随机性选择[2]或确定性选择[3]，其中前者更为常见。 跳表就是有序链表加上多层索引的实现，实现上比红黑树要简单，比红黑树要的一点是可以快速找到一个有序的区间，但是总体上的平衡性是比不上红黑树的，下面主要看看redis中sorted set里面是怎么使用跳表的。 第一次费时间画如此精细的图，画完很满意，看图就很好理解了。 struct12345678910111213141516/* ZSETs use a specialized version of Skiplists */typedef struct zskiplistNode &#123; sds ele; //对象指针 double score; //分数 struct zskiplistNode *backward; //指向前驱结点，前指针不指向表头 struct zskiplistLevel &#123; struct zskiplistNode *forward; //指向后继结点 unsigned long span; //对应层级的步长，用来计算排位的 &#125; level[];&#125; zskiplistNode;typedef struct zskiplist &#123; struct zskiplistNode *header, *tail; //链表的头和尾 unsigned long length; //原始链表的长度 int level; //最大的层级(不算表头节点)&#125; zskiplist; 创建zslCreate123456789101112131415161718/* Create a new skiplist. */zskiplist *zslCreate(void) &#123; int j; zskiplist *zsl; zsl = zmalloc(sizeof(*zsl)); zsl-&gt;level = 1; zsl-&gt;length = 0; //ZSKIPLIST_MAXLEVEL=64 zsl-&gt;header = zslCreateNode(ZSKIPLIST_MAXLEVEL,0,NULL); for (j = 0; j &lt; ZSKIPLIST_MAXLEVEL; j++) &#123; zsl-&gt;header-&gt;level[j].forward = NULL; zsl-&gt;header-&gt;level[j].span = 0; &#125; zsl-&gt;header-&gt;backward = NULL; zsl-&gt;tail = NULL; return zsl;&#125; 创建zskiplist结构体，保存全局信息，一开始创建的时候会顺带创建一个表头节点，包含64层 zslCreateNode123456789/* Create a skiplist node with the specified number of levels. * The SDS string &#x27;ele&#x27; is referenced by the node after the call. */zskiplistNode *zslCreateNode(int level, double score, sds ele) &#123; zskiplistNode *zn = zmalloc(sizeof(*zn)+level*sizeof(struct zskiplistLevel)); zn-&gt;score = score; zn-&gt;ele = ele; return zn;&#125; 创建zskiplistNode结构，保存节点信息 插入zslInsert12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061/* Insert a new node in the skiplist. Assumes the element does not already * exist (up to the caller to enforce that). The skiplist takes ownership * of the passed SDS string &#x27;ele&#x27;. */zskiplistNode *zslInsert(zskiplist *zsl, double score, sds ele) &#123; zskiplistNode *update[ZSKIPLIST_MAXLEVEL], *x; unsigned int rank[ZSKIPLIST_MAXLEVEL]; int i, level; serverAssert(!isnan(score)); x = zsl-&gt;header; for (i = zsl-&gt;level-1; i &gt;= 0; i--) &#123; /* store rank that is crossed to reach the insert position */ rank[i] = i == (zsl-&gt;level-1) ? 0 : rank[i+1]; while (x-&gt;level[i].forward &amp;&amp; (x-&gt;level[i].forward-&gt;score &lt; score || (x-&gt;level[i].forward-&gt;score == score &amp;&amp; sdscmp(x-&gt;level[i].forward-&gt;ele,ele) &lt; 0))) &#123; rank[i] += x-&gt;level[i].span; x = x-&gt;level[i].forward; &#125; update[i] = x; &#125; /* we assume the element is not already inside, since we allow duplicated * scores, reinserting the same element should never happen since the * caller of zslInsert() should test in the hash table if the element is * already inside or not. */ //返回1-maxlevel的随机数 level = zslRandomLevel(); if (level &gt; zsl-&gt;level) &#123; for (i = zsl-&gt;level; i &lt; level; i++) &#123; rank[i] = 0; update[i] = zsl-&gt;header; update[i]-&gt;level[i].span = zsl-&gt;length; &#125; zsl-&gt;level = level; &#125; x = zslCreateNode(level,score,ele); for (i = 0; i &lt; level; i++) &#123; x-&gt;level[i].forward = update[i]-&gt;level[i].forward; update[i]-&gt;level[i].forward = x; /* update span covered by update[i] as x is inserted here */ x-&gt;level[i].span = update[i]-&gt;level[i].span - (rank[0] - rank[i]); update[i]-&gt;level[i].span = (rank[0] - rank[i]) + 1; &#125; /* increment span for untouched levels */ for (i = level; i &lt; zsl-&gt;level; i++) &#123; update[i]-&gt;level[i].span++; &#125; x-&gt;backward = (update[0] == zsl-&gt;header) ? NULL : update[0]; if (x-&gt;level[0].forward) x-&gt;level[0].forward-&gt;backward = x; else zsl-&gt;tail = x; zsl-&gt;length++; return x;&#125; 这里需要注意的是update和rank这两个值，update保存每一层的x，即要插入的节点的每一层的左边的节点。后续farwork指针修改用到。然后rank是保存每一层x对应到头结点的位置，而rank[0]是第一层中要插入节点的左边的节点，rank[0]-rank[i]就是插入位置左边的节点到i层对应节点的距离，i的span减去这个值就是插入节点的spn.i的新的span就是rank[0]-rank[i]向右再挪动1位。 然后这里的层级是随机数，随机生成一个1-max level的层级。就是0-max-1的数组索引 zsetAdd123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160/* Add a new element or update the score of an existing element in a sorted * set, regardless of its encoding. * * The set of flags change the command behavior. They are passed with an integer * pointer since the function will clear the flags and populate them with * other flags to indicate different conditions. * * The input flags are the following: * * ZADD_INCR: Increment the current element score by &#x27;score&#x27; instead of updating * the current element score. If the element does not exist, we * assume 0 as previous score. * ZADD_NX: Perform the operation only if the element does not exist. * ZADD_XX: Perform the operation only if the element already exist. * * When ZADD_INCR is used, the new score of the element is stored in * &#x27;*newscore&#x27; if &#x27;newscore&#x27; is not NULL. * * The returned flags are the following: * * ZADD_NAN: The resulting score is not a number. * ZADD_ADDED: The element was added (not present before the call). * ZADD_UPDATED: The element score was updated. * ZADD_NOP: No operation was performed because of NX or XX. * * Return value: * * The function returns 1 on success, and sets the appropriate flags * ADDED or UPDATED to signal what happened during the operation (note that * none could be set if we re-added an element using the same score it used * to have, or in the case a zero increment is used). * * The function returns 0 on erorr, currently only when the increment * produces a NAN condition, or when the &#x27;score&#x27; value is NAN since the * start. * * The commad as a side effect of adding a new element may convert the sorted * set internal encoding from ziplist to hashtable+skiplist. * * Memory managemnet of &#x27;ele&#x27;: * * The function does not take ownership of the &#x27;ele&#x27; SDS string, but copies * it if needed. */int zsetAdd(robj *zobj, double score, sds ele, int *flags, double *newscore) &#123; /* Turn options into simple to check vars. */ int incr = (*flags &amp; ZADD_INCR) != 0; int nx = (*flags &amp; ZADD_NX) != 0; int xx = (*flags &amp; ZADD_XX) != 0; *flags = 0; /* We&#x27;ll return our response flags. */ double curscore; /* NaN as input is an error regardless of all the other parameters. */ if (isnan(score)) &#123; *flags = ZADD_NAN; return 0; &#125; /* Update the sorted set according to its encoding. */ //压缩列表，暂时不看 if (zobj-&gt;encoding == OBJ_ENCODING_ZIPLIST) &#123; unsigned char *eptr; if ((eptr = zzlFind(zobj-&gt;ptr,ele,&amp;curscore)) != NULL) &#123; /* NX? Return, same element already exists. */ if (nx) &#123; *flags |= ZADD_NOP; return 1; &#125; /* Prepare the score for the increment if needed. */ if (incr) &#123; score += curscore; if (isnan(score)) &#123; *flags |= ZADD_NAN; return 0; &#125; if (newscore) *newscore = score; &#125; /* Remove and re-insert when score changed. */ if (score != curscore) &#123; zobj-&gt;ptr = zzlDelete(zobj-&gt;ptr,eptr); zobj-&gt;ptr = zzlInsert(zobj-&gt;ptr,ele,score); *flags |= ZADD_UPDATED; &#125; return 1; &#125; else if (!xx) &#123; /* Optimize: check if the element is too large or the list * becomes too long *before* executing zzlInsert. */ zobj-&gt;ptr = zzlInsert(zobj-&gt;ptr,ele,score); if (zzlLength(zobj-&gt;ptr) &gt; server.zset_max_ziplist_entries || sdslen(ele) &gt; server.zset_max_ziplist_value) zsetConvert(zobj,OBJ_ENCODING_SKIPLIST); if (newscore) *newscore = score; *flags |= ZADD_ADDED; return 1; &#125; else &#123; *flags |= ZADD_NOP; return 1; &#125; //跳表 &#125; else if (zobj-&gt;encoding == OBJ_ENCODING_SKIPLIST) &#123; zset *zs = zobj-&gt;ptr; zskiplistNode *znode; dictEntry *de; //先从hash找，这里相当于是hash+skip list的结合，hash在其他post另外整理 de = dictFind(zs-&gt;dict,ele); //ele原来就存在 if (de != NULL) &#123; /* NX? Return, same element already exists. */ //nx是只新增，不更新 所以就ret if (nx) &#123; *flags |= ZADD_NOP; return 1; &#125; curscore = *(double*)dictGetVal(de); /* Prepare the score for the increment if needed. */ if (incr) &#123; score += curscore; if (isnan(score)) &#123; *flags |= ZADD_NAN; return 0; &#125; if (newscore) *newscore = score; &#125; /* Remove and re-insert when score changes. */ //更新分数 if (score != curscore) &#123; //更新跳表的分值 znode = zslUpdateScore(zs-&gt;zsl,curscore,ele,score); /* Note that we did not removed the original element from * the hash table representing the sorted set, so we just * update the score. */ //更新hash的分值 dictGetVal(de) = &amp;znode-&gt;score; /* Update score ptr. */ *flags |= ZADD_UPDATED; &#125; return 1; //插入的是新的元素 xx是只更新不新增，所以这里过滤下 &#125; else if (!xx) &#123; ele = sdsdup(ele); //插入 znode = zslInsert(zs-&gt;zsl,score,ele); serverAssert(dictAdd(zs-&gt;dict,ele,&amp;znode-&gt;score) == DICT_OK); *flags |= ZADD_ADDED; if (newscore) *newscore = score; return 1; &#125; else &#123; *flags |= ZADD_NOP; return 1; &#125; &#125; else &#123; serverPanic(&quot;Unknown sorted set encoding&quot;); &#125; return 0; /* Never reached. */&#125; 更新zslUpdateScore1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768/* Update the score of an elmenent inside the sorted set skiplist. * Note that the element must exist and must match &#x27;score&#x27;. * This function does not update the score in the hash table side, the * caller should take care of it. * * Note that this function attempts to just update the node, in case after * the score update, the node would be exactly at the same position. * Otherwise the skiplist is modified by removing and re-adding a new * element, which is more costly. * * The function returns the updated element skiplist node pointer. */zskiplistNode *zslUpdateScore(zskiplist *zsl, double curscore, sds ele, double newscore) &#123; zskiplistNode *update[ZSKIPLIST_MAXLEVEL], *x; int i; /* We need to seek to element to update to start: this is useful anyway, * we&#x27;ll have to update or remove it. */ x = zsl-&gt;header; for (i = zsl-&gt;level-1; i &gt;= 0; i--) &#123; while (x-&gt;level[i].forward &amp;&amp; (x-&gt;level[i].forward-&gt;score &lt; curscore || (x-&gt;level[i].forward-&gt;score == curscore &amp;&amp; sdscmp(x-&gt;level[i].forward-&gt;ele,ele) &lt; 0))) &#123; x = x-&gt;level[i].forward; &#125; //存放左边的位置，删除用到 update[i] = x; &#125; /* Jump to our element: note that this function assumes that the * element with the matching score exists. */ //x=current的位置 x = x-&gt;level[0].forward; serverAssert(x &amp;&amp; curscore == x-&gt;score &amp;&amp; sdscmp(x-&gt;ele,ele) == 0); /* If the node, after the score update, would be still exactly * at the same position, we can just update the score without * actually removing and re-inserting the element in the skiplist. */ //case1 x-&gt;backward == NULL &amp;&amp; x-&gt;level[0].forward == NULL //只有一个节点直接更新 //case2 x-&gt;backward == NULL &amp;&amp; x-&gt;level[0].forward-&gt;score &gt; newscore //原来是level0的第一个节点(不算表头节点)，并且右边的分数大于新的分数 //case3 x-&gt;backward-&gt;score &lt; newscore &amp;&amp; x-&gt;level[0].forward == NULL //左边的分数小于新的分数并且右边为空 //case4 x-&gt;backward-&gt;score &lt; newscore &amp;&amp; x-&gt;level[0].forward-&gt;score &gt; newscore //左边的分数小于新的分数并且右边的分数大于新的分数 if ((x-&gt;backward == NULL || x-&gt;backward-&gt;score &lt; newscore) &amp;&amp; (x-&gt;level[0].forward == NULL || x-&gt;level[0].forward-&gt;score &gt; newscore)) &#123; x-&gt;score = newscore; return x; &#125; /* No way to reuse the old node: we need to remove and insert a new * one at a different place. */ zslDeleteNode(zsl, x, update); zskiplistNode *newnode = zslInsert(zsl,newscore,x-&gt;ele); /* We reused the old node x-&gt;ele SDS string, free the node now * since zslInsert created a new one. */ x-&gt;ele = NULL; zslFreeNode(x); return newnode;&#125; 先判断如果新的分值更新后如果跳表规则不变，就直接更新在原来的位置。否则，先删除，再插入。 删除zslDeleteNode1234567891011121314151617181920212223242526/* Internal function used by zslDelete, zslDeleteByScore and zslDeleteByRank */void zslDeleteNode(zskiplist *zsl, zskiplistNode *x, zskiplistNode **update) &#123; int i; for (i = 0; i &lt; zsl-&gt;level; i++) &#123; if (update[i]-&gt;level[i].forward == x) &#123; //左边元素到x的步长更新为到x的右边元素的步长 update[i]-&gt;level[i].span += x-&gt;level[i].span - 1; //更新后继指针 update[i]-&gt;level[i].forward = x-&gt;level[i].forward; //else的情况没有想到 &#125; else &#123; update[i]-&gt;level[i].span -= 1; &#125; &#125; if (x-&gt;level[0].forward) &#123; //更新前驱指针 x-&gt;level[0].forward-&gt;backward = x-&gt;backward; &#125; else &#123; //更新尾指针 zsl-&gt;tail = x-&gt;backward; &#125; //从最高层遍历获取新的层级 while(zsl-&gt;level &gt; 1 &amp;&amp; zsl-&gt;header-&gt;level[zsl-&gt;level-1].forward == NULL) zsl-&gt;level--; zsl-&gt;length--;&#125; zslDelete123456789101112131415161718192021222324252627282930313233343536/* Delete an element with matching score/element from the skiplist. * The function returns 1 if the node was found and deleted, otherwise * 0 is returned. * * If &#x27;node&#x27; is NULL the deleted node is freed by zslFreeNode(), otherwise * it is not freed (but just unlinked) and *node is set to the node pointer, * so that it is possible for the caller to reuse the node (including the * referenced SDS string at node-&gt;ele). */int zslDelete(zskiplist *zsl, double score, sds ele, zskiplistNode **node) &#123; zskiplistNode *update[ZSKIPLIST_MAXLEVEL], *x; int i; x = zsl-&gt;header; for (i = zsl-&gt;level-1; i &gt;= 0; i--) &#123; while (x-&gt;level[i].forward &amp;&amp; (x-&gt;level[i].forward-&gt;score &lt; score || (x-&gt;level[i].forward-&gt;score == score &amp;&amp; sdscmp(x-&gt;level[i].forward-&gt;ele,ele) &lt; 0))) &#123; x = x-&gt;level[i].forward; &#125; update[i] = x; &#125; /* We may have multiple elements with the same score, what we need * is to find the element with both the right score and object. */ x = x-&gt;level[0].forward; if (x &amp;&amp; score == x-&gt;score &amp;&amp; sdscmp(x-&gt;ele,ele) == 0) &#123; zslDeleteNode(zsl, x, update); if (!node) zslFreeNode(x); else *node = x; return 1; &#125; return 0; /* not found */&#125;","categories":[],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://riverferry.site/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"},{"name":"redis","slug":"redis","permalink":"https://riverferry.site/tags/redis/"}],"keywords":[]},{"title":"gin-基本操作","slug":"2020-11-05-gin-基本操作","date":"2020-11-05T00:00:00.000Z","updated":"2022-09-12T16:24:32.288Z","comments":true,"path":"2020-11-05-gin-基本操作/","link":"","permalink":"https://riverferry.site/2020-11-05-gin-%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/","excerpt":"https://github.com/gin-gonic/gin官方文档的实践，一些值得记录的地方","text":"https://github.com/gin-gonic/gin官方文档的实践，一些值得记录的地方 jsonitergo build -tags=jsoniter . jsoniter比默认的encoding/json能快点 Query12c.Query(&quot;lastname&quot;) &#x2F;&#x2F;shortcut for c.Request.URL.Query().Get(&quot;lastname&quot;)c.DefaultQuery(&quot;firstname&quot;, &quot;Guest&quot;) 查url中的参数 PostForm示例代码 这里post的格式只能是form-data或者x-www-form-urlencoded form-data 12345678message: m111Postman-Token: 72271c98-353b-4a80-bdf2-740297332161Host: localhost:9999Content-Type: application&#x2F;x-www-form-urlencodedContent-Length: 30message&#x3D;mmmmmm&amp;nick&#x3D;nnnnnnnnnn x-www-form-urlencoded 123456789101112131415message: m111Postman-Token: dc3d1280-bbae-46b3-8eda-7df92fa08cd4Host: localhost:9999Content-Type: multipart&#x2F;form-data; boundary&#x3D;--------------------------194386765225837300878008Content-Length: 277----------------------------194386765225837300878008Content-Disposition: form-data; name&#x3D;&quot;message&quot;m23333----------------------------194386765225837300878008Content-Disposition: form-data; name&#x3D;&quot;nick&quot;n11111----------------------------194386765225837300878008-- FormFilecurl 123curl -X POST http:&#x2F;&#x2F;localhost:8080&#x2F;upload \\ -F &quot;file&#x3D;@&#x2F;Users&#x2F;appleboy&#x2F;test.zip&quot; \\ -H &quot;Content-Type: multipart&#x2F;form-data&quot; postman Group123456v1 :&#x3D; router.Group(&quot;&#x2F;v1&quot;) &#123; v1.POST(&quot;&#x2F;login&quot;, loginEndpoint) v1.POST(&quot;&#x2F;submit&quot;, submitEndpoint) v1.POST(&quot;&#x2F;read&quot;, readEndpoint) &#125; 写起来规整，匹配结果是/v1/login /v1/submit /v1/read gin.Newr := gin.New() r.Use(gin.Logger()) new返回engine,可以自定义中间件 default里面也是调用的New: 1234567&#x2F;&#x2F; Default returns an Engine instance with the Logger and Recovery middleware already attached.func Default() *Engine &#123; debugPrintWARNINGDefault() engine :&#x3D; New() engine.Use(Logger(), Recovery()) return engine&#125; CustomRecovery123456789101112&#x2F;&#x2F; Recovery middleware recovers from any panics and writes a 500 if there was one. r.Use(gin.CustomRecovery(func(c *gin.Context, recovered interface&#123;&#125;) &#123; if err, ok :&#x3D; recovered.(string); ok &#123; c.String(http.StatusInternalServerError, fmt.Sprintf(&quot;error: %s&quot;, err)) &#125; c.AbortWithStatus(http.StatusInternalServerError) &#125;)) r.GET(&quot;&#x2F;panic&quot;, func(c *gin.Context) &#123; &#x2F;&#x2F; panic with a string -- the custom middleware could save this to a database or report it to the user panic(&quot;foo&quot;) &#125;) catch到panic,保证服务稳定运行 Model binding示例代码 bind默认情况下只要bind的参数带了，即使是空，也不认为有问题。binding:&quot;required&quot;可以用来约束bind的字段不为空 BindJSON如果bind的字段没带齐，直接返回404了。 ShouldBindJSON如果bind的字段没带齐，需要自行处理:err := c.ShouldBindJSON(&amp;json); err != nil Validators示例代码 12345678910111213141516171819type Booking struct &#123; CheckIn time.Time &#96;form:&quot;check_in&quot; binding:&quot;required,bookabledate&quot; time_format:&quot;2006-01-02&quot;&#96; CheckOut time.Time &#96;form:&quot;check_out&quot; binding:&quot;required,gtfield&#x3D;CheckIn&quot; time_format:&quot;2006-01-02&quot;&#96;&#125;if v, ok :&#x3D; binding.Validator.Engine().(*validator.Validate); ok &#123; v.RegisterValidation(&quot;bookabledate&quot;, bookableDate) &#125;var bookableDate validator.Func &#x3D; func(fl validator.FieldLevel) bool &#123; date, ok :&#x3D; fl.Field().Interface().(time.Time) if ok &#123; today :&#x3D; time.Now() if today.After(date) &#123; return false &#125; &#125; return true&#125; 上面的代码注册一个新的Tag，本身validator是有很多默认的Tag的，比如email或者上面代码中的gtfield=CheckIn,表示大于CheckIn.具体参考https://frankhitman.github.io/zh-CN/gin-validator/ BindQuery示例代码 BindQuery或者ShouldBindQuery只绑定url中的字段，忽略post的body带的参数 具体可看https://github.com/gin-gonic/gin/issues/742 12345# only bind query$ curl -X GET &quot;localhost:8085&#x2F;testing?name&#x3D;eason&amp;address&#x3D;xyz&quot;# only bind query string, ignore form data$ curl -X POST &quot;localhost:8085&#x2F;testing?name&#x3D;eason&amp;address&#x3D;xyz&quot; --data &#39;name&#x3D;ignore&amp;address&#x3D;ignore&#39; -H &quot;Content-Type:application&#x2F;x-www-form-urlencoded&quot; BindBind和ShouldBind对于url和post的body都进行绑定 BindUri示例代码 JSONP示例代码 返回函数名包裹上参数，比json多了个callback curl http://127.0.0.1:8080/JSONP\\?callback\\=x x(&#123;&quot;foo&quot;:&quot;bar&quot;&#125;);% Serving static files示例代码 Custom Middleware12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970package mainimport ( &quot;fmt&quot; &quot;log&quot; &quot;time&quot; &quot;github.com/gin-gonic/gin&quot;)func Logger() gin.HandlerFunc &#123; return func(c *gin.Context) &#123; t := time.Now() // Set example variable c.Set(&quot;example&quot;, &quot;12345&quot;) fmt.Println(&quot;12345&quot;) // before request c.Next() // after request latency := time.Since(t) log.Print(latency) // access the status we are sending status := c.Writer.Status() log.Println(status) &#125;&#125;func Logger2() gin.HandlerFunc &#123; return func(c *gin.Context) &#123; t := time.Now() // Set example variable c.Set(&quot;example&quot;, &quot;abcde&quot;) fmt.Println(&quot;abcde&quot;) // before request c.Next() // after request latency := time.Since(t) log.Print(latency) // access the status we are sending status := c.Writer.Status() log.Println(status) &#125;&#125;func main() &#123; r := gin.New() r.Use(Logger()) r.Use(Logger2()) r.GET(&quot;/test&quot;, func(c *gin.Context) &#123; example := c.MustGet(&quot;example&quot;).(string) // it would print: &quot;12345&quot; log.Println(example) &#125;) // Listen and serve on 0.0.0.0:8080 r.Run(&quot;:8080&quot;)&#125; output 12345678[GIN-debug] Listening and serving HTTP on :808012345abcde2020&#x2F;11&#x2F;05 19:39:47 abcde2020&#x2F;11&#x2F;05 19:39:47 203.826µs2020&#x2F;11&#x2F;05 19:39:47 2002020&#x2F;11&#x2F;05 19:39:47 243.954µs2020&#x2F;11&#x2F;05 19:39:47 200 可以仿照自己写一个中间件，在请求执行的过程中会执行所有中间件。具体后面看代码了再分析 BasicAuth示例代码 BasicAuth是一种鉴权的方式,具体参考HTTP Basic Auth 是怎么样工作的 示例代码效果演示： 报文： Goroutines inside a middleware示例代码 gin下的context不是原生的context,它是并发不安全的，所以协程里面使用copy，不要用传进来的context.可参考https://www.jianshu.com/p/b3a6d5680e7c Custom HTTP configuration示例代码 Run multiple service using Gin示例代码 可监听多个端口，处理相同的请求。 其他根据官方文档执行下就好","categories":[],"tags":[],"keywords":[]},{"title":"golang sema treap","slug":"2020-11-04-golang sema treap","date":"2020-11-04T00:00:00.000Z","updated":"2022-09-12T16:24:32.288Z","comments":true,"path":"2020-11-04-golang sema treap/","link":"","permalink":"https://riverferry.site/2020-11-04-golang%20sema%20treap/","excerpt":"接着runtime sema的部分，梳理wait的队列实现细节。","text":"接着runtime sema的部分，梳理wait的队列实现细节。 queue123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293// queue adds s to the blocked goroutines in semaRoot.func (root *semaRoot) queue(addr *uint32, s *sudog, lifo bool) &#123; s.g = getg() //当前的G s.elem = unsafe.Pointer(addr) s.next = nil s.prev = nil var last *sudog pt := &amp;root.treap for t := *pt; t != nil; t = *pt &#123; //bst搜索 if t.elem == unsafe.Pointer(addr) &#123; // Already have addr in list. //lifo:插到head if lifo &#123; // Substitute s in t&#x27;s place in treap. //old: t-&gt;t1-&gt;t2 //new s-&gt;t-&gt;t1 *pt = s s.ticket = t.ticket s.acquiretime = t.acquiretime s.parent = t.parent s.prev = t.prev s.next = t.next if s.prev != nil &#123; s.prev.parent = s &#125; if s.next != nil &#123; s.next.parent = s &#125; // Add t first in s&#x27;s wait list. s.waitlink = t s.waittail = t.waittail if s.waittail == nil &#123; s.waittail = t &#125; t.parent = nil t.prev = nil t.next = nil t.waittail = nil //fifo:插到tail &#125; else &#123; // Add s to end of t&#x27;s wait list. if t.waittail == nil &#123; t.waitlink = s &#125; else &#123; t.waittail.waitlink = s &#125; //只更新了链表第一个元素指向的tail,其他元素的tail指针好像没有同步 t.waittail = s s.waitlink = nil &#125; return &#125; last = t if uintptr(unsafe.Pointer(addr)) &lt; uintptr(t.elem) &#123; pt = &amp;t.prev &#125; else &#123; pt = &amp;t.next &#125; &#125; // Add s as new leaf in tree of unique addrs. // The balanced tree is a treap using ticket as the random heap priority. // That is, it is a binary tree ordered according to the elem addresses, // but then among the space of possible binary trees respecting those // addresses, it is kept balanced on average by maintaining a heap ordering // on the ticket: s.ticket &lt;= both s.prev.ticket and s.next.ticket. // https://en.wikipedia.org/wiki/Treap // https://faculty.washington.edu/aragon/pubs/rst89.pdf // // s.ticket compared with zero in couple of places, therefore set lowest bit. // It will not affect treap&#x27;s quality noticeably. //更新s的优先级，平衡整棵树 s.ticket = fastrand() | 1 s.parent = last *pt = s // Rotate up into tree according to ticket (priority). for s.parent != nil &amp;&amp; s.parent.ticket &gt; s.ticket &#123; //当前节点是左节点就右旋，右节点则左旋 //这里看样子用的是小顶堆 if s.parent.prev == s &#123; root.rotateRight(s.parent) &#125; else &#123; if s.parent.next != s &#123; panic(&quot;semaRoot queue&quot;) &#125; root.rotateLeft(s.parent) &#125; &#125;&#125; dequeue123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778// dequeue searches for and finds the first goroutine// in semaRoot blocked on addr.// If the sudog was being profiled, dequeue returns the time// at which it was woken up as now. Otherwise now is 0.func (root *semaRoot) dequeue(addr *uint32) (found *sudog, now int64) &#123; ps := &amp;root.treap s := *ps for ; s != nil; s = *ps &#123; if s.elem == unsafe.Pointer(addr) &#123; goto Found &#125; //bst搜索 if uintptr(unsafe.Pointer(addr)) &lt; uintptr(s.elem) &#123; ps = &amp;s.prev &#125; else &#123; ps = &amp;s.next &#125; &#125; return nil, 0Found: //s:对应addr的节点 now = int64(0) if s.acquiretime != 0 &#123; now = cputicks() &#125; if t := s.waitlink; t != nil &#123; // Substitute t, also waiting on addr, for s in root tree of unique addrs. //链表有2个以上元素，把第2个元素挪到treap下，删掉s *ps = t t.ticket = s.ticket t.parent = s.parent t.prev = s.prev if t.prev != nil &#123; t.prev.parent = t &#125; t.next = s.next if t.next != nil &#123; t.next.parent = t &#125; if t.waitlink != nil &#123; t.waittail = s.waittail &#125; else &#123; t.waittail = nil &#125; t.acquiretime = now s.waitlink = nil s.waittail = nil &#125; else &#123; //链表只有1个元素，这个元素s有子节点才考虑旋转，将这个元素删掉 // Rotate s down to be leaf of tree for removal, respecting priorities. for s.next != nil || s.prev != nil &#123; //只有右节点，或者有2个节点但是右节点大于左节点，都右旋 if s.next == nil || s.prev != nil &amp;&amp; s.prev.ticket &lt; s.next.ticket &#123; root.rotateRight(s) &#125; else &#123; root.rotateLeft(s) &#125; &#125; // Remove s, now a leaf. if s.parent != nil &#123; if s.parent.prev == s &#123; s.parent.prev = nil &#125; else &#123; s.parent.next = nil &#125; &#125; else &#123; root.treap = nil &#125; &#125; s.parent = nil s.elem = nil s.next = nil s.prev = nil s.ticket = 0 return s, now&#125; rotateLeft12345678910111213141516171819202122232425262728// rotateLeft rotates the tree rooted at node x.// turning (x a (y b c)) into (y (x a b) c).func (root *semaRoot) rotateLeft(x *sudog) &#123; // p -&gt; (x a (y b c)) p := x.parent y := x.next b := y.prev y.prev = x x.parent = y x.next = b if b != nil &#123; b.parent = x &#125; y.parent = p if p == nil &#123; root.treap = y &#125; else if p.prev == x &#123; p.prev = y &#125; else &#123; if p.next != x &#123; throw(&quot;semaRoot rotateLeft&quot;) &#125; p.next = y &#125;&#125; rotateRight12345678910111213141516171819202122232425262728// rotateRight rotates the tree rooted at node y.// turning (y (x a b) c) into (x a (y b c)).func (root *semaRoot) rotateRight(y *sudog) &#123; // p -&gt; (y (x a b) c) p := y.parent x := y.prev b := x.next x.next = y y.parent = x y.prev = b if b != nil &#123; b.parent = y &#125; x.parent = p if p == nil &#123; root.treap = x &#125; else if p.prev == y &#123; p.prev = x &#125; else &#123; if p.next != y &#123; throw(&quot;semaRoot rotateRight&quot;) &#125; p.next = x &#125;&#125; note之前看红黑树的时候没有注意这一点：选择左旋还是右旋，是考虑到了旋转后还是bst树。这样就都清晰了。 reference[1]https://byvoid.com/zhs/blog/treap-analysis-and-application/","categories":[],"tags":[],"keywords":[]},{"title":"golang RWmutex","slug":"2020-11-04-golang-RWmutex","date":"2020-11-04T00:00:00.000Z","updated":"2022-09-12T16:24:32.288Z","comments":true,"path":"2020-11-04-golang-RWmutex/","link":"","permalink":"https://riverferry.site/2020-11-04-golang-RWmutex/","excerpt":"读和读不隔离，写和写通过mutex隔离，写和读通过sema互相配合。","text":"读和读不隔离，写和写通过mutex隔离，写和读通过sema互相配合。 demo123456789101112131415161718192021222324252627282930313233343536package mainimport ( &quot;fmt&quot; &quot;sync&quot; &quot;time&quot;)// Main functionfunc main() &#123; rw := new(sync.RWMutex) var wg sync.WaitGroup //写锁 rw.Lock() for i := 0; i &lt; 10; i++ &#123; wg.Add(1) go func(i int) &#123; //读锁 defer func() &#123; wg.Done() rw.RUnlock() &#125;() rw.RLock() fmt.Println(i) &#125;(i) &#125; time.Sleep(2 * time.Second) fmt.Println(&quot;print:&quot;) rw.Unlock() wg.Wait()&#125; struct1234567891011121314151617181920212223242526// There is a modified copy of this file in runtime/rwmutex.go.// If you make any changes here, see if you should make them there.// A RWMutex is a reader/writer mutual exclusion lock.// The lock can be held by an arbitrary number of readers or a single writer.// The zero value for a RWMutex is an unlocked mutex.//// A RWMutex must not be copied after first use.//// If a goroutine holds a RWMutex for reading and another goroutine might// call Lock, no goroutine should expect to be able to acquire a read lock// until the initial read lock is released. In particular, this prohibits// recursive read locking. This is to ensure that the lock eventually becomes// available; a blocked Lock call excludes new readers from acquiring the// lock.type RWMutex struct &#123; w Mutex // held if there are pending writers writerSem uint32 // semaphore for writers to wait for completing readers readerSem uint32 // semaphore for readers to wait for completing writers //当前读操作的个数 readerCount int32 // number of pending readers //被写阻塞的读g的个数 readerWait int32 // number of departing readers&#125;const rwmutexMaxReaders = 1 &lt;&lt; 30 RLock12345678910111213141516171819// RLock locks rw for reading.//// It should not be used for recursive read locking; a blocked Lock// call excludes new readers from acquiring the lock. See the// documentation on the RWMutex type.func (rw *RWMutex) RLock() &#123; if race.Enabled &#123; _ = rw.w.state race.Disable() &#125; if atomic.AddInt32(&amp;rw.readerCount, 1) &lt; 0 &#123; // A writer is pending, wait for it. runtime_SemacquireMutex(&amp;rw.readerSem, false, 0) &#125; if race.Enabled &#123; race.Enable() race.Acquire(unsafe.Pointer(&amp;rw.readerSem)) &#125;&#125; RLock给readerCount加1 readerCount为负数，表示有写在进行，这里就阻塞了 RUnlock12345678910111213141516171819202122232425262728293031// RUnlock undoes a single RLock call;// it does not affect other simultaneous readers.// It is a run-time error if rw is not locked for reading// on entry to RUnlock.func (rw *RWMutex) RUnlock() &#123; if race.Enabled &#123; _ = rw.w.state race.ReleaseMerge(unsafe.Pointer(&amp;rw.writerSem)) race.Disable() &#125; if r := atomic.AddInt32(&amp;rw.readerCount, -1); r &lt; 0 &#123; // Outlined slow-path to allow the fast-path to be inlined rw.rUnlockSlow(r) &#125; if race.Enabled &#123; race.Enable() &#125;&#125;func (rw *RWMutex) rUnlockSlow(r int32) &#123; if r+1 == 0 || r+1 == -rwmutexMaxReaders &#123; race.Enable() throw(&quot;sync: RUnlock of unlocked RWMutex&quot;) &#125; // A writer is pending. if atomic.AddInt32(&amp;rw.readerWait, -1) == 0 &#123; // The last reader unblocks the writer. //读读是可以并行的，这里只需要唤醒阻塞的写 runtime_Semrelease(&amp;rw.writerSem, false, 1) &#125;&#125; RUnlock给readerCount减1 r &lt; 0表示写锁已经加上了还没释放，那么现在的读g就是被阻塞的，所以readerWait要减1，等减到0的时候就可以唤醒写了(阻塞在Lock下的写) readerWait=0的时候写才会被唤醒 Lock1234567891011121314151617181920212223242526// Lock locks rw for writing.// If the lock is already locked for reading or writing,// Lock blocks until the lock is available.func (rw *RWMutex) Lock() &#123; if race.Enabled &#123; _ = rw.w.state race.Disable() &#125; // First, resolve competition with other writers. rw.w.Lock() // Announce to readers there is a pending writer. //readerCount为负数，阻塞其他的新的读 r := atomic.AddInt32(&amp;rw.readerCount, -rwmutexMaxReaders) + rwmutexMaxReaders // Wait for active readers. //r就是原来的readerCount，这些读都被写操作阻塞了，记录在readerWait //等待被读锁唤醒，每唤醒一个读，readerWait-1 //这里说明当前有读在进行中，所以写只能阻塞等待被读唤醒。 if r != 0 &amp;&amp; atomic.AddInt32(&amp;rw.readerWait, r) != 0 &#123; runtime_SemacquireMutex(&amp;rw.writerSem, false, 0) &#125; if race.Enabled &#123; race.Enable() race.Acquire(unsafe.Pointer(&amp;rw.readerSem)) race.Acquire(unsafe.Pointer(&amp;rw.writerSem)) &#125;&#125; 写和写通过rw.w.Lock()隔离，写和读通过sema隔离，读和读不隔离 所有在运行的读都RUnlock了写才被唤醒 Unlock1234567891011121314151617181920212223242526272829303132// Unlock unlocks rw for writing. It is a run-time error if rw is// not locked for writing on entry to Unlock.//// As with Mutexes, a locked RWMutex is not associated with a particular// goroutine. One goroutine may RLock (Lock) a RWMutex and then// arrange for another goroutine to RUnlock (Unlock) it.func (rw *RWMutex) Unlock() &#123; if race.Enabled &#123; _ = rw.w.state race.Release(unsafe.Pointer(&amp;rw.readerSem)) race.Disable() &#125; // Announce to readers there is no active writer. r := atomic.AddInt32(&amp;rw.readerCount, rwmutexMaxReaders) if r &gt;= rwmutexMaxReaders &#123; race.Enable() throw(&quot;sync: Unlock of unlocked RWMutex&quot;) &#125; // Unblock blocked readers, if any. //唤醒所有阻塞的读 for i := 0; i &lt; int(r); i++ &#123; runtime_Semrelease(&amp;rw.readerSem, false, 0) &#125; // Allow other writers to proceed. //将锁让给其他的写 rw.w.Unlock() if race.Enabled &#123; race.Enable() &#125;&#125; 还原readerCount的值 唤醒写加锁后新来的被阻塞的读","categories":[],"tags":[],"keywords":[]},{"title":"golang runtime sema","slug":"2020-11-03-golang-runtime-sema","date":"2020-11-03T00:00:00.000Z","updated":"2022-09-12T16:24:32.288Z","comments":true,"path":"2020-11-03-golang-runtime-sema/","link":"","permalink":"https://riverferry.site/2020-11-03-golang-runtime-sema/","excerpt":"go实现的sleep和wakeup，底层是gopark和goready，需要结合调度来看。其他同步手段基本都与这里有关。版本go/1.15.2/libexec/src/runtime/sema.go","text":"go实现的sleep和wakeup，底层是gopark和goready，需要结合调度来看。其他同步手段基本都与这里有关。版本go/1.15.2/libexec/src/runtime/sema.go struct123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263//go:linkname sync_runtime_Semacquire sync.runtime_Semacquirefunc sync_runtime_Semacquire(addr *uint32) &#123; semacquire1(addr, false, semaBlockProfile, 0)&#125;//go:linkname poll_runtime_Semacquire internal/poll.runtime_Semacquirefunc poll_runtime_Semacquire(addr *uint32) &#123; semacquire1(addr, false, semaBlockProfile, 0)&#125;//go:linkname sync_runtime_Semrelease sync.runtime_Semreleasefunc sync_runtime_Semrelease(addr *uint32, handoff bool, skipframes int) &#123; semrelease1(addr, handoff, skipframes)&#125;//go:linkname sync_runtime_SemacquireMutex sync.runtime_SemacquireMutexfunc sync_runtime_SemacquireMutex(addr *uint32, lifo bool, skipframes int) &#123; semacquire1(addr, lifo, semaBlockProfile|semaMutexProfile, skipframes)&#125;// Prime to not correlate(相关) with any user patterns.const semTabSize = 251var semtable [semTabSize]struct &#123; root semaRoot pad [cpu.CacheLinePadSize - unsafe.Sizeof(semaRoot&#123;&#125;)]byte&#125;type semaRoot struct &#123; lock mutex treap *sudog // root of balanced tree of unique waiters. nwait uint32 // Number of waiters. Read w/o the lock.&#125;type sudog struct &#123; // The following fields are protected by the hchan.lock of the // channel this sudog is blocking on. shrinkstack depends on // this for sudogs involved in channel ops. g *g next *sudog prev *sudog elem unsafe.Pointer // data element (may point to stack) // The following fields are never accessed concurrently. // For channels, waitlink is only accessed by g. // For semaphores, all fields (including the ones above) // are only accessed when holding a semaRoot lock. acquiretime int64 releasetime int64 ticket uint32 // isSelect indicates g is participating in a select, so // g.selectDone must be CAS&#x27;d to win the wake-up race. isSelect bool parent *sudog // semaRoot binary tree waitlink *sudog // g.waiting list or semaRoot waittail *sudog // semaRoot c *hchan // channel&#125; semtable是大小251的数组，数组元素存放了semaRoot,每个semaRoot都是一个树堆，key是锁的地址elem，优先级是生成的一个随机数ticket.并且相同地址的elem不是存在树堆里面的，而是通过和树堆里相同的key组成单向链表串起来的(waitlink指向链表下一个元素，waittail指向链表最后的一个元素)。sudog.g保存了阻塞在锁上面的g,即goroutine的信息，在唤醒的时候会用到。 cansemacquire1234567891011func cansemacquire(addr *uint32) bool &#123; for &#123; v := atomic.Load(addr) if v == 0 &#123; return false &#125; if atomic.Cas(addr, v, v-1) &#123; return true &#125; &#125;&#125; treap是存放等待队列的，所以如果能直接取到锁的值可以修改的话，就不用阻塞也就不用入队了，这里是easy case. semacquire11234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859func semacquire1(addr *uint32, lifo bool, profile semaProfileFlags, skipframes int) &#123; gp := getg() //记录当前的G信息 if gp != gp.m.curg &#123; throw(&quot;semacquire not on the G stack&quot;) &#125; // Easy case. //尝试原子操作-1 if cansemacquire(addr) &#123; return &#125; // Harder case: // increment waiter count // try cansemacquire one more time, return if succeeded // enqueue itself as a waiter // sleep // (waiter descriptor is dequeued by signaler) s := acquireSudog() root := semroot(addr) t0 := int64(0) s.releasetime = 0 s.acquiretime = 0 s.ticket = 0 if profile&amp;semaBlockProfile != 0 &amp;&amp; blockprofilerate &gt; 0 &#123; t0 = cputicks() s.releasetime = -1 &#125; if profile&amp;semaMutexProfile != 0 &amp;&amp; mutexprofilerate &gt; 0 &#123; if t0 == 0 &#123; t0 = cputicks() &#125; s.acquiretime = t0 &#125; for &#123; lockWithRank(&amp;root.lock, lockRankRoot) // Add ourselves to nwait to disable &quot;easy case&quot; in semrelease. //nwaiter+1,让其他cas失效 atomic.Xadd(&amp;root.nwait, 1) // Check cansemacquire to avoid missed wakeup. if cansemacquire(addr) &#123; atomic.Xadd(&amp;root.nwait, -1) unlock(&amp;root.lock) break &#125; // Any semrelease after the cansemacquire knows we&#x27;re waiting // (we set nwait above), so go to sleep. //s加到treap里面，然后gopark睡眠 root.queue(addr, s, lifo) goparkunlock(&amp;root.lock, waitReasonSemacquire, traceEvGoBlockSync, 4+skipframes) if s.ticket != 0 || cansemacquire(addr) &#123; break &#125; &#125; if s.releasetime &gt; 0 &#123; blockevent(s.releasetime-t0, 3+skipframes) &#125; releaseSudog(s)&#125; semrelease1123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263func semrelease1(addr *uint32, handoff bool, skipframes int) &#123; root := semroot(addr) //+1 atomic.Xadd(addr, 1) // Easy case: no waiters? // This check must happen after the xadd, to avoid a missed wakeup // (see loop in semacquire). //再次检查，刚add的看样子已经被其他g给acquire了 if atomic.Load(&amp;root.nwait) == 0 &#123; return &#125; // Harder case: search for a waiter and wake it. lockWithRank(&amp;root.lock, lockRankRoot) if atomic.Load(&amp;root.nwait) == 0 &#123; // The count is already consumed by another goroutine, // so no need to wake up another goroutine. unlock(&amp;root.lock) return &#125; //出队，从treap/sudog链表删除 s, t0 := root.dequeue(addr) if s != nil &#123; atomic.Xadd(&amp;root.nwait, -1) &#125; unlock(&amp;root.lock) if s != nil &#123; // May be slow or even yield, so unlock first acquiretime := s.acquiretime if acquiretime != 0 &#123; mutexevent(t0-acquiretime, 3+skipframes) &#125; if s.ticket != 0 &#123; throw(&quot;corrupted semaphore ticket&quot;) &#125; if handoff &amp;&amp; cansemacquire(addr) &#123; s.ticket = 1 &#125; //goready唤醒 readyWithTime(s, 5+skipframes) if s.ticket == 1 &amp;&amp; getg().m.locks == 0 &#123; // Direct G handoff // readyWithTime has added the waiter G as runnext in the // current P; we now call the scheduler so that we start running // the waiter G immediately. // Note that waiter inherits our time slice: this is desirable // to avoid having a highly contended semaphore hog the P // indefinitely. goyield is like Gosched, but it emits a // &quot;preempted&quot; trace event instead and, more importantly, puts // the current G on the local runq instead of the global one. // We only do this in the starving regime (handoff=true), as in // the non-starving case it is possible for a different waiter // to acquire the semaphore while we are yielding/scheduling, // and this would be wasteful. We wait instead to enter starving // regime, and then we start to do direct handoffs of ticket and // P. // See issue 33747 for discussion. //将当前g放到P的可运行队列，而不是全局的可运行队列 goyield() &#125; &#125;&#125; reference[1]https://github.com/cch123/golang-notes/blob/master/semaphore.md [2]https://github.com/thinkboy/go-notes/blob/master/%E4%BB%8E%E6%BA%90%E7%A0%81%E8%A7%92%E5%BA%A6%E7%9C%8BGolang%E7%9A%84%E8%B0%83%E5%BA%A6.md [3]数据结构与算法之美","categories":[],"tags":[{"name":"golang","slug":"golang","permalink":"https://riverferry.site/tags/golang/"}],"keywords":[]},{"title":"golang sync.cond","slug":"2020-10-29-golang-sync-cond","date":"2020-10-29T00:00:00.000Z","updated":"2022-09-12T16:24:32.287Z","comments":true,"path":"2020-10-29-golang-sync-cond/","link":"","permalink":"https://riverferry.site/2020-10-29-golang-sync-cond/","excerpt":"Cond implements a condition variable, a rendezvous(会和) point for goroutines waiting for or announcing(宣布，公告) the occurrence(发生) of an event. Each Cond has an associated(关联) Locker L (often a *Mutex or *RWMutex), which must be held when changing the condition and when calling the Wait method. A Cond must not be copied after first use. 函数以及用法和unix的条件变量很相似。代码路径/usr/local/Cellar/go/1.15.2/libexec/src/sync/cond.go","text":"Cond implements a condition variable, a rendezvous(会和) point for goroutines waiting for or announcing(宣布，公告) the occurrence(发生) of an event. Each Cond has an associated(关联) Locker L (often a *Mutex or *RWMutex), which must be held when changing the condition and when calling the Wait method. A Cond must not be copied after first use. 函数以及用法和unix的条件变量很相似。代码路径/usr/local/Cellar/go/1.15.2/libexec/src/sync/cond.go struct12345678910111213141516171819type Cond struct &#123; noCopy noCopy //禁止拷贝 // L is held while observing or changing the condition L Locker notify notifyList checker copyChecker&#125;// Approximation of notifyList in runtime/sema.go. Size and alignment must// agree.type notifyList struct &#123; wait uint32 notify uint32 lock uintptr // key field of the mutex head unsafe.Pointer tail unsafe.Pointer&#125; NewCondNewCond returns a new Cond with Locker l. 1234// NewCond returns a new Cond with Locker l.func NewCond(l Locker) *Cond &#123; return &amp;Cond&#123;L: l&#125;&#125; Wait1234567891011121314151617181920212223// Wait atomically unlocks c.L and suspends execution// of the calling goroutine. After later resuming execution,// Wait locks c.L before returning. Unlike in other systems,// Wait cannot return unless awoken by Broadcast or Signal.//// Because c.L is not locked when Wait first resumes, the caller// typically cannot assume that the condition is true when// Wait returns. Instead, the caller should Wait in a loop://// c.L.Lock()// for !condition() &#123;// c.Wait()// &#125;// ... make use of condition ...// c.L.Unlock()//func (c *Cond) Wait() &#123; c.checker.check() //检查有没有被copy t := runtime_notifyListAdd(&amp;c.notify) c.L.Unlock() runtime_notifyListWait(&amp;c.notify, t) c.L.Lock()&#125; check12345678910// copyChecker holds back pointer to itself to detect object copying.type copyChecker uintptrfunc (c *copyChecker) check() &#123; if uintptr(*c) != uintptr(unsafe.Pointer(c)) &amp;&amp; !atomic.CompareAndSwapUintptr((*uintptr)(c), 0, uintptr(unsafe.Pointer(c))) &amp;&amp; uintptr(*c) != uintptr(unsafe.Pointer(c)) &#123; panic(&quot;sync.Cond is copied&quot;) &#125;&#125; Signal12345678// Signal wakes one goroutine waiting on c, if there is any.//// It is allowed but not required for the caller to hold c.L// during the call.func (c *Cond) Signal() &#123; c.checker.check() runtime_notifyListNotifyOne(&amp;c.notify)&#125; Broadcast12345678// Broadcast wakes all goroutines waiting on c.//// It is allowed but not required for the caller to hold c.L// during the call.func (c *Cond) Broadcast() &#123; c.checker.check() runtime_notifyListNotifyAll(&amp;c.notify)&#125; 基本比较简单，麻烦的是runtime系列函数，我在别的文章单独整理吧.reference[1]https://golang.org/pkg/sync/#Cond","categories":[],"tags":[{"name":"golang","slug":"golang","permalink":"https://riverferry.site/tags/golang/"}],"keywords":[]},{"title":"golang sync.once","slug":"2020-10-29-golang-sync-once","date":"2020-10-29T00:00:00.000Z","updated":"2022-09-12T16:24:32.288Z","comments":true,"path":"2020-10-29-golang-sync-once/","link":"","permalink":"https://riverferry.site/2020-10-29-golang-sync-once/","excerpt":"Once is an object that will perform exactly one action.类似c++的单例模式。代码路径/usr/local/Cellar/go/1.15.2/libexec/src/sync/once.go。代码很少，实现起来也比较简单。","text":"Once is an object that will perform exactly one action.类似c++的单例模式。代码路径/usr/local/Cellar/go/1.15.2/libexec/src/sync/once.go。代码很少，实现起来也比较简单。 demo123456789101112131415161718192021222324package mainimport ( &quot;fmt&quot; &quot;sync&quot;)func main() &#123; var once sync.Once onceBody := func() &#123; fmt.Println(&quot;Only once&quot;) &#125; done := make(chan bool) for i := 0; i &lt; 10; i++ &#123; go func() &#123; once.Do(onceBody) done &lt;- true &#125;() &#125; for i := 0; i &lt; 10; i++ &#123; &lt;-done &#125; fmt.Println(&quot;all done!&quot;)&#125; output: Only once all done! source codestruct1234567891011// Once is an object that will perform exactly one action.type Once struct &#123; // done indicates whether the action has been performed. // It is first in the struct because it is used in the hot path. // The hot path is inlined at every call site. // Placing done first allows more compact instructions on some architectures (amd64/x86), // and fewer instructions (to calculate offset) on other architectures. //0表示第一次执行 done uint32 m Mutex&#125; Do123456789101112131415161718192021222324252627282930313233343536373839// Do calls the function f if and only if Do is being called for the// first time for this instance of Once. In other words, given// var once Once// if once.Do(f) is called multiple times, only the first call will invoke f,// even if f has a different value in each invocation. A new instance of// Once is required for each function to execute.//// Do is intended for initialization that must be run exactly once. Since f// is niladic, it may be necessary to use a function literal to capture the// arguments to a function to be invoked by Do:// config.once.Do(func() &#123; config.init(filename) &#125;)//// Because no call to Do returns until the one call to f returns, if f causes// Do to be called, it will deadlock.//// If f panics, Do considers it to have returned; future calls of Do return// without calling f.//func (o *Once) Do(f func()) &#123; // Note: Here is an incorrect implementation of Do: // // if atomic.CompareAndSwapUint32(&amp;o.done, 0, 1) &#123; // f() // &#125; // // Do guarantees that when it returns, f has finished. // This implementation would not implement that guarantee: // given two simultaneous calls, the winner of the cas would // call f, and the second would return immediately, without // waiting for the first&#x27;s call to f to complete. // This is why the slow path falls back to a mutex, and why // the atomic.StoreUint32 must be delayed until after f returns. if atomic.LoadUint32(&amp;o.done) == 0 &#123; // Outlined slow-path to allow inlining of the fast-path. o.doSlow(f) &#125;&#125; doSlow123456789func (o *Once) doSlow(f func()) &#123; o.m.Lock() defer o.m.Unlock() //两次判断 if o.done == 0 &#123; defer atomic.StoreUint32(&amp;o.done, 1) f() &#125;&#125; 总结总体比较简单，需要注意的就是2次加锁。然后2次defer,defer有如析构是先构造后析构的，所以先修改值再释放锁 12345678910package mainimport ( &quot;fmt&quot;)func main() &#123; defer fmt.Println(&quot;111&quot;) defer fmt.Println(&quot;222&quot;)&#125; output: 222 111 reference[1]https://golang.org/pkg/sync/#Once","categories":[],"tags":[{"name":"golang","slug":"golang","permalink":"https://riverferry.site/tags/golang/"}],"keywords":[]},{"title":"golang sync WaitGroup","slug":"2020-10-28-golang sync-WaitGroup","date":"2020-10-28T00:00:00.000Z","updated":"2022-09-12T16:24:32.287Z","comments":true,"path":"2020-10-28-golang sync-WaitGroup/","link":"","permalink":"https://riverferry.site/2020-10-28-golang%20sync-WaitGroup/","excerpt":"官方的demo演示如下，做了点小改动","text":"官方的demo演示如下，做了点小改动 demo123456789101112131415161718192021222324252627282930313233343536package mainimport ( &quot;fmt&quot; &quot;sync&quot;)type httpPkg struct&#123;&#125;func (httpPkg) Get(url string, i int) &#123; fmt.Println(i) &#125;var http httpPkgfunc main() &#123; var wg sync.WaitGroup var urls = []string&#123; &quot;http://www.golang.org/&quot;, &quot;http://www.google.com/&quot;, &quot;http://www.somestupidname.com/&quot;, &#125; var i = 0 for _, url := range urls &#123; // Increment the WaitGroup counter. wg.Add(1) // Launch a goroutine to fetch the URL. go func(url string, i int) &#123; // Decrement the counter when the goroutine completes. defer wg.Done() // Fetch the URL. http.Get(url, i) &#125;(url, i) i += 1 &#125; // Wait for all HTTP fetches to complete. wg.Wait()&#125; output: 2 0 1 source codestruct1234567891011121314151617// A WaitGroup waits for a collection of goroutines to finish.// The main goroutine calls Add to set the number of// goroutines to wait for. Then each of the goroutines// runs and calls Done when finished. At the same time,// Wait can be used to block until all goroutines have finished.//// A WaitGroup must not be copied after first use.type WaitGroup struct &#123; noCopy noCopy // 64-bit value: high 32 bits are counter, low 32 bits are waiter count. // 64-bit atomic operations require 64-bit alignment, but 32-bit // compilers do not ensure it. So we allocate 12 bytes and then use // the aligned 8 bytes in them as state, and the other 4 as storage // for the sema. state1 [3]uint32&#125; 用[3]uint32保证在32/64位系统下都是12字节，然后4位保存计数，4位保存等待计数，4位保存sema.64位系统的原子操作是保证8个字节对齐的，32位不能保证。所以用此判断区别32/64位系统。 state12345678910// state returns pointers to the state and sema fields stored within wg.state1.func (wg *WaitGroup) state() (statep *uint64, semap *uint32) &#123; //64 bit state1[0]=count, state1[1]=wait, state1[2]=sema if uintptr(unsafe.Pointer(&amp;wg.state1))%8 == 0 &#123; return (*uint64)(unsafe.Pointer(&amp;wg.state1)), &amp;wg.state1[2] //32 bit state1[0]=sema, state1[1]=count, state1[2]=wait &#125; else &#123; return (*uint64)(unsafe.Pointer(&amp;wg.state1[1])), &amp;wg.state1[0] &#125;&#125; 返回32/64位系统中count和sema的地址 Add1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465// Add adds delta, which may be negative, to the WaitGroup counter.// If the counter becomes zero, all goroutines blocked on Wait are released.// If the counter goes negative, Add panics.//// Note that calls with a positive delta that occur when the counter is zero// must happen before a Wait. Calls with a negative delta, or calls with a// positive delta that start when the counter is greater than zero, may happen// at any time.// Typically this means the calls to Add should execute before the statement// creating the goroutine or other event to be waited for.// If a WaitGroup is reused to wait for several independent sets of events,// new Add calls must happen after all previous Wait calls have returned.// See the WaitGroup example.func (wg *WaitGroup) Add(delta int) &#123; statep, semap := wg.state() if race.Enabled &#123; _ = *statep // trigger nil deref early if delta &lt; 0 &#123; // Synchronize decrements with Wait. race.ReleaseMerge(unsafe.Pointer(wg)) &#125; race.Disable() defer race.Enable() &#125; //计数器是4字节的，这里用uint64存的数也只能是4字节大小，然后左移32位加给计数器 state := atomic.AddUint64(statep, uint64(delta)&lt;&lt;32) //算出计数器的实际值 v := int32(state &gt;&gt; 32) //截断成32位，表示waiter w := uint32(state) if race.Enabled &amp;&amp; delta &gt; 0 &amp;&amp; v == int32(delta) &#123; // The first increment must be synchronized with Wait. // Need to model this as a read, because there can be // several concurrent wg.counter transitions from 0. race.Read(unsafe.Pointer(semap)) &#125; //计数器小于0报错 if v &lt; 0 &#123; panic(&quot;sync: negative WaitGroup counter&quot;) &#125; //已经有goroutine在wait,且计数器等于0，就不能再add一个正数 //应该是计数器=0，正要唤醒wait的g,这时候就不要再add了，并发安全 if w != 0 &amp;&amp; delta &gt; 0 &amp;&amp; v == int32(delta) &#123; panic(&quot;sync: WaitGroup misuse: Add called concurrently with Wait&quot;) &#125; if v &gt; 0 || w == 0 &#123; return &#125; //说明 v =0 &amp;&amp; w &gt; 0,需要唤醒所有waiter // This goroutine has set counter to 0 when waiters &gt; 0. // Now there can&#x27;t be concurrent mutations(变动) of state: // - Adds must not happen concurrently with Wait, // - Wait does not increment waiters if it sees counter == 0. // Still do a cheap sanity(合理) check to detect WaitGroup misuse(滥用). if *statep != state &#123; panic(&quot;sync: WaitGroup misuse: Add called concurrently with Wait&quot;) &#125; // Reset waiters count to 0. *statep = 0 for ; w != 0; w-- &#123; //逐个唤醒 runtime_Semrelease(semap, false, 0) &#125;&#125; Done1234// Done decrements the WaitGroup counter by one.func (wg *WaitGroup) Done() &#123; wg.Add(-1)&#125; Wait1234567891011121314151617181920212223242526272829303132333435363738394041424344// Wait blocks until the WaitGroup counter is zero.func (wg *WaitGroup) Wait() &#123; statep, semap := wg.state() if race.Enabled &#123; _ = *statep // trigger nil deref early race.Disable() &#125; for &#123; //同上 state := atomic.LoadUint64(statep) v := int32(state &gt;&gt; 32) w := uint32(state) if v == 0 &#123; // Counter is 0, no need to wait. if race.Enabled &#123; race.Enable() race.Acquire(unsafe.Pointer(wg)) &#125; //=0就不用阻塞了 return &#125; // Increment waiters count. if atomic.CompareAndSwapUint64(statep, state, state+1) &#123; if race.Enabled &amp;&amp; w == 0 &#123; // Wait must be synchronized with the first Add. // Need to model this is as a write to race with the read in Add. // As a consequence, can do the write only for the first waiter, // otherwise concurrent Waits will race with each other. race.Write(unsafe.Pointer(semap)) &#125; //阻塞 runtime_Semacquire(semap) if *statep != 0 &#123; panic(&quot;sync: WaitGroup is reused before previous Wait has returned&quot;) &#125; if race.Enabled &#123; race.Enable() race.Acquire(unsafe.Pointer(wg)) &#125; return &#125; &#125;&#125; 总结 waitegroup主要用来做wait,等待一组goroutine结束。手动通过channel也能实现。这是抽象好的易用的形式，而且是用Semacquire实现的(另行总结) add用来给计数器做增减，done就是add(-1).wait给waiter+1然后阻塞，计数器=0的时候唤醒所有waiter. 实现上有特色的就是位操作，虽然能看懂。但是这样搞的实际价值以及动机还是有点模糊。 go语言函数参数都是值传递，所以waitgroup作为参数的时候要传递地址，不然就出问题了，来个demo测下 WaitGroup值传递12345678910111213141516171819202122232425262728293031323334353637383940414243package mainimport ( &quot;fmt&quot; &quot;sync&quot;)type httpPkg struct&#123;&#125;func (httpPkg) Get(url string, i int) &#123; fmt.Println(i) &#125;var http httpPkgfunc test(wg sync.WaitGroup, url string, i int) &#123; defer wg.Done() http.Get(url, i)&#125;func main() &#123; var wg sync.WaitGroup var urls = []string&#123; &quot;http://www.golang.org/&quot;, &quot;http://www.google.com/&quot;, &quot;http://www.somestupidname.com/&quot;, &#125; var i = 0 for _, url := range urls &#123; // Increment the WaitGroup counter. wg.Add(1) // Launch a goroutine to fetch the URL. // go func(url string, i int) &#123; // // Decrement the counter when the goroutine completes. // defer wg.Done() // // Fetch the URL. // http.Get(url, i) // &#125;(url, i) go test(wg, url, i) i += 1 &#125; // Wait for all HTTP fetches to complete. wg.Wait()&#125; output: 12345678910111213201fatal error: all goroutines are asleep - deadlock!goroutine 1 [semacquire]:sync.runtime_Semacquire(0xc000016088) /usr/local/Cellar/go/1.15.2/libexec/src/runtime/sema.go:56 +0x45sync.(*WaitGroup).Wait(0xc000016080) /usr/local/Cellar/go/1.15.2/libexec/src/sync/waitgroup.go:130 +0x65main.main() /Users/river/go/src/grpc/test/main.go:41 +0x178exit status 2 值传递导致是一个新的WaitGroup对象,原来的Done就没生效。死锁了.这里需要注意的是nocopy的实现，就是定义了一空结构体，然后一个Lock方法。这种类型如果复制,go vet可以检测出来，vscode上也会直观提示的。 reference[1]https://draveness.me/golang/docs/part3-runtime/ch06-concurrency/golang-sync-primitives/#waitgroup [2]https://golang.design/under-the-hood/zh-cn/part4lib/ch15sync/waitgroup/","categories":[],"tags":[{"name":"golang","slug":"golang","permalink":"https://riverferry.site/tags/golang/"}],"keywords":[]},{"title":"golang semaphore","slug":"2020-10-28-golang-semaphore","date":"2020-10-28T00:00:00.000Z","updated":"2022-09-12T16:24:32.287Z","comments":true,"path":"2020-10-28-golang-semaphore/","link":"","permalink":"https://riverferry.site/2020-10-28-golang-semaphore/","excerpt":"golang.org/x下面的包是区别于标椎库的，具有实验性质的辅助包，一些功能日趋完善后也可能添加到标准库中。","text":"golang.org/x下面的包是区别于标椎库的，具有实验性质的辅助包，一些功能日趋完善后也可能添加到标准库中。 demo12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576package mainimport ( &quot;context&quot; &quot;fmt&quot; &quot;log&quot; &quot;runtime&quot; &quot;golang.org/x/sync/semaphore&quot;)// collatzSteps computes the number of steps to reach 1 under the Collatz// conjecture. (See https://en.wikipedia.org/wiki/Collatz_conjecture.)func collatzSteps(n int) (steps int) &#123; if n &lt;= 0 &#123; panic(&quot;nonpositive input&quot;) &#125; for ; n &gt; 1; steps++ &#123; //time.Sleep(1 * time.Second) if steps &lt; 0 &#123; panic(&quot;too many steps&quot;) &#125; if n%2 == 0 &#123; n /= 2 continue &#125; const maxInt = int(^uint(0) &gt;&gt; 1) if n &gt; (maxInt-1)/3 &#123; panic(&quot;overflow&quot;) &#125; n = 3*n + 1 &#125; return steps&#125;// Main functionfunc main() &#123; ctx := context.TODO() var ( maxWorkers = runtime.GOMAXPROCS(0) //12 sem = semaphore.NewWeighted(int64(maxWorkers)) out = make([]int, 32) ) // Compute the output using up to maxWorkers goroutines at a time. for i := range out &#123; // When maxWorkers goroutines are in flight, Acquire blocks until one of the // workers finishes. if err := sem.Acquire(ctx, 1); err != nil &#123; log.Printf(&quot;Failed to acquire semaphore: %v&quot;, err) break &#125; fmt.Println(i) go func(i int) &#123; defer sem.Release(1) out[i] = collatzSteps(i + 1) &#125;(i) &#125; // Acquire all of the tokens to wait for any remaining workers to finish. // // If you are already waiting for the workers by some other means (such as an // errgroup.Group), you can omit this final Acquire call. if err := sem.Acquire(ctx, int64(maxWorkers)); err != nil &#123; log.Printf(&quot;Failed to acquire semaphore: %v&quot;, err) &#125; fmt.Println(out)&#125; 一个官方的demohttps://godoc.org/golang.org/x/sync/semaphore.out大小是32，我这里maxWorkers是12，一开始很快打开12个goroutine,然后后面的开始等待，因为channel满了。for循环外面的sem.Acquire保证所有gouritine都执行结束，像是多线程的wait函数。 NewWeighted传入权重也就是信号量的计数器，然后Acquire就是P操作(wait,-1),Release是V操作(post,+1) source codestruct12345678910111213// Weighted provides a way to bound concurrent access to a resource.// The callers can request access with a given weight.type Weighted struct &#123; size int64 //权重，信号量个数 cur int64 //使用的信号量个数 mu sync.Mutex waiters list.List //等待的goroutine&#125;type waiter struct &#123; n int64 ready chan&lt;- struct&#123;&#125; // Closed when semaphore acquired.&#125; Acquire123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657// Acquire acquires the semaphore with a weight of n, blocking until resources// are available or ctx is done. On success, returns nil. On failure, returns// ctx.Err() and leaves the semaphore unchanged.//// If ctx is already done, Acquire may still succeed without blocking.func (s *Weighted) Acquire(ctx context.Context, n int64) error &#123; s.mu.Lock() //信号量够用，并且没有goroutine在排队，cur增加，返回成功 if s.size-s.cur &gt;= n &amp;&amp; s.waiters.Len() == 0 &#123; s.cur += n s.mu.Unlock() return nil &#125; //请求的大于容量的值，关闭context if n &gt; s.size &#123; // Don&#x27;t make other Acquire calls block on one that&#x27;s doomed to fail. s.mu.Unlock() &lt;-ctx.Done() return ctx.Err() &#125; //要排队的情况 ready := make(chan struct&#123;&#125;) //转换成只能发送的channel w := waiter&#123;n: n, ready: ready&#125; //加入等待队列 elem := s.waiters.PushBack(w) s.mu.Unlock() select &#123; //context结束的话，做错误处理 case &lt;-ctx.Done(): err := ctx.Err() s.mu.Lock() select &#123; case &lt;-ready: // Acquired the semaphore after we were canceled. Rather than trying to // fix up the queue, just pretend we didn&#x27;t notice the cancelation. err = nil default: isFront := s.waiters.Front() == elem s.waiters.Remove(elem) // If we&#x27;re at the front and there&#x27;re extra tokens left, notify other waiters. if isFront &amp;&amp; s.size &gt; s.cur &#123; s.notifyWaiters() &#125; &#125; s.mu.Unlock() return err //阻塞到channel可读了 case &lt;-ready: return nil &#125;&#125; TryAcquire123456789101112// TryAcquire acquires the semaphore with a weight of n without blocking.// On success, returns true. On failure, returns false and leaves the semaphore unchanged.//非阻塞式的，只判断能否成功func (s *Weighted) TryAcquire(n int64) bool &#123; s.mu.Lock() success := s.size-s.cur &gt;= n &amp;&amp; s.waiters.Len() == 0 if success &#123; s.cur += n &#125; s.mu.Unlock() return success&#125; Release123456789101112// Release releases the semaphore with a weight of n.//很直观，信号量-n,并唤醒func (s *Weighted) Release(n int64) &#123; s.mu.Lock() s.cur -= n if s.cur &lt; 0 &#123; s.mu.Unlock() panic(&quot;semaphore: released more than held&quot;) &#125; s.notifyWaiters() s.mu.Unlock()&#125; notifyWaiters1234567891011121314151617181920212223242526272829303132//广播操作func (s *Weighted) notifyWaiters() &#123; for &#123; next := s.waiters.Front() if next == nil &#123; break // No more waiters blocked. &#125; w := next.Value.(waiter) //不够唤醒，退出 if s.size-s.cur &lt; w.n &#123; // Not enough tokens for the next waiter. We could keep going (to try to // find a waiter with a smaller request), but under load that could cause // starvation for large requests; instead, we leave all remaining waiters // blocked. // // Consider a semaphore used as a read-write lock, with N tokens, N // readers, and one writer. Each reader can Acquire(1) to obtain a read // lock. The writer can Acquire(N) to obtain a write lock, excluding all // of the readers. If we allow the readers to jump ahead in the queue, // the writer will starve — there is always one token available for every // reader. break &#125; s.cur += w.n s.waiters.Remove(next) //close唤醒阻塞的goroutine close(w.ready) &#125;&#125; 总结 通过头遍历双向链表实现了fifo唤醒等待队列 通过channel实现semaphore,数据结构设计很有意思，引入了权重的概念，从而多了cur,mutex,waiter(waiter内置了channel,并且支持一个goroutine可以递增技术量&gt;=1的值，也就是权重的概念)，所以这里不仅是实现了多元信号量，并且区别posix那种实现(每个线程只占用1个计数量) reference[1]https://www.codeleading.com/article/44422188264/ [2]https://draveness.me/golang/docs/part3-runtime/ch06-concurrency/golang-sync-primitives/#semaphore","categories":[],"tags":[{"name":"golang","slug":"golang","permalink":"https://riverferry.site/tags/golang/"}],"keywords":[]},{"title":"grpc 实现","slug":"2020-10-28-grpc 实现","date":"2020-10-28T00:00:00.000Z","updated":"2022-09-12T16:24:32.287Z","comments":true,"path":"2020-10-28-grpc 实现/","link":"","permalink":"https://riverferry.site/2020-10-28-grpc%20%E5%AE%9E%E7%8E%B0/","excerpt":"TODO","text":"TODO RegisterName123456789101112131415161718192021222324252627282930rpc.RegisterName(&quot;hello&quot;, new(hello.Hello))// RegisterName is like Register but uses the provided name for the type// instead of the receiver&#x27;s concrete type.func RegisterName(name string, rcvr interface&#123;&#125;) error &#123; return DefaultServer.RegisterName(name, rcvr)&#125;// DefaultServer is the default instance of *Server.var DefaultServer = NewServer()// NewServer returns a new Server.func NewServer() *Server &#123; return &amp;Server&#123;&#125;&#125;// Server represents an RPC Server.type Server struct &#123; serviceMap sync.Map // map[string]*service reqLock sync.Mutex // protects freeReq freeReq *Request respLock sync.Mutex // protects freeResp freeResp *Response&#125;// RegisterName is like Register but uses the provided name for the type// instead of the receiver&#x27;s concrete type.func (server *Server) RegisterName(name string, rcvr interface&#123;&#125;) error &#123; return server.register(rcvr, name, true)&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354type service struct &#123; name string // name of service rcvr reflect.Value // receiver of methods for the service typ reflect.Type // type of the receiver method map[string]*methodType // registered methods&#125;func (server *Server) register(rcvr interface&#123;&#125;, name string, useName bool) error &#123; s := new(service) s.typ = reflect.TypeOf(rcvr) s.rcvr = reflect.ValueOf(rcvr) sname := reflect.Indirect(s.rcvr).Type().Name() if useName &#123; sname = name &#125; if sname == &quot;&quot; &#123; s := &quot;rpc.Register: no service name for type &quot; + s.typ.String() log.Print(s) return errors.New(s) &#125; if !token.IsExported(sname) &amp;&amp; !useName &#123; s := &quot;rpc.Register: type &quot; + sname + &quot; is not exported&quot; log.Print(s) return errors.New(s) &#125; s.name = sname // Install the methods s.method = suitableMethods(s.typ, true) if len(s.method) == 0 &#123; str := &quot;&quot; // To help the user, see if a pointer receiver would work. //转换成指针类型再试试 method := suitableMethods(reflect.PtrTo(s.typ), false) if len(method) != 0 &#123; str = &quot;rpc.Register: type &quot; + sname + &quot; has no exported methods of suitable type (hint: pass a pointer to value of that type)&quot; &#125; else &#123; str = &quot;rpc.Register: type &quot; + sname + &quot; has no exported methods of suitable type&quot; &#125; log.Print(str) return errors.New(str) &#125; if _, dup := server.serviceMap.LoadOrStore(sname, s); dup &#123; return errors.New(&quot;rpc: service already defined: &quot; + sname) &#125; return nil&#125; suitableMethods12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061// suitableMethods returns suitable Rpc methods of typ, it will report// error using log if reportErr is true.func suitableMethods(typ reflect.Type, reportErr bool) map[string]*methodType &#123; methods := make(map[string]*methodType) for m := 0; m &lt; typ.NumMethod(); m++ &#123; method := typ.Method(m) mtype := method.Type mname := method.Name // Method must be exported. if method.PkgPath != &quot;&quot; &#123; continue &#125; // Method needs three ins: receiver, *args, *reply. //func (h *Hello) Hello(req string, rep *string) error if mtype.NumIn() != 3 &#123; if reportErr &#123; log.Printf(&quot;rpc.Register: method %q has %d input parameters; needs exactly three\\n&quot;, mname, mtype.NumIn()) &#125; continue &#125; // First arg need not be a pointer. argType := mtype.In(1) if !isExportedOrBuiltinType(argType) &#123; if reportErr &#123; log.Printf(&quot;rpc.Register: argument type of method %q is not exported: %q\\n&quot;, mname, argType) &#125; continue &#125; // Second arg must be a pointer. replyType := mtype.In(2) if replyType.Kind() != reflect.Ptr &#123; if reportErr &#123; log.Printf(&quot;rpc.Register: reply type of method %q is not a pointer: %q\\n&quot;, mname, replyType) &#125; continue &#125; // Reply type must be exported. if !isExportedOrBuiltinType(replyType) &#123; if reportErr &#123; log.Printf(&quot;rpc.Register: reply type of method %q is not exported: %q\\n&quot;, mname, replyType) &#125; continue &#125; // Method needs one out. if mtype.NumOut() != 1 &#123; if reportErr &#123; log.Printf(&quot;rpc.Register: method %q has %d output parameters; needs exactly one\\n&quot;, mname, mtype.NumOut()) &#125; continue &#125; // The return type of the method must be error. if returnType := mtype.Out(0); returnType != typeOfError &#123; if reportErr &#123; log.Printf(&quot;rpc.Register: return type of method %q is %q, must be error\\n&quot;, mname, returnType) &#125; continue &#125; methods[mname] = &amp;methodType&#123;method: method, ArgType: argType, ReplyType: replyType&#125; &#125; return methods&#125; noteRegisterName其实就是通过reflect把数据结构的所有方法存到sync.map中","categories":[],"tags":[{"name":"golang","slug":"golang","permalink":"https://riverferry.site/tags/golang/"}],"keywords":[]},{"title":"golang concurrent map","slug":"2020-10-27-golang concurrent-map","date":"2020-10-27T00:00:00.000Z","updated":"2022-09-12T16:24:32.287Z","comments":true,"path":"2020-10-27-golang concurrent-map/","link":"","permalink":"https://riverferry.site/2020-10-27-golang%20concurrent-map/","excerpt":"本文是对github上https://github.com/orcaman/concurrent-map此rep的一点学习记录。","text":"本文是对github上https://github.com/orcaman/concurrent-map此rep的一点学习记录。 官方demo123456789101112131415161718192021222324package mainimport ( &quot;fmt&quot; cmap &quot;github.com/orcaman/concurrent-map&quot;)func main() &#123; // Create a new map. m := cmap.New() // Sets item within map, sets &quot;bar&quot; under key &quot;foo&quot; m.Set(&quot;foo&quot;, &quot;bar&quot;) // Retrieve item from map. if tmp, ok := m.Get(&quot;foo&quot;); ok &#123; fmt.Println(tmp) &#125; // Removes item under key &quot;foo&quot; m.Remove(&quot;foo&quot;)&#125; 分析struct1234567891011var SHARD_COUNT = 32// A &quot;thread&quot; safe map of type string:Anything.// To avoid lock bottlenecks this map is dived to several (SHARD_COUNT) map shards.type ConcurrentMap []*ConcurrentMapShared// A &quot;thread&quot; safe string to anything map.type ConcurrentMapShared struct &#123; items map[string]interface&#123;&#125; sync.RWMutex // Read Write mutex, guards access to internal map.&#125; New12345678// Creates a new concurrent map.func New() ConcurrentMap &#123; m := make(ConcurrentMap, SHARD_COUNT) for i := 0; i &lt; SHARD_COUNT; i++ &#123; m[i] = &amp;ConcurrentMapShared&#123;items: make(map[string]interface&#123;&#125;)&#125; &#125; return m&#125; GetShard1234&#x2F;&#x2F; GetShard returns shard under given keyfunc (m ConcurrentMap) GetShard(key string) *ConcurrentMapShared &#123; return m[uint(fnv32(key))%uint(SHARD_COUNT)]&#125; Set12345678// Sets the given value under the specified key.func (m ConcurrentMap) Set(key string, value interface&#123;&#125;) &#123; // Get map shard. shard := m.GetShard(key) shard.Lock() shard.items[key] = value shard.Unlock()&#125; Get12345678910// Get retrieves an element from map under given key.func (m ConcurrentMap) Get(key string) (interface&#123;&#125;, bool) &#123; // Get shard shard := m.GetShard(key) shard.RLock() // Get item from shard. val, ok := shard.items[key] shard.RUnlock() return val, ok&#125; 总结 就是原生map+rwmutex的细化，这里分了32个map,通过hash落在一个map加锁，锁的粒度更小了，从而提升并发性能 主要函数就这几个，其他函数基本基于这个原则 sync.map主要针对读多写少的场景，写的时候会加mutex，并且可能刷新dirty，读的时候因为是atomic.value性能会好 concurrent map比较综合吧，更细粒度的锁对缓存数据库更友好","categories":[],"tags":[{"name":"golang","slug":"golang","permalink":"https://riverferry.site/tags/golang/"}],"keywords":[]},{"title":"golang atomic.value","slug":"2020-10-27-golang-atomic-value","date":"2020-10-27T00:00:00.000Z","updated":"2022-09-12T16:24:32.287Z","comments":true,"path":"2020-10-27-golang-atomic-value/","link":"","permalink":"https://riverferry.site/2020-10-27-golang-atomic-value/","excerpt":"Package atomic provides low-level atomic memory primitives useful for implementing synchronization algorithms. These functions require great care to be used correctly. Except for special, low-level applications, synchronization is better done with channels or the facilities of the sync package. Share memory by communicating; don’t communicate by sharing memory.","text":"Package atomic provides low-level atomic memory primitives useful for implementing synchronization algorithms. These functions require great care to be used correctly. Except for special, low-level applications, synchronization is better done with channels or the facilities of the sync package. Share memory by communicating; don’t communicate by sharing memory. atomic.value12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182// A Value provides an atomic load and store of a consistently typed value.// The zero value for a Value returns nil from Load.// Once Store has been called, a Value must not be copied.//// A Value must not be copied after first use.type Value struct &#123; v interface&#123;&#125;&#125;// Load returns the value set by the most recent Store.// It returns nil if there has been no call to Store for this Value.func (v *Value) Load() (x interface&#123;&#125;) &#123; vp := (*ifaceWords)(unsafe.Pointer(v)) typ := LoadPointer(&amp;vp.typ) if typ == nil || uintptr(typ) == ^uintptr(0) &#123; // First store not yet completed. return nil &#125; data := LoadPointer(&amp;vp.data) xp := (*ifaceWords)(unsafe.Pointer(&amp;x)) xp.typ = typ xp.data = data return&#125;// ifaceWords is interface&#123;&#125; internal representation.type ifaceWords struct &#123; typ unsafe.Pointer data unsafe.Pointer&#125;// Store sets the value of the Value to x.// All calls to Store for a given Value must use values of the same concrete type.// Store of an inconsistent type panics, as does Store(nil).func (v *Value) Store(x interface&#123;&#125;) &#123; if x == nil &#123; panic(&quot;sync/atomic: store of nil value into Value&quot;) &#125; vp := (*ifaceWords)(unsafe.Pointer(v)) //old value,类型一致，只改data xp := (*ifaceWords)(unsafe.Pointer(&amp;x)) //new value for &#123; //原子读 typ := LoadPointer(&amp;vp.typ) //case1 nil if typ == nil &#123; // Attempt to start first store. // Disable preemption so that other goroutines can use // active spin wait to wait for completion; and so that // GC does not see the fake type accidentally. runtime_procPin() //set 中间值 if !CompareAndSwapPointer(&amp;vp.typ, nil, unsafe.Pointer(^uintptr(0))) &#123; runtime_procUnpin() continue &#125; // Complete first store. //第一次存储，既要更新data,还要更新type，这里的type作为实际的类型 StorePointer(&amp;vp.data, xp.data) StorePointer(&amp;vp.typ, xp.typ) runtime_procUnpin() return &#125; //case2 ^uintptr(0) //第一阶段未完成,typ作为是否完成的标记 //第一阶段未完成，为什么会走下来？是异步的还是并发情况？ if uintptr(typ) == ^uintptr(0) &#123; // First store in progress. Wait. // Since we disable preemption around the first store, // we can wait with active spinning. continue &#125; // First store completed. Check type and overwrite data. //case3 类型不符 if typ != xp.typ &#123; panic(&quot;sync/atomic: store of inconsistently typed value into Value&quot;) &#125; StorePointer(&amp;vp.data, xp.data) return &#125;&#125; 总结 ifaceWords是interface的抽象，函数参数就是interface ^uintptr(0)作为一个中间值，用来保证原子性，读和写都会判断 Load()只是将value转换成ifaceWords类型并返回 runtime_procPin涉及调度，作为todo以后看到调度的部分了再补充 atomic是原子的，针对小的操作，保证不可中断。mutex是操作系统实现，通过原子性的判断锁标记来隔离其他进程/线程访问大的临界区，临界区内可中断。 reference[1]https://blog.betacat.io/post/golang-atomic-value-exploration/ [2]https://mp.weixin.qq.com/s/re_9CmGm3xEbY7xCr5CYbQ [3]https://www.quora.com/What-is-the-difference-between-Mutex-and-Atomic-Operation","categories":[],"tags":[{"name":"golang","slug":"golang","permalink":"https://riverferry.site/tags/golang/"}],"keywords":[]},{"title":"golang sync map","slug":"2020-10-26-golang-sync map","date":"2020-10-26T00:00:00.000Z","updated":"2022-09-12T16:24:32.287Z","comments":true,"path":"2020-10-26-golang-sync map/","link":"","permalink":"https://riverferry.site/2020-10-26-golang-sync%20map/","excerpt":"struct123456789101112131415// Map is like a Go map[interface&#123;&#125;]interface&#123;&#125; but is safe for concurrent use// by multiple goroutines without additional locking or coordination.// Loads, stores, and deletes run in amortized constant time.//// The Map type is specialized. Most code should use a plain Go map instead,// with separate locking or coordination, for better type safety and to make it// easier to maintain other invariants along with the map content.//// The Map type is optimized for two common use cases: (1) when the entry for a given// key is only ever written once but read many times, as in caches that only grow,// or (2) when multiple goroutines read, write, and overwrite entries for disjoint// sets of keys. In these two cases, use of a Map may significantly reduce lock// contention compared to a Go map paired with a separate Mutex or RWMutex.//// The zero Map is empty and ready for use. A Map must not be copied after first use.","text":"struct123456789101112131415// Map is like a Go map[interface&#123;&#125;]interface&#123;&#125; but is safe for concurrent use// by multiple goroutines without additional locking or coordination.// Loads, stores, and deletes run in amortized constant time.//// The Map type is specialized. Most code should use a plain Go map instead,// with separate locking or coordination, for better type safety and to make it// easier to maintain other invariants along with the map content.//// The Map type is optimized for two common use cases: (1) when the entry for a given// key is only ever written once but read many times, as in caches that only grow,// or (2) when multiple goroutines read, write, and overwrite entries for disjoint// sets of keys. In these two cases, use of a Map may significantly reduce lock// contention compared to a Go map paired with a separate Mutex or RWMutex.//// The zero Map is empty and ready for use. A Map must not be copied after first use. 1234567891011121314151617181920212223242526272829303132333435type Map struct &#123; mu Mutex // read contains the portion of the map&#x27;s contents that are safe for // concurrent access (with or without mu held). // // The read field itself is always safe to load, but must only be stored with // mu held. // // Entries stored in read may be updated concurrently without mu, but updating // a previously-expunged entry requires that the entry be copied to the dirty // map and unexpunged with mu held. read atomic.Value // readOnly // dirty contains the portion of the map&#x27;s contents that require mu to be // held. To ensure that the dirty map can be promoted to the read map quickly, // it also includes all of the non-expunged entries in the read map. // // Expunged entries are not stored in the dirty map. An expunged entry in the // clean map must be unexpunged and added to the dirty map before a new value // can be stored to it. // // If the dirty map is nil, the next write to the map will initialize it by // making a shallow copy of the clean map, omitting stale entries. dirty map[interface&#123;&#125;]*entry // misses counts the number of loads since the read map was last updated that // needed to lock mu to determine whether the key was present. // // Once enough misses have occurred to cover the cost of copying the dirty // map, the dirty map will be promoted to the read map (in the unamended // state) and the next store to the map will make a new dirty copy. misses int&#125; mapLoad()12345678910111213141516171819202122232425262728// Load returns the value stored in the map for a key, or nil if no// value is present.// The ok result indicates whether value was found in the map.func (m *Map) Load(key interface&#123;&#125;) (value interface&#123;&#125;, ok bool) &#123; read, _ := m.read.Load().(readOnly) e, ok := read.m[key] if !ok &amp;&amp; read.amended &#123; m.mu.Lock() // Avoid reporting a spurious miss if m.dirty got promoted while we were // blocked on m.mu. (If further loads of the same key will not miss, it&#x27;s // not worth copying the dirty map for this key.) read, _ = m.read.Load().(readOnly) e, ok = read.m[key] if !ok &amp;&amp; read.amended &#123; e, ok = m.dirty[key] // Regardless of whether the entry was present, record a miss: this key // will take the slow path until the dirty map is promoted to the read // map. m.missLocked() &#125; m.mu.Unlock() &#125; if !ok &#123; return nil, false &#125; return e.load()&#125; note 先从read查，查到就直接返回。查不到并且read.amended=true(dirty!=read)再去dirty中查，查dirty要加互斥锁。 这里用到了两次查询，参考单例的设计。 read是atomic.value类型的，atomic.value的Load/Store是线程安全的，所以不用加锁，读性能比较好。但是其实也用到了cas,所以也用到了lock指令，不是完全无锁定的。 demo123456789101112131415161718192021222324252627282930package mainimport ( &quot;fmt&quot; &quot;sync&quot; &quot;sync/atomic&quot;)type Map struct &#123; mu sync.Mutex read atomic.Value // readOnly dirty map[interface&#123;&#125;]*int misses int&#125;type readOnly struct &#123; m map[interface&#123;&#125;]*int amended bool // true if the dirty map contains some key not in m.&#125;func main() &#123; m := Map&#123;&#125; //fmt.Println(m.read.Load().(readOnly)) //panic fmt.Println(m.read.Load()) //&lt;nil&gt; var v interface&#123;&#125; read, _ := (v).(readOnly) fmt.Println(read) //&#123;map[] false&#125;&#125; Store()1234567891011121314151617181920212223242526272829303132333435363738394041424344// Store sets the value for a key.func (m *Map) Store(key, value interface&#123;&#125;) &#123; read, _ := m.read.Load().(readOnly) //先从read读，读成功再尝试store更新 //tryStore先load,如果标记为expunged则ret false, ow store if e, ok := read.m[key]; ok &amp;&amp; e.tryStore(&amp;value) &#123; return &#125; //read读不到则store到dirty，要加锁 m.mu.Lock() read, _ = m.read.Load().(readOnly) //两次读，第2次读到了 if e, ok := read.m[key]; ok &#123; //unexpungeLocked：如果e.p=expunged，则set e.p=nil if e.unexpungeLocked() &#123; // The entry was previously expunged, which implies that there is a // non-nil dirty map and this entry is not in it. m.dirty[key] = e &#125; //atomic.StorePointer 更新entry e.storeLocked(&amp;value) //dirty中有，则更新 &#125; else if e, ok := m.dirty[key]; ok &#123; e.storeLocked(&amp;value) //read/dirty都没有 //新增数据 &#125; else &#123; //并且read.amended=0 if !read.amended &#123; // We&#x27;re adding the first new key to the dirty map. // Make sure it is allocated and mark the read-only map as incomplete. //如果dirty=nil,则把read(未删除的)拷贝给dirty //初始化后第一次store会进入这里，或者misscount&gt;=len(dirty)也会进来重新刷新dirty. m.dirtyLocked() //更新了amended m.read.Store(readOnly&#123;m: read.m, amended: true&#125;) &#125; //新增entry并加到dirty m.dirty[key] = newEntry(value) &#125; m.mu.Unlock()&#125; note 任何值可以赋值给空接口的值，空接口的值也可以赋值给任何值 第一次新增和misscount达到限制都会刷新dirty(吧read赋值给dirty,如果read为空，这一步就提前ret) store包含了更新和新增 这里加锁是给m.dirty加锁，加锁是内核的调度器执行的主要用于大的复合对象/临界区，原子操作是硬件指令主要针对单个值 (新增元素或者刷新dirty的时候)tryExpungeLocked将nil的标记为已删除expunged，新增entry的时候read如果能读到，unexpungeLocked对于expunged又改为nil并更新dirty demomissLocked123456789func (m *Map) missLocked() &#123; m.misses++ if m.misses &lt; len(m.dirty) &#123; return &#125; m.read.Store(readOnly&#123;m: m.dirty&#125;) m.dirty = nil m.misses = 0&#125; LoadOrStore1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950// LoadOrStore returns the existing value for the key if present.// Otherwise, it stores and returns the given value.// The loaded result is true if the value was loaded, false if stored.func (m *Map) LoadOrStore(key, value interface&#123;&#125;) (actual interface&#123;&#125;, loaded bool) &#123; // Avoid locking if it&#x27;s a clean hit. read, _ := m.read.Load().(readOnly) //如果read里面有 if e, ok := read.m[key]; ok &#123; //tryLoadOrStore逻辑： //tryLoadOrStore:先load //if e.p=expunged, ret nil, false, false //if e.p=nil, 返回原来的值，true, true //else store，return value, false, true actual, loaded, ok := e.tryLoadOrStore(value) if ok &#123; return actual, loaded &#125; //如果read读到了，并且e.p=expunged,则往下执行，走dirty &#125; m.mu.Lock() read, _ = m.read.Load().(readOnly) //如果从read读到 if e, ok := read.m[key]; ok &#123; //unexpungeLocked: return atomic.CompareAndSwapPointer(&amp;e.p, expunged, nil) if e.unexpungeLocked() &#123; //If the entry was previously expunged, it must be added to the dirty map //before m.mu is unlocked. m.dirty[key] = e &#125; actual, loaded, _ = e.tryLoadOrStore(value) //如果从dirty读到 &#125; else if e, ok := m.dirty[key]; ok &#123; actual, loaded, _ = e.tryLoadOrStore(value) m.missLocked() &#125; else &#123; if !read.amended &#123; // We&#x27;re adding the first new key to the dirty map. // Make sure it is allocated and mark the read-only map as incomplete. m.dirtyLocked() m.read.Store(readOnly&#123;m: read.m, amended: true&#125;) &#125; m.dirty[key] = newEntry(value) actual, loaded = value, false &#125; m.mu.Unlock() return actual, loaded&#125; noteload和store的结合体，不赘述 Delete1234// Delete deletes the value for a key.func (m *Map) Delete(key interface&#123;&#125;) &#123; m.LoadAndDelete(key)&#125; LoadAndDelete1234567891011121314151617181920212223242526// LoadAndDelete deletes the value for a key, returning the previous value if any.// The loaded result reports whether the key was present.func (m *Map) LoadAndDelete(key interface&#123;&#125;) (value interface&#123;&#125;, loaded bool) &#123; read, _ := m.read.Load().(readOnly) e, ok := read.m[key] if !ok &amp;&amp; read.amended &#123; m.mu.Lock() read, _ = m.read.Load().(readOnly) e, ok = read.m[key] if !ok &amp;&amp; read.amended &#123; e, ok = m.dirty[key] delete(m.dirty, key) // Regardless of whether the entry was present, record a miss: this key // will take the slow path until the dirty map is promoted to the read // map. m.missLocked() &#125; m.mu.Unlock() &#125; if ok &#123; //if e.p=nil/expunged,ret //else set e.p = nil return e.delete() &#125; return nil, false&#125; note 如果read中找到了，直接在read标记删除，否则才去找dirty read的删除，对于nil/expunged直接ret,不然标记为nil dirty的删除，才是真的删除 删除dirty也会使misscount+1 Range12345678910111213141516171819202122232425262728293031323334353637383940414243// Range calls f sequentially for each key and value present in the map.// If f returns false, range stops the iteration.//// Range does not necessarily correspond to any consistent snapshot of the Map&#x27;s// contents: no key will be visited more than once, but if the value for any key// is stored or deleted concurrently, Range may reflect any mapping for that key// from any point during the Range call.//// Range may be O(N) with the number of elements in the map even if f returns// false after a constant number of calls.func (m *Map) Range(f func(key, value interface&#123;&#125;) bool) &#123; // We need to be able to iterate over all of the keys that were already // present at the start of the call to Range. // If read.amended is false, then read.m satisfies that property without // requiring us to hold m.mu for a long time. read, _ := m.read.Load().(readOnly) if read.amended &#123; // m.dirty contains keys not in read.m. Fortunately, Range is already O(N) // (assuming the caller does not break out early), so a call to Range // amortizes an entire copy of the map: we can promote the dirty copy // immediately! m.mu.Lock() read, _ = m.read.Load().(readOnly) if read.amended &#123; //如果dirty有新数据，则先同步到read在range read = readOnly&#123;m: m.dirty&#125; m.read.Store(read) m.dirty = nil m.misses = 0 &#125; m.mu.Unlock() &#125; for k, e := range read.m &#123; v, ok := e.load() if !ok &#123; continue &#125; if !f(k, v) &#123; break &#125; &#125;&#125; dirtyLocked12345678910111213func (m *Map) dirtyLocked() &#123; if m.dirty != nil &#123; return &#125; read, _ := m.read.Load().(readOnly) m.dirty = make(map[interface&#123;&#125;]*entry, len(read.m)) for k, e := range read.m &#123; if !e.tryExpungeLocked() &#123; m.dirty[k] = e &#125; &#125;&#125; entry1234567891011121314151617181920212223// An entry is a slot in the map corresponding to a particular key.type entry struct &#123; // p points to the interface&#123;&#125; value stored for the entry. // // If p == nil, the entry has been deleted and m.dirty == nil. // // If p == expunged, the entry has been deleted, m.dirty != nil, and the entry // is missing from m.dirty. // // Otherwise, the entry is valid and recorded in m.read.m[key] and, if m.dirty // != nil, in m.dirty[key]. // // An entry can be deleted by atomic replacement with nil: when m.dirty is // next created, it will atomically replace nil with expunged and leave // m.dirty[key] unset. // // An entry&#x27;s associated value can be updated by atomic replacement, provided // p != expunged. If p == expunged, an entry&#x27;s associated value can be updated // only after first setting m.dirty[key] = e so that lookups using the dirty // map find the entry. p unsafe.Pointer // *interface&#123;&#125;&#125; tryStore123456789101112131415// tryStore stores a value if the entry has not been expunged.//// If the entry is expunged, tryStore returns false and leaves the entry// unchanged.func (e *entry) tryStore(i *interface&#123;&#125;) bool &#123; for &#123; p := atomic.LoadPointer(&amp;e.p) if p == expunged &#123; return false &#125; if atomic.CompareAndSwapPointer(&amp;e.p, p, unsafe.Pointer(i)) &#123; return true &#125; &#125;&#125; unexpungeLocked1234567// unexpungeLocked ensures that the entry is not marked as expunged.//// If the entry was previously expunged, it must be added to the dirty map// before m.mu is unlocked.func (e *entry) unexpungeLocked() (wasExpunged bool) &#123; return atomic.CompareAndSwapPointer(&amp;e.p, expunged, nil)&#125; storeLocked123456// storeLocked unconditionally stores a value to the entry.//// The entry must be known not to be expunged.func (e *entry) storeLocked(i *interface&#123;&#125;) &#123; atomic.StorePointer(&amp;e.p, unsafe.Pointer(i))&#125; tryLoadOrStore12345678910111213141516171819202122232425262728293031// tryLoadOrStore atomically loads or stores a value if the entry is not// expunged.//// If the entry is expunged, tryLoadOrStore leaves the entry unchanged and// returns with ok==false.func (e *entry) tryLoadOrStore(i interface&#123;&#125;) (actual interface&#123;&#125;, loaded, ok bool) &#123; p := atomic.LoadPointer(&amp;e.p) if p == expunged &#123; return nil, false, false &#125; if p != nil &#123; return *(*interface&#123;&#125;)(p), true, true &#125; // Copy the interface after the first load to make this method more amenable // to escape analysis: if we hit the &quot;load&quot; path or the entry is expunged, we // shouldn&#x27;t bother heap-allocating. ic := i for &#123; if atomic.CompareAndSwapPointer(&amp;e.p, nil, unsafe.Pointer(&amp;ic)) &#123; return i, false, true &#125; p = atomic.LoadPointer(&amp;e.p) if p == expunged &#123; return nil, false, false &#125; if p != nil &#123; return *(*interface&#123;&#125;)(p), true, true &#125; &#125;&#125; delete1234567891011func (e *entry) delete() (value interface&#123;&#125;, ok bool) &#123; for &#123; p := atomic.LoadPointer(&amp;e.p) if p == nil || p == expunged &#123; return nil, false &#125; if atomic.CompareAndSwapPointer(&amp;e.p, p, nil) &#123; return *(*interface&#123;&#125;)(p), true &#125; &#125;&#125; tryExpungeLocked12345678910func (e *entry) tryExpungeLocked() (isExpunged bool) &#123; p := atomic.LoadPointer(&amp;e.p) for p == nil &#123; if atomic.CompareAndSwapPointer(&amp;e.p, nil, expunged) &#123; return true &#125; p = atomic.LoadPointer(&amp;e.p) &#125; return p == expunged&#125; 总结 misscount达到阈值，将dirty刷回read,set dirty=nil 新增元素的时候(区别与修改)，如果amend=false,则将read刷回dirty reference[1]https://colobu.com/2017/07/11/dive-into-sync-Map/ [2]https://draveness.me/golang/docs/part2-foundation/ch03-datastructure/golang-hashmap/ [3]https://juejin.im/post/6844903895227957262","categories":[],"tags":[{"name":"golang","slug":"golang","permalink":"https://riverferry.site/tags/golang/"}],"keywords":[]},{"title":"golang mutex","slug":"2020-10-22-golang-mutex","date":"2020-10-22T00:00:00.000Z","updated":"2022-09-12T16:24:32.287Z","comments":true,"path":"2020-10-22-golang-mutex/","link":"","permalink":"https://riverferry.site/2020-10-22-golang-mutex/","excerpt":"下面这段注释很重要。简单翻一下： Mutex有2种模式：normal/starvation 。 正常模式下的waiter是排成fifo的队列，但是被唤醒的waiter遇到刚运行的goroutine(有更高的优先级)是竞争不过mutex的所有权的。这时候这个waiter就在queue的head等待。如果超过1ms还没拿到锁，就切换成饥饿模式。其实就是做补偿处理，防止饿死 在饥饿模式下，mutex的所有权从未加锁的goroutine直接传递给queue头部的那个饥饿模式下的waiter.新的goroutine不会尝试获取锁，不会自旋。而是将自己放到了queue的tail.所以这里是挂起了自己？ 对于一个拿到mutex所有权的waiter,有两种情况：1&gt;这个waiter是queue的最后一个 2&gt;这个waiter获取所有权不超过1ms,满足其一则将模式切换回Normal 普通模式下应该考虑到一个goroutine可能一直尝试获取mutext很多次，即使已经有很多被阻塞的waiters. starvation对于饿死情况有很好的的补偿处理","text":"下面这段注释很重要。简单翻一下： Mutex有2种模式：normal/starvation 。 正常模式下的waiter是排成fifo的队列，但是被唤醒的waiter遇到刚运行的goroutine(有更高的优先级)是竞争不过mutex的所有权的。这时候这个waiter就在queue的head等待。如果超过1ms还没拿到锁，就切换成饥饿模式。其实就是做补偿处理，防止饿死 在饥饿模式下，mutex的所有权从未加锁的goroutine直接传递给queue头部的那个饥饿模式下的waiter.新的goroutine不会尝试获取锁，不会自旋。而是将自己放到了queue的tail.所以这里是挂起了自己？ 对于一个拿到mutex所有权的waiter,有两种情况：1&gt;这个waiter是queue的最后一个 2&gt;这个waiter获取所有权不超过1ms,满足其一则将模式切换回Normal 普通模式下应该考虑到一个goroutine可能一直尝试获取mutext很多次，即使已经有很多被阻塞的waiters. starvation对于饿死情况有很好的的补偿处理 1234567891011121314151617181920212223242526272829303132const ( mutexLocked = 1 &lt;&lt; iota // mutex is locked mutexWoken mutexStarving mutexWaiterShift = iota // Mutex fairness. // // Mutex can be in 2 modes of operations: normal and starvation. // In normal mode waiters are queued in FIFO order, but a woken up waiter // does not own the mutex and competes with new arriving goroutines over // the ownership. New arriving goroutines have an advantage -- they are // already running on CPU and there can be lots of them, so a woken up // waiter has good chances of losing. In such case it is queued at front // of the wait queue. If a waiter fails to acquire the mutex for more than 1ms, // it switches mutex to the starvation mode. // // In starvation mode ownership of the mutex is directly handed off from // the unlocking goroutine to the waiter at the front of the queue. // New arriving goroutines don&#x27;t try to acquire the mutex even if it appears // to be unlocked, and don&#x27;t try to spin. Instead they queue themselves at // the tail of the wait queue. // // If a waiter receives ownership of the mutex and sees that either // (1) it is the last waiter in the queue, or (2) it waited for less than 1 ms, // it switches mutex back to normal operation mode. // // Normal mode has considerably better performance as a goroutine can acquire // a mutex several times in a row even if there are blocked waiters. // Starvation mode is important to prevent pathological cases of tail latency. starvationThresholdNs = 1e6) Lock()1234567891011121314151617181920212223242526// Lock locks m.// If the lock is already in use, the calling goroutine// blocks until the mutex is available.func (m *Mutex) Lock() &#123; // Fast path: grab unlocked mutex. // CompareAndSwapInt32 executes the compare-and-swap operation for an int32 value. //如果m未加锁，则加锁 if atomic.CompareAndSwapInt32(&amp;m.state, 0, mutexLocked) &#123; if race.Enabled &#123; //race是做竞争检测的 race.Acquire(unsafe.Pointer(m)) &#125; return &#125; // Slow path (outlined so that the fast path can be inlined) m.lockSlow()&#125;// A Mutex is a mutual exclusion lock.// The zero value for a Mutex is an unlocked mutex.//// A Mutex must not be copied after first use.type Mutex struct &#123; state int32 //0:unlock 1:lock sema uint32&#125; cascompare-and-swap是原子操作的一种，可用于在多线程编程中实现不被打断的数据交换操作，从而避免多线程同时改写某一数据时由于执行顺序不确定性以及中断的不可预知性产生的数据不一致问题。 该操作通过将内存中的值与指定数据进行比较，当数值一样时将内存中的数据替换为新的值。 wiki上的一个伪代码例子： 12345678int cas(long *addr, long old, long new)&#123; /* Executes atomically. */ if(*addr != old) return 0; *addr = new; return 1;&#125; cas的底层实现是cmpxchg,类似的指令还有xchg,xadd等。cas的原理是判断内存地址的值和存的旧值是否相等，如果相等就认为没有被修改过，是原子安全的。就把新值set进去。但这里有个问题，即旧值被修改了&gt;=2次，最终和原来的值保持一致，就造成了误判，也就是ABA问题，参考wiki.所以使用的时候，cmpxchg在多cpu下需要加lock前缀，锁住内存总线或者对应的内存地址，具体的处理方法细节太底层不捉摸了。(unicore下就不用加lock了？在单核下，只有中断会打断进程的执行，但不会打断一条指令的执行，所以单个cmpxchg指令是原子的。) On a single-CPU system, cmpxchg is atomic with respect to other threads, or any other code running on the same CPU core. (But not to “system” observers like a memory-mapped I/O device, or a device doing DMA reads of normal memory, so lock cmpxchg was relevant even on uniprocessor CPU designs). Context switches can only happen on interrupts, and interrupts happen before or after an instruction, not in the middle. Any code running on the same CPU will see the cmpxchg as either fully executed or not at all. https://stackoverflow.com/questions/27837731/is-x86-cmpxchg-atomic-if-so-why-does-it-need-lock/44273130#44273130 需要注意的是，xchg是inter x86底层的一个实现了tsl的指令。其包含了一个隐含的lock指令，而不像cmpxchg是需要手动在必要情况下添加lock的。这两个的性能好像也没啥区别，参考:https://software.intel.com/content/www/us/en/develop/articles/implementing-scalable-atomic-locks-for-multi-core-intel-em64t-and-ia32-architectures.html CompareAndSwapInt32实现的源代码在https://github.com/golang/go/blob/master/src/runtime/internal/atomic/asm_amd64.s,就是通过lock+cmpxchg实现的。 lockSlow123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124func (m *Mutex) lockSlow() &#123; var waitStartTime int64 starving := false awoke := false iter := 0 old := m.state for &#123; // Don&#x27;t spin in starvation mode, ownership is handed off to waiters // so we won&#x27;t be able to acquire the mutex anyway. //前面说过了饥饿模式下是通过其他goroutine把mutex转交过来的，所以饥饿模式下不用再去申请锁了 //这里判断是普通模式下，处于锁定状态，然后runtime_canSpin判断能否进入自旋 //old&amp;mutexStarving=0 //old&amp;mutexLocked=1 //old:0*1 --&gt; old &amp; 101 = 001 if old&amp;(mutexLocked|mutexStarving) == mutexLocked &amp;&amp; runtime_canSpin(iter) &#123; // Active spinning makes sense. // Try to set mutexWoken flag to inform Unlock // to not wake other blocked goroutines. if !awoke &amp;&amp; old&amp;mutexWoken == 0 &amp;&amp; old&gt;&gt;mutexWaiterShift != 0 &amp;&amp; atomic.CompareAndSwapInt32(&amp;m.state, old, old|mutexWoken) &#123; awoke = true &#125; runtime_doSpin() iter++ old = m.state continue &#125; //走到这有3个case //1: old=0*0 普通模式，unlock //2: old=1*1 饥饿模式，lock //3: old=1*0 饥饿模式，unlock new := old // Don&#x27;t try to acquire starving mutex, new arriving goroutines must queue. //old=0*0,不是饥饿模式，说明mutex是unlock,则吧mutexLocked加锁标记加上,-&gt;0*1 if old&amp;mutexStarving == 0 &#123; new |= mutexLocked &#125; //old &amp; 101 != 000 , old = 0*0不进入if，不给mutexWaiterShift置位 if old&amp;(mutexLocked|mutexStarving) != 0 &#123; //new += (1&lt;&lt;3) //等待队列+1 new += 1 &lt;&lt; mutexWaiterShift &#125; // The current goroutine switches mutex to starvation mode. // But if the mutex is currently unlocked, don&#x27;t do the switch. // Unlock expects that starving mutex has waiters, which will not // be true in this case. //第一次循环starving=false //上一次被唤醒等待超过1m，starving为true了。这一次自旋获取锁失败，则进入饥饿模式 if starving &amp;&amp; old&amp;mutexLocked != 0 &#123; new |= mutexStarving &#125; if awoke &#123; // The goroutine has been woken from sleep, // so we need to reset the flag in either case. if new&amp;mutexWoken == 0 &#123; throw(&quot;sync: inconsistent mutex state&quot;) &#125; //已经被唤醒了，置mutexWoken=0 new &amp;^= mutexWoken &#125; //更新m.state if atomic.CompareAndSwapInt32(&amp;m.state, old, new) &#123; //old=000 //普通模式，前面new已经加了上锁标记了，所以cas后退出循环，拿锁成功 if old&amp;(mutexLocked|mutexStarving) == 0 &#123; break // locked the mutex with CAS &#125; //走到这里只能是饥饿模式 // If we were already waiting before, queue at the front of the queue. queueLifo := waitStartTime != 0 // if waitStartTime == 0 &#123; //设置为当前时间 waitStartTime = runtime_nanotime() &#125; //获取信号量 //queueLifo=false,g是新执行的,加入队列tail //queueLifo=true,g是被唤醒的,加入队列head runtime_SemacquireMutex(&amp;m.sema, queueLifo, 1) //等待超过1秒,设置为饥饿模式，给下一次循环用的 starving = starving || runtime_nanotime()-waitStartTime &gt; starvationThresholdNs old = m.state //饥饿模式下 if old&amp;mutexStarving != 0 &#123; // If this goroutine was woken and mutex is in starvation mode, // ownership was handed off to us but mutex is in somewhat // inconsistent state: mutexLocked is not set and we are still // accounted as waiter. Fix that. //case1&gt; old(1**) &amp; 011 != 0, old ！= 100为真 //case2&gt; old&gt;&gt;mutexWaiterShift == 0,表示old=0*0 //old = 100 &amp;&amp; old != 0*0,才不抛异常;等待队列为空 if old&amp;(mutexLocked|mutexWoken) != 0 || old&gt;&gt;mutexWaiterShift == 0 &#123; throw(&quot;sync: inconsistent mutex state&quot;) &#125; //old = 100 //等待队列-1并获取锁 delta := int32(mutexLocked - 1&lt;&lt;mutexWaiterShift) //已经不是饥饿模式了，或者waiter queue只剩下一个了 if !starving || old&gt;&gt;mutexWaiterShift == 1 &#123; // Exit starvation mode. // Critical to do it here and consider wait time. // Starvation mode is so inefficient, that two goroutines // can go lock-step infinitely once they switch mutex // to starvation mode. //退出starving delta -= mutexStarving &#125; //原子add操作 atomic.AddInt32(&amp;m.state, delta) break &#125; awoke = true iter = 0 &#125; else &#123; old = m.state &#125; &#125; if race.Enabled &#123; race.Acquire(unsafe.Pointer(m)) &#125;&#125; unlock123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263// Unlock unlocks m.// It is a run-time error if m is not locked on entry to Unlock.//// A locked Mutex is not associated with a particular goroutine.// It is allowed for one goroutine to lock a Mutex and then// arrange for another goroutine to unlock it.func (m *Mutex) Unlock() &#123; if race.Enabled &#123; _ = m.state race.Release(unsafe.Pointer(m)) &#125; // Fast path: drop lock bit. new := atomic.AddInt32(&amp;m.state, -mutexLocked) if new != 0 &#123; // Outlined slow path to allow inlining the fast path. // To hide unlockSlow during tracing we skip one extra frame when tracing GoUnblock. m.unlockSlow(new) &#125;&#125;func (m *Mutex) unlockSlow(new int32) &#123; if (new+mutexLocked)&amp;mutexLocked == 0 &#123; throw(&quot;sync: unlock of unlocked mutex&quot;) &#125; //普通模式 if new&amp;mutexStarving == 0 &#123; old := new for &#123; // If there are no waiters or a goroutine has already // been woken or grabbed the lock, no need to wake anyone. // In starvation mode ownership is directly handed off from unlocking // goroutine to the next waiter. We are not part of this chain, // since we did not observe mutexStarving when we unlocked the mutex above. // So get off the way. //等待队列为空或者 old &amp; 111 != 0即old != 000,至少1位是1，抢到锁/被唤醒/饥饿模式下不用唤醒 if old&gt;&gt;mutexWaiterShift == 0 || old&amp;(mutexLocked|mutexWoken|mutexStarving) != 0 &#123; return &#125; // Grab the right to wake someone. //等待队列-1，置位mutexWoken //先更新m.state，再唤醒 new = (old - 1&lt;&lt;mutexWaiterShift) | mutexWoken if atomic.CompareAndSwapInt32(&amp;m.state, old, new) &#123; runtime_Semrelease(&amp;m.sema, false, 1) return &#125; old = m.state &#125; //饥饿模式 &#125; else &#123; // Starving mode: handoff mutex ownership to the next waiter, and yield // our time slice so that the next waiter can start to run immediately. // Note: mutexLocked is not set, the waiter will set it after wakeup. // But mutex is still considered locked if mutexStarving is set, // so new coming goroutines won&#x27;t acquire it. //饥饿模式下，将所有权交给head的waiter，waiter置位mutexlock //不用更新m.state,直接唤醒 runtime_Semrelease(&amp;m.sema, true, 1) &#125;&#125; reference[1]https://studygolang.com/articles/17017 [2]https://studygolang.com/articles/25155 [3]https://draveness.me/golang/docs/part3-runtime/ch06-concurrency/golang-sync-primitives/","categories":[],"tags":[{"name":"golang","slug":"golang","permalink":"https://riverferry.site/tags/golang/"}],"keywords":[]},{"title":"bloom filter","slug":"2020-10-24-bloom-filter","date":"2020-10-22T00:00:00.000Z","updated":"2022-09-12T16:24:32.287Z","comments":true,"path":"2020-10-24-bloom-filter/","link":"","permalink":"https://riverferry.site/2020-10-24-bloom-filter/","excerpt":"","text":"reference[1]https://www.wmyskxz.com/2020/03/11/redis-5-yi-ji-shu-ju-guo-lu-he-bu-long-guo-lu-qi/ [2]https://github.com/willf/bloom/blob/master/bloom.go [3]https://blog.huoding.com/2020/06/22/825 [4]https://zhuanlan.zhihu.com/p/43263751 [5]http://oserror.com/backend/bloomfilter/","categories":[],"tags":[],"keywords":[]},{"title":"golang channel","slug":"2020-10-21-golang-channel","date":"2020-10-21T00:00:00.000Z","updated":"2022-09-12T16:24:32.286Z","comments":true,"path":"2020-10-21-golang-channel/","link":"","permalink":"https://riverferry.site/2020-10-21-golang-channel/","excerpt":"channel数据结构使用了有锁队列(mutex+双向链表)，区别于runtime sema的mutex+[]treap,主要差异是对于锁和等待队列的实现。睡眠和唤醒都是goready和gppark来实现的，代码版本go version go1.15.2 darwin/amd64","text":"channel数据结构使用了有锁队列(mutex+双向链表)，区别于runtime sema的mutex+[]treap,主要差异是对于锁和等待队列的实现。睡眠和唤醒都是goready和gppark来实现的，代码版本go version go1.15.2 darwin/amd64 demo123456789101112131415161718192021package mainimport ( &quot;fmt&quot; &quot;time&quot;)// Main functionfunc main() &#123; ch := make(chan int) go func() &#123; time.Sleep(2 * time.Second) close(ch) &#125;() select &#123; case &lt;-ch: fmt.Println(&quot;recv!&quot;) &#125;&#125; close后会触发读。 struct12345678910111213141516171819202122232425type hchan struct &#123; qcount uint // total data in the queue dataqsiz uint // size of the circular queue buf unsafe.Pointer // points to an array of dataqsiz elements elemsize uint16 closed uint32 elemtype *_type // element type sendx uint // send index recvx uint // receive index recvq waitq // list of recv waiters sendq waitq // list of send waiters // lock protects all fields in hchan, as well as several // fields in sudogs blocked on this channel. // // Do not change another G&#x27;s status while holding this lock // (in particular, do not ready a G), as this can deadlock // with stack shrinking. lock mutex&#125;type waitq struct &#123; first *sudog last *sudog&#125; chansend123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139/* * generic single channel send/recv * If block is not nil, * then the protocol will not * sleep but return if it could * not complete. * * sleep can wake up with g.param == nil * when a channel involved in the sleep has * been closed. it is easiest to loop and re-run * the operation; we&#x27;ll see that it&#x27;s now closed. */func chansend(c *hchan, ep unsafe.Pointer, block bool, callerpc uintptr) bool &#123; if c == nil &#123; if !block &#123; return false &#125; gopark(nil, nil, waitReasonChanSendNilChan, traceEvGoStop, 2) throw(&quot;unreachable&quot;) &#125; if debugChan &#123; print(&quot;chansend: chan=&quot;, c, &quot;\\n&quot;) &#125; if raceenabled &#123; racereadpc(c.raceaddr(), callerpc, funcPC(chansend)) &#125; // Fast path: check for failed non-blocking operation without acquiring the lock. // // After observing that the channel is not closed, we observe that the channel is // not ready for sending. Each of these observations is a single word-sized read // (first c.closed and second full()). // Because a closed channel cannot transition from &#x27;ready for sending&#x27; to // &#x27;not ready for sending&#x27;, even if the channel is closed between the two observations, // they imply a moment between the two when the channel was both not yet closed // and not ready for sending. We behave as if we observed the channel at that moment, // and report that the send cannot proceed. // // It is okay if the reads are reordered here: if we observe that the channel is not // ready for sending and then observe that it is not closed, that implies that the // channel wasn&#x27;t closed during the first observation. However, nothing here // guarantees forward progress. We rely on the side effects of lock release in // chanrecv() and closechan() to update this thread&#x27;s view of c.closed and full(). if !block &amp;&amp; c.closed == 0 &amp;&amp; full(c) &#123; return false &#125; var t0 int64 if blockprofilerate &gt; 0 &#123; t0 = cputicks() &#125; //有锁队列 lock(&amp;c.lock) if c.closed != 0 &#123; unlock(&amp;c.lock) panic(plainError(&quot;send on closed channel&quot;)) &#125; //case1: 有等待者，则唤醒 if sg := c.recvq.dequeue(); sg != nil &#123; // Found a waiting receiver. We pass the value we want to send // directly to the receiver, bypassing the channel buffer (if any). send(c, sg, ep, func() &#123; unlock(&amp;c.lock) &#125;, 3) return true &#125; //case2: 没有等待者并且缓冲区未满，则写缓冲区 if c.qcount &lt; c.dataqsiz &#123; // Space is available in the channel buffer. Enqueue the element to send. qp := chanbuf(c, c.sendx) if raceenabled &#123; raceacquire(qp) racerelease(qp) &#125; typedmemmove(c.elemtype, qp, ep) c.sendx++ if c.sendx == c.dataqsiz &#123; c.sendx = 0 &#125; c.qcount++ unlock(&amp;c.lock) return true &#125; if !block &#123; unlock(&amp;c.lock) return false &#125; //case3: 没有等待者，缓冲区已满 则gopark挂起 // Block on the channel. Some receiver will complete our operation for us. gp := getg() mysg := acquireSudog() mysg.releasetime = 0 if t0 != 0 &#123; mysg.releasetime = -1 &#125; // No stack splits between assigning elem and enqueuing mysg // on gp.waiting where copystack can find it. mysg.elem = ep mysg.waitlink = nil mysg.g = gp mysg.isSelect = false mysg.c = c gp.waiting = mysg gp.param = nil c.sendq.enqueue(mysg) gopark(chanparkcommit, unsafe.Pointer(&amp;c.lock), waitReasonChanSend, traceEvGoBlockSend, 2) // Ensure the value being sent is kept alive until the // receiver copies it out. The sudog has a pointer to the // stack object, but sudogs aren&#x27;t considered as roots of the // stack tracer. KeepAlive(ep) // someone woke us up. if mysg != gp.waiting &#123; throw(&quot;G waiting list is corrupted&quot;) &#125; gp.waiting = nil gp.activeStackChans = false if gp.param == nil &#123; if c.closed == 0 &#123; throw(&quot;chansend: spurious wakeup&quot;) &#125; panic(plainError(&quot;send on closed channel&quot;)) &#125; gp.param = nil if mysg.releasetime &gt; 0 &#123; blockevent(mysg.releasetime-t0, 2) &#125; mysg.c = nil releaseSudog(mysg) return true&#125; chanrecv123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145// chanrecv receives on channel c and writes the received data to ep.// ep may be nil, in which case received data is ignored.// If block == false and no elements are available, returns (false, false).// Otherwise, if c is closed, zeros *ep and returns (true, false).// Otherwise, fills in *ep with an element and returns (true, true).// A non-nil ep must point to the heap or the caller&#x27;s stack.func chanrecv(c *hchan, ep unsafe.Pointer, block bool) (selected, received bool) &#123; // raceenabled: don&#x27;t need to check ep, as it is always on the stack // or is new memory allocated by reflect. if debugChan &#123; print(&quot;chanrecv: chan=&quot;, c, &quot;\\n&quot;) &#125; if c == nil &#123; if !block &#123; return &#125; gopark(nil, nil, waitReasonChanReceiveNilChan, traceEvGoStop, 2) throw(&quot;unreachable&quot;) &#125; // Fast path: check for failed non-blocking operation without acquiring the lock. if !block &amp;&amp; empty(c) &#123; // After observing that the channel is not ready for receiving, we observe whether the // channel is closed. // // Reordering of these checks could lead to incorrect behavior when racing with a close. // For example, if the channel was open and not empty, was closed, and then drained, // reordered reads could incorrectly indicate &quot;open and empty&quot;. To prevent reordering, // we use atomic loads for both checks, and rely on emptying and closing to happen in // separate critical sections under the same lock. This assumption fails when closing // an unbuffered channel with a blocked send, but that is an error condition anyway. if atomic.Load(&amp;c.closed) == 0 &#123; // Because a channel cannot be reopened, the later observation of the channel // being not closed implies that it was also not closed at the moment of the // first observation. We behave as if we observed the channel at that moment // and report that the receive cannot proceed. return &#125; // The channel is irreversibly closed. Re-check whether the channel has any pending data // to receive, which could have arrived between the empty and closed checks above. // Sequential consistency is also required here, when racing with such a send. if empty(c) &#123; // The channel is irreversibly closed and empty. if raceenabled &#123; raceacquire(c.raceaddr()) &#125; if ep != nil &#123; typedmemclr(c.elemtype, ep) &#125; return true, false &#125; &#125; var t0 int64 if blockprofilerate &gt; 0 &#123; t0 = cputicks() &#125; lock(&amp;c.lock) if c.closed != 0 &amp;&amp; c.qcount == 0 &#123; if raceenabled &#123; raceacquire(c.raceaddr()) &#125; unlock(&amp;c.lock) if ep != nil &#123; typedmemclr(c.elemtype, ep) &#125; return true, false &#125; //case1: 有发送者阻塞，直接接受 if sg := c.sendq.dequeue(); sg != nil &#123; // Found a waiting sender. If buffer is size 0, receive value // directly from sender. Otherwise, receive from head of queue // and add sender&#x27;s value to the tail of the queue (both map to // the same buffer slot because the queue is full). recv(c, sg, ep, func() &#123; unlock(&amp;c.lock) &#125;, 3) return true, true &#125; //case2: 没有发送者阻塞，但缓冲区有内容 if c.qcount &gt; 0 &#123; // Receive directly from queue qp := chanbuf(c, c.recvx) if raceenabled &#123; raceacquire(qp) racerelease(qp) &#125; if ep != nil &#123; typedmemmove(c.elemtype, ep, qp) &#125; typedmemclr(c.elemtype, qp) c.recvx++ if c.recvx == c.dataqsiz &#123; c.recvx = 0 &#125; c.qcount-- unlock(&amp;c.lock) return true, true &#125; if !block &#123; unlock(&amp;c.lock) return false, false &#125; //case3: 没有发送者阻塞，缓冲区为空 gopark挂起 // no sender available: block on this channel. gp := getg() mysg := acquireSudog() mysg.releasetime = 0 if t0 != 0 &#123; mysg.releasetime = -1 &#125; // No stack splits between assigning elem and enqueuing mysg // on gp.waiting where copystack can find it. mysg.elem = ep mysg.waitlink = nil gp.waiting = mysg mysg.g = gp mysg.isSelect = false mysg.c = c gp.param = nil c.recvq.enqueue(mysg) gopark(chanparkcommit, unsafe.Pointer(&amp;c.lock), waitReasonChanReceive, traceEvGoBlockRecv, 2) // someone woke us up if mysg != gp.waiting &#123; throw(&quot;G waiting list is corrupted&quot;) &#125; gp.waiting = nil gp.activeStackChans = false if mysg.releasetime &gt; 0 &#123; blockevent(mysg.releasetime-t0, 2) &#125; closed := gp.param == nil gp.param = nil mysg.c = nil releaseSudog(mysg) return true, !closed&#125;","categories":[],"tags":[{"name":"golang","slug":"golang","permalink":"https://riverferry.site/tags/golang/"}],"keywords":[]},{"title":"golang context","slug":"2020-10-21-golang-context","date":"2020-10-21T00:00:00.000Z","updated":"2022-09-12T16:24:32.286Z","comments":true,"path":"2020-10-21-golang-context/","link":"","permalink":"https://riverferry.site/2020-10-21-golang-context/","excerpt":"author title version TheRiver golang reflect go version go1.15.2 darwin/amd64","text":"author title version TheRiver golang reflect go version go1.15.2 darwin/amd64 context.Context12345678910// A Context carries a deadline, a cancellation signal, and other values across// API boundaries.//// Context&#x27;s methods may be called by multiple goroutines simultaneously.type Context interface &#123; Deadline() (deadline time.Time, ok bool) Done() &lt;-chan struct&#123;&#125; Err() error Value(key interface&#123;&#125;) interface&#123;&#125;&#125; 12345678910111213141516171819202122var ( background = new(emptyCtx) todo = new(emptyCtx))type emptyCtx intfunc (*emptyCtx) Deadline() (deadline time.Time, ok bool) &#123; return&#125;func (*emptyCtx) Done() &lt;-chan struct&#123;&#125; &#123; return nil&#125;func (*emptyCtx) Err() error &#123; return nil&#125;func (*emptyCtx) Value(key interface&#123;&#125;) interface&#123;&#125; &#123; return nil&#125; Background()123func Background() Context &#123; return background&#125; TODO()123func TODO() Context &#123; return todo&#125; 小结Background()和TODO()都返回一个实现了context.Context接口的类型emptyCtx,通常作为parent的context节点使用。一般都是用Background(),TODO if you are unsure about which Context to use. WithValue()123456789101112131415161718192021222324252627282930// WithValue returns a copy of parent in which the value associated with key is// val.//// Use context Values only for request-scoped data that transits processes and// APIs, not for passing optional parameters to functions.//// The provided key must be comparable and should not be of type// string or any other built-in type to avoid collisions between// packages using context. Users of WithValue should define their own// types for keys. To avoid allocating when assigning to an// interface&#123;&#125;, context keys often have concrete type// struct&#123;&#125;. Alternatively, exported context key variables&#x27; static// type should be a pointer or interface.func WithValue(parent Context, key, val interface&#123;&#125;) Context &#123; if parent == nil &#123; panic(&quot;cannot create context from nil parent&quot;) &#125; if key == nil &#123; panic(&quot;nil key&quot;) &#125; if !reflectlite.TypeOf(key).Comparable() &#123; panic(&quot;key is not comparable&quot;) &#125; return &amp;valueCtx&#123;parent, key, val&#125;&#125;type valueCtx struct &#123; Context key, val interface&#123;&#125;&#125; Value()123456func (c *valueCtx) Value(key interface&#123;&#125;) interface&#123;&#125; &#123; if c.key == key &#123; return c.val &#125; return c.Context.Value(key)&#125; 小结key必须是可比较的类型，并且不能是string或者其他内置类型，通常定义为type xxx struct{}.valueCtx通过嵌入接口来继承接口的方法，也即是实现了该接口，并在此基础上新增了几个方法(Value()…) demo1234567891011121314package mainimport ( &quot;context&quot; &quot;fmt&quot;)type k struct&#123;&#125;func main() &#123; ctx := context.Background() valueCtx := context.WithValue(ctx, k&#123;&#125;, &quot;parent&quot;) fmt.Println(valueCtx.Value(k&#123;&#125;)) //parent&#125; WithCancel123456789101112131415// WithCancel returns a copy of parent with a new Done channel. The returned// context&#x27;s Done channel is closed when the returned cancel function is called// or when the parent context&#x27;s Done channel is closed, whichever happens first.//// Canceling this context releases resources associated with it, so code should// call cancel as soon as the operations running in this Context complete.func WithCancel(parent Context) (ctx Context, cancel CancelFunc) &#123; if parent == nil &#123; panic(&quot;cannot create context from nil parent&quot;) &#125; c := newCancelCtx(parent) propagateCancel(parent, &amp;c) //var Canceled = errors.New(&quot;context canceled&quot;) return &amp;c, func() &#123; c.cancel(true, Canceled) &#125;&#125; newCancelCtx1234567891011121314151617181920212223242526272829303132// newCancelCtx returns an initialized cancelCtx.func newCancelCtx(parent Context) cancelCtx &#123; return cancelCtx&#123;Context: parent&#125;&#125;// A cancelCtx can be canceled. When canceled, it also cancels any children// that implement canceler.type cancelCtx struct &#123; Context mu sync.Mutex // protects following fields done chan struct&#123;&#125; // created lazily, closed by first cancel call children map[canceler]struct&#123;&#125; // set to nil by the first cancel call err error // set to non-nil by the first cancel call&#125;func (c *cancelCtx) Done() &lt;-chan struct&#123;&#125; &#123; c.mu.Lock() if c.done == nil &#123; c.done = make(chan struct&#123;&#125;) &#125; d := c.done c.mu.Unlock() return d&#125;// A canceler is a context type that can be canceled directly. The// implementations are *cancelCtx and *timerCtx.type canceler interface &#123; cancel(removeFromParent bool, err error) Done() &lt;-chan struct&#123;&#125;&#125; propagateCancel123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117// cancel closes c.done, cancels each of c&#x27;s children, and, if// removeFromParent is true, removes c from its parent&#x27;s children.func (c *cancelCtx) cancel(removeFromParent bool, err error) &#123; if err == nil &#123; panic(&quot;context: internal error: missing cancel error&quot;) &#125; c.mu.Lock() if c.err != nil &#123; c.mu.Unlock() return // already canceled &#125; c.err = err if c.done == nil &#123; //var closedchan = make(chan struct&#123;&#125;) c.done = closedchan &#125; else &#123; close(c.done) &#125; for child := range c.children &#123; // NOTE: acquiring the child&#x27;s lock while holding parent&#x27;s lock. child.cancel(false, err) &#125; c.children = nil c.mu.Unlock() if removeFromParent &#123; removeChild(c.Context, c) &#125;&#125;// removeChild removes a context from its parent.func removeChild(parent Context, child canceler) &#123; p, ok := parentCancelCtx(parent) //第2层以下的为真 if !ok &#123; return &#125; p.mu.Lock() if p.children != nil &#123; delete(p.children, child) &#125; p.mu.Unlock()&#125;// parentCancelCtx returns the underlying *cancelCtx for parent.// It does this by looking up parent.Value(&amp;cancelCtxKey) to find// the innermost enclosing *cancelCtx and then checking whether// parent.Done() matches that *cancelCtx. (If not, the *cancelCtx// has been wrapped in a custom implementation providing a// different done channel, in which case we should not bypass it.)func parentCancelCtx(parent Context) (*cancelCtx, bool) &#123; done := parent.Done() if done == closedchan || done == nil &#123; return nil, false &#125; //这里value返回parent,转换成cancelCtx,按说本来就是cancelCtx。 //对于root的ctx这里类型转换会panic,不过前面if已经拒绝了root的ctx //也就是说这里是第2层以下的parent的ctx p, ok := parent.Value(&amp;cancelCtxKey).(*cancelCtx) if !ok &#123; return nil, false &#125; p.mu.Lock() ok = p.done == done p.mu.Unlock() if !ok &#123; return nil, false &#125; return p, true&#125;func (c *cancelCtx) Value(key interface&#123;&#125;) interface&#123;&#125; &#123; if key == &amp;cancelCtxKey &#123; return c &#125; return c.Context.Value(key)&#125;// propagateCancel arranges for child to be canceled when parent is.func propagateCancel(parent Context, child canceler) &#123; done := parent.Done() if done == nil &#123; return // parent is never canceled &#125; select &#123; case &lt;-done: // parent is already canceled child.cancel(false, parent.Err()) return default: &#125; if p, ok := parentCancelCtx(parent); ok &#123; p.mu.Lock() if p.err != nil &#123; // parent has already been canceled child.cancel(false, p.err) &#125; else &#123; if p.children == nil &#123; p.children = make(map[canceler]struct&#123;&#125;) &#125; p.children[child] = struct&#123;&#125;&#123;&#125; &#125; p.mu.Unlock() &#125; else &#123; atomic.AddInt32(&amp;goroutines, +1) go func() &#123; select &#123; case &lt;-parent.Done(): child.cancel(false, parent.Err()) case &lt;-child.Done(): &#125; &#125;() &#125;&#125; 小结newCancelCtx返回cancelCtx，cancelCtx实现了5个方法： func (c *cancelCtx) Value(key interface{}) interface{} func (c *cancelCtx) Done() &lt;-chan struct{} //生成channel func (c *cancelCtx) Err() error func (c *cancelCtx) String() string func (c *cancelCtx) cancel(removeFromParent bool, err error) //关闭 最重要的是Done(),Value和cancel函数。 Done生成一个channel Vaule返回自身的ctx或者调用parent.Value() cancle关闭自身和children的channel propagateCancel会把children存入map. 由于context可以无限的向下扩展，层级可能很复杂，这里的函数看起来挺绕的，不深究了。 WithTimeout123func WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc) &#123; return WithDeadline(parent, time.Now().Add(timeout))&#125; WithDeadline1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950// WithDeadline returns a copy of the parent context with the deadline adjusted// to be no later than d. If the parent&#x27;s deadline is already earlier than d,// WithDeadline(parent, d) is semantically equivalent to parent. The returned// context&#x27;s Done channel is closed when the deadline expires, when the returned// cancel function is called, or when the parent context&#x27;s Done channel is// closed, whichever happens first.//// Canceling this context releases resources associated with it, so code should// call cancel as soon as the operations running in this Context complete.func WithDeadline(parent Context, d time.Time) (Context, CancelFunc) &#123; if parent == nil &#123; panic(&quot;cannot create context from nil parent&quot;) &#125; if cur, ok := parent.Deadline(); ok &amp;&amp; cur.Before(d) &#123; // The current deadline is already sooner than the new one. return WithCancel(parent) &#125; c := &amp;timerCtx&#123; cancelCtx: newCancelCtx(parent), deadline: d, &#125; propagateCancel(parent, c) dur := time.Until(d) if dur &lt;= 0 &#123; c.cancel(true, DeadlineExceeded) // deadline has already passed return c, func() &#123; c.cancel(false, Canceled) &#125; &#125; c.mu.Lock() defer c.mu.Unlock() if c.err == nil &#123; c.timer = time.AfterFunc(dur, func() &#123; c.cancel(true, DeadlineExceeded) &#125;) &#125; return c, func() &#123; c.cancel(true, Canceled) &#125;&#125;// A timerCtx carries a timer and a deadline. It embeds a cancelCtx to// implement Done and Err. It implements cancel by stopping its timer then// delegating to cancelCtx.cancel.type timerCtx struct &#123; cancelCtx timer *time.Timer // Under cancelCtx.mu. deadline time.Time&#125;func (c *timerCtx) Deadline() (deadline time.Time, ok bool) &#123; return c.deadline, true&#125; 小结和withcancle差别不大，就是多了计时功能。WithDeadline生成的ctx才有Deadline()函数。 WithDeadline在time.Time时间后异步的关闭channel CancelFunc1type CancelFunc func() 其他在database/sql中有遇到context的使用，但只有一层，没看出多大用。以后遇到有意义的场景再补充。 层层生成的新的层级的ctx和一个ctx层层传递的区别？ 关闭当前的ctx也会把底层的ctx关闭，这就是区别吧？？？ 12345678910111213141516171819202122232425package mainimport ( &quot;context&quot;)func ctx2(ctx context.Context) &#123;&#125;func ctx3(ctx context.Context) &#123; ctx2(ctx)&#125;func main() &#123; ctx, cancle := context.WithCancel(context.Background()) ctx2, cancle2 := context.WithCancel(ctx) _, cancle3 := context.WithCancel(ctx2) defer func() &#123; cancle() cancle2() cancle3() &#125;()&#125; reference[1]https://draveness.me/golang/docs/part3-runtime/ch06-concurrency/golang-context/ [2]https://golang.org/pkg/context/","categories":[],"tags":[{"name":"golang","slug":"golang","permalink":"https://riverferry.site/tags/golang/"}],"keywords":[]},{"title":"git 工作流","slug":"2020-10-20-git-工作流","date":"2020-10-20T00:00:00.000Z","updated":"2022-09-12T16:24:32.286Z","comments":true,"path":"2020-10-20-git-工作流/","link":"","permalink":"https://riverferry.site/2020-10-20-git-%E5%B7%A5%E4%BD%9C%E6%B5%81/","excerpt":"","text":"参考Git 工作流程 forked from xirong/my-git GitFlow considered harmful","categories":[],"tags":[],"keywords":[]},{"title":"golang reflect","slug":"2020-10-19-golang-reflect","date":"2020-10-19T00:00:00.000Z","updated":"2022-09-12T16:24:32.286Z","comments":true,"path":"2020-10-19-golang-reflect/","link":"","permalink":"https://riverferry.site/2020-10-19-golang-reflect/","excerpt":"author title version TheRiver golang reflect go version go1.15.2 darwin/amd64 前言 在计算机学中，反射（英语：reflection）是指计算机程序在运行时（runtime）可以访问、检测和修改它本身状态或行为的一种能力。[1]用比喻来说，反射就是程序在运行的时候能够“观察”并且修改自己的行为。 反射主要的两个类型：Type和Value,结合函数Typeof，Valueof使用。看下代码是怎么实现的：","text":"author title version TheRiver golang reflect go version go1.15.2 darwin/amd64 前言 在计算机学中，反射（英语：reflection）是指计算机程序在运行时（runtime）可以访问、检测和修改它本身状态或行为的一种能力。[1]用比喻来说，反射就是程序在运行的时候能够“观察”并且修改自己的行为。 反射主要的两个类型：Type和Value,结合函数Typeof，Valueof使用。看下代码是怎么实现的： Type123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206// Type is the representation of a Go type.// 并非所有方法都适用于所有类型。在每种方法的文档中都注明了限制（如有）// Not all methods apply to all kinds of types. Restrictions,// if any, are noted in the documentation for each method.// 在调用特定于种类的方法之前，请使用Kind方法找出类型。调用不适合该类型的方法会导致运行时panic。// Use the Kind method to find out the kind of type before// calling kind-specific methods. Calling a method// inappropriate to the kind of type causes a run-time panic.//// Type values are comparable, such as with the == operator,// so they can be used as map keys.// Two Type values are equal if they represent identical types.type Type interface &#123; // Methods applicable to all types. // Align returns the alignment in bytes of a value of // this type when allocated in memory. //内存对齐字节数 Align() int // FieldAlign returns the alignment in bytes of a value of // this type when used as a field in a struct. //结构体中对齐字节数 FieldAlign() int // Method returns the i&#x27;th method in the type&#x27;s method set. // It panics if i is not in the range [0, NumMethod()). //非接口类型，返回带接受者的方法 // For a non-interface type T or *T, the returned Method&#x27;s Type and Func // fields describe a function whose first argument is the receiver. //接口类型，返回函数签名，不带接收者 // For an interface type, the returned Method&#x27;s Type field gives the // method signature, without a receiver, and the Func field is nil. // // Only exported methods are accessible and they are sorted in // lexicographic order. //返回第i个method Method(int) Method // MethodByName returns the method with that name in the type&#x27;s // method set and a boolean indicating if the method was found. // // For a non-interface type T or *T, the returned Method&#x27;s Type and Func // fields describe a function whose first argument is the receiver. // // For an interface type, the returned Method&#x27;s Type field gives the // method signature, without a receiver, and the Func field is nil. //返回对应名字的method MethodByName(string) (Method, bool) // NumMethod returns the number of exported methods in the type&#x27;s method set. //返回method的总数 NumMethod() int // Name returns the type&#x27;s name within its package for a defined type. // For other (non-defined) types it returns the empty string. //返回类型名 Name() string // PkgPath returns a defined type&#x27;s package path, that is, the import path // that uniquely identifies the package, such as &quot;encoding/base64&quot;. // If the type was predeclared (string, error) or not defined (*T, struct&#123;&#125;, // []int, or A where A is an alias for a non-defined type), the package path // will be the empty string. PkgPath() string // Size returns the number of bytes needed to store // a value of the given type; it is analogous to unsafe.Sizeof. Size() uintptr // String returns a string representation of the type. // The string representation may use shortened package names // (e.g., base64 instead of &quot;encoding/base64&quot;) and is not // guaranteed to be unique among types. To test for type identity, // compare the Types directly. //返回字符串的类型描述，比较类型的话直接用Type别用这个 String() string // Kind returns the specific kind of this type. //返回特定的类型 Kind() Kind // Implements reports whether the type implements the interface type u. Implements(u Type) bool // AssignableTo reports whether a value of the type is assignable to type u. // AssignableTo(u Type) bool // ConvertibleTo reports whether a value of the type is convertible to type u. ConvertibleTo(u Type) bool // Comparable reports whether values of this type are comparable. Comparable() bool // Methods applicable only to some types, depending on Kind. // The methods allowed for each kind are: // // Int*, Uint*, Float*, Complex*: Bits // Array: Elem, Len // Chan: ChanDir, Elem // Func: In, NumIn, Out, NumOut, IsVariadic. // Map: Key, Elem // Ptr: Elem // Slice: Elem // Struct: Field, FieldByIndex, FieldByName, FieldByNameFunc, NumField // Bits returns the size of the type in bits. // It panics if the type&#x27;s Kind is not one of the // sized or unsized Int, Uint, Float, or Complex kinds. Bits() int // ChanDir returns a channel type&#x27;s direction. // It panics if the type&#x27;s Kind is not Chan. ChanDir() ChanDir // IsVariadic reports whether a function type&#x27;s final input parameter // is a &quot;...&quot; parameter. If so, t.In(t.NumIn() - 1) returns the parameter&#x27;s // implicit actual type []T. // // For concreteness, if t represents func(x int, y ... float64), then // // t.NumIn() == 2 // t.In(0) is the reflect.Type for &quot;int&quot; // t.In(1) is the reflect.Type for &quot;[]float64&quot; // t.IsVariadic() == true // // IsVariadic panics if the type&#x27;s Kind is not Func. IsVariadic() bool // Elem returns a type&#x27;s element type. // It panics if the type&#x27;s Kind is not Array, Chan, Map, Ptr, or Slice. //返回元素类型 Elem() Type // Field returns a struct type&#x27;s i&#x27;th field. // It panics if the type&#x27;s Kind is not Struct. // It panics if i is not in the range [0, NumField()). //返回第i个字段 Field(i int) StructField // FieldByIndex returns the nested field corresponding // to the index sequence. It is equivalent to calling Field // successively for each index i. // It panics if the type&#x27;s Kind is not Struct. FieldByIndex(index []int) StructField // FieldByName returns the struct field with the given name // and a boolean indicating if the field was found. //返回对应名称的字段 FieldByName(name string) (StructField, bool) // FieldByNameFunc returns the struct field with a name // that satisfies the match function and a boolean indicating if // the field was found. // // FieldByNameFunc considers the fields in the struct itself // and then the fields in any embedded structs, in breadth first order, // stopping at the shallowest nesting depth containing one or more // fields satisfying the match function. If multiple fields at that depth // satisfy the match function, they cancel each other // and FieldByNameFunc returns no match. // This behavior mirrors Go&#x27;s handling of name lookup in // structs containing embedded fields. FieldByNameFunc(match func(string) bool) (StructField, bool) // In returns the type of a function type&#x27;s i&#x27;th input parameter. // It panics if the type&#x27;s Kind is not Func. // It panics if i is not in the range [0, NumIn()). //第i个入参 In(i int) Type // Key returns a map type&#x27;s key type. // It panics if the type&#x27;s Kind is not Map. Key() Type // Len returns an array type&#x27;s length. // It panics if the type&#x27;s Kind is not Array. Len() int // NumField returns a struct type&#x27;s field count. // It panics if the type&#x27;s Kind is not Struct. //字段数量 NumField() int // NumIn returns a function type&#x27;s input parameter count. // It panics if the type&#x27;s Kind is not Func. //函数入参个数 NumIn() int // NumOut returns a function type&#x27;s output parameter count. // It panics if the type&#x27;s Kind is not Func. //函数出参个数 NumOut() int // Out returns the type of a function type&#x27;s i&#x27;th output parameter. // It panics if the type&#x27;s Kind is not Func. // It panics if i is not in the range [0, NumOut()). //第i个出参 Out(i int) Type common() *rtype uncommon() *uncommonType&#125; 简单测试下常用的函数： Name Name() string, Name returns the type’s name within its package for a defined type.For other (non-defined) types it returns the empty string. 12345678910111213141516171819202122232425262728293031package mainimport ( &quot;fmt&quot; &quot;reflect&quot;)var data = struct &#123; name string id int family []string&#125;&#123; name: &quot;river&quot;, id: 1, family: []string&#123;&quot;me&quot;, &quot;you&quot;, &quot;we&quot;&#125;,&#125;type data2 struct &#123; name string id int family []string&#125;func main() &#123; t := reflect.TypeOf(data) fmt.Println(t.Name()) // t2 := reflect.TypeOf(data2&#123;&#125;) fmt.Println(t2.Name()) //data2&#125; String String() string, String returns a string representation of the type. 12345678910111213141516171819package mainimport ( &quot;fmt&quot; &quot;reflect&quot;)type data struct &#123; name string id int family []string&#125;func main() &#123; t := reflect.TypeOf(data&#123;&#125;) fmt.Println(t.String()) //main.data fmt.Println(t.Name()) //data&#125; Len Len() int, Len returns an array type’s length. It panics if the type’s Kind is not Array. demo: 123456789101112131415161718package mainimport ( &quot;fmt&quot; &quot;reflect&quot;)type data struct &#123; name string id int family []string&#125;func main() &#123; t := reflect.TypeOf([10]data&#123;&#125;) fmt.Println(t.Len()) //10&#125; Elem Elem() Type ,Elem returns a type’s element type. It panics if the type’s Kind is not Array, Chan, Map, Ptr, or Slice. 12345678910111213141516171819package mainimport ( &quot;fmt&quot; &quot;reflect&quot;)type data struct &#123; name string id int family []string&#125;func main() &#123; //t := reflect.TypeOf(data&#123;name: &quot;river&quot;&#125;) panic t := reflect.TypeOf(&amp;data&#123;name: &quot;river&quot;&#125;) fmt.Println(t.Elem()) //main.data&#125; Kind Kind() Kind, Kind returns the specific kind of this type. 1234567891011121314151617package mainimport ( &quot;fmt&quot; &quot;reflect&quot;)type data struct &#123; name string id int family []string&#125;func main() &#123; t := reflect.TypeOf(data&#123;name: &quot;river&quot;&#125;) fmt.Println(t.Kind()) //struct&#125; kind返回的值类型： 123456789101112131415161718192021222324252627282930313233343536373839/* * These data structures are known to the compiler (../../cmd/internal/gc/reflect.go). * A few are known to ../runtime/type.go to convey to debuggers. * They are also known to ../runtime/type.go. */// A Kind represents the specific kind of type that a Type represents.// The zero Kind is not a valid kind.type Kind uintconst ( Invalid Kind = iota Bool Int Int8 Int16 Int32 Int64 Uint Uint8 Uint16 Uint32 Uint64 Uintptr Float32 Float64 Complex64 Complex128 Array Chan Func Interface Map Ptr Slice String Struct UnsafePointer) MethodMethod(int) Method MethodByName(string) (Method, bool) NumMethod() int 12345678910111213141516171819202122232425262728293031323334353637package mainimport ( &quot;fmt&quot; &quot;reflect&quot;)type data struct &#123; name string id int family []string&#125;func (d data) Func1() &#123; fmt.Println(&quot;1&quot;)&#125;func (d data) Func2() &#123; fmt.Println(&quot;2&quot;)&#125;func (d *data) Func3() &#123; fmt.Println(&quot;3&quot;)&#125;func (d data) func4() &#123; fmt.Println(&quot;4&quot;)&#125;func main() &#123; t := reflect.TypeOf(data&#123;name: &quot;river&quot;&#125;) t2 := reflect.TypeOf(&amp;data&#123;name: &quot;river&quot;&#125;) fmt.Println(t.NumMethod()) //2 fmt.Println(t2.NumMethod()) //3 fmt.Println(t.Method(0).Name) //Func1 fmt.Println(t.MethodByName(&quot;Func2&quot;)) //&#123;Func2 func(main.data) &lt;func(main.data) Value&gt; 1&#125; true&#125; 函数名要大写，不然num不增加。绑定到指针类型的方法和绑定到对象的方法对于指针的NUM和对象的NUM的计数是不同的 FieldNumField() int Field(i int) StructField FieldByIndex(index []int) StructField FieldByName(name string) (StructField, bool) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package mainimport ( &quot;fmt&quot; &quot;reflect&quot;)type User struct &#123; Id int Name string Age int&#125;type Log struct &#123; Id int Time string User int&#125;type Manager struct &#123; User User Log Log&#125;// Main functionfunc main() &#123; m := Manager&#123;User: User&#123;1, &quot;Jack&quot;, 12&#125;, Log: Log&#123;1, &quot;20:01:01&quot;, 10000&#125;&#125; t := reflect.TypeOf(m) fmt.Printf(&quot;%#v\\n&quot;, t.Field(0)) fmt.Printf(&quot;%#v \\n&quot;, t.Field(1)) fmt.Println(&quot;&quot;) // use of FieldByIndex() method fmt.Println(t.FieldByIndex([]int&#123;0, 0&#125;).Name) fmt.Println(t.FieldByIndex([]int&#123;0, 1&#125;).Name) fmt.Println(t.FieldByIndex([]int&#123;0, 2&#125;).Name) fmt.Println(&quot;&quot;) fmt.Println(t.FieldByIndex([]int&#123;1, 0&#125;).Name) fmt.Println(t.FieldByIndex([]int&#123;1, 1&#125;).Name) fmt.Println(t.FieldByIndex([]int&#123;1, 2&#125;).Name) fmt.Println(&quot;&quot;) fmt.Println(t.FieldByName(&quot;User&quot;)) fmt.Println(t.FieldByName(&quot;Name&quot;))&#125; output: 12345678910111213reflect.StructField&#123;Name:&quot;User&quot;, PkgPath:&quot;&quot;, Type:(*reflect.rtype)(0x10bfd20), Tag:&quot;&quot;, Offset:0x0, Index:[]int&#123;0&#125;, Anonymous:false&#125;reflect.StructField&#123;Name:&quot;Log&quot;, PkgPath:&quot;&quot;, Type:(*reflect.rtype)(0x10bfc60), Tag:&quot;&quot;, Offset:0x20, Index:[]int&#123;1&#125;, Anonymous:false&#125; IdNameAgeIdTimeUser&#123;User main.User 0 [0] false&#125; true&#123; &lt;nil&gt; 0 [] false&#125; false In OutIn(i int) Type NumIn() int Out(i int) Type NumOut() int 12345678910111213141516171819202122232425262728293031323334353637383940414243package mainimport ( &quot;fmt&quot; &quot;reflect&quot;)func func1(In1 int, In2 string) (Out1 int, Out2 int) &#123; return 1, 2&#125;type HHello struct&#123;&#125;func (h *HHello) Hello(req string, rep *string) error &#123; *rep = &quot;hello:&quot; + req return nil&#125;// Main functionfunc main() &#123; //函数 t := reflect.TypeOf(func1) for i := 0; i &lt; t.NumIn(); i++ &#123; fmt.Println(t.In(i)) &#125; fmt.Println(&quot;-------------&quot;) for i := 0; i &lt; t.NumOut(); i++ &#123; fmt.Println(t.Out(i)) &#125; fmt.Println(&quot;-------------&quot;) //方法 typ := reflect.TypeOf(new(HHello)) fmt.Println(typ.NumMethod()) m := typ.Method(0) mt := m.Type fmt.Println(mt.NumIn()) for i := 0; i &lt; mt.NumIn(); i++ &#123; fmt.Println(mt.In(i)) &#125;&#125; output: 1234567891011intstring-------------intint-------------13*main.HHellostring*string 方法的入参个数是算接受者的. Value123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051// Value is the reflection interface to a Go value.//// Not all methods apply to all kinds of values. Restrictions,// if any, are noted in the documentation for each method.// Use the Kind method to find out the kind of value before// calling kind-specific methods. Calling a method// inappropriate to the kind of type causes a run time panic.//// The zero Value represents no value.// Its IsValid method returns false, its Kind method returns Invalid,// its String method returns &quot;&lt;invalid Value&gt;&quot;, and all other methods panic.// Most functions and methods never return an invalid value.// If one does, its documentation states the conditions explicitly.//// A Value can be used concurrently by multiple goroutines provided that// the underlying Go value can be used concurrently for the equivalent// direct operations.//// To compare two Values, compare the results of the Interface method.// Using == on two Values does not compare the underlying values// they represent.type Value struct &#123; // typ holds the type of the value represented by a Value. //指向类型的指针 typ *rtype // Pointer-valued data or, if flagIndir is set, pointer to data. // Valid when either flagIndir is set or typ.pointers() is true. //指向值得指针 ptr unsafe.Pointer // flag holds metadata about the value. // The lowest bits are flag bits: // - flagStickyRO: obtained via unexported not embedded field, so read-only // - flagEmbedRO: obtained via unexported embedded field, so read-only // - flagIndir: val holds a pointer to the data // - flagAddr: v.CanAddr is true (implies flagIndir) // - flagMethod: v is a method value. // The next five bits give the Kind of the value. // This repeats typ.Kind() except for method values. // The remaining 23+ bits give a method number for method values. // If flag.kind() != Func, code can assume that flagMethod is unset. // If ifaceIndir(typ), code can assume that flagIndir is set. flag // A method value represents a curried method invocation // like r.Read for some receiver r. The typ+val+flag bits describe // the receiver r, but the flag&#x27;s Kind bits say Func (methods are // functions), and the top bits of the flag give the method number // in r&#x27;s type&#x27;s method table.&#125; 123456789101112131415161718192021222324252627282930313233343536//func (v Value) pointer() unsafe.Pointer &#123;&#125;func (v Value) Addr() Value &#123;&#125;//func (v Value) Bool() bool &#123;&#125;//func (v Value) Bytes() []byte &#123;&#125;//func (v Value) runes() []rune &#123;&#125;func (v Value) CanAddr() bool &#123;&#125;func (v Value) CanSet() bool &#123;&#125;func (v Value) Set(x Value) &#123;&#125;func (v Value) Call(in []Value) []Value &#123;&#125;//func (v Value) CallSlice(in []Value) []Value &#123;&#125;//func (v Value) call(op string, in []Value) []Value &#123;&#125;//func (v Value) Cap() int &#123;&#125;func (v Value) Elem() Value &#123;&#125;func (v Value) Field(i int) Value &#123;&#125;func (v Value) NumField() int &#123;&#125;func (v Value) FieldByIndex(index []int) Value &#123;&#125;func (v Value) FieldByName(name string) Value &#123;&#125;func (v Value) FieldByNameFunc(match func(string) bool) Value &#123;&#125;func (v Value) Index(i int) Value &#123;&#125;//func (v Value) Int() int64 &#123;&#125;func (v Value) Interface() (i interface&#123;&#125;) &#123;&#125;//func (v Value) IsValid() bool &#123;&#125;//func (v Value) IsZero() bool &#123;&#125;func (v Value) Kind() Kind &#123;&#125;//func (v Value) Len() int &#123;&#125;func (v Value) Method(i int) Value &#123;func (v Value) NumMethod() int &#123;func (v Value) MethodByName(name string) Value &#123;&#125;func (v Value) String() string &#123;&#125;func (v Value) Type() Type &#123;&#125;... String123456789101112131415161718192021package mainimport ( &quot;fmt&quot; &quot;reflect&quot;)type User struct &#123; Id int Name string Age int&#125;// Main functionfunc main() &#123; v := reflect.ValueOf(User&#123;Id: 1, Name: &quot;river&quot;, Age: 26&#125;) fmt.Println(v.String()) //&lt;main.User Value&gt; t := reflect.TypeOf(User&#123;Id: 1, Name: &quot;river&quot;, Age: 26&#125;) fmt.Println(t.String()) //main.User&#125; Type12345678910111213141516171819package mainimport ( &quot;fmt&quot; &quot;reflect&quot;)type User struct &#123; Id int Name string Age int&#125;// Main functionfunc main() &#123; v := reflect.ValueOf(User&#123;Id: 1, Name: &quot;river&quot;, Age: 26&#125;) fmt.Println(v.Type()) //main.User&#125; Index Index returns v’s i’th element. It panics if v’s Kind is not Array, Slice, or String or i is out of range. 12345678910111213141516171819202122package mainimport ( &quot;fmt&quot; &quot;reflect&quot;)// Main functionfunc main() &#123; a := [2]int&#123;1, 2&#125; s := []int&#123;3, 4&#125; str := &quot;abcd&quot; v := reflect.ValueOf(a) fmt.Println(v.Index(1)) //2 v = reflect.ValueOf(s) fmt.Println(v.Index(1)) //4 v = reflect.ValueOf(str) fmt.Println(v.Index(1)) //98&#125; Elem1234567891011121314151617181920212223242526272829303132// Elem returns the value that the interface v contains// or that the pointer v points to.// It panics if v&#x27;s Kind is not Interface or Ptr.// It returns the zero Value if v is nil.package mainimport ( &quot;fmt&quot; &quot;reflect&quot;)type User struct &#123; Id int Name string Age int&#125;// Main functionfunc main() &#123; //v := reflect.ValueOf(User&#123;Id: 1, Name: &quot;river&quot;, Age: 26&#125;) //fmt.Println(v.Elem()) //panic v := reflect.ValueOf(&amp;User&#123;Id: 1, Name: &quot;river&quot;, Age: 26&#125;) fmt.Println(v.Elem()) //&#123;1 river 26&#125; // var vv reflect.Value // fmt.Println(vv.Elem()) //panic v = reflect.ValueOf(&amp;User&#123;&#125;) fmt.Println(v.Elem()) //&#123;0 0&#125;&#125; Call123456789101112131415161718192021222324package mainimport ( &quot;fmt&quot; &quot;reflect&quot;)type User struct &#123; Id int Name string Age int&#125;func (u User) Printt() &#123; fmt.Println(&quot;yes&quot;)&#125;// Main functionfunc main() &#123; v := reflect.ValueOf(User&#123;Id: 1, Name: &quot;river&quot;, Age: 26&#125;) var r []reflect.Value v.Method(0).Call(r) //yes&#125; Kind1234567891011121314151617181920212223242526272829303132333435package mainimport ( &quot;fmt&quot; &quot;reflect&quot;)type User struct &#123; Id int Name string Age int&#125;func ff() &#123;&#125;// Main functionfunc main() &#123; v := reflect.ValueOf(User&#123;Id: 1, Name: &quot;river&quot;, Age: 26&#125;) fmt.Println(v.Kind()) //struct v = reflect.ValueOf(1) fmt.Println(v.Kind()) //int v = reflect.ValueOf(&quot;2222&quot;) fmt.Println(v.Kind()) //string v = reflect.ValueOf([]int&#123;1, 2, 3&#125;) fmt.Println(v.Kind()) //slice v = reflect.ValueOf(ff) fmt.Println(v.Kind()) //func&#125; 感觉和Type的Kind没啥区别 Set Addr CanAddr reports whether the value’s address can be obtained with Addr. Such values are called addressable. A value is addressable if it is an element of a slice, an element of an addressable array, a field of an addressable struct, or the result of dereferencing a pointer. If CanAddr returns false, calling Addr will panic. 反射中这几种值可以寻址： 切片的一个元素(ValueOf().Index()) 可寻址数组的一个元素 可寻址结构体的一个字段 解引用的结果 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061package mainimport ( &quot;fmt&quot; &quot;reflect&quot;)type User struct &#123; Id int Name string Age int pi *int&#125;// Main functionfunc main() &#123; v := reflect.ValueOf(User&#123;Id: 1, Name: &quot;river&quot;, Age: 26&#125;) fmt.Println(&quot;1: &quot;, v.CanAddr(), v.CanSet()) //false false v = reflect.ValueOf(&amp;User&#123;Id: 1, Name: &quot;river&quot;, Age: 26&#125;) fmt.Println(&quot;2: &quot;, v.CanAddr(), v.CanSet()) //false false p := 10 u := User&#123;Id: 1, Name: &quot;river&quot;, Age: 26, pi: &amp;p&#125; v = reflect.ValueOf(&amp;u.pi) fmt.Println(&quot;3: &quot;, v.CanAddr(), v.CanSet()) //false false s := []int&#123;1, 2, 3&#125; v = reflect.ValueOf(s) fmt.Println(&quot;4: &quot;, v.CanAddr(), v.CanSet()) //false false s = []int&#123;1, 2, 3&#125; v = reflect.ValueOf(s[0]) fmt.Println(&quot;5: &quot;, v.CanAddr(), v.CanSet()) //false false s = []int&#123;1, 2, 3&#125; v = reflect.ValueOf(&amp;s[1]) fmt.Println(&quot;6: &quot;, v.CanAddr(), v.CanSet()) //false false s = []int&#123;1, 2, 3&#125; v = reflect.ValueOf(s).Index(0) fmt.Println(&quot;7: &quot;, v.CanAddr(), v.CanSet()) //true true v = reflect.ValueOf(&amp;p) fmt.Println(&quot;8: &quot;, v.CanAddr(), v.CanSet()) //false false v = reflect.ValueOf(&amp;p).Elem() fmt.Println(&quot;9: &quot;, v.CanAddr(), v.CanSet()) //true true v = reflect.Indirect(reflect.ValueOf(&amp;p)) fmt.Println(&quot;10: &quot;, v.CanAddr(), v.CanSet()) //true true ss := [3]int&#123;1, 2, 3&#125; v = reflect.ValueOf(ss).Index(0) fmt.Println(&quot;11: &quot;, v.CanAddr(), v.CanSet()) //false false v = reflect.ValueOf(User&#123;Id: 1, Name: &quot;river&quot;, Age: 26&#125;).Field(0) fmt.Println(&quot;12: &quot;, v.CanAddr(), v.CanSet()) //false false&#125; 这个寻址可以说非常严格了，4条规则我也是没搞懂太含糊了。只能说解引用是最保险的了。 Interface类型转换成interface(),还原到ValueOf的入参。结合addr可以修改值 123456789101112131415161718192021222324252627package mainimport ( &quot;fmt&quot; &quot;reflect&quot;)// Main function//1func main() &#123; i := 10 add := reflect.ValueOf(&amp;i).Elem() pi := add.Addr().Interface().(*int) *pi = 20 fmt.Println(i)&#125;//2func main() &#123; i := 10 add := reflect.ValueOf(&amp;i).Elem() if add.CanSet() &#123; add.Set(reflect.ValueOf(20)) &#125; fmt.Println(i)&#125; Method参考Type的函数 Field参考Type的函数 Elem and Indirectgolang - Elem Vs Indirect in the reflect package If a reflect.Value is a pointer, then v.Elem() is equivalent to reflect.Indirect(v). If it is not a pointer, then they are not equivalent: If the value is an interface then reflect.Indirect(v) will return the same value, while v.Elem() will return the contained dynamic value. If the value is something else, then v.Elem() will panic. The reflect.Indirect helper is intended for cases where you want to accept either a particular type, or a pointer to that type. One example is the database/sql conversion routines: by using reflect.Indirect, it can use the same code paths to handle the various types and pointers to those types. 总结 Type是接口，Value是结构体和方法 函数名要大写，不然num不增加。绑定到指针类型的方法和绑定到对象的方法对于指针的NUM和对象的NUM的计数是不同的 可寻址的条件是很苛刻的 canset比canaddr多了一个限制，即内部是exported的 结合addr和interface可以修改值,或者set Elem和Indirect在都是指针的时候没有区别 东西挺多的，以后遇到了再补充 参考golang - Elem Vs Indirect in the reflect package go addressable 详解 https://www.geeksforgeeks.org/ 深入理解Golang之interface和reflect","categories":[],"tags":[{"name":"golang","slug":"golang","permalink":"https://riverferry.site/tags/golang/"}],"keywords":[]},{"title":"gitlab+github+hexo","slug":"2020-10-14-gitlab+github+hexo","date":"2020-10-14T00:00:00.000Z","updated":"2022-09-12T16:24:32.286Z","comments":true,"path":"2020-10-14-gitlab+github+hexo/","link":"","permalink":"https://riverferry.site/2020-10-14-gitlab+github+hexo/","excerpt":"前言以前的blog是基于github page + jekyll实现的，参考别人的模板修修改改。存在一些痛点： 代码段不能显示行号 文章没有分页功能 没有搜索功能 没有评论系统(其实是可以实现，但是因为参考别人的模板，之前参考文章失效了，也不知道怎么修改了) 不够流畅，并且缺乏定制化的东西 后面选择的方案是hexo+github+gitlab.通过hexo生成静态网页，依赖next的强大可用资源，然后用gitlab实现ci/cd,整个流程还是比较满意的。也考虑过hugo框架，但是资源太少，放弃了","text":"前言以前的blog是基于github page + jekyll实现的，参考别人的模板修修改改。存在一些痛点： 代码段不能显示行号 文章没有分页功能 没有搜索功能 没有评论系统(其实是可以实现，但是因为参考别人的模板，之前参考文章失效了，也不知道怎么修改了) 不够流畅，并且缺乏定制化的东西 后面选择的方案是hexo+github+gitlab.通过hexo生成静态网页，依赖next的强大可用资源，然后用gitlab实现ci/cd,整个流程还是比较满意的。也考虑过hugo框架，但是资源太少，放弃了 实现过程step 1 安装nodejs我之前安装过，就跳过这步了，安装步骤网上很好找 step 2 安装hexonpm i hexo-cli -g npm install hexo init //初始化，生成必要的文件 hexo g //hexo generate 生成静态网页 hexo s //hexo server 本地部署 hexo clean step 3 配置githubgit config --global user.name git config --global user.email ssh-keygen -t rsa -C //添加ssh pub key 到github setting中的ssh key配置中 ssh -T git@github.com //修改项目路径下的_config.yml repository:填入github仓库地址 step 4 写文章hexo new post //会在source/_post下面生成md文章 step 5 ci/cd本地部署hexo的话，直接hexo g -d就行了，会把静态网页传到github下。 gitlab部署的话，需要在gitlab新增一个private的仓库，把hexo下面的文件传进去，把github的rsa也放在仓库中。然后写.gitlab-ci.yml文件，就是脚本配置文件，然后以后push/merge会触发ci/cd.从gitlab配置的share running的docker中执行脚本，部署到github. 我的文件： 12345678910111213141516171819202122232425262728293031323334353637image: node:14.11.0cache: paths: - node_modules/before_script: - npm install hexo-cli -g - npm install - npm audit fix - npm install hexo-deployer-git --save# - npm install hexo-symbols-count-time --save# - npm install --save hexo-helper-live2d# - npm install hexo-generator-searchdb --save# - npm install live2d-widget-model-tororo# - npm i hexo-generator-json-content@2.2.0 -S# - npm install hexo-wordcount --save# - npm install hexo-generator-sitemap --save# - npm uninstall hexo-generator-baidu-sitemap --save# - npm uninstall hexo-baidu-url-submit --savepages: script: - eval $(ssh-agent -s) - chmod 700 github-rsa - ssh-add github-rsa - git config --global user.email &quot;wang84819762@gmail.com&quot; - git config --global user.name &quot;RiverFerry&quot; - echo StrictHostKeyChecking no &gt;&gt; /etc/ssh/ssh_config# - ssh -T git@github.com - hexo clean - hexo g -d - echo &quot;Deploy succeed!&quot; artifacts: paths: - public only: - master 谷歌收录百度收录比较麻烦，并且被github屏蔽了，双线部署觉得没必要。就只搞了谷歌收录： 登陆谷歌站长，添加你的站点，新版本有不带前缀的选项，我用的这一个，然后dns验证 然后生成sitemap： 1npm install hexo-generator-sitemap --save 修改项目的config: 1234url: https:&#x2F;&#x2F;riverferry.sitesitemap:path: sitemap.xml source目录下新增robots.txt： 12345678910111213# hexo robots.txtUser-agent: *Allow: &#x2F;Allow: &#x2F;archives&#x2F;Allow: &#x2F;categories&#x2F;Allow: &#x2F;tags&#x2F;Disallow: &#x2F;vendors&#x2F;Disallow: &#x2F;js&#x2F;Disallow: &#x2F;css&#x2F;Disallow: &#x2F;fonts&#x2F;Disallow: &#x2F;vendors&#x2F;Disallow: &#x2F;fancybox&#x2F;Sitemap: https:&#x2F;&#x2F;riverferry.site&#x2F;sitemap.xml 在google的search console添加sitemap即可。 更新 色表:https://flatuicolors.com/palette/fr图：腾讯cos 其他报错可以参考下面的文章寻找解决方案。 参考将 Hexo 部署到 GitLab Pages 使用GitLab Ci 自动部署Hexo到GitHub Hexo 搭建个人博客系列：主题美化篇 超详细Hexo+Github Page搭建技术博客教程【持续更新】 超详细Hexo+Github博客搭建小白教程 利用 GitHub + Hexo + Next 从零搭建一个博客","categories":[],"tags":[{"name":"gitlab","slug":"gitlab","permalink":"https://riverferry.site/tags/gitlab/"},{"name":"hexo","slug":"hexo","permalink":"https://riverferry.site/tags/hexo/"},{"name":"github","slug":"github","permalink":"https://riverferry.site/tags/github/"},{"name":"blog","slug":"blog","permalink":"https://riverferry.site/tags/blog/"}],"keywords":[]},{"title":"grpc hello","slug":"2020-10-13-grpc hello","date":"2020-10-13T00:00:00.000Z","updated":"2022-09-12T16:24:32.286Z","comments":true,"path":"2020-10-13-grpc hello/","link":"","permalink":"https://riverferry.site/2020-10-13-grpc%20hello/","excerpt":"用golang+grpc生成一个简单的hello world程序。代码地址：https://github.com/RiverFerry/grpc。","text":"用golang+grpc生成一个简单的hello world程序。代码地址：https://github.com/RiverFerry/grpc。 步骤准备工作brew install protobuf brew install golang brew install grpc go get -u github.com/golang/protobuf/&#123;proto,protoc-gen-go&#125; go get -u google.golang.org/grpc proto文件123456789101112131415161718syntax = &quot;proto3&quot;;package hello;message HelloRequest &#123; string name = 1;&#125;message HelloReply &#123; string message = 1;&#125;service Greeter &#123; rpc SayHello (HelloRequest) returns (HelloReply) &#123;&#125;&#125; server123456789101112131415161718192021222324252627282930313233343536373839package mainimport ( &quot;context&quot; &quot;log&quot; &quot;net&quot; pb &quot;grpc/hello&quot; &quot;google.golang.org/grpc&quot;)const ( port = &quot;:10000&quot;)// server is used to implement helloworld.GreeterServer.type server struct &#123; pb.UnimplementedGreeterServer&#125;// SayHello implements helloworld.GreeterServerfunc (s *server) SayHello(ctx context.Context, in *pb.HelloRequest) (*pb.HelloReply, error) &#123; log.Printf(&quot;Received: %v&quot;, in.GetName()) return &amp;pb.HelloReply&#123;Message: &quot;Hello &quot; + in.GetName()&#125;, nil&#125;func main() &#123; lis, err := net.Listen(&quot;tcp&quot;, port) if err != nil &#123; log.Fatalf(&quot;failed to listen: %v&quot;, err) &#125; s := grpc.NewServer() pb.RegisterGreeterServer(s, &amp;server&#123;&#125;) if err := s.Serve(lis); err != nil &#123; log.Fatalf(&quot;failed to serve: %v&quot;, err) &#125;&#125; client1234567891011121314151617181920212223242526272829303132333435363738394041package mainimport ( &quot;context&quot; &quot;log&quot; &quot;os&quot; &quot;time&quot; pb &quot;grpc/hello&quot; &quot;google.golang.org/grpc&quot;)const ( address = &quot;localhost:10000&quot; defaultName = &quot;23333333&quot;)func main() &#123; // Set up a connection to the server. conn, err := grpc.Dial(address, grpc.WithInsecure(), grpc.WithBlock()) if err != nil &#123; log.Fatalf(&quot;did not connect: %v&quot;, err) &#125; defer conn.Close() c := pb.NewGreeterClient(conn) // Contact the server and print out its response. name := defaultName if len(os.Args) &gt; 1 &#123; name = os.Args[1] &#125; ctx, cancel := context.WithTimeout(context.Background(), time.Second) defer cancel() r, err := c.SayHello(ctx, &amp;pb.HelloRequest&#123;Name: name&#125;) if err != nil &#123; log.Fatalf(&quot;could not greet: %v&quot;, err) &#125; log.Printf(&quot;Greeting: %s&quot;, r.GetMessage())&#125; 其他protoc -I=../grpc/hello --go_out=plugins=grpc:./hello/ hello.proto --experimental_allow_proto3_optional -I是–proto_path的简写，表示proto文件所在路径 –go_out后面./hello表示生成文件所在路径 experimental_allow_proto3_optional是proto3版本要带的参数 把项目代码放在GOPATH/src下面，import的时候pb &quot;grpc/hello&quot;路径到hello.pb.go文件所在的文件夹就行了 proto文件的message添加optional后go文件中的struct的name/message就变成string*,这里需要注意下 总结main的代码基本是拷贝官方的example,这里主要是编译和设置的问题比较多。其他细节的东西后面其他文章再研究，然后补充。 参考gRPC 官方文档中文版V1.0 protoc-gen-go: program not found or is not executable Command not found go — on Mac after installing Go Could not make proto path relative and No such file or directory Correct format of protoc go_package? 用Golang构建gRPC服务","categories":[],"tags":[{"name":"grpc","slug":"grpc","permalink":"https://riverferry.site/tags/grpc/"}],"keywords":[]},{"title":"golang连接mysql","slug":"2020-10-10-golang连接mysql","date":"2020-10-10T00:00:00.000Z","updated":"2022-09-12T16:24:32.286Z","comments":true,"path":"2020-10-10-golang连接mysql/","link":"","permalink":"https://riverferry.site/2020-10-10-golang%E8%BF%9E%E6%8E%A5mysql/","excerpt":"参考http://go-database-sql.org/","text":"参考http://go-database-sql.org/ code123456789 CREATE TABLE `tt` ( `id` int(11) NOT NULL AUTO_INCREMENT, `c` int(11) DEFAULT NULL, `d` int(11) DEFAULT NULL, `field` varchar(64) NOT NULL DEFAULT &#x27;&#x27;, PRIMARY KEY (`id`), UNIQUE KEY `c` (`c`), KEY `index_d` (`d`)) ENGINE=InnoDB AUTO_INCREMENT=26 DEFAULT CHARSET=latin1 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143package mainimport ( &quot;database/sql&quot; &quot;fmt&quot; &quot;log&quot; &quot;strings&quot; _ &quot;github.com/go-sql-driver/mysql&quot;)//go get github.com/go-sql-driver/mysqlfunc mysql_open() (*sql.DB, error) &#123; db, err := sql.Open(&quot;mysql&quot;, &quot;root:123456@tcp(127.0.0.1:3306)/mysql&quot;) if err != nil &#123; log.Fatal(err) &#125; return db, err&#125;/*MySQL [mysql]&gt; select * from tt;+----+------+------+-------+| id | c | d | field |+----+------+------+-------+| 1 | 1 | 777 | hello || 2 | 2 | 200 | || 3 | 3 | 999 | || 9 | 5 | 0 | || 20 | 4 | 0 | || 25 | 6 | 600 | |+----+------+------+-------+6 rows in set (0.00 sec)*/type tt struct &#123; id int c int d int field string&#125;func queryAll(db *sql.DB) []*tt &#123; var ret []*tt //query all rows, err := db.Query(&quot;select id, c, d, field from tt where 1 = ?&quot;, 1) defer rows.Close() if err != nil &#123; log.Fatal(err) &#125; fmt.Println(&quot;id\\tc\\td\\tfield&quot;) for rows.Next() &#123; data := &amp;tt&#123;&#125; err = rows.Scan(&amp;data.id, &amp;data.c, &amp;data.d, &amp;data.field) if err != nil &#123; log.Fatal(err) &#125; ret = append(ret, data) //log.Println(data.id, &quot;\\t&quot;, data.c, &quot;\\t&quot;, data.d, &quot;\\t&quot;, data.field) fmt.Println(data.id, &quot;\\t&quot;, data.c, &quot;\\t&quot;, data.d, &quot;\\t&quot;, data.field) &#125; err = rows.Err() if err != nil &#123; log.Fatal(err) &#125; return ret&#125;func querySingle(db *sql.DB) *tt &#123; var data tt //query single-row err := db.QueryRow(&quot;select id, c, d, field from tt where id = ?&quot;, 1).Scan(&amp;data.id, &amp;data.c, &amp;data.d, &amp;data.field) if err != nil &#123; log.Fatal(err) &#125; fmt.Println() fmt.Println(&quot;id\\tc\\td\\tfield&quot;) fmt.Println(data.id, &quot;\\t&quot;, data.c, &quot;\\t&quot;, data.d, &quot;\\t&quot;, data.field) return &amp;data&#125;func modifybyTx(db *sql.DB, data []*tt) &#123; tx, err := db.Begin() if err != nil &#123; fmt.Println(&quot;begin tx err!&quot;) log.Fatal(err) &#125; defer func() &#123; if err == nil &#123; _ = tx.Commit() &#125; else &#123; _ = tx.Rollback() &#125; &#125;() param := make([]interface&#123;&#125;, 0) for _, row := range data &#123; param = append(param, row.id) &#125; sql := strings.Builder&#123;&#125; sql.WriteString(fmt.Sprintf(&quot;update tt set field = unix_timestamp(NOW()) where id in (?%s)&quot;, strings.Repeat(&quot;, ?&quot;, len(data)-1))) _, err = tx.Exec(sql.String(), param...) if err != nil &#123; log.Fatal(err) &#125;&#125;func main() &#123; db, err := mysql_open() if err != nil &#123; fmt.Println(&quot;open mysql error!&quot;) return &#125; var data []*tt data = queryAll(db) fmt.Println(&quot;-------------------------&quot;) querySingle(db) fmt.Println(&quot;-------------------------&quot;) modifybyTx(db, data) queryAll(db) fmt.Println(&quot;-------------------------&quot;) defer func() &#123; db.Close() &#125;()&#125; errornext循环异常结束123456for rows.Next() &#123; // ...&#125;if err = rows.Err(); err != nil &#123; // handle the error here&#125; The error from rows.Err() could be the result of a variety of errors in the rows.Next() loop. The loop might exit for some reason other than finishing the loop normally, so you always need to check whether the loop terminated normally or not. An abnormal termination automatically calls rows.Close(), although it’s harmless to call it multiple times. 查询结果为空1234567891011var name stringerr = db.QueryRow(&quot;select name from users where id = ?&quot;, 1).Scan(&amp;name)if err != nil &#123; if err == sql.ErrNoRows &#123; // there were no rows, but otherwise no error occurred &#125; else &#123; log.Fatal(err) &#125;&#125;fmt.Println(name) 未知列1234567891011121314151617181920212223242526272829303132func Unknown(db *sql.DB) &#123; //query all rows, err := db.Query(&quot;select * from tt&quot;) defer rows.Close() if err != nil &#123; log.Fatal(err) &#125; cols, err := rows.Columns() // Remember to check err afterwards if err != nil &#123; log.Fatal(err) &#125; fmt.Println(len(cols)) // if len(cols) == 11 &#123; // // Percona Server // &#125; else if len(cols) &gt; 8 &#123; // // Handle this case // &#125; vals := make([]interface&#123;&#125;, len(cols)) for i, _ := range cols &#123; vals[i] = new(sql.RawBytes) &#125; for rows.Next() &#123; err = rows.Scan(vals...) // Now you can check each element of vals for nil-ness, // and you can use type introspection and type assertions // to fetch the column into a typed variable. fmt.Println(vals) &#125;&#125; ending","categories":[],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://riverferry.site/tags/mysql/"},{"name":"golang","slug":"golang","permalink":"https://riverferry.site/tags/golang/"}],"keywords":[]},{"title":"golang连接redis","slug":"2020-10-10-golang连接redis","date":"2020-10-10T00:00:00.000Z","updated":"2022-09-12T16:24:32.286Z","comments":true,"path":"2020-10-10-golang连接redis/","link":"","permalink":"https://riverferry.site/2020-10-10-golang%E8%BF%9E%E6%8E%A5redis/","excerpt":"前言通过redigo连接redis,以后有时间的话搞搞go-redis.","text":"前言通过redigo连接redis,以后有时间的话搞搞go-redis. 参考https://github.com/go-redis/redis https://github.com/gomodule/redigo redis命令 funcfunc Dial1func Dial(network, address string, options ...DialOption) (Conn, error) Dial connects to the Redis server at the given network and address using the specified options. Connect to local instance of Redis running on the default port. Code: 12345c, err := redis.Dial(&quot;tcp&quot;, &quot;:6379&quot;)if err != nil &#123; // handle error&#125;defer c.Close() Connect to an Redis instance using the Redis ACL system Code: 12345678c, err := redis.Dial(&quot;tcp&quot;, &quot;localhost:6379&quot;, redis.DialUsername(&quot;username&quot;), redis.DialPassword(&quot;password&quot;),)if err != nil &#123; // handle error&#125;defer c.Close() func DialTimeout1func DialTimeout(network, address string, connectTimeout, readTimeout, writeTimeout time.Duration) (Conn, error) DialTimeout acts like Dial but takes timeouts for establishing the connection to the server, writing a command and reading a reply. Deprecated: Use Dial with options instead. func NewConn1func NewConn(netConn net.Conn, readTimeout, writeTimeout time.Duration) Conn NewConn returns a new Redigo connection for the given net connection. func do1Do(commandName string, args ...interface&#123;&#125;) (reply interface&#123;&#125;, err error) The Do method converts command arguments to bulk strings for transmission to the server as follows: Go Type Conversion []byte Sent as is string Sent as is int, int64 strconv.FormatInt(v) float64 strconv.FormatFloat(v, &#39;g&#39;, -1, 64) bool true -&gt; &quot;1&quot;, false -&gt; &quot;0&quot; nil &quot;&quot; all other types fmt.Fprint(w, v) Redis command reply types are represented using the following Go types: Redis type Go type error redis.Error integer int64 simple string string bulk string []byte or nil if value not present. array []interface&#123;&#125; or nil if value not present. func bytes1func Bytes(reply interface&#123;&#125;, err error) ([]byte, error) Bytes is a helper that converts a command reply to a slice of bytes. If err is not equal to nil, then Bytes returns nil, err. Otherwise Bytes converts the reply to a slice of bytes as follows: Reply type Result bulk string reply, nil simple string []byte(reply), nil nil nil, ErrNil other nil, error func ByteSlices1func ByteSlices(reply interface&#123;&#125;, err error) ([][]byte, error) ByteSlices is a helper that converts an array command reply to a [][]byte. If err is not equal to nil, then ByteSlices returns nil, err. Nil array items are stay nil. ByteSlices returns an error if an array item is not a bulk string or nil. func Bool1func Bool(reply interface&#123;&#125;, err error) (bool, error) Bool is a helper that converts a command reply to a boolean. If err is not equal to nil, then Bool returns false, err. Otherwise Bool converts the reply to boolean as follows: Reply type Resultinteger value != 0, nilbulk string strconv.ParseBool(reply)nil false, ErrNilother false, error demo123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475package mainimport ( &quot;fmt&quot; &quot;log&quot; &quot;time&quot; &quot;github.com/gomodule/redigo/redis&quot;)//go get -u &quot;github.com/gomodule/redigo/redis&quot;//go get -u &quot;github.com/gogf/gf/net/gtcp&quot;func redis_open() (redis.Conn, error) &#123; connectTimeout := 10 * time.Second readTimeout := 10 * time.Second writeTimeout := 10 * time.Second /* c1, err := redis.Dial(&quot;tcp&quot;, &quot;127.0.0.1:6379&quot;, redis.DialPassword(&quot;123456&quot;), redis.DialConnectTimeout(connectTimeout), redis.DialReadTimeout(readTimeout), redis.DialWriteTimeout(writeTimeout)) defer c1.Close() if err != nil &#123; // handle error return nil, err &#125; */ /* conn, err := net.Dial(&quot;tcp&quot;, &quot;127.0.0.1:6379&quot;) if err != nil &#123; log.Fatal(err) &#125; c2 := redis.NewConn(conn, readTimeout, writeTimeout) */ c3, err := redis.DialTimeout(&quot;tcp&quot;, &quot;127.0.0.1:6379&quot;, connectTimeout, readTimeout, writeTimeout) //defer c3.Close() if err != nil &#123; // handle error return nil, err &#125; if _, err = c3.Do(&quot;AUTH&quot;, &quot;123456&quot;); err != nil &#123; log.Fatal(err) &#125; return c3, nil&#125;func main() &#123; cache, err := redis_open() defer cache.Close() if err != nil &#123; log.Fatal(err) &#125; if _, err = cache.Do(&quot;SET&quot;, &quot;key1&quot;, &quot;values1&quot;); err != nil &#123; log.Fatal(err) &#125; bytes, err := redis.Bytes(cache.Do(&quot;Get&quot;, &quot;key1&quot;)) if err != nil &#123; log.Fatal(err) &#125; fmt.Println(string(bytes))&#125; pipeline123456789101112131415161718192021222324252627282930313233343536373839if _, err = cache.Do(&quot;SET&quot;, &quot;key2&quot;, 1); err != nil &#123; log.Fatal(err) &#125; cache.Send(&quot;INCR&quot;, &quot;key2&quot;) cache.Send(&quot;INCR&quot;, &quot;key2&quot;) cache.Send(&quot;INCR&quot;, &quot;key2&quot;) bytes, err := redis.Bytes(cache.Do(&quot;Get&quot;, &quot;key2&quot;)) if err != nil &#123; log.Fatal(err) &#125; n, _ := strconv.Atoi(string(bytes)) fmt.Println(n) //4 if _, err = cache.Do(&quot;SET&quot;, &quot;key3&quot;, 1); err != nil &#123; log.Fatal(err) &#125; cache.Send(&quot;INCR&quot;, &quot;key3&quot;) cache.Send(&quot;INCR&quot;, &quot;key3&quot;) cache.Send(&quot;INCR&quot;, &quot;key3&quot;) cache.Flush() n1, err := cache.Receive() if err != nil &#123; log.Fatal(err) &#125; fmt.Println(n1) //2 n2, err := cache.Receive() if err != nil &#123; log.Fatal(err) &#125; fmt.Println(n2) //3 n3, err := cache.Receive() if err != nil &#123; log.Fatal(err) &#125; fmt.Println(n3) //4 通过Do的get返回的interface{}需要转换成切片再转成数字，receive返回的直接就是interface{}-&gt;int64了，这个后面再看下原因。 这里主要的点是连续作业，send+flush+receive或者send+do,do相当于flush+receive了。也可以DO(“”)来flush然后取上一条命令的结果。 ending","categories":[],"tags":[{"name":"redis","slug":"redis","permalink":"https://riverferry.site/tags/redis/"},{"name":"golang","slug":"golang","permalink":"https://riverferry.site/tags/golang/"}],"keywords":[]},{"title":"sql 窗口函数","slug":"2020-10-09-sql 窗口函数","date":"2020-10-09T00:00:00.000Z","updated":"2022-09-12T16:24:32.285Z","comments":true,"path":"2020-10-09-sql 窗口函数/","link":"","permalink":"https://riverferry.site/2020-10-09-sql%20%E7%AA%97%E5%8F%A3%E5%87%BD%E6%95%B0/","excerpt":"参考通俗易懂的学会：SQL窗口函数","text":"参考通俗易懂的学会：SQL窗口函数 TODOending","categories":[],"tags":[{"name":"坑","slug":"坑","permalink":"https://riverferry.site/tags/%E5%9D%91/"}],"keywords":[]},{"title":"golang 接口","slug":"2020-09-30-golang 接口","date":"2020-09-30T00:00:00.000Z","updated":"2022-09-12T16:24:32.285Z","comments":true,"path":"2020-09-30-golang 接口/","link":"","permalink":"https://riverferry.site/2020-09-30-golang%20%E6%8E%A5%E5%8F%A3/","excerpt":"前言简单整理go的接口相关知识","text":"前言简单整理go的接口相关知识 接口的定义12345678910111213141516171819202122232425262728293031323334package mainimport ( &quot;fmt&quot;)type data interface &#123; print()&#125;type i intfunc (i) print() &#123; fmt.Println(&quot;int&quot;)&#125;type f float32func (f) print() &#123; fmt.Println(&quot;float&quot;)&#125;func main() &#123; var d data var in i d = in d.print() var flo f d = flo d.print()&#125; 一个类型实现了接口的所有方法，则这个类型就是实现了接口的类型，可以赋值给接口类型的值。具有面向对象的特征。 空接口1234567891011121314151617181920212223package mainimport ( &quot;fmt&quot;)type nul interface &#123;&#125;func main() &#123; var i int = 10 var f float32 = 10.10 var s string = &quot;10&quot; var data nul data = i fmt.Println(data) data = f fmt.Println(data) data = s fmt.Println(data)&#125; 空接口可以接受任意类型的值 flag.value1234567891011121314//main.gopackage mainimport ( &quot;flag&quot; &quot;fmt&quot;)var num = change(&quot;number&quot;, 0, &quot;input a number, output num*2&quot;)func main() &#123; flag.Parse() fmt.Println(num)&#125; 1234567891011121314151617181920212223242526272829303132//num.gopackage mainimport ( &quot;flag&quot; &quot;fmt&quot; &quot;strconv&quot;)type data struct &#123; number int64&#125;func (d *data) String() string &#123; return fmt.Sprintf(&quot;output is %d&quot;, d.number)&#125;func (d *data) Set(s string) error &#123; out, err := strconv.ParseInt(s, 10, 64) if err != nil &#123; return fmt.Errorf(&quot;error!&quot;) &#125; d.number = out * 2 return nil&#125;func change(name string, value int64, usage string) *data &#123; f := data&#123;value&#125; flag.CommandLine.Var(&amp;f, name, usage) return &amp;f&#125; 1234[*** ]$ ./main -number 100output is 200[*** ]$ ./main -number 1000output is 2000 nil接口1234567891011121314151617181920212223242526272829303132package mainimport &quot;fmt&quot;type test1 interface &#123; print()&#125;type test2 struct &#123; i int&#125;func (test2) print() &#123;&#125;func check(in test1) &#123; if in == nil &#123; fmt.Println(&quot;nil&quot;) return &#125; fmt.Println(&quot;not nil&quot;)&#125;func main() &#123; var a test1 check(a) var b test2 check(b)&#125; nil not nil 一个包含nil指针/值的接口不是nil接口，test2实现了print函数，是test1的一个实现类型。但b不是nil 12345|-----------------|| test2 ||_________________| //type| nil ||-----------------| //value todoending","categories":[],"tags":[{"name":"golang","slug":"golang","permalink":"https://riverferry.site/tags/golang/"}],"keywords":[]},{"title":"golang 方法和嵌入","slug":"2020-09-29-golang 方法和嵌入","date":"2020-09-29T00:00:00.000Z","updated":"2022-09-12T16:24:32.285Z","comments":true,"path":"2020-09-29-golang 方法和嵌入/","link":"","permalink":"https://riverferry.site/2020-09-29-golang%20%E6%96%B9%E6%B3%95%E5%92%8C%E5%B5%8C%E5%85%A5/","excerpt":"格式函数名和func之间添加指定类型作为receiver,只要底层数据类型不是指针和接口的类型都可以。绑定方法的时候，既可以绑定到对象本身，也可以绑定到对象的指针","text":"格式函数名和func之间添加指定类型作为receiver,只要底层数据类型不是指针和接口的类型都可以。绑定方法的时候，既可以绑定到对象本身，也可以绑定到对象的指针 1234567891011121314151617package mainimport ( &quot;fmt&quot;)type i intfunc (i) f() int &#123; fmt.Println(&quot;f()&quot;) return 0&#125;func main() &#123; var test i test.f()&#125; 底层类型不能是pointer和interfacepointer123456type i interface&#123;&#125;func (i) f() int &#123; fmt.Print(&quot;f()&quot;) return 0&#125; invalid receiver type i (i is an interface type) interface123456type i *intfunc (i) f() int &#123; fmt.Print(&quot;f()&quot;) return 0&#125; invalid receiver type i (i is a pointer type) 指针和对象如果方法中绑定的对象是值类型，则会造成拷贝，副本。如果结构很大，会影响性能，所以可以用指针。 12345678910111213type i int//case1func (*i) f() int &#123; fmt.Println(&quot;*i&quot;) return 0&#125;//case2func (i) f() int &#123; fmt.Println(&quot;i&quot;) return 0&#125; case1和case2两种写法都是正确的，但只能存在一种，否则会认为是重定义。调用的时候只要i.f()即可，编译器会自动引用或者解引用。 123456789101112131415161718package mainimport ( &quot;fmt&quot;)type i intfunc (i) f() int &#123; fmt.Println(&quot;i&quot;) return 0&#125;func main() &#123; var test i ptest := &amp;test ptest.f()&#125; 注意点 不管method的receiver是指针类型还是非指针类型，都是可以通过指针/非指针类型进行调用的，编译器会帮你做类型转换。 大对象可以考虑指针，指针需要考虑浅拷贝。 嵌入123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173package mainimport ( &quot;fmt&quot;)type small_has_func struct&#123; a int b int&#125;func (small_has_func) f() int &#123; fmt.Println(&quot;small&quot;) return 0&#125;type small_no_func struct&#123; a int b int&#125;//@1 value has nametype big_hasName_bs_hasFunc struct &#123; s small_has_func cc int&#125;type big_hasName_b_hasFunc struct &#123; s small_no_func cc int&#125;type big_hasName_s_hasFunc struct &#123; s small_has_func cc int&#125;func (big_hasName_bs_hasFunc) f() int &#123; fmt.Println(&quot;big_hasName_bs_hasFunc&quot;) return 0&#125;func (big_hasName_b_hasFunc) f() int &#123; fmt.Println(&quot;big_hasName_b_hasFunc&quot;) return 0&#125;//@2 value no nametype big_noName_bs_hasFunc struct &#123; small_has_func cc int&#125;type big_noName_b_hasFunc struct &#123; small_no_func cc int&#125;type big_noName_s_hasFunc struct &#123; small_has_func cc int&#125;func (big_noName_bs_hasFunc) f() int &#123; fmt.Println(&quot;big_noName_bs_hasFunc&quot;) return 0&#125;func (big_noName_b_hasFunc) f() int &#123; fmt.Println(&quot;big_noName_b_hasFunc&quot;) return 0&#125;//@3 pvalue has nametype pbig_hasName_bs_hasFunc struct &#123; ps *small_has_func cc int&#125;type pbig_hasName_b_hasFunc struct &#123; ps *small_no_func cc int&#125;type pbig_hasName_s_hasFunc struct &#123; ps *small_has_func cc int&#125;func (pbig_hasName_bs_hasFunc) f() int &#123; fmt.Println(&quot;pbig_hasName_bs_hasFunc&quot;) return 0&#125;func (pbig_hasName_b_hasFunc) f() int &#123; fmt.Println(&quot;pbig_hasName_b_hasFunc&quot;) return 0&#125;//@4 pvalue no nametype pbig_noName_bs_hasFunc struct &#123; *small_has_func cc int&#125;type pbig_noName_b_hasFunc struct &#123; *small_no_func cc int&#125;type pbig_noName_s_hasFunc struct &#123; *small_has_func cc int&#125;func (pbig_noName_bs_hasFunc) f() int &#123; fmt.Println(&quot;pbig_noName_bs_hasFunc&quot;) return 0&#125;func (pbig_noName_b_hasFunc) f() int &#123; fmt.Println(&quot;pbig_noName_b_hasFunc&quot;) return 0&#125;func main() &#123; var t1 big_hasName_bs_hasFunc t1.f() //big_hasName_bs_hasFunc t1.s.f() //small var t2 big_hasName_b_hasFunc t2.f() //big_hasName_b_hasFunc var t3 big_hasName_s_hasFunc //t3.f() //error t3.s.f() //small var t4 big_noName_bs_hasFunc t4.f() //big_noName_bs_hasFunc t4.small_has_func.f() //small var t5 big_noName_b_hasFunc t5.f() //big_noName_b_hasFunc var t6 big_noName_s_hasFunc t6.f() //small t6.small_has_func.f() //small //var t7 pbig_hasName_bs_hasFunc //t7.f() //t7.ps.f() //error t7_1 := pbig_hasName_bs_hasFunc&#123;&amp;small_has_func&#123;a:1, b:2&#125;,2&#125; t7_1.f() //pbig_hasName_bs_hasFunc t7_1.ps.f() //small var t8 pbig_hasName_b_hasFunc t8.f() //pbig_hasName_b_hasFunc t9 := pbig_hasName_s_hasFunc&#123;&amp;small_has_func&#123;a:1, b:2&#125;,2&#125; t9.ps.f() //small t10 := pbig_noName_bs_hasFunc&#123;&amp;small_has_func&#123;a:1, b:2&#125;,2&#125; t10.f() //pbig_noName_bs_hasFunc t10.small_has_func.f() //small var t11 pbig_noName_b_hasFunc t11.f() //pbig_noName_b_hasFunc t12 := pbig_noName_s_hasFunc&#123;&amp;small_has_func&#123;a:1, b:2&#125;,2&#125; t12.f() //small t12.small_has_func.f() //small&#125; 匿名的嵌入对象，可以用外部类型作为选择器，调用匿名对象的方法或者值。也可以用外部对象.内部对象的类型来作为选择器调用 同一层次不能存在相同的函数名，不同层次可以。优先级是先外层再内层递归 对于指针类型的嵌入，指针类型的对象一定要存在才可以，不然编译报错 方法值和方法表达式方法值1234567891011121314151617181920212223package mainimport ( &quot;fmt&quot;)type i intfunc (i) f() int &#123; fmt.Println(&quot;f()&quot;) return 0&#125;func main() &#123; //ok var data i = 100 test := data.f test() //not ok test := i.f test()&#125; 方法表达式12345678910111213141516171819package mainimport ( &quot;fmt&quot;)type i intfunc (i) f() int &#123; fmt.Println(&quot;f()&quot;) return 0&#125;func main() &#123; //ok test := i.f var data i = 100 test(data)&#125; 接收器类型是nil123456789101112131415161718package mainimport &quot;fmt&quot;type i intfunc (pi *i) test() &#123; if pi == nil &#123; fmt.Println(&quot;nil&quot;) return &#125; fmt.Println(&quot;not nil&quot;)&#125;func main() &#123; var m *i = nil //nil m.test()&#125; ending","categories":[],"tags":[{"name":"golang","slug":"golang","permalink":"https://riverferry.site/tags/golang/"}],"keywords":[]},{"title":"redis-数据结构","slug":"2020-09-25-redis-数据结构","date":"2020-09-25T00:00:00.000Z","updated":"2022-09-12T16:24:32.285Z","comments":true,"path":"2020-09-25-redis-数据结构/","link":"","permalink":"https://riverferry.site/2020-09-25-redis-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/","excerpt":"参考REDIS-5.0.9","text":"参考REDIS-5.0.9 字符串对于不需要修改的字符串，沿用C语言的格式。对于像键值这种可能修改的，采用SDS，内部实现的数据结构： 123456789101112131415161718192021222324252627282930313233343536373839404142/* Note: sdshdr5 is never used, we just access the flags byte directly. * However is here to document the layout of type 5 SDS strings. */ //lsb:低3位struct __attribute__ ((__packed__)) sdshdr5 &#123; unsigned char flags; /* 3 lsb of type, and 5 msb of string length */ char buf[];&#125;;struct __attribute__ ((__packed__)) sdshdr8 &#123; uint8_t len; /* used */ uint8_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[];&#125;;struct __attribute__ ((__packed__)) sdshdr16 &#123; uint16_t len; /* used */ uint16_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[];&#125;;struct __attribute__ ((__packed__)) sdshdr32 &#123; uint32_t len; /* used */ uint32_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[];&#125;;struct __attribute__ ((__packed__)) sdshdr64 &#123; uint64_t len; /* used */ uint64_t alloc; /* excluding the header and null terminator */ unsigned char flags; /* 3 lsb of type, 5 unused bits */ char buf[];&#125;;#define SDS_TYPE_5 0#define SDS_TYPE_8 1#define SDS_TYPE_16 2#define SDS_TYPE_32 3#define SDS_TYPE_64 4#define SDS_TYPE_MASK 7#define SDS_TYPE_BITS 3#define SDS_HDR_VAR(T,s) struct sdshdr##T *sh = (void*)((s)-(sizeof(struct sdshdr##T)));#define SDS_HDR(T,s) ((struct sdshdr##T *)((s)-(sizeof(struct sdshdr##T))))#define SDS_TYPE_5_LEN(f) ((f)&gt;&gt;SDS_TYPE_BITS) sdshdr*中flags的低3位表示类型(eg:SDS_TYPE_5)，sdshdr5中的flags的高5位表示string的长度，其他长度结果体的len表示长度，alloc表示总的大小。 sdsnewlen1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677/* Create a new sds string with the content specified by the &#x27;init&#x27; pointer * and &#x27;initlen&#x27;. * If NULL is used for &#x27;init&#x27; the string is initialized with zero bytes. * If SDS_NOINIT is used, the buffer is left uninitialized; * * The string is always null-termined (all the sds strings are, always) so * even if you create an sds string with: * * mystring = sdsnewlen(&quot;abc&quot;,3); * * You can print the string with printf() as there is an implicit \\0 at the * end of the string. However the string is binary safe and can contain * \\0 characters in the middle, as the length is stored in the sds header. */sds sdsnewlen(const void *init, size_t initlen) &#123; void *sh; sds s; //根据长度选择合适的数据结构sdshdr char type = sdsReqType(initlen); /* Empty strings are usually created in order to append. Use type 8 * since type 5 is not good at this. */ if (type == SDS_TYPE_5 &amp;&amp; initlen == 0) type = SDS_TYPE_8; //对应数据结构体sdshdr的大小 int hdrlen = sdsHdrSize(type); unsigned char *fp; /* flags pointer. */ //malloc,结构体大小+字符串长度+1个结束符 sh = s_malloc(hdrlen+initlen+1); if (init==SDS_NOINIT) init = NULL; else if (!init) memset(sh, 0, hdrlen+initlen+1); if (sh == NULL) return NULL; //s是结构体后面柔性数组的位置 s = (char*)sh+hdrlen; fp = ((unsigned char*)s)-1; switch(type) &#123; case SDS_TYPE_5: &#123; //高5位存长度，低3位存类型 *fp = type | (initlen &lt;&lt; SDS_TYPE_BITS); break; &#125; case SDS_TYPE_8: &#123; //sh从void*转成对应结构体的指针 SDS_HDR_VAR(8,s); sh-&gt;len = initlen; sh-&gt;alloc = initlen; *fp = type; break; &#125; case SDS_TYPE_16: &#123; SDS_HDR_VAR(16,s); sh-&gt;len = initlen; sh-&gt;alloc = initlen; *fp = type; break; &#125; case SDS_TYPE_32: &#123; SDS_HDR_VAR(32,s); sh-&gt;len = initlen; sh-&gt;alloc = initlen; *fp = type; break; &#125; case SDS_TYPE_64: &#123; SDS_HDR_VAR(64,s); sh-&gt;len = initlen; sh-&gt;alloc = initlen; *fp = type; break; &#125; &#125; //拷贝数据 if (initlen &amp;&amp; init) memcpy(s, init, initlen); s[initlen] = &#x27;\\0&#x27;; return s;&#125; sdscatlen123456789101112131415/* Append the specified binary-safe string pointed by &#x27;t&#x27; of &#x27;len&#x27; bytes to the * end of the specified sds string &#x27;s&#x27;. * * After the call, the passed sds string is no longer valid and all the * references must be substituted with the new pointer returned by the call. */sds sdscatlen(sds s, const void *t, size_t len) &#123; size_t curlen = sdslen(s); s = sdsMakeRoomFor(s,len); if (s == NULL) return NULL; memcpy(s+curlen, t, len); sdssetlen(s, curlen+len); s[curlen+len] = &#x27;\\0&#x27;; return s;&#125; 字符串拼接函数，主要是sdsMakeRoomFor，如果空余长度够用直接拷贝，不够的话sdsMakeRoomFor函数重新申请内存并返回新的地址，进行拷贝。拷贝完更新结构体的值。 sdsMakeRoomFor123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657/* Enlarge the free space at the end of the sds string so that the caller * is sure that after calling this function can overwrite up to addlen * bytes after the end of the string, plus one more byte for nul term. * * Note: this does not change the *length* of the sds string as returned * by sdslen(), but only the free buffer space we have. */sds sdsMakeRoomFor(sds s, size_t addlen) &#123; void *sh, *newsh; size_t avail = sdsavail(s); size_t len, newlen; //[-1]在c语言是允许的，c++尽量不要这么来，参考https://www.zhihu.com/question/34790951 //s[-1]是flag的地址 char type, oldtype = s[-1] &amp; SDS_TYPE_MASK; int hdrlen; /* Return ASAP if there is enough space left. */ if (avail &gt;= addlen) return s; //len是字符串的长度 len = sdslen(s); //sh结构体的地址 sh = (char*)s-sdsHdrSize(oldtype); newlen = (len+addlen); if (newlen &lt; SDS_MAX_PREALLOC) newlen *= 2; else newlen += SDS_MAX_PREALLOC; //重新计算新的长度需要的结构体类型 type = sdsReqType(newlen); /* Don&#x27;t use type 5: the user is appending to the string and type 5 is * not able to remember empty space, so sdsMakeRoomFor() must be called * at every appending operation. */ if (type == SDS_TYPE_5) type = SDS_TYPE_8; hdrlen = sdsHdrSize(type); if (oldtype==type) &#123; //结构体类型不变的，直接realloc newsh = s_realloc(sh, hdrlen+newlen+1); if (newsh == NULL) return NULL; s = (char*)newsh+hdrlen; &#125; else &#123; /* Since the header size changes, need to move the string forward, * and can&#x27;t use realloc */ //结构体类型变化的，申请新的空间，拷贝老的过来，释放来的空间 newsh = s_malloc(hdrlen+newlen+1); if (newsh == NULL) return NULL; memcpy((char*)newsh+hdrlen, s, len+1); s_free(sh); s = (char*)newsh+hdrlen; s[-1] = type; sdssetlen(s, len); &#125; sdssetalloc(s, newlen); return s;&#125; 链表ending","categories":[],"tags":[{"name":"redis","slug":"redis","permalink":"https://riverferry.site/tags/redis/"}],"keywords":[]},{"title":"redis 安装","slug":"2020-09-02-redis 安装","date":"2020-09-02T00:00:00.000Z","updated":"2022-09-12T16:24:32.285Z","comments":true,"path":"2020-09-02-redis 安装/","link":"","permalink":"https://riverferry.site/2020-09-02-redis%20%E5%AE%89%E8%A3%85/","excerpt":"安装下载地址,我下的5.0的版本，然后make即可。","text":"安装下载地址,我下的5.0的版本，然后make即可。 测试： server 12345678910111213141516171819202122232425[root@**** ]# ./src/redis-server 27306:C 02 Sep 2020 17:51:42.050 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo27306:C 02 Sep 2020 17:51:42.051 # Redis version=5.0.9, bits=64, commit=00000000, modified=0, pid=27306, just started27306:C 02 Sep 2020 17:51:42.051 # Warning: no config file specified, using the default config. In order to specify a config file use ./src/redis-server /path/to/redis.conf _._ _.-``__ &#x27;&#x27;-._ _.-`` `. `_. &#x27;&#x27;-._ Redis 5.0.9 (00000000/0) 64 bit .-`` .-```. ```\\/ _.,_ &#x27;&#x27;-._ ( &#x27; , .-` | `, ) Running in standalone mode |`-._`-...-` __...-.``-._|&#x27;` _.-&#x27;| Port: 6379 | `-._ `._ / _.-&#x27; | PID: 27306 `-._ `-._ `-./ _.-&#x27; _.-&#x27; |`-._`-._ `-.__.-&#x27; _.-&#x27;_.-&#x27;| | `-._`-._ _.-&#x27;_.-&#x27; | http://redis.io `-._ `-._`-.__.-&#x27;_.-&#x27; _.-&#x27; |`-._`-._ `-.__.-&#x27; _.-&#x27;_.-&#x27;| | `-._`-._ _.-&#x27;_.-&#x27; | `-._ `-._`-.__.-&#x27;_.-&#x27; _.-&#x27; `-._ `-.__.-&#x27; _.-&#x27; `-._ _.-&#x27; `-.__.-&#x27; 27306:M 02 Sep 2020 17:51:42.052 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.27306:M 02 Sep 2020 17:51:42.052 # Server initialized27306:M 02 Sep 2020 17:51:42.052 * Ready to accept connections client 123456[root@**** ]# ./src/redis-cli 127.0.0.1:6379&gt; set key valueOK127.0.0.1:6379&gt; get key&quot;value&quot;127.0.0.1:6379&gt; 前台运行是这样的，后台运行需要配合配置文件。 修改redis.conf 12#daemonize nodaemonize yes 运行 1234[root@**** ]# ./src/redis-server ./redis.conf 27989:C 02 Sep 2020 17:58:47.478 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo27989:C 02 Sep 2020 17:58:47.478 # Redis version=5.0.9, bits=64, commit=00000000, modified=0, pid=27989, just started27989:C 02 Sep 2020 17:58:47.478 # Configuration loaded 开机启动参考: redis开机自动启动服务设置 step 11cp /usr/local/redis/redis-5.0.9/utils/redis_init_script /etc/init.d/redis step 2修改配置文件 123456789REDISPORT=6379#EXEC=/usr/local/bin/redis-server#CLIEXEC=/usr/local/bin/redis-cliEXEC=/usr/local/redis/redis-5.0.9/src/redis-serverCLIEXEC=/usr/local/redis/redis-5.0.9/src/redis-cliPIDFILE=/var/run/redis_$&#123;REDISPORT&#125;.pid#CONF=&quot;/etc/redis/$&#123;REDISPORT&#125;.conf&quot;CONF=&quot;/usr/local/redis/redis-5.0.9/redis.conf&quot; step 312345678910111213141516171819202122//加入chkconfig[root@**** ]# chkconfig --add redis//开机启动[root@**** ]# chkconfig redis on[root@**** ]# ps aux | grep redisroot 27990 0.0 0.0 51304 2880 ? Ssl 17:58 0:00 ./src/redis-server 127.0.0.1:6379root 28960 0.0 0.0 12148 688 pts/1 S+ 18:09 0:00 grep --color=auto redis//stop redis[root@**** ]# service redis stopStopping ...Redis stopped[root@**** ]# ps aux | grep redisroot 29107 0.0 0.0 12148 684 pts/1 S+ 18:10 0:00 grep --color=auto redis//start redis[root@**** ]# service redis startStarting Redis server...29120:C 02 Sep 2020 18:10:16.256 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo29120:C 02 Sep 2020 18:10:16.256 # Redis version=5.0.9, bits=64, commit=00000000, modified=0, pid=29120, just started29120:C 02 Sep 2020 18:10:16.256 # Configuration loaded[root@**** ]# ps aux | grep redisroot 29121 0.0 0.0 51304 2744 ? Ssl 18:10 0:00 /usr/local/redis/redis-5.0.9/src/redis-server 127.0.0.1:6379root 29126 0.0 0.0 12148 688 pts/1 S+ 18:10 0:00 grep --color=auto redis ending","categories":[],"tags":[{"name":"redis","slug":"redis","permalink":"https://riverferry.site/tags/redis/"}],"keywords":[]},{"title":"mysql 索引","slug":"2020-09-01-mysql 索引","date":"2020-09-01T00:00:00.000Z","updated":"2022-09-12T16:24:32.285Z","comments":true,"path":"2020-09-01-mysql 索引/","link":"","permalink":"https://riverferry.site/2020-09-01-mysql%20%E7%B4%A2%E5%BC%95/","excerpt":"前言留的坑，以后填","text":"前言留的坑，以后填 TODO聚簇索引和非聚簇索引的区别，实现原理。 ending","categories":[],"tags":[{"name":"坑","slug":"坑","permalink":"https://riverferry.site/tags/%E5%9D%91/"}],"keywords":[]},{"title":"网络 https原理","slug":"2020-09-01-网络 https原理","date":"2020-09-01T00:00:00.000Z","updated":"2022-09-12T16:24:32.285Z","comments":true,"path":"2020-09-01-网络 https原理/","link":"","permalink":"https://riverferry.site/2020-09-01-%E7%BD%91%E7%BB%9C%20https%E5%8E%9F%E7%90%86/","excerpt":"前言留的坑，以后填","text":"前言留的坑，以后填 TODOending","categories":[],"tags":[{"name":"坑","slug":"坑","permalink":"https://riverferry.site/tags/%E5%9D%91/"}],"keywords":[]},{"title":"数据库 范式","slug":"2020-08-29-数据库 范式","date":"2020-08-29T00:00:00.000Z","updated":"2022-09-12T16:24:32.285Z","comments":true,"path":"2020-08-29-数据库 范式/","link":"","permalink":"https://riverferry.site/2020-08-29-%E6%95%B0%E6%8D%AE%E5%BA%93%20%E8%8C%83%E5%BC%8F/","excerpt":"参考如何理解关系型数据库的常见设计范式？ 前言留的坑，以后填","text":"参考如何理解关系型数据库的常见设计范式？ 前言留的坑，以后填 TODOending","categories":[],"tags":[{"name":"坑","slug":"坑","permalink":"https://riverferry.site/tags/%E5%9D%91/"}],"keywords":[]},{"title":"mysql change buffer","slug":"2020-08-26-mysql change buffer","date":"2020-08-26T00:00:00.000Z","updated":"2022-09-12T16:24:32.285Z","comments":true,"path":"2020-08-26-mysql change buffer/","link":"","permalink":"https://riverferry.site/2020-08-26-mysql%20change%20buffer/","excerpt":"参考innodb buffer poll inser bufferinnodb的索引是B+树，主键索引也叫聚簇索引，是自增的一个非空的键值。所以顺序插入的效率是很高的。但是对于非聚簇索引(第二索引)，则往往是离散插入的，效率很低。经常会碰到字符串，或者非递增的数据作为第二索引。","text":"参考innodb buffer poll inser bufferinnodb的索引是B+树，主键索引也叫聚簇索引，是自增的一个非空的键值。所以顺序插入的效率是很高的。但是对于非聚簇索引(第二索引)，则往往是离散插入的，效率很低。经常会碰到字符串，或者非递增的数据作为第二索引。 为了减少离散插入造成的效率损失，innodb引入了insert buffer缓冲区，对于第二索引的插入，先放到缓冲区中，然后merge，如果merge的时候，一次可以处理多个，就提升了性能。 insert buffer使用要满足： 索引是辅助索引(第二索引) 索引不是唯一的 因为唯一索引要判断唯一性，就不能直接放到缓冲区不管。 1234567891011show engine innodb status;-------------------------------------INSERT BUFFER AND ADAPTIVE HASH INDEX-------------------------------------Ibuf: size 1, free list len 0, seg size 2, 0 mergesmerged operations: insert 0, delete mark 0, delete 0discarded operations: insert 0, delete mark 0, delete 0 segsize表示insert buffer大小：2*16kb free list代表空闲列表长度 size表示已经合并数据页的长度 change bufferinnodb从1.0.x版本引入change buffer,是insert buffer的加强版，不仅支持insert,还支持其他dml操作(insert buffer, delete buffer, purge buffer)。所以，insert buffer也是个老古董了。 delete操作可能的过程： 将记录标记为已删除 真正删除记录 第一步就是delete buffer,第二步是purge buffer. innodb_change_buffering1234567MySQL [mysql]&gt; show variables like &#x27;innodb_change_buffering&#x27;;+-------------------------+-------+| Variable_name | Value |+-------------------------+-------+| innodb_change_buffering | all |+-------------------------+-------+1 row in set (0.00 sec) innodb_change_buffering可选的值： inserts deletes purges changes all none changes = inserts + deletes all = 所有 none表示不启用 innodb_change_buffer_max_size1234567MySQL [mysql]&gt; show variables like &#x27;innodb_change_buffer_max_size&#x27;;+-------------------------------+-------+| Variable_name | Value |+-------------------------------+-------+| innodb_change_buffer_max_size | 25 |+-------------------------------+-------+1 row in set (0.00 sec) innodb_change_buffer_max_size表示change buffer的最大大小，25表示最多使用1/4的缓冲池空间。 change buffer内部也是B+树，具体不研究了。 question如果binlog=row,需要旧的数据，会影响change buffer吗？ 这个mysql实战45讲下面的问题，之前自己也没搞懂，这篇文章写完似乎明白了。 聚簇索引和第二索引都是B+树，不管是新增数据还是删除数据，聚簇索引和第二索引都是要同步的。所以change buffer必要性在这里。同步聚簇索引效率高，同步第二索引效率低，所以先缓存，并不真的落盘同步。等下次查询的时候，在从磁盘读取第二索引的值，将之前的buffer数据读入merge.或者后台线程merge. 然后查老得数据是从聚簇索引查的，不影响。我理解聚簇索引是肯定要持久化到磁盘的，第二索引应该也会持久化到磁盘。所以对于查老得数据，如果内存不存在，直接将磁盘的聚簇索引的记录查出来就是完整的行记录，不用查磁盘的第二索引的值，所以change buffer还是起效果的。 ending","categories":[],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://riverferry.site/tags/mysql/"}],"keywords":[]},{"title":"mysql 脏读 不可重复读","slug":"2020-08-26-mysql 脏读 不可重复读","date":"2020-08-26T00:00:00.000Z","updated":"2022-09-12T16:24:32.285Z","comments":true,"path":"2020-08-26-mysql 脏读 不可重复读/","link":"","permalink":"https://riverferry.site/2020-08-26-mysql%20%E8%84%8F%E8%AF%BB%20%E4%B8%8D%E5%8F%AF%E9%87%8D%E5%A4%8D%E8%AF%BB/","excerpt":"参考mysql技术内幕 脏读先看下脏页和脏数据的区别","text":"参考mysql技术内幕 脏读先看下脏页和脏数据的区别 脏页 脏页是缓冲区中的已经提交的数据，但还没刷到磁盘持久化，不过重做日志会刷盘的。 脏数据 脏数据是事务还未提交，进行修改后的数据 那么脏读，就是读到了脏数据，例如： 1234567891011//read uncommitted sessionA sessionBT1 begin; begin; select * from tt where c = 3;//d = 0T2 update tt set d = 999 where c = 3;T3 select * from tt where c = 3;//d = 999 sessionB 1234567891011121314151617181920212223242526MySQL [mysql]&gt; show variables like &#x27;%binlog_format%&#x27;;+---------------+-------+| Variable_name | Value |+---------------+-------+| binlog_format | ROW |+---------------+-------+1 row in set (0.00 sec)MySQL [mysql]&gt; set session tx_isolation = &#x27;read-uncommitted&#x27;;Query OK, 0 rows affected, 1 warning (0.00 sec)MySQL [mysql]&gt; select * from tt where c = 3;+----+------+------+-------+------+------+| id | c | d | field | f2 | f3 |+----+------+------+-------+------+------+| 3 | 3 | 0 | NULL | NULL | NULL |+----+------+------+-------+------+------+1 row in set (0.00 sec)MySQL [mysql]&gt; select * from tt where c = 3;+----+------+------+-------+------+------+| id | c | d | field | f2 | f3 |+----+------+------+-------+------+------+| 3 | 3 | 999 | NULL | NULL | NULL |+----+------+------+-------+------+------+1 row in set (0.00 sec) sessionA 12345678910111213141516171819202122MySQL [mysql]&gt; show variables like &#x27;%binlog_format%&#x27;;+---------------+-------+| Variable_name | Value |+---------------+-------+| binlog_format | ROW |+---------------+-------+1 row in set (0.01 sec)MySQL [mysql]&gt; set session tx_isolation = &#x27;read-uncommitted&#x27;;Query OK, 0 rows affected, 1 warning (0.00 sec)MySQL [mysql]&gt; select * from tt where c = 3;+----+------+------+-------+------+------+| id | c | d | field | f2 | f3 |+----+------+------+-------+------+------+| 3 | 3 | 0 | NULL | NULL | NULL |+----+------+------+-------+------+------+1 row in set (0.00 sec)MySQL [mysql]&gt; update tt set d = 999 where c = 3;Query OK, 1 row affected (0.04 sec)Rows matched: 1 Changed: 1 Warnings: 0 sessionB读到了d=999,即sessionA修改的未提交的数据，也就是脏数据，发生了脏读。脏读只在read uncommitted隔离级别下发生，其破坏了事务的隔离性，基本没啥用。pgsql都没有实现ru这个级别。 书中讲，这种情况下可以使用脏读：replication环境的slave节点，并且在该slave上的查询并不需要特别精确的返回值。 不可重复读 幻读是读到了别的事务未提交的数据，导致两次读结果不一致 不可重复读是读到了别的事务已提交的数据，导致两次读结果不一致 这个已经很常见了，模拟一种： 12345678910111213//read committed sessionA sessionBT1 begin; select * from tt where c = 3;T2 update tt set d = 999 where c = 3;T3 select * from tt where c = 3; sessionA 1234567891011121314151617181920212223242526MySQL [mysql]&gt; select @@tx_isolation;+----------------+| @@tx_isolation |+----------------+| READ-COMMITTED |+----------------+1 row in set, 1 warning (0.00 sec)MySQL [mysql]&gt; begin;Query OK, 0 rows affected (0.00 sec)MySQL [mysql]&gt; select * from tt where c = 3;+----+------+------+-------+------+------+| id | c | d | field | f2 | f3 |+----+------+------+-------+------+------+| 3 | 3 | 0 | NULL | NULL | NULL |+----+------+------+-------+------+------+1 row in set (0.00 sec)MySQL [mysql]&gt; select * from tt where c = 3;+----+------+------+-------+------+------+| id | c | d | field | f2 | f3 |+----+------+------+-------+------+------+| 3 | 3 | 999 | NULL | NULL | NULL |+----+------+------+-------+------+------+1 row in set (0.00 sec) sessionB 123456789101112MySQL [mysql]&gt; select @@tx_isolation;+----------------+| @@tx_isolation |+----------------+| READ-COMMITTED |+----------------+1 row in set, 1 warning (0.00 sec)MySQL [mysql]&gt; update tt set d = 999 where c = 3;Query OK, 1 row affected (0.01 sec)Rows matched: 1 Changed: 1 Warnings: 0 不可重复读是可接受的，读到别的事务一提交的结果，还好吧，根据实际情况选择就好。 不可重复读发生在read committed隔离级别下，当前更低的ru也会发生。rr下通过next-key lock解决不可重复读问题(如果是普通读，读快照，是不存在不可重复读的；如果是加锁读，因为next-key lock，也不存在不可重复读). ending","categories":[],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://riverferry.site/tags/mysql/"}],"keywords":[]},{"title":"mysql 事务","slug":"2020-08-25-mysql 事务","date":"2020-08-25T00:00:00.000Z","updated":"2022-09-12T16:24:32.285Z","comments":true,"path":"2020-08-25-mysql 事务/","link":"","permalink":"https://riverferry.site/2020-08-25-mysql%20%E4%BA%8B%E5%8A%A1/","excerpt":"参考数据库事务、隔离级别和锁 mysql技术内幕 wikipedia mysql实战45讲","text":"参考数据库事务、隔离级别和锁 mysql技术内幕 wikipedia mysql实战45讲 概念 数据库事务（简称：事务）是数据库管理系统执行过程中的一个逻辑单位，由一个有限的数据库操作序列构成 ACIDatomicity 原子性 事务作为一个整体被执行，包含在其中的对数据库的操作要么全部被执行，要么都不执行 就像atm取款一样，出账和入账不能部分完成。 consistency 一致性 事务应确保数据库的状态从一个一致状态转变为另一个一致状态。一致状态的含义是数据库中的数据应满足完整性约束 比如唯一键约束，外键约束 isolation 隔离性 多个事务并发执行时，一个事务的执行不应影响其他事务的执行 通常通过锁，或者mvcc等实现 durability 持久性 已被提交的事务对数据库的修改应该永久保存在数据库中 事务提交的时候，redo log, binlog会刷盘(也可根据配置参数调整)，总之，在数据库层面是可以保证事务提交后的持久性的，但外部比如硬件导致的异常不可控 事务的实现 隔离性通过锁或者mvcc实现 原子性，持久性通过redo log 一致性通过undo log redo loginnodb_flush_log_at_trx_commit事务提交时候，redo log会把redo log buffer的数据写入系统文件缓存，并同步到磁盘(可以根据参数innodb_flush_log_at_trx_commit控制写入的时机)。 图片来源：mysql实战45讲 innodb_flush_log_at_trx_commit的取值情况： 0: 事务提交时不写重做日志(redo log和undo log),只是留在redo log buffer,master thread会每隔1s进行fsync的 1: 默认值，每次提交进行fsync 2: 提交时候，写入系统文件缓存 除了后台线程刷盘，还有两种情况导致redo log持久化的： redo log buffer大小达到innodb_log_buffer_size一半的时候 其他事物提交的时候如果设置的要刷盘，由于redo log buffer对于事务是公用的，事务会把别的事务的redo log连带fsync sync_binlog 图片来源：mysql实战45讲 binlog也有刷盘策略可以控制的： sync_binlog的取值： 0: 每次事务提交，只write写文件缓存，不fsync 1: 每次提交都fsync N&gt;1: 每次提交都write,积累N个事务后，fsync 双1sync_binlog=1,innodb_flush_log_at_trx_commit=1 这样设置可以保证每次提交事务，binlog和redo log都刷盘，高可用，但是io压力大 非双1业务高峰期，备库延迟，批量导入这样的场景可以设置非双1，提高数据库性能，牺牲一点可靠性的代价。mysql实战45讲给的参考是：innodb_flush_logs_at_trx_commit=2、sync_binlog=1000。 两阶段提交redo log的写入是基于两阶段提交的： 二阶段提交（英语：Two-phase Commit）是指在计算机网络以及数据库领域内，为了使基于分布式系统架构下的所有节点在进行事务提交时保持一致性而设计的一种算法。通常，二阶段提交也被称为是一种协议（Protocol）。在分布式系统中，每个节点虽然可以知晓自己的操作时成功或者失败，却无法知道其他节点的操作的成功或失败。当一个事务跨越多个节点时，为了保持事务的ACID特性，需要引入一个作为协调者的组件来统一掌控所有节点（称作参与者）的操作结果并最终指示这些节点是否要把操作结果进行真正的提交（比如将更新后的数据写入磁盘等等）。因此，二阶段提交的算法思路可以概括为： 参与者将操作成败通知协调者，再由协调者根据所有参与者的反馈情报决定各参与者是否要提交操作还是中止操作。 概念中的两阶段提交主要针对分布式事务，这里讲的是内部事务的两阶段提交，大同小异。 LSNlog sequence number,日志序列号。在innodb中，占用8字节，单调递增 含义： 重做日志写入的总量 //1 checkpoint的位置 //2 页的版本 //3 1: lsn表示了重做日志的字节的总量，加入原来lsn=1000,重做日志写入1000字节，则lsn=1100 2:可用于checkpoint的记录 redo log组的第一个日志文件的文件头会保存checkpoint位置，checkpoint表示已经刷新到磁盘的lsn号 3:每个页的头部，FIL_PAGE_LSN记录这个页的lsn号，表示该页最后刷新时的lsn号，通过对比redo log中的lsn号，可用于恢复页 group commitfsync的效率是很慢的，组提交可以一次将多个fsync同时进行，提高效率。 两阶段提交过程： 1: innodb存储引擎进行prepare 2: mysql写入binlog日志 3: innodb写入重做日志文件 3.1 将日志写入日志缓冲 3.2 调用fsync 3.1步可以并发执行的时候，到3.2就可能一次把多个事务的日志刷盘。但是mysql老得版本不支持，因为老得版本两阶段提交会加锁prepare_commit_mutex,这个锁会导致3.2执行的时候，其他事物不能执行3.1.导致group commit不可用。不过mysql5.6通过BLGC解决了该问题： BLGC binlog group comit，mysql server层提交时，按顺序将其放入一个队列，队列中的第一个事务成为leader,其他事务成为follower,leader控制follower,分3个阶段： flush阶段，二进制日志写入内存 sync阶段，二进制日志刷盘，将队列中所有事物刷盘 commit阶段，leader根据顺序调用存储引擎层的事务的提交。innodb本来就支持组提交。 blgc实现没有用到prepare_commit_mutex锁，所以innodb层group commmit可以发挥出来，并且server层的binlog也变成了group commit,性能很好。 原来server层的binlog是每个线程单独一个binlog cache的，不像redo log是公用的redo log buffer,通过队列将binlog cache串起来组提交。并且leader可以根据顺序控制引擎层按照顺序提交，不需要加锁。 purge 由于mvcc的缘故，删除操作并不直接删除数据，因为这个版本的记录可能被其他事务引用，所以update/delete的时候如果是删除数据，只是把删除标记置为真(不确定这个标记是不是就是del_trx_id),真正删除是purge线程判断然后处理的。 undo log允许在一个页上保存多个undo log记录，之前也总结过undo log是通过链表串起来的，结合这两点，再看上面的图： 从链表第一个节点开始，trx1找到undo page1,清除trx1的undo log,然后继续在这个页中找其他的事务，清除trx3,然后找到trx5,trx5被其他事务引用了，不能删除，回到链表，找到trx2,然后trx6,trx4,整个undo page2就清除完了，该页可以被其他地方使用了。 以上就是purge的大概流程，优先清除一个页上的undo log,避免了过多的随机写操作。 purge还涉及一些配置参数，感觉不是很重要，就不记录了。 ending","categories":[],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://riverferry.site/tags/mysql/"}],"keywords":[]},{"title":"mysql 幻读","slug":"2020-08-25-mysql 幻读","date":"2020-08-25T00:00:00.000Z","updated":"2022-09-12T16:24:32.285Z","comments":true,"path":"2020-08-25-mysql 幻读/","link":"","permalink":"https://riverferry.site/2020-08-25-mysql%20%E5%B9%BB%E8%AF%BB/","excerpt":"参考mysql实战45讲","text":"参考mysql实战45讲 概念 phantom problem是指在同一事务下，连续执行两次的sql语句可能导致不同的结果，第二次的sql语句可能会返回之前不存在的行 一定记住是之前不存在的行，这点很重要。 复现1234567891011MySQL [mysql]&gt; select * from tt;+----+------+------+-------+------+------+| id | c | d | field | f2 | f3 |+----+------+------+-------+------+------+| 1 | 1 | 777 | NULL | NULL | NULL || 2 | 2 | 200 | NULL | NULL | NULL || 3 | 3 | 30 | NULL | NULL | NULL || 9 | 5 | 50 | NULL | NULL | NULL || 20 | 4 | 90 | NULL | NULL | NULL |+----+------+------+-------+------+------+5 rows in set (0.00 sec) 设置场景： 123456789101112131415 sessionA sessionB begin;T1 select * from tt where c &gt; 2; //select * from tt where c &gt; 2 for update; update tt set d = 0 where c &gt; 2; T2 insert tt select null,6,60,null,null,null;T3 select * from tt where c &gt; 2; //select * from tt where c &gt; 2 for update; commit; 预期结果： 12345678910111213141516171819202122232425262728293031323334T1 select:| 3 | 3 | 30 | NULL | NULL | NULL || 9 | 5 | 50 | NULL | NULL | NULL || 20 | 4 | 90 | NULL | NULL | NULL |--------------------------------------------------T1 update:| 3 | 3 | 0 | NULL | NULL | NULL || 9 | 5 | 0 | NULL | NULL | NULL || 20 | 4 | 0 | NULL | NULL | NULL |--------------------------------------------------T2 insert:| 3 | 3 | 0 | NULL | NULL | NULL || 9 | 5 | 0 | NULL | NULL | NULL || 20 | 4 | 0 | NULL | NULL | NULL || 21 | 6 | 60 | NULL | NULL | NULL |--------------------------------------------------T3 select:可能1:| 3 | 3 | 0 | NULL | NULL | NULL || 9 | 5 | 0 | NULL | NULL | NULL || 20 | 4 | 0 | NULL | NULL | NULL || 21 | 6 | 60 | NULL | NULL | NULL |可能2:| 3 | 3 | 0 | NULL | NULL | NULL || 9 | 5 | 0 | NULL | NULL | NULL || 20 | 4 | 0 | NULL | NULL | NULL | 读提交场景sessionB: 12345678910111213141516MySQL [mysql]&gt; set session tx_isolation=&quot;read-committed&quot;;Query OK, 0 rows affected, 1 warning (0.00 sec)MySQL [mysql]&gt; select @@tx_isolation;+----------------+| @@tx_isolation |+----------------+| READ-COMMITTED |+----------------+1 row in set, 1 warning (0.00 sec)MySQL [mysql]&gt; begin;Query OK, 0 rows affected (0.00 sec)MySQL [mysql]&gt; insert tt select null,6,60,null,null,null;ERROR 1665 (HY000): Cannot execute statement: impossible to write to binary log since BINLOG_FORMAT = STATEMENT and at least one table uses a storage engine limited to row-based logging. InnoDB is limited to row-logging when transaction isolation level is READ COMMITTED or READ UNCOMMITTED. ERROR 1665 (HY000): Cannot execute statement: impossible to write to binary log since BINLOG_FORMAT = STATEMENT and at least one table uses a storage engine limited to row-based logging. InnoDB is limited to row-logging when transaction isolation level is READ COMMITTED or READ UNCOMMITTED. 这里报错，因为binlog现在是statement,innodb认为在rc/ru下，binlog应该设置为row. ok,改成row,继续： sessionA 1234567891011121314151617181920212223242526272829303132MySQL [mysql]&gt; select @@tx_isolation;+----------------+| @@tx_isolation |+----------------+| READ-COMMITTED |+----------------+1 row in set, 1 warning (0.00 sec)MySQL [mysql]&gt; select * from tt where c &gt; 2; +----+------+------+-------+------+------+| id | c | d | field | f2 | f3 |+----+------+------+-------+------+------+| 3 | 3 | 30 | NULL | NULL | NULL || 9 | 5 | 50 | NULL | NULL | NULL || 20 | 4 | 90 | NULL | NULL | NULL |+----+------+------+-------+------+------+3 rows in set (0.00 sec)MySQL [mysql]&gt; update tt set d = 0 where c &gt; 2; Query OK, 3 rows affected (0.01 sec)Rows matched: 3 Changed: 3 Warnings: 0MySQL [mysql]&gt; select * from tt where c &gt; 2;+----+------+------+-------+------+------+| id | c | d | field | f2 | f3 |+----+------+------+-------+------+------+| 3 | 3 | 0 | NULL | NULL | NULL || 9 | 5 | 0 | NULL | NULL | NULL || 12 | 6 | 60 | NULL | NULL | NULL || 20 | 4 | 0 | NULL | NULL | NULL |+----+------+------+-------+------+------+4 rows in set (0.01 sec) sessionB 1234567891011MySQL [mysql]&gt; select @@tx_isolation;+----------------+| @@tx_isolation |+----------------+| READ-COMMITTED |+----------------+1 row in set, 1 warning (0.00 sec)MySQL [mysql]&gt; insert tt select null,6,60,null,null,null;Query OK, 1 row affected (0.03 sec)Records: 1 Duplicates: 0 Warnings: 0 按照幻读的定义，rc级别下，是会产生幻读的，同理，ru也是一样的。隔离级别：ru &lt; rc &lt; rr &lt; se.序列化读，每次都会加锁，不会产生幻读，是最高的隔离级别。读提交，从定义来看，就是要能读到其他事务提交的结果，本身隔离性就比较低，幻读也比较能理解。主要读提交下，innodb要求binlog是row格式，所以即使幻读，binlog日志恢复的数据起码是一致的。注意，rc只会持有行锁。 可重复读作为默认的隔离级别，再来看看这种情况。 可重复读场景sessionA 123456789101112131415161718192021222324MySQL [mysql]&gt; select @@tx_isolation;+-----------------+| @@tx_isolation |+-----------------+| REPEATABLE-READ |+-----------------+1 row in set, 1 warning (0.00 sec)MySQL [mysql]&gt; begin;Query OK, 0 rows affected (0.00 sec)MySQL [mysql]&gt; select * from tt where c &gt; 2 for update; +----+------+------+-------+------+------+| id | c | d | field | f2 | f3 |+----+------+------+-------+------+------+| 3 | 3 | 30 | NULL | NULL | NULL || 9 | 5 | 50 | NULL | NULL | NULL || 20 | 4 | 90 | NULL | NULL | NULL |+----+------+------+-------+------+------+3 rows in set (0.00 sec)MySQL [mysql]&gt; update tt set d = 0 where c &gt; 2; Query OK, 3 rows affected (0.00 sec)Rows matched: 3 Changed: 3 Warnings: 0 sessionB 12345678910MySQL [mysql]&gt; select @@tx_isolation;+-----------------+| @@tx_isolation |+-----------------+| REPEATABLE-READ |+-----------------+1 row in set, 1 warning (0.00 sec)MySQL [mysql]&gt; insert tt select null,6,60,null,null,null;ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transaction 可重复读，由于快照的原因，普通的读是不会有幻读的。所以这里用锁定一致性视图读，即加锁的当前读。 但是这里sessionB被阻塞了，因为锁的原因： 12345678MySQL [mysql]&gt; select * from information_schema.innodb_locks;+--------------+-------------+-----------+-----------+--------------+------------+------------+-----------+----------+-----------+| lock_id | lock_trx_id | lock_mode | lock_type | lock_table | lock_index | lock_space | lock_page | lock_rec | lock_data |+--------------+-------------+-----------+-----------+--------------+------------+------------+-----------+----------+-----------+| 18687:76:3:5 | 18687 | X,GAP | RECORD | `mysql`.`tt` | PRIMARY | 76 | 3 | 5 | 20 || 18685:76:3:5 | 18685 | X | RECORD | `mysql`.`tt` | PRIMARY | 76 | 3 | 5 | 20 |+--------------+-------------+-----------+-----------+--------------+------------+------------+-----------+----------+-----------+2 rows in set, 1 warning (0.00 sec) 可以看到sessionA持有了X锁和gap锁。X锁属于行锁，而行锁加上间隙锁合称为next-key lock.实际应该没有实现的next-key lock,其只是对于实现的行锁+间隙锁的统称。 由于间隙锁的存在，rr级别下，可以解决幻读的问题。select不加锁的话，根据快照不会产生幻读。select加锁读，通过间隙锁解决幻读问题。 幻读对binlog的影响如果rr下，没有gap lock机制的话，幻读对binlog也会有影响，如果binlog=statement,回想前面，rc,ru下强制要求binlog=row是有原因的。现在分析下，rr下，binlog=statement的情况： 关闭间隙锁的方式： 隔离级别设置为rc innodb_locks_unsafe_for_binlog=1 sessionA: 12345678910111213141516171819202122232425262728293031323334353637MySQL [mysql]&gt; show variables like &#x27;innodb_locks_unsafe_for_binlog&#x27;;+--------------------------------+-------+| Variable_name | Value |+--------------------------------+-------+| innodb_locks_unsafe_for_binlog | ON |+--------------------------------+-------+1 row in set (0.00 sec)MySQL [mysql]&gt; begin;Query OK, 0 rows affected (0.00 sec)MySQL [mysql]&gt; select * from tt where c &gt; 2 for update; +----+------+------+-------+------+------+| id | c | d | field | f2 | f3 |+----+------+------+-------+------+------+| 3 | 3 | 30 | NULL | NULL | NULL || 9 | 5 | 50 | NULL | NULL | NULL || 20 | 4 | 90 | NULL | NULL | NULL |+----+------+------+-------+------+------+3 rows in set (0.00 sec)MySQL [mysql]&gt; update tt set d = 0 where c &gt; 2; Query OK, 3 rows affected (0.00 sec)Rows matched: 3 Changed: 3 Warnings: 0MySQL [mysql]&gt; select * from tt where c &gt; 2;+----+------+------+-------+------+------+| id | c | d | field | f2 | f3 |+----+------+------+-------+------+------+| 3 | 3 | 0 | NULL | NULL | NULL || 9 | 5 | 0 | NULL | NULL | NULL || 20 | 4 | 0 | NULL | NULL | NULL || 25 | 6 | 60 | NULL | NULL | NULL |+----+------+------+-------+------+------+4 rows in set (0.00 sec)MySQL [mysql]&gt; commit; sessionB: 12345678MySQL [(none)]&gt; use mysql;Reading table information for completion of table and column namesYou can turn off this feature to get a quicker startup with -ADatabase changedMySQL [mysql]&gt; insert tt select null,6,60,null,null,null;Query OK, 1 row affected (0.01 sec)Records: 1 Duplicates: 0 Warnings: 0 binlog: 1234567891011121314151617181920212223242526SET TIMESTAMP=1598347030/*!*/;BEGIN/*!*/;# at 1708# at 1740#200825 17:17:10 server id 1 end_log_pos 1740 CRC32 0xe0159005 IntvarSET INSERT_ID=25/*!*/;#200825 17:17:10 server id 1 end_log_pos 1857 CRC32 0xc851009c Query thread_id=4 exec_time=0 error_code=0SET TIMESTAMP=1598347030/*!*/;insert tt select null,6,60,null,null,null/*!*/;# at 1857#200825 17:17:10 server id 1 end_log_pos 1888 CRC32 0x9f72707d Xid = 142COMMIT/*!*/;# at 1888#200825 17:17:54 server id 1 end_log_pos 1953 CRC32 0x1b7f81f5 Anonymous_GTID last_committed=5 sequence_number=7 rbr_only=noSET @@SESSION.GTID_NEXT= &#x27;ANONYMOUS&#x27;/*!*/;# at 1953#200825 17:16:39 server id 1 end_log_pos 2034 CRC32 0xc51fd871 Query thread_id=2 exec_time=0 error_code=0SET TIMESTAMP=1598346999/*!*/;BEGIN/*!*/;# at 2034#200825 17:16:39 server id 1 end_log_pos 2141 CRC32 0xa64310b0 Query thread_id=2 exec_time=0 error_code=0SET TIMESTAMP=1598346999/*!*/;update tt set d = 0 where c &gt; 2 sessionA后提交的，如果根据binlog恢复数据或者从库更新： 1 insert tt select null,6,60,null,null,null 2 update tt set d = 0 where c &gt; 2 就得不到主库的结果了： 123456789MySQL [mysql]&gt; select * from tt where c &gt; 2;+----+------+------+-------+------+------+| id | c | d | field | f2 | f3 |+----+------+------+-------+------+------+| 3 | 3 | 0 | NULL | NULL | NULL || 9 | 5 | 0 | NULL | NULL | NULL || 20 | 4 | 0 | NULL | NULL | NULL || 25 | 6 | 60 | NULL | NULL | NULL |+----+------+------+-------+------+------+ 这是幻读在rr模式下，binlog=statement可能造成的问题，但是gap lock没让这种情况发生。 gap lock前面碰到了间隙锁，这里再深化一下： sessionA: 12345678910111213141516171819202122MySQL [mysql]&gt; select * from tt;+----+------+------+-------+------+------+| id | c | d | field | f2 | f3 |+----+------+------+-------+------+------+| 1 | 1 | 777 | NULL | NULL | NULL || 2 | 2 | 200 | NULL | NULL | NULL || 3 | 3 | 30 | NULL | NULL | NULL || 9 | 5 | 50 | NULL | NULL | NULL || 20 | 4 | 90 | NULL | NULL | NULL |+----+------+------+-------+------+------+5 rows in set (0.00 sec)MySQL [mysql]&gt; begin;Query OK, 0 rows affected (0.00 sec)MySQL [mysql]&gt; select * from tt where d = 90 for update;+----+------+------+-------+------+------+| id | c | d | field | f2 | f3 |+----+------+------+-------+------+------+| 20 | 4 | 90 | NULL | NULL | NULL |+----+------+------+-------+------+------+1 row in set (0.00 sec) select * from tt where d = 90 for update;这条语句加了2个锁，一个x锁，一个gap锁。 间隙锁锁住了d=90的间隙,(50-90),(90-200). x锁锁住了d=90 next-key lock锁的是(50-200) 所以，添加数据： sessionB: 123456789MySQL [mysql]&gt; insert tt select null,6,60,null,null,null;ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transactionMySQL [mysql]&gt; insert tt select null,6,100,null,null,null;ERROR 1205 (HY000): Lock wait timeout exceeded; try restarting transactionMySQL [mysql]&gt; insert tt select null,6,45,null,null,null;Query OK, 1 row affected (0.01 sec)Records: 1 Duplicates: 0 Warnings: 0 间隙锁的降级当条件语句是唯一索引，则gap锁降级为行锁，只锁定索引记录。 sessionA: 12345678910MySQL [mysql]&gt; begin;Query OK, 0 rows affected (0.00 sec)MySQL [mysql]&gt; select * from tt where id = 20 for update;+----+------+------+-------+------+------+| id | c | d | field | f2 | f3 |+----+------+------+-------+------+------+| 20 | 4 | 90 | NULL | NULL | NULL |+----+------+------+-------+------+------+1 row in set (0.01 sec) sessionB: 1234567MySQL [mysql]&gt; insert tt select null,7,110,null,null,null;Query OK, 1 row affected (0.01 sec)Records: 1 Duplicates: 0 Warnings: 0MySQL [mysql]&gt; insert tt select 21,8,92,null,null,null;Query OK, 1 row affected (0.01 sec)Records: 1 Duplicates: 0 Warnings: 0 gap lock导致的死锁间隙锁和间隙锁之前是兼容的，间隙锁和insert插入间隙的操作是不兼容的，所以： 123456789101112MySQL [mysql]&gt; select * from tt;+----+------+------+-------+------+------+| id | c | d | field | f2 | f3 |+----+------+------+-------+------+------+| 1 | 1 | 777 | NULL | NULL | NULL || 2 | 2 | 200 | NULL | NULL | NULL || 3 | 3 | 0 | NULL | NULL | NULL || 9 | 5 | 0 | NULL | NULL | NULL || 20 | 4 | 0 | NULL | NULL | NULL || 25 | 6 | 60 | NULL | NULL | NULL |+----+------+------+-------+------+------+6 rows in set (0.00 sec) 1234567891011 sessionA sessinBT1 begin;select * from tt where d = 300 for update;T2 begin; select * from tt where d = 300 for update;T3 insert tt select null,7,400,null,null,null;T4 insert tt select null,8,500,null,null,null; 结果： T3 成功插入； T4死锁； 又一个事务可以成功提交，其他死锁的报错： ERROR 1213 (40001): Deadlock found when trying to get lock; try restarting transaction 也还好吧。 ending","categories":[],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://riverferry.site/tags/mysql/"}],"keywords":[]},{"title":"c++ 虚析构","slug":"2020-08-24-c++ 虚析构","date":"2020-08-24T00:00:00.000Z","updated":"2022-09-12T16:24:32.285Z","comments":true,"path":"2020-08-24-c++ 虚析构/","link":"","permalink":"https://riverferry.site/2020-08-24-c++%20%E8%99%9A%E6%9E%90%E6%9E%84/","excerpt":"前言一个非常基础又常见的问题，总感觉隔一段时间突然遇到这个问题的时候会有点”不安全“的感觉。不能很确定完整的讲述出来，所以做一个简单的总结，加深记忆。","text":"前言一个非常基础又常见的问题，总感觉隔一段时间突然遇到这个问题的时候会有点”不安全“的感觉。不能很确定完整的讲述出来，所以做一个简单的总结，加深记忆。 case112345678910111213141516171819202122232425262728293031323334#include &lt;iostream&gt;using namespace std;class base&#123;public: base() &#123; cout &lt;&lt; &quot;cons -&gt; base&quot; &lt;&lt; endl; //step 2 &#125; //step 3 ~base() &#123; cout &lt;&lt; &quot;dest -&gt; base&quot; &lt;&lt; endl; //s 3 &#125; //s 4&#125;;class drive: public base&#123;public: drive() &#123; //step 1 cout &lt;&lt; &quot;cons -&gt; drive&quot; &lt;&lt; endl; //step 4 &#125; //step 5 ~drive() &#123; //s 2 cout &lt;&lt; &quot;dest -&gt; drive&quot; &lt;&lt; endl; //s 1 &#125; //s 5&#125;;int main()&#123; drive *d = new drive; delete d; return 0;&#125; output 1234cons -&gt; basecons -&gt; drivedest -&gt; drivedest -&gt; base gdb 123看注释构造函数：先基类，后派生类析构函数：先派生类，后基类 case 212345678910111213141516171819202122232425262728293031323334#include &lt;iostream&gt;using namespace std;class base&#123;public: base() &#123; cout &lt;&lt; &quot;cons -&gt; base&quot; &lt;&lt; endl; &#125; virtual ~base() &#123; cout &lt;&lt; &quot;dest -&gt; base&quot; &lt;&lt; endl; &#125;&#125;;class drive: public base&#123;public: drive() &#123; cout &lt;&lt; &quot;cons -&gt; drive&quot; &lt;&lt; endl; &#125; ~drive() &#123; cout &lt;&lt; &quot;dest -&gt; drive&quot; &lt;&lt; endl; &#125;&#125;;int main()&#123; base *b = new drive; delete b; return 0;&#125; output 1234cons -&gt; basecons -&gt; drivedest -&gt; drivedest -&gt; base 总结利用多态的时候 如果析构函数不是虚函数，则delete基类指针，就只执行基类的析构函数。 如果析构函数是虚函数，则根据多态，执行实际指向类的析构函数 对于基类指针指向派生类的情况，delete基类指针可以调用派生类的析构函数，派生类的析构函数自己执行完再调用基类的析构函数，保证都得到了释放，仅此而已。 ending","categories":[],"tags":[{"name":"c++","slug":"c","permalink":"https://riverferry.site/tags/c/"}],"keywords":[]},{"title":"mysql mvcc","slug":"2020-08-24-mysql mvcc","date":"2020-08-24T00:00:00.000Z","updated":"2022-09-12T16:24:32.285Z","comments":true,"path":"2020-08-24-mysql mvcc/","link":"","permalink":"https://riverferry.site/2020-08-24-mysql%20mvcc/","excerpt":"参考数据库事务、隔离级别和锁 高性能mysql第三版 mysql技术内幕 mysql实战45讲 wikipedia","text":"参考数据库事务、隔离级别和锁 高性能mysql第三版 mysql技术内幕 mysql实战45讲 wikipedia 概念 多版本并发控制(Multiversion concurrency control， MCC 或 MVCC)，是数据库管理系统常用的一种并发控制，也用于程序设计语言实现事务内存。[1] MVCC意图解决读写锁造成的多个、长时间的读操作饿死写操作问题。每个事务读到的数据项都是一个历史快照（snapshot)并依赖于实现的隔离级别。写操作不覆盖已有数据项，而是创建一个新的版本，直至所在操作提交时才变为可见。快照隔离使得事物看到它启动时的数据状态。 特点 主要针对读操作，减少加锁的负担 写操作不覆盖历史版本 innodb的实现Innodb的mvcc，是通过在每行记录后面保存两个隐藏的列来实现的，增加了一定的存储空间。两个列： 创建事务的trx_id //create_trx_id 删除事物的trx_id //del_trx_id dml操作如何操纵，利用这两个值(mvcc只对repeatable read/read committed两种隔离级别有效)： select select取的是snapshot的结果： 更新点： 对于repeatale read,在begin select或者start transaction with consistent snapshot的时候更新快照 对于read committed,在每条语句执行的时候更新快照 快照通过当前事务的trx_id和对应行记录现存的所有版本的create_trx_id,del_trx_id对比得到。不同版本的行记录是通过链表保存的。链表中所有记录的trx_id不是递增的，老得事务可能后提交，链表是根据版本递增的。 如果是rc,在更新点，取已提交的最新版本(&lt; current_trx_id或者 &gt; current_trx_id),每条语句都更新结果.并且del_trx_id为空才可查到如果是rr,在更新点，取已提交的最新版本(&lt; current_trx_id),当前事务后续进行的修改会更新结果。并且del_trx_id为空才可查到 insert 将create_trx_id更新为当前事务的trx_id delete 将del_trx_id更新为当前事物的trx_id update 如果不是主键列，则记录反向的日志，如果执行delete,则undo记录insert,可以反推出更改前的值 如果是主键列，新增一条行记录，也就是多了一个版本，将老得行记录版本的del_trx_id更新为当前事务的trx_id,将新的行记录版本的create_trx_id更新为当前事务的trx_id 对于innodb,mvcc只适用于repeatable read, read committed两种隔离级别，对于read uncommitted,直接读最新版本即可不需要历史版本的参考，而serializable的每次读都是select … lock in share mode,都是加锁读 innodb的purse线程会清除部分历史版本的row记录，当链表中的版本中的create_trx_id小于当前活跃的事务的最小id的时候，这个版本的记录就可能被清楚。 undo logpgsql中mvcc的实现，是把所有版本都存在b+树中，这样查询很快，删除比较麻烦 innodb通过undo log来保存mvcc的多版本，b+树只保存最新提交的版本，老版本保存在undolog中，通过链表串起来 undo log也会持久化的，默认存在共享表空间 undo log也可用于事务回滚，保证事务的一致性，undo log记录的是逻辑日志。 mvcc的作用如果有人这样问，总得有个差不多的听起来是对的回答： 降低多版本并发时候的读负担(相对加锁)，以牺牲一点存储空间为代价 ending","categories":[],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://riverferry.site/tags/mysql/"}],"keywords":[]},{"title":"mysql binlog","slug":"2020-08-20-mysql binlog","date":"2020-08-20T00:00:00.000Z","updated":"2022-09-12T16:24:32.284Z","comments":true,"path":"2020-08-20-mysql binlog/","link":"","permalink":"https://riverferry.site/2020-08-20-mysql%20binlog/","excerpt":"参考MySQL实战45讲 mysql技术内幕 关于binary log那些事","text":"参考MySQL实战45讲 mysql技术内幕 关于binary log那些事 查看配置信息查看binlog是否打开以及配置信息： 123456789101112MySQL [mysql]&gt; show variables like &#x27;%log_bin%&#x27;;+---------------------------------+---------------------------------------+| Variable_name | Value |+---------------------------------+---------------------------------------+| log_bin | ON || log_bin_basename | /usr/local/mysql/data/mysql-bin || log_bin_index | /usr/local/mysql/data/mysql-bin.index || log_bin_trust_function_creators | OFF || log_bin_use_v1_row_events | OFF || sql_log_bin | ON |+---------------------------------+---------------------------------------+6 rows in set (0.00 sec) 查看配置文件： log_bin是打开binlog的开关. 12345678910[root@xxxx]# mysql --help | grep cnf/etc/mysql/my.cnf /etc/my.cnf ~/.my.cnf order of preference, my.cnf, $MYSQL_TCP_PORT,[root@xxxx]# cat /etc/my.cnf[mysqld]... log_bin = mysql-binbinlog-format=STATEMENT expire_logs_days = 30 文件列表： index是binlog的索引文件，记录所有的binlog日志文件。binlog日志是可续写的，不停有新的文件产生。而redo log是循环写的，固定文件个数，满了后从头开始。 1234567891011[root@xxxx]# ll mysql-bin.*-rw-r----- 1 mysql mysql 177 Jul 31 17:22 mysql-bin.000001-rw-r----- 1 mysql mysql 177 Jul 31 17:26 mysql-bin.000002-rw-r----- 1 mysql mysql 1321 Jul 31 17:36 mysql-bin.000003-rw-r----- 1 mysql mysql 21167 Aug 20 10:50 mysql-bin.000004-rw-r----- 1 mysql mysql 76 Jul 31 17:36 mysql-bin.index[root@xxxx]# cat mysql-bin.index./mysql-bin.000001./mysql-bin.000002./mysql-bin.000003./mysql-bin.000004 参数含义1234567891011121314151617181920212223242526272829303132+--------------------------------------------+---------------------------------------+| Variable_name | Value |+--------------------------------------------+---------------------------------------+| binlog_cache_size | 32768 || binlog_checksum | CRC32 || binlog_direct_non_transactional_updates | OFF || binlog_error_action | ABORT_SERVER || binlog_format | STATEMENT || binlog_group_commit_sync_delay | 0 || binlog_group_commit_sync_no_delay_count | 0 || binlog_gtid_simple_recovery | ON || binlog_max_flush_queue_time | 0 || binlog_order_commits | ON || binlog_row_image | FULL || binlog_rows_query_log_events | OFF || binlog_stmt_cache_size | 32768 || binlog_transaction_dependency_history_size | 25000 || binlog_transaction_dependency_tracking | COMMIT_ORDER || innodb_api_enable_binlog | OFF || innodb_locks_unsafe_for_binlog | OFF || log_bin | ON || log_bin_basename | /usr/local/mysql/data/mysql-bin || log_bin_index | /usr/local/mysql/data/mysql-bin.index || log_bin_trust_function_creators | OFF || log_bin_use_v1_row_events | OFF || log_statements_unsafe_for_binlog | ON || max_binlog_cache_size | 18446744073709547520 || max_binlog_size | 1073741824 || max_binlog_stmt_cache_size | 18446744073709547520 || sql_log_bin | ON || sync_binlog | 1 |+--------------------------------------------+---------------------------------------+ max_binlog_size表示单个binlog日志文件的大小，默认是1g,超过后产生新文件 binlog_cache_size表示binlog在内存的缓冲区大小，默认32k,这个大小是基于会话的，所以不能太大。也不能太小，因为io压力会大 sync_binlog是否同步binlog到磁盘，就不写缓冲区了。高可用但是对磁盘io有压力 binlog_formatbinlog_formatmysql5.1引入的，可设置的值有：statement, row, mixed. 1 statement: 记录逻辑日志2 row: 记录表的行更改情况3 mixed: 默认采用statement格式记录日志，但是在一些情况下会使用row格式，可能的情况有 表的存储引擎为ndb,这时对表的dml操作 使用了uuid(), user(), current_user(), found_user(), row_count()等不确定函数 使用了insert delay语句 使用了用户定义函数 使用了临时表 对比： statement: update tt set d = 4 where c = 4row: update tt set d = 5 where c = 4; show binlog events in ‘mysql-bin.000004’; 12345678| mysql-bin.000004 | 20948 | Query | 1 | 21029 | BEGIN || mysql-bin.000004 | 21029 | Query | 1 | 21136 | use `mysql`; update tt set d = 4 where c = 4 || mysql-bin.000004 | 21136 | Xid | 1 | 21167 | COMMIT /* xid=645 */ || mysql-bin.000004 | 21167 | Anonymous_Gtid | 1 | 21232 | SET @@SESSION.GTID_NEXT= &#x27;ANONYMOUS&#x27; || mysql-bin.000004 | 21232 | Query | 1 | 21305 | BEGIN || mysql-bin.000004 | 21305 | Table_map | 1 | 21353 | table_id: 146 (mysql.tt) || mysql-bin.000004 | 21353 | Update_rows | 1 | 21415 | table_id: 146 flags: STMT_END_F || mysql-bin.000004 | 21415 | Xid | 1 | 21446 | COMMIT /* xid=662 */ /usr/local/mysql/mysql/bin/mysqlbinlog mysql-bin.000004 -vv 12345678910111213141516171819202122232425262728293031323334353637383940414243444546BEGIN/*!*/;# at 21029#200820 10:50:40 server id 1 end_log_pos 21136 CRC32 0xab574d07 Query thread_id=11 exec_time=0 error_code=0SET TIMESTAMP=1597891840/*!*/;update tt set d = 4 where c = 4/*!*/;# at 21136#200820 10:50:40 server id 1 end_log_pos 21167 CRC32 0xdd08f243 Xid = 645COMMIT/*!*/;# at 21167#200820 11:26:28 server id 1 end_log_pos 21232 CRC32 0xe81ffc29 Anonymous_GTID last_committed=76 sequence_number=77 rbr_only=yes/*!50718 SET TRANSACTION ISOLATION LEVEL READ COMMITTED*//*!*/;SET @@SESSION.GTID_NEXT= &#x27;ANONYMOUS&#x27;/*!*/;# at 21232#200820 11:26:28 server id 1 end_log_pos 21305 CRC32 0x2e084ad1 Query thread_id=11 exec_time=0 error_code=0SET TIMESTAMP=1597893988/*!*/;BEGIN/*!*/;# at 21305#200820 11:26:28 server id 1 end_log_pos 21353 CRC32 0x13267696 Table_map: `mysql`.`tt` mapped to number 146# at 21353#200820 11:26:28 server id 1 end_log_pos 21415 CRC32 0xf078d9cb Update_rows: table id 146 flags: STMT_END_FBINLOG &#x27;ZO09XxMBAAAAMAAAAGlTAAAAAJIAAAAAAAEABW15c3FsAAJ0dAADAwMDAAaWdiYTZO09Xx8BAAAAPgAAAKdTAAAAAJIAAAAAAAEAAgAD///4FAAAAAQAAAAEAAAA+BQAAAAEAAAABQAAAMvZePA=&#x27;/*!*/;### UPDATE `mysql`.`tt`### WHERE### @1=20 /* INT meta=0 nullable=0 is_null=0 */### @2=4 /* INT meta=0 nullable=1 is_null=0 */### @3=4 /* INT meta=0 nullable=1 is_null=0 */### SET### @1=20 /* INT meta=0 nullable=0 is_null=0 */### @2=4 /* INT meta=0 nullable=1 is_null=0 */### @3=5 /* INT meta=0 nullable=1 is_null=0 */# at 21415#200820 11:26:28 server id 1 end_log_pos 21446 CRC32 0xfa03d621 Xid = 662COMMIT/*!*/;SET @@SESSION.GTID_NEXT= &#x27;AUTOMATIC&#x27; /* added by mysqlbinlog */ /*!*/;DELIMITER ;# End of log file/*!50003 SET COMPLETION_TYPE=@OLD_COMPLETION_TYPE*/;/*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=0*/; binlog_rows_query_log_events表示binlog日志中row格式下用不用打印执行语句，从前面的事件看，row格式下默认不打印执行语句的。这个参数默认是off: 查看并修改binlog_rows_query_log_events123456789101112131415161718MySQL [mysql]&gt; show variables like &#x27;binlog_rows_query_log_events&#x27;;+------------------------------+-------+| Variable_name | Value |+------------------------------+-------+| binlog_rows_query_log_events | OFF |+------------------------------+-------+1 row in set (0.00 sec)MySQL [mysql]&gt; set binlog_rows_query_log_events = &#x27;ON&#x27;;Query OK, 0 rows affected (0.00 sec)MySQL [mysql]&gt; show variables like &#x27;binlog_rows_query_log_events&#x27;;+------------------------------+-------+| Variable_name | Value |+------------------------------+-------+| binlog_rows_query_log_events | ON |+------------------------------+-------+1 row in set (0.00 sec) dml查看binlog打印结果1234567891011121314151617181920212223MySQL [mysql]&gt; update tt set d = 20 where id = 2;Query OK, 1 row affected (0.00 sec)Rows matched: 1 Changed: 1 Warnings: 0MySQL [mysql]&gt; show master status;+------------------+----------+--------------+------------------+-------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+------------------+----------+--------------+------------------+-------------------+| mysql-bin.000004 | 21782 | | | |+------------------+----------+--------------+------------------+-------------------+1 row in set (0.00 sec)MySQL [mysql]&gt; update tt set d = 200 where id = 2;Query OK, 1 row affected (0.00 sec)Rows matched: 1 Changed: 1 Warnings: 0MySQL [mysql]&gt; show master status;+------------------+----------+--------------+------------------+-------------------+| File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+------------------+----------+--------------+------------------+-------------------+| mysql-bin.000004 | 22119 | | | |+------------------+----------+--------------+------------------+-------------------+1 row in set (0.00 sec) 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162[root@xxxx ]# /usr/local/mysql/mysql/bin/mysqlbinlog mysql-bin.000004 -vv --start-position=21782 --stop-position=22119 /*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=1*/;/*!50003 SET @OLD_COMPLETION_TYPE=@@COMPLETION_TYPE,COMPLETION_TYPE=0*/;DELIMITER /*!*/;# at 4#200731 17:36:11 server id 1 end_log_pos 123 CRC32 0xb2d914dd Start: binlog v 4, server v 5.7.24-log created 200731 17:36:11 at startup# Warning: this binlog is either in use or was not closed properly.ROLLBACK/*!*/;BINLOG &#x27;C+YjXw8BAAAAdwAAAHsAAAABAAQANS43LjI0LWxvZwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAL5iNfEzgNAAgAEgAEBAQEEgAAXwAEGggAAAAICAgCAAAACgoKKioAEjQAAd0U2bI=&#x27;/*!*/;# at 21782#200820 14:37:40 server id 1 end_log_pos 21847 CRC32 0x78241dac Anonymous_GTID last_committed=78 sequence_number=79 rbr_only=yes/*!50718 SET TRANSACTION ISOLATION LEVEL READ COMMITTED*//*!*/;SET @@SESSION.GTID_NEXT= &#x27;ANONYMOUS&#x27;/*!*/;# at 21847#200820 14:37:40 server id 1 end_log_pos 21920 CRC32 0xf4915dd7 Query thread_id=11 exec_time=0 error_code=0SET TIMESTAMP=1597905460/*!*/;SET @@session.pseudo_thread_id=11/*!*/;SET @@session.foreign_key_checks=1, @@session.sql_auto_is_null=0, @@session.unique_checks=1, @@session.autocommit=1/*!*/;SET @@session.sql_mode=1075838976/*!*/;SET @@session.auto_increment_increment=1, @@session.auto_increment_offset=1/*!*/;/*!\\C latin1 *//*!*/;SET @@session.character_set_client=8,@@session.collation_connection=8,@@session.collation_server=8/*!*/;SET @@session.lc_time_names=0/*!*/;SET @@session.collation_database=DEFAULT/*!*/;BEGIN/*!*/;# at 21920#200820 14:37:40 server id 1 end_log_pos 21978 CRC32 0x3308d5eb Rows_query# update tt set d = 200 where id = 2# at 21978#200820 14:37:40 server id 1 end_log_pos 22026 CRC32 0x06c85227 Table_map: `mysql`.`tt` mapped to number 146# at 22026#200820 14:37:40 server id 1 end_log_pos 22088 CRC32 0xd1e44ca1 Update_rows: table id 146 flags: STMT_END_FBINLOG &#x27;NBo+Xx0BAAAAOgAAANpVAACAACJ1cGRhdGUgdHQgc2V0IGQgPSAyMDAgd2hlcmUgaWQgPSAy69UIMw==NBo+XxMBAAAAMAAAAApWAAAAAJIAAAAAAAEABW15c3FsAAJ0dAADAwMDAAYnUsgGNBo+Xx8BAAAAPgAAAEhWAAAAAJIAAAAAAAEAAgAD///4AgAAAAIAAAAUAAAA+AIAAAACAAAAyAAAAKFM5NE=&#x27;/*!*/;### UPDATE `mysql`.`tt`### WHERE### @1=2 /* INT meta=0 nullable=0 is_null=0 */### @2=2 /* INT meta=0 nullable=1 is_null=0 */### @3=20 /* INT meta=0 nullable=1 is_null=0 */### SET### @1=2 /* INT meta=0 nullable=0 is_null=0 */### @2=2 /* INT meta=0 nullable=1 is_null=0 */### @3=200 /* INT meta=0 nullable=1 is_null=0 */# at 22088#200820 14:37:40 server id 1 end_log_pos 22119 CRC32 0x45b08113 Xid = 670COMMIT/*!*/;SET @@SESSION.GTID_NEXT= &#x27;AUTOMATIC&#x27; /* added by mysqlbinlog */ /*!*/;DELIMITER ;# End of log file/*!50003 SET COMPLETION_TYPE=@OLD_COMPLETION_TYPE*/;/*!50530 SET @@SESSION.PSEUDO_SLAVE_MODE=0*/; ending","categories":[],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://riverferry.site/tags/mysql/"}],"keywords":[]},{"title":"mysql slow log","slug":"2020-08-20-mysql slow log","date":"2020-08-20T00:00:00.000Z","updated":"2022-09-12T16:24:32.284Z","comments":true,"path":"2020-08-20-mysql slow log/","link":"","permalink":"https://riverferry.site/2020-08-20-mysql%20slow%20log/","excerpt":"参考MySQL实战45讲 mysql技术内幕","text":"参考MySQL实战45讲 mysql技术内幕 查看配置12345678MySQL [mysql]&gt; show variables like &#x27;%slow_query%&#x27;;+---------------------+-------------------------------+| Variable_name | Value |+---------------------+-------------------------------+| slow_query_log | ON || slow_query_log_file | /usr/local/mysql/log/slow.log |+---------------------+-------------------------------+2 rows in set (0.00 sec) 123456[root@xxxx ]# cat /etc/my.cnf[mysqld]...slow_query_log=1slow_query_log_file=/usr/local/mysql/log/slow.loglong_query_time=1 运行时间&gt;long_query_time的语句会被记录下来，和postgresql的日志文件有点像。 log_queries_not_using_indexes该参数打开的话，没有使用索引的语句也会被打印出来。 1234567MySQL [mysql]&gt; show variables like &#x27;%using_in%&#x27;;+----------------------------------------+-------+| Variable_name | Value |+----------------------------------------+-------+| log_queries_not_using_indexes | OFF || log_throttle_queries_not_using_indexes | 0 |+----------------------------------------+-------+ log_throttle_queries_not_using_indexes该参数表示每分钟允许记录到slow log的未使用索引的语句次数，默认是0表示没限制，这个参数是mysql5.6.5版本引入的。 mysqldumpslow该工具有助于分析slow log,参数如下： 12345678910111213141516171819202122232425262728[root@xxxx ]# /usr/local/mysql/mysql/bin/mysqldumpslow --helpUsage: mysqldumpslow [ OPTS... ] [ LOGS... ]Parse and summarize the MySQL slow query log. Options are --verbose verbose --debug debug --help write this text to standard output -v verbose -d debug -s ORDER what to sort by (al, at, ar, c, l, r, t), &#x27;at&#x27; is default al: average lock time ar: average rows sent at: average query time c: count l: lock time r: rows sent t: query time -r reverse the sort order (largest last instead of first) -t NUM just show the top n queries -a don&#x27;t abstract all numbers to N and strings to &#x27;S&#x27; -n NUM abstract numbers with at least n digits within names -g PATTERN grep: only consider stmts that include this string -h HOSTNAME hostname of db server for *-slow.log filename (can be wildcard), default is &#x27;*&#x27;, i.e. match all -i NAME name of server instance (if using mysql.server startup script) -l don&#x27;t subtract lock time from total time table slow_Log打开存放满日志到table slow_log的开关： 1234567891011121314151617181920MySQL [mysql]&gt; show variables like &#x27;log_output&#x27;;+---------------+-------+| Variable_name | Value |+---------------+-------+| log_output | FILE |+---------------+-------+1 row in set (0.00 sec)MySQL [mysql]&gt; set log_output = &#x27;TABLE&#x27;;ERROR 1229 (HY000): Variable &#x27;log_output&#x27; is a GLOBAL variable and should be set with SET GLOBALMySQL [mysql]&gt; set GLOBAL log_output = &#x27;TABLE&#x27;;Query OK, 0 rows affected (0.00 sec)MySQL [mysql]&gt; show variables like &#x27;log_output&#x27;;+---------------+-------+| Variable_name | Value |+---------------+-------+| log_output | TABLE |+---------------+-------+1 row in set (0.02 sec) 123456789MySQL [mysql]&gt; select * from slow_log;+----------------------------+------------------------------------------------+-----------------+-----------------+-----------+---------------+-------+----------------+-----------+-----------+-----------------+-----------+| start_time | user_host | query_time | lock_time | rows_sent | rows_examined | db | last_insert_id | insert_id | server_id | sql_text | thread_id |+----------------------------+------------------------------------------------+-----------------+-----------------+-----------+---------------+-------+----------------+-----------+-----------+-----------------+-----------+| 2020-07-31 16:28:22.604167 | skip-grants user[root] @ localhost [127.0.0.1] | 00:00:02.001130 | 00:00:00.000000 | 1 | 0 | mysql | 0 | 0 | 0 | select sleep(2) | 2 || 2020-08-20 15:30:33.876872 | skip-grants user[root] @ localhost [127.0.0.1] | 00:00:03.000253 | 00:00:00.000000 | 1 | 0 | mysql | 0 | 0 | 1 | select sleep(3) | 12 || 2020-08-20 15:30:55.647108 | skip-grants user[root] @ localhost [127.0.0.1] | 00:00:04.000252 | 00:00:00.000000 | 1 | 0 | mysql | 0 | 0 | 1 | select sleep(4) | 12 |+----------------------------+------------------------------------------------+-----------------+-----------------+-----------+---------------+-------+----------------+-----------+-----------+-----------------+-----------+3 rows in set (0.00 sec) 表结构： 1234567891011121314151617181920MySQL [mysql]&gt; show create table slow_log;+----------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| Table | Create Table |+----------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| slow_log | CREATE TABLE `slow_log` ( `start_time` timestamp(6) NOT NULL DEFAULT CURRENT_TIMESTAMP(6) ON UPDATE CURRENT_TIMESTAMP(6), `user_host` mediumtext NOT NULL, `query_time` time(6) NOT NULL, `lock_time` time(6) NOT NULL, `rows_sent` int(11) NOT NULL, `rows_examined` int(11) NOT NULL, `db` varchar(512) NOT NULL, `last_insert_id` int(11) NOT NULL, `insert_id` int(11) NOT NULL, `server_id` int(10) unsigned NOT NULL, `sql_text` mediumblob NOT NULL, `thread_id` bigint(21) unsigned NOT NULL) ENGINE=CSV DEFAULT CHARSET=utf8 COMMENT=&#x27;Slow log&#x27; |+----------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+1 row in set (0.00 sec) 跟pgsql的统计表很像。不过没找到命中率之类的统计信息。 ending","categories":[],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://riverferry.site/tags/mysql/"}],"keywords":[]},{"title":"mysql 锁与一致性视图","slug":"2020-08-20-mysql 锁与一致性视图","date":"2020-08-20T00:00:00.000Z","updated":"2022-09-12T16:24:32.285Z","comments":true,"path":"2020-08-20-mysql 锁与一致性视图/","link":"","permalink":"https://riverferry.site/2020-08-20-mysql%20%E9%94%81%E4%B8%8E%E4%B8%80%E8%87%B4%E6%80%A7%E8%A7%86%E5%9B%BE/","excerpt":"参考MySQL实战45讲 mysql技术内幕","text":"参考MySQL实战45讲 mysql技术内幕 锁lock latchlatch是闩(shuan)锁,就是互斥量，读写锁这种控制临界资源的锁。 lock说的是数据库中的锁，用于锁定事物，包括表锁，行锁，意向锁。 innodb的锁innodb支持行锁，有两种类型： S锁，共享锁，允许事物读 x锁，排他锁，允许事物删除或更新 兼容性： 1234 X SX 不兼容 不兼容S 不兼容 兼容 监测锁show processlist查看所有线程 12345678MySQL [mysql]&gt; show processlist;+----+------+-----------+-------+---------+------+-------------+------------------+| Id | User | Host | db | Command | Time | State | Info |+----+------+-----------+-------+---------+------+-------------+------------------+| 16 | root | localhost | mysql | Query | 0 | System lock | show processlist || 17 | root | localhost | mysql | Sleep | 86 | | NULL || 18 | root | localhost | mysql | Sleep | 611 | | NULL |+----+------+-----------+-------+---------+------+-------------+------------------+ information_schema.innodb_trx查看运行的事务 123456789101112131415161718192021222324252627282930313233| INNODB_TRX | CREATE TEMPORARY TABLE `INNODB_TRX` ( `trx_id` varchar(18) NOT NULL DEFAULT &#x27;&#x27;, `trx_state` varchar(13) NOT NULL DEFAULT &#x27;&#x27;, `trx_started` datetime NOT NULL DEFAULT &#x27;0000-00-00 00:00:00&#x27;, `trx_requested_lock_id` varchar(81) DEFAULT NULL, `trx_wait_started` datetime DEFAULT NULL, `trx_weight` bigint(21) unsigned NOT NULL DEFAULT &#x27;0&#x27;, `trx_mysql_thread_id` bigint(21) unsigned NOT NULL DEFAULT &#x27;0&#x27;, `trx_query` varchar(1024) DEFAULT NULL, `trx_operation_state` varchar(64) DEFAULT NULL, `trx_tables_in_use` bigint(21) unsigned NOT NULL DEFAULT &#x27;0&#x27;, `trx_tables_locked` bigint(21) unsigned NOT NULL DEFAULT &#x27;0&#x27;, `trx_lock_structs` bigint(21) unsigned NOT NULL DEFAULT &#x27;0&#x27;, `trx_lock_memory_bytes` bigint(21) unsigned NOT NULL DEFAULT &#x27;0&#x27;, `trx_rows_locked` bigint(21) unsigned NOT NULL DEFAULT &#x27;0&#x27;, `trx_rows_modified` bigint(21) unsigned NOT NULL DEFAULT &#x27;0&#x27;, `trx_concurrency_tickets` bigint(21) unsigned NOT NULL DEFAULT &#x27;0&#x27;, `trx_isolation_level` varchar(16) NOT NULL DEFAULT &#x27;&#x27;, `trx_unique_checks` int(1) NOT NULL DEFAULT &#x27;0&#x27;, `trx_foreign_key_checks` int(1) NOT NULL DEFAULT &#x27;0&#x27;, `trx_last_foreign_key_error` varchar(256) DEFAULT NULL, `trx_adaptive_hash_latched` int(1) NOT NULL DEFAULT &#x27;0&#x27;, `trx_adaptive_hash_timeout` bigint(21) unsigned NOT NULL DEFAULT &#x27;0&#x27;, `trx_is_read_only` int(1) NOT NULL DEFAULT &#x27;0&#x27;, `trx_autocommit_non_locking` int(1) NOT NULL DEFAULT &#x27;0&#x27;) ENGINE=MEMORY DEFAULT CHARSET=utf8 |MySQL [mysql]&gt; select trx_id,trx_state,trx_query from information_schema.innodb_trx;+-----------------+-----------+-----------+| trx_id | trx_state | trx_query |+-----------------+-----------+-----------+| 421346370501344 | RUNNING | NULL |+-----------------+-----------+-----------+ information_schema.innodb_locks12345678MySQL [mysql]&gt; select * from information_schema.innodb_locks;+--------------+-------------+-----------+-----------+--------------+------------+------------+-----------+----------+-----------+| lock_id | lock_trx_id | lock_mode | lock_type | lock_table | lock_index | lock_space | lock_page | lock_rec | lock_data |+--------------+-------------+-----------+-----------+--------------+------------+------------+-----------+----------+-----------+| 18651:76:4:5 | 18651 | X | RECORD | `mysql`.`tt` | c | 76 | 4 | 5 | 4 || 18650:76:4:5 | 18650 | X | RECORD | `mysql`.`tt` | c | 76 | 4 | 5 | 4 |+--------------+-------------+-----------+-----------+--------------+------------+------------+-----------+----------+-----------+2 rows in set, 1 warning (0.01 sec) information_schema.innodb_lock_waits1234567MySQL [mysql]&gt; select * from information_schema.innodb_lock_waits;+-------------------+-------------------+-----------------+------------------+| requesting_trx_id | requested_lock_id | blocking_trx_id | blocking_lock_id |+-------------------+-------------------+-----------------+------------------+| 18651 | 18651:76:4:5 | 18650 | 18650:76:4:5 |+-------------------+-------------------+-----------------+------------------+1 row in set, 1 warning (0.00 sec) 视图一致性非锁定读一致性非锁定读是innodb根据mvcc的方式来读取数据库中的数据。读取不需要等待对应行上的x锁的释放。读取是按照快照的形式，快照是通过undo日志实现的。 图中u1,u2,u3记录的是undo日志，v1,v2,v3,v4是根据undo日志反推出来的结果。trx_id是事务id,是事务系统维护的一个递增的值，可以用来判断版本和事务之间的关系。 在实现上， InnoDB 为每个事务构造了一个数组，用来保存这个事务启动瞬间，当前正在“活跃”的所有事务 ID。“活跃”指的就是，启动了但还没提交。 在隔离级别read committed, repeatable read下，innodb使用一致性非锁定读。两种隔离级别选择快照的时间点是不一样的。 RC下，在每条语句执行前，记录快照/视图 RR下，在事物启动后，第一条查询语句执行后(或者start transaction with consistent snapshot),记录快照/视图 测试下： 123456789MySQL [mysql]&gt; select * from tt;+----+------+------+-------+------+------+| id | c | d | field | f2 | f3 |+----+------+------+-------+------+------+| 1 | 1 | 1 | NULL | NULL | NULL || 2 | 2 | 200 | NULL | NULL | NULL || 3 | 3 | 30 | NULL | NULL | NULL || 20 | 4 | 500 | NULL | NULL | NULL |+----+------+------+-------+------+------+ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051 sessionA sessionBstart transaction with consistent snapshot; update tt set d = 0 where c = 4;select * from tt where c = 4;//d=500 isolation=RR//d=0 isolation=RC//REPEATABLE-READMySQL [mysql]&gt; select @@tx_isolation;+-----------------+| @@tx_isolation |+-----------------+| REPEATABLE-READ |+-----------------+1 row in set, 1 warning (0.00 sec)MySQL [mysql]&gt; select * from tt where c = 4;+----+------+------+-------+------+------+| id | c | d | field | f2 | f3 |+----+------+------+-------+------+------+| 20 | 4 | 500 | NULL | NULL | NULL |+----+------+------+-------+------+------+1 row in set (0.00 sec)//READ-COMMITTED MySQL [mysql]&gt; set session transaction isolation level READ COMMITTED;Query OK, 0 rows affected (0.00 sec)MySQL [mysql]&gt; select @@tx_isolation;+----------------+| @@tx_isolation |+----------------+| READ-COMMITTED |+----------------+1 row in set, 1 warning (0.00 sec)MySQL [mysql]&gt; begin;Query OK, 0 rows affected (0.00 sec)//sessionB MySQL [mysql]&gt; update tt set d = 20 where c = 4;MySQL [mysql]&gt; select * from tt where c = 4;+----+------+------+-------+------+------+| id | c | d | field | f2 | f3 |+----+------+------+-------+------+------+| 20 | 4 | 20 | NULL | NULL | NULL |+----+------+------+-------+------+------+ 一致性锁定读一致性非锁定读基于mvcc，利用快照去找对应版本的行记录，不需要等待x锁的释放。而一致性锁定读需要加锁，来取最新版本的数据。有两种形式： select … for update select … lock in share mode 两阶段锁 两阶段锁（two-phase locking，2PL）是数据库事务处理时的并发控制方法，以保证可串行化。[1][2] 这种方法使用数据库锁在两个阶段： 扩张阶段：不断上锁，没有锁被释放 收缩阶段：锁被陆续释放，没有新的加锁 2PL可能会导致死锁。 证明如下，太麻烦了，贴个链接不看了 CMU-15445 LAB3:事务隔离，two-phase locking，锁管理器 gap lock放在幻读的文章总结了。 ending","categories":[],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://riverferry.site/tags/mysql/"}],"keywords":[]},{"title":"mysql 自增主键","slug":"2020-08-20-mysql 自增主键","date":"2020-08-20T00:00:00.000Z","updated":"2022-09-12T16:24:32.285Z","comments":true,"path":"2020-08-20-mysql 自增主键/","link":"","permalink":"https://riverferry.site/2020-08-20-mysql%20%E8%87%AA%E5%A2%9E%E4%B8%BB%E9%94%AE/","excerpt":"参考MySQL实战45讲 前言这里只考虑Innodb的情况。","text":"参考MySQL实战45讲 前言这里只考虑Innodb的情况。 创建自增主键的创建： 123456789101112131415MySQL [mysql]&gt; show create table t;+-------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| Table | Create Table |+-------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| t | CREATE TABLE `t` ( `id` int(11) NOT NULL AUTO_INCREMENT, `c` int(11) DEFAULT NULL, `d` int(11) DEFAULT NULL, PRIMARY KEY (`id`), UNIQUE KEY `c` (`c`)) ENGINE=InnoDB AUTO_INCREMENT=4 DEFAULT CHARSET=latin1 |+-------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+1 row in set (0.00 sec) 插入： null, 0, 不指定，指定， 都可以使用自增id 1234567891011121314151617181920212223242526272829MySQL [mysql]&gt; select * from t;Empty set (0.00 sec)MySQL [mysql]&gt; insert into t select null,1,1;Query OK, 1 row affected (0.01 sec)Records: 1 Duplicates: 0 Warnings: 0MySQL [mysql]&gt; insert into t select 0,2,2; Query OK, 1 row affected (0.01 sec)Records: 1 Duplicates: 0 Warnings: 0MySQL [mysql]&gt; insert into t(c,d) select 3,3;Query OK, 1 row affected (0.01 sec)Records: 1 Duplicates: 0 Warnings: 0MySQL [mysql]&gt; insert into t select 4,4,4;Query OK, 1 row affected (0.01 sec)Records: 1 Duplicates: 0 Warnings: 0MySQL [mysql]&gt; select * from t;+----+------+------+| id | c | d |+----+------+------+| 1 | 1 | 1 || 2 | 2 | 2 || 3 | 3 | 3 || 4 | 4 | 4 |+----+------+------+ 乱序case1 唯一键冲突AUTO_INCREMENT表示下一个记录默认会取的自增主键的值。 12345678910111213141516171819202122232425262728293031323334353637383940MySQL [mysql]&gt; show create table t;+-------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| Table | Create Table |+-------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| t | CREATE TABLE `t` ( `id` int(11) NOT NULL AUTO_INCREMENT, `c` int(11) DEFAULT NULL, `d` int(11) DEFAULT NULL, PRIMARY KEY (`id`), UNIQUE KEY `c` (`c`)) ENGINE=InnoDB AUTO_INCREMENT=5 DEFAULT CHARSET=latin1 |+-------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+1 row in set (0.00 sec)MySQL [mysql]&gt; select * from t;+----+------+------+| id | c | d |+----+------+------+| 1 | 1 | 1 || 2 | 2 | 2 || 3 | 3 | 3 || 4 | 4 | 4 |+----+------+------+4 rows in set (0.00 sec)MySQL [mysql]&gt; insert into t(c,d) select 4,5;ERROR 1062 (23000): Duplicate entry &#x27;4&#x27; for key &#x27;c&#x27;MySQL [mysql]&gt; show create table t;+-------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| Table | Create Table |+-------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| t | CREATE TABLE `t` ( `id` int(11) NOT NULL AUTO_INCREMENT, `c` int(11) DEFAULT NULL, `d` int(11) DEFAULT NULL, PRIMARY KEY (`id`), UNIQUE KEY `c` (`c`)) ENGINE=InnoDB AUTO_INCREMENT=6 DEFAULT CHARSET=latin1 |+-------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+1 row in set (0.00 sec) case2 事务回滚12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849MySQL [mysql]&gt; begin;Query OK, 0 rows affected (0.00 sec)MySQL [mysql]&gt; insert into t(c,d) select 5,5;Query OK, 1 row affected (0.00 sec)Records: 1 Duplicates: 0 Warnings: 0MySQL [mysql]&gt; select * from t;+----+------+------+| id | c | d |+----+------+------+| 1 | 1 | 1 || 2 | 2 | 2 || 3 | 3 | 3 || 4 | 4 | 4 || 6 | 5 | 5 |+----+------+------+5 rows in set (0.00 sec)MySQL [mysql]&gt; rollback;Query OK, 0 rows affected (0.01 sec)MySQL [mysql]&gt; select * from t;+----+------+------+| id | c | d |+----+------+------+| 1 | 1 | 1 || 2 | 2 | 2 || 3 | 3 | 3 || 4 | 4 | 4 |+----+------+------+4 rows in set (0.00 sec)MySQL [mysql]&gt; commit;Query OK, 0 rows affected (0.00 sec)MySQL [mysql]&gt; show create table t;+-------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| Table | Create Table |+-------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| t | CREATE TABLE `t` ( `id` int(11) NOT NULL AUTO_INCREMENT, `c` int(11) DEFAULT NULL, `d` int(11) DEFAULT NULL, PRIMARY KEY (`id`), UNIQUE KEY `c` (`c`)) ENGINE=InnoDB AUTO_INCREMENT=7 DEFAULT CHARSET=latin1 |+-------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+1 row in set (0.00 sec) case3 批量插入批量语句：insert … select、replace … select 和 load data 语句 这里的逻辑是，申请主键id的方法如下： 申请1 申请2，3 申请4，5，6，7 每次2的倍数的申请，所以会存在浪费的现象 123456789101112131415161718192021222324252627282930313233343536373839404142434445MySQL [mysql]&gt; create table tt like t;Query OK, 0 rows affected (0.04 sec)MySQL [mysql]&gt; show create table tt;+-------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| Table | Create Table |+-------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| tt | CREATE TABLE `tt` ( `id` int(11) NOT NULL AUTO_INCREMENT, `c` int(11) DEFAULT NULL, `d` int(11) DEFAULT NULL, PRIMARY KEY (`id`), UNIQUE KEY `c` (`c`)) ENGINE=InnoDB DEFAULT CHARSET=latin1 |+-------+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+1 row in set (0.00 sec)MySQL [mysql]&gt; insert into tt(c,d) select c,d from t;Query OK, 4 rows affected, 1 warning (0.00 sec)Records: 4 Duplicates: 0 Warnings: 1MySQL [mysql]&gt; select * from tt; +----+------+------+| id | c | d |+----+------+------+| 1 | 1 | 1 || 2 | 2 | 2 || 3 | 3 | 3 || 4 | 4 | 4 |+----+------+------+4 rows in set (0.00 sec)MySQL [mysql]&gt; show create table tt;+-------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| Table | Create Table |+-------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| tt | CREATE TABLE `tt` ( `id` int(11) NOT NULL AUTO_INCREMENT, `c` int(11) DEFAULT NULL, `d` int(11) DEFAULT NULL, PRIMARY KEY (`id`), UNIQUE KEY `c` (`c`)) ENGINE=InnoDB AUTO_INCREMENT=8 DEFAULT CHARSET=latin1 |+-------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+1 row in set (0.00 sec) case4 update自增主键update并不改变AUTO_INCREMENT的值 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253MySQL [mysql]&gt; select * from tt; +----+------+------+| id | c | d |+----+------+------+| 1 | 1 | 1 || 2 | 2 | 2 || 3 | 3 | 3 || 4 | 4 | 4 |+----+------+------+4 rows in set (0.00 sec)MySQL [mysql]&gt; show create table tt;+-------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| Table | Create Table |+-------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| tt | CREATE TABLE `tt` ( `id` int(11) NOT NULL AUTO_INCREMENT, `c` int(11) DEFAULT NULL, `d` int(11) DEFAULT NULL, PRIMARY KEY (`id`), UNIQUE KEY `c` (`c`)) ENGINE=InnoDB AUTO_INCREMENT=8 DEFAULT CHARSET=latin1 |+-------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+1 row in set (0.00 sec)MySQL [mysql]&gt; update tt set id=20 where c = 4;Query OK, 1 row affected (0.01 sec)Rows matched: 1 Changed: 1 Warnings: 0MySQL [mysql]&gt; select * from tt;+----+------+------+| id | c | d |+----+------+------+| 1 | 1 | 1 || 2 | 2 | 2 || 3 | 3 | 3 || 20 | 4 | 4 |+----+------+------+4 rows in set (0.00 sec)MySQL [mysql]&gt; show create table tt;+-------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| Table | Create Table |+-------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| tt | CREATE TABLE `tt` ( `id` int(11) NOT NULL AUTO_INCREMENT, `c` int(11) DEFAULT NULL, `d` int(11) DEFAULT NULL, PRIMARY KEY (`id`), UNIQUE KEY `c` (`c`)) ENGINE=InnoDB AUTO_INCREMENT=8 DEFAULT CHARSET=latin1 |+-------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+1 row in set (0.00 sec) case5 删除自增主键delete并不改变的AUTO_INCREMENT值 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253MySQL [mysql]&gt; select * from tt;+----+------+------+| id | c | d |+----+------+------+| 1 | 1 | 1 || 2 | 2 | 2 || 3 | 3 | 3 || 8 | 5 | 5 || 20 | 4 | 4 |+----+------+------+5 rows in set (0.00 sec)MySQL [mysql]&gt; show create table tt;+-------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| Table | Create Table |+-------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| tt | CREATE TABLE `tt` ( `id` int(11) NOT NULL AUTO_INCREMENT, `c` int(11) DEFAULT NULL, `d` int(11) DEFAULT NULL, PRIMARY KEY (`id`), UNIQUE KEY `c` (`c`)) ENGINE=InnoDB AUTO_INCREMENT=9 DEFAULT CHARSET=latin1 |+-------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+1 row in set (0.00 sec)MySQL [mysql]&gt; delete from tt where id = 8;Query OK, 1 row affected (0.00 sec)MySQL [mysql]&gt; select * from tt;+----+------+------+| id | c | d |+----+------+------+| 1 | 1 | 1 || 2 | 2 | 2 || 3 | 3 | 3 || 20 | 4 | 4 |+----+------+------+4 rows in set (0.00 sec)MySQL [mysql]&gt; show create table tt;+-------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| Table | Create Table |+-------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+| tt | CREATE TABLE `tt` ( `id` int(11) NOT NULL AUTO_INCREMENT, `c` int(11) DEFAULT NULL, `d` int(11) DEFAULT NULL, PRIMARY KEY (`id`), UNIQUE KEY `c` (`c`)) ENGINE=InnoDB AUTO_INCREMENT=9 DEFAULT CHARSET=latin1 |+-------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+1 row in set (0.00 sec) 自增主键的存放 MyISAM的自增值保存在数据文件中 Innodb的自增值AUTO_INCREMENT保存在内存中(mysql重启后找到表内max(id),然后让AUTO_INCREMENT=max(id)+1),mysql8.0版本后，才有了自增值的持久化能力 innodb_autoinc_lock_modeinnodb_autoinc_lock_mode是mysql5.1版本引入的，可以控制自增锁的释放时机 1234567MySQL [mysql]&gt; show variables like &#x27;innodb_autoinc_lock_mode&#x27;;+--------------------------+-------+| Variable_name | Value |+--------------------------+-------+| innodb_autoinc_lock_mode | 1 |+--------------------------+-------+1 row in set (0.00 sec) 默认值是1，不同取值含义如下： 0 保持mysql5.0版本策略，语句执行完成释放自增锁 1 分两种情况 普通insert语句(包括insert … values(),(),())，自增锁在申请之后就释放 批量插入语句，还是要等到语句执行结束才释放 2 所有申请自增主键的动作都是申请后就释放锁 对于批量插入，考虑到并发性，建议innodb_autoinc_lock_mode = 2, 加上binlog_format=row的用法。=2的模式可以尽早释放锁，row记录的是实际的所有列的值(full模式)，或者noblob模式也会记录主键的。从库备份的时候拿到的就是主库插入的主键的值，如果是statement就会乱套，对于这种情况： 12345678//伪代码sessionA sessionBinsert into t values()insert into t values()insert into t values() create table tt like t;insert into tt vaules() insert tt select .. from t; 如果insert select获取自增锁然后释放锁，只insert了部分记录，然后sesiionA获取锁，插入了一条导致自增主键值加1，然后sesisionB继续执行，对于sesiionB来说和预期的会不同，t的数据拷贝到tt中间有一条的主键值跃了一次，但是statement的binlog只记录了两条语句，insert select(sesiionB), insert vaules(sessionA),从库备份的时候结果是不能准确预计的。 书上的补充： todo其他值得注意的地方以后补充","categories":[],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://riverferry.site/tags/mysql/"}],"keywords":[]},{"title":"mysql 索引","slug":"2020-07-30-mysql 索引","date":"2020-07-30T00:00:00.000Z","updated":"2022-09-12T16:24:32.284Z","comments":true,"path":"2020-07-30-mysql 索引/","link":"","permalink":"https://riverferry.site/2020-07-30-mysql%20%E7%B4%A2%E5%BC%95/","excerpt":"前言留的坑，以后填","text":"前言留的坑，以后填 TODOending","categories":[],"tags":[{"name":"坑","slug":"坑","permalink":"https://riverferry.site/tags/%E5%9D%91/"}],"keywords":[]},{"title":"golang routine","slug":"2020-07-28-golang routine","date":"2020-07-28T00:00:00.000Z","updated":"2022-09-12T16:24:32.284Z","comments":true,"path":"2020-07-28-golang routine/","link":"","permalink":"https://riverferry.site/2020-07-28-golang%20routine/","excerpt":"前言留的坑，以后填","text":"前言留的坑，以后填 TODOending","categories":[],"tags":[{"name":"坑","slug":"坑","permalink":"https://riverferry.site/tags/%E5%9D%91/"}],"keywords":[]},{"title":"mysql安装","slug":"2020-07-27-mysql-安装","date":"2020-07-27T00:00:00.000Z","updated":"2022-09-12T16:24:32.284Z","comments":true,"path":"2020-07-27-mysql-安装/","link":"","permalink":"https://riverferry.site/2020-07-27-mysql-%E5%AE%89%E8%A3%85/","excerpt":"begin安装总体流程参考: https://blog.csdn.net/u013011879/article/details/106554289","text":"begin安装总体流程参考: https://blog.csdn.net/u013011879/article/details/106554289 遇到的问题汇总： case 1Couldn’t find MySQL server case 2Can’t connect to local MySQL server case 3提示/etc/my.cnf 被忽略的问题处理 case 4Your password has expired end","categories":[],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://riverferry.site/tags/mysql/"}],"keywords":[]},{"title":"c++内存模型","slug":"2020-07-27-c++内存模型","date":"2020-07-27T00:00:00.000Z","updated":"2022-09-12T16:24:32.284Z","comments":true,"path":"2020-07-27-c++内存模型/","link":"","permalink":"https://riverferry.site/2020-07-27-c++%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B/","excerpt":"参考http://baiy.cn/doc/cpp/inside_rtti.htm https://stackoverflow.com/questions/6258559/what-is-the-vtt-for-a-class https://zhuanlan.zhihu.com/p/41309205 深度探索C++对象模型 https://stackoverflow.com/questions/6613870/gnu-gcc-g-why-does-it-generate-multiple-dtors","text":"参考http://baiy.cn/doc/cpp/inside_rtti.htm https://stackoverflow.com/questions/6258559/what-is-the-vtt-for-a-class https://zhuanlan.zhihu.com/p/41309205 深度探索C++对象模型 https://stackoverflow.com/questions/6613870/gnu-gcc-g-why-does-it-generate-multiple-dtors 虚函数和虚基类code1234567891011121314151617181920212223242526272829303132333435363738394041#include &lt;iostream&gt;using namespace std;class A &#123;public: A():a(0) &#123;cout &lt;&lt; &quot;A&quot; &lt;&lt; endl;&#125;; int a; virtual void v()&#123;&#125;;&#125;;class B : public virtual A &#123;public: B():b(0) &#123;cout &lt;&lt; &quot;B&quot; &lt;&lt; endl;&#125;; int b; virtual void w()&#123;&#125;;&#125;;class C : public virtual A &#123;public: C():c(0) &#123;cout &lt;&lt; &quot;C&quot; &lt;&lt; endl;&#125;; int c; virtual void x()&#123;&#125;;&#125;;class D : public B, public C &#123;public: D():d(0) &#123;cout &lt;&lt; &quot;D&quot; &lt;&lt; endl;&#125;; int d; virtual void y()&#123;&#125;;&#125;;int main()&#123; D dd; return 0;&#125; sizeof虚基类：单独sizeof A 16 //vptr_a inta 8+8=16 B 32 //vptr_b intb vptr_a inta 8*4=32 C 32 //vptr_c intc vptr_a inta 8*4=32 D 48 //vptr_b intb vptr_c (intc intd) vptr_a inta 8*6=48 | vtable | +----------+ | b | +----------+ | vtable | +----------+ | c | +----------+ | d | +----------+ | vtable | +----------+ | a | +----------+ 非虚基类： 单独sizeof A 16 //vptr_a inta 8+8=16 B 16 //vptr_a (inta intb) 8*2=16 A C 16 //vptr_a (inta intc) 8*2=16 D 40 //vptr_a (inta inb) vptr_a (inta intc) intd 8*5=40 | vtable | +----------+ | a | +----------+ | b | +----------+ | vtable | +----------+ | a | +----------+ | c | +----------+ | d | +----------+ -fdump-class-hierarchyVtable for A A::_ZTV1A: 3u entries 0 (int (*)(...))0 8 (int (*)(...))(&amp; _ZTI1A) 16 (int (*)(...))A::v Class A size=16 align=8 base size=12 base align=8 A (0x0x7f0f37c70b40) 0 vptr=((&amp; A::_ZTV1A) + 16u) Vtable for B B::_ZTV1B: 8u entries 0 16u 8 (int (*)(...))0 16 (int (*)(...))(&amp; _ZTI1B) 24 (int (*)(...))B::w 32 0u 40 (int (*)(...))-16 48 (int (*)(...))(&amp; _ZTI1B) 56 (int (*)(...))A::v VTT for B B::_ZTT1B: 2u entries 0 ((&amp; B::_ZTV1B) + 24u) 8 ((&amp; B::_ZTV1B) + 56u) Class B size=32 align=8 base size=12 base align=8 B (0x0x7f0f37cab5b0) 0 vptridx=0u vptr=((&amp; B::_ZTV1B) + 24u) A (0x0x7f0f37c70ba0) 16 virtual vptridx=8u vbaseoffset=-24 vptr=((&amp; B::_ZTV1B) + 56u) Vtable for C C::_ZTV1C: 8u entries 0 16u 8 (int (*)(...))0 16 (int (*)(...))(&amp; _ZTI1C) 24 (int (*)(...))C::x 32 0u 40 (int (*)(...))-16 48 (int (*)(...))(&amp; _ZTI1C) 56 (int (*)(...))A::v VTT for C C::_ZTT1C: 2u entries 0 ((&amp; C::_ZTV1C) + 24u) 8 ((&amp; C::_ZTV1C) + 56u) Class C size=32 align=8 base size=12 base align=8 C (0x0x7f0f37cab9c0) 0 vptridx=0u vptr=((&amp; C::_ZTV1C) + 24u) A (0x0x7f0f37c70c00) 16 virtual vptridx=8u vbaseoffset=-24 vptr=((&amp; C::_ZTV1C) + 56u) Vtable for D D::_ZTV1D: 13u entries 0 32u 8 (int (*)(...))0 16 (int (*)(...))(&amp; _ZTI1D) 24 (int (*)(...))B::w 32 (int (*)(...))D::y 40 16u 48 (int (*)(...))-16 56 (int (*)(...))(&amp; _ZTI1D) 64 (int (*)(...))C::x 72 0u 80 (int (*)(...))-32 88 (int (*)(...))(&amp; _ZTI1D) 96 (int (*)(...))A::v Construction vtable for B (0x0x7f0f37cabdd0 instance) in D D::_ZTC1D0_1B: 8u entries 0 32u 8 (int (*)(...))0 16 (int (*)(...))(&amp; _ZTI1B) 24 (int (*)(...))B::w 32 0u 40 (int (*)(...))-32 48 (int (*)(...))(&amp; _ZTI1B) 56 (int (*)(...))A::v Construction vtable for C (0x0x7f0f37cabe38 instance) in D D::_ZTC1D16_1C: 8u entries 0 16u 8 (int (*)(...))0 16 (int (*)(...))(&amp; _ZTI1C) 24 (int (*)(...))C::x 32 0u 40 (int (*)(...))-16 48 (int (*)(...))(&amp; _ZTI1C) 56 (int (*)(...))A::v VTT for D D::_ZTT1D: 7u entries 0 ((&amp; D::_ZTV1D) + 24u) 8 ((&amp; D::_ZTC1D0_1B) + 24u) 16 ((&amp; D::_ZTC1D0_1B) + 56u) 24 ((&amp; D::_ZTC1D16_1C) + 24u) 32 ((&amp; D::_ZTC1D16_1C) + 56u) 40 ((&amp; D::_ZTV1D) + 96u) 48 ((&amp; D::_ZTV1D) + 64u) Class D size=48 align=8 base size=32 base align=8 D (0x0x7f0f37a82a80) 0 vptridx=0u vptr=((&amp; D::_ZTV1D) + 24u) B (0x0x7f0f37cabdd0) 0 primary-for D (0x0x7f0f37a82a80) subvttidx=8u A (0x0x7f0f37c70c60) 32 virtual vptridx=40u vbaseoffset=-24 vptr=((&amp; D::_ZTV1D) + 96u) C (0x0x7f0f37cabe38) 16 subvttidx=24u vptridx=48u vptr=((&amp; D::_ZTV1D) + 64u) A (0x0x7f0f37c70c60) alternative-path 这个结果挺乱的，不好分析，命令记住就行 子类对象完整性子类对象data member并没有和派生类对象data member放在一起，中间有对其的字节填充。这样是为了保持派生类中子类对象的完整性 如果不填充的话，BB拷贝给CC,会把CC的data member(c)给覆盖掉。 1234567891011121314151617181920212223class AA&#123;public: int a;&#125;;class BB : AA&#123;public: char b;&#125;;class CC : BB&#123;public: char c;&#125;;int main()&#123; cout &lt;&lt; sizeof(CC) &lt;&lt; endl; return 0;&#125;output: 8 然而我的测试结果是填充在一起了，具体原因未知。 指向数据成员的指针1234567891011121314151617181920212223242526272829303132class AA &#123;public: int a; int a2; int a3;&#125;;int main()&#123; //D dd; cout &lt;&lt; sizeof(A) &lt;&lt; endl; cout &lt;&lt; sizeof(B) &lt;&lt; endl; int AA::*p = 0; int AA::*a = &amp;AA::a; int AA::*b = &amp;AA::a2; int AA::*c = &amp;AA::a3; printf(&quot;%p\\n&quot;, &amp;AA::a); //(nil) printf(&quot;%p\\n&quot;, &amp;AA::a2); //0x4 printf(&quot;%p\\n&quot;, &amp;AA::a3); //0x8 printf(&quot;%p\\n&quot;, p); //0xffffffffffffffff printf(&quot;%p\\n&quot;, a); //(nil) printf(&quot;%p\\n&quot;, b); //0x4 printf(&quot;%p\\n&quot;, c); //0x8 cout &lt;&lt; (p == a) &lt;&lt; endl; //0 return 0;&#125; 有的编译期给&amp;AA::a这样的成员变量偏移值结果+1,用于区分AA::*p.即区别： 没有指向任何成员变量的指针 指向第一个成员变量的指针 但是显然gcc没有这样做。但也可以区分。 成员函数指针1234567891011121314151617181920class AA &#123;public: void func() &#123;cout &lt;&lt; &quot;yes\\n&quot;; &#125;;&#125;;int main()&#123; //def member function pointer void (AA::*pmf)(); pmf = &amp;AA::func; AA a; AA *pa; (a.*pmf)(); (pa-&gt;*pmf)(); (*pmf)(); //error: invalid use of unary ‘*’ on pointer to member (*pmf)(); return 0;&#125; this指针的作用：主要是找派生类对象的地址。 12345678910111213141516171819base2 * pb = new derived;pb-&gt;func();类结构：class base1&#123; ~base1(); virtual vfunc()&#123;&#125;;&#125;class base2;&#123; ~base2(); virtual vfunc2()&#123;&#125;;&#125;class derived: public base, public base2&#123; ~derived(); vfunc()&#123;&#125;;&#125; new之后，pb = &amp;derived + sizeof(base1); //编译期由编译器决定pb-&gt;func()在这里是调用的derived的func函数，但也可能调用base2的func函数。想想random的情况。所以这是运行期才能决定的。编译器在编译期并不能算出固定结果，所以编译器让他指向一个可变的地址,假如是： (*pb-&gt;vptr[4])(this + pb-&gt;vptr[2].offset) //derived--&gt;table vptr_base1 0 rtti 1 base_offset 2 top_offset //0 3 ~derived() 4 func vptr_base2 0 rtti 1 base_offset 2 top_offset //-20 假定是-20 3 ~derived() 4 func //base2--&gt;table vptr 0 rtti 1 base_offset 2 top_offset //0 3 ~base2() 4 func 如果pb = new base2,则top_offset=0，this指针就是base2的地址,detele &amp;base2 如果pb = new derived,则pb(this) = &amp;derived + sizeof(base1)(编译器计算)，(this + pb-&gt;vptr[2].offset)，指向的具体值运行期判断，这里就是offset = -20,得到derived的地址，delete &amp;derived 总结： 派生类可以赋值给基类(upcast),是因为有一系列机制来保证，比如this指针偏移，base指针偏移，rtti,即整个vtable. 正是因为有这么多机制保证upcast转换可行，才导致base指针可能指向base对象也可能指向derived对象的不确定性，从而导致downcast的不可行，只能在运行期判断了。编译器在对象构造的时候已经确定了vptr和vtable,同样的this+offset指向的内存确实根据base指针指向的空间即vtable的不同来变化的。 下面的代码对于downcast也印证了this指针偏移在类型转换的时候，也是找对象首地址的: 1234567891011121314151617181920212223242526272829303132class AA &#123;public: int a; virtual void func() &#123;cout &lt;&lt; &quot;yes\\n&quot;; &#125;;&#125;;class BB&#123;public: virtual void func2()&#123;&#125;; int b;&#125;;class CC: public AA, public BB&#123;public: virtual void func() &#123;cout &lt;&lt; &quot;yes\\n&quot;; &#125;; virtual void func2()&#123;&#125;; int c;&#125;;int main()&#123; //dynamic_cast只能用于指针和引用 AA *a = new AA; CC *c = dynamic_cast&lt;CC*&gt;(a); if (c) cout &lt;&lt; &quot;true 1&quot; &lt;&lt; endl; //false AA *b = new CC; CC *d = dynamic_cast&lt;CC*&gt;(b); if (d) cout &lt;&lt; &quot;true 2&quot; &lt;&lt; endl; //true return 0;&#125; upcast是在编译期执行的，对象内存布局是确定的，只有在指针，引用的时候由于不明确导致的含义模糊才需要this指针。 base指针的作用就是因为有虚基类才有了base指针： 虚基类的地址在类的最下边，属于可变区域，编译器不能直接sizeof计算偏移值，所以引入了base指针偏移值来计算。不同于this指针是找对象的首地址，base指针是找对象的末尾子类地址的。仅此而已了。 thrunk123456789101112131415161718192021222324252627282930313233class A &#123;public: int a; virtual void v();&#125;;class B &#123;public: int b; virtual void w();&#125;;class C : public A, public B &#123;public: int c; void w();&#125;; +-----------------------+ | 0 (top_offset) | +-----------------------+c --&gt; +----------+ | ptr to typeinfo for C | | vtable |-------&gt; +-----------------------+ +----------+ | A::v() | | a | +-----------------------+ +----------+ | C::w() | | vtable |---+ +-----------------------+ +----------+ | | -8 (top_offset) | | b | | +-----------------------+ +----------+ | | ptr to typeinfo for C | | c | +---&gt; +-----------------------+ +----------+ | thunk to C::w() | +-----------------------+ C重写了B的w函数，vptr_b和vptr_a都指向了一个w().thrunk的作用就是用trunk函数做一个转换，先偏移this指针，然后调用上面的C::w(). VTT(virtual table tbale)避免二次消化，把原文贴上来，即使是英文，啃下来确实收益很大的： https://stackoverflow.com/questions/6258559/what-is-the-vtt-for-a-class PART2: Construction/Destruction in the Presence of Multiple Inheritance How is the above object constructed in memory when the object itself is constructed? And how do we ensure that a partially-constructed object (and its vtable) are safe for constructors to operate on? Fortunately, it’s all handled very carefully for us. Say we’re constructing a new object of type D (through, for example, new D). First, the memory for the object is allocated in the heap and a pointer returned. D’s constructor is invoked, but before doing any D-specific construction it call’s A’s constructor on the object (after adjusting the this pointer, of course!). A’s constructor fills in the A part of the D object as if it were an instance of A. d --&gt; +----------+ | | +----------+ | | +----------+ | | +----------+ | | +-----------------------+ +----------+ | 0 (top_offset) | | | +-----------------------+ +----------+ | ptr to typeinfo for A | | vtable |-----&gt; +-----------------------+ +----------+ | A::v() | | a | +-----------------------+ +----------+ Control is returned to D’s constructor, which invokes B’s constructor. (Pointer adjustment isn’t needed here.) When B’s constructor is done,the object looks like this: B-in-D +-----------------------+ | 20 (vbase_offset) | +-----------------------+ | 0 (top_offset) | +-----------------------+ d --&gt; +----------+ | ptr to typeinfo for B | | vtable |------&gt; +-----------------------+ +----------+ | B::w() | | b | +-----------------------+ +----------+ | 0 (vbase_offset) | | | +-----------------------+ +----------+ | -20 (top_offset) | | | +-----------------------+ +----------+ | ptr to typeinfo for B | | | +--&gt; +-----------------------+ +----------+ | | A::v() | | vtable |---+ +-----------------------+ +----------+ | a | +----------+ But wait… B’s constructor modified the A part of the object by changing it’s vtable pointer! How did it know to distinguish this kind of B-in-D from a B-in-something-else (or a standalone B for that matter)? Simple. The virtual table table told it to do this. This structure, abbreviated VTT, is a table of vtables used in construction. In our case, the VTT for D looks like this: B-in-D +-----------------------+ | 20 (vbase_offset) | VTT for D +-----------------------+ +-------------------+ | 0 (top_offset) | | vtable for D |-------------+ +-----------------------+ +-------------------+ | | ptr to typeinfo for B | | vtable for B-in-D |-------------|----------&gt; +-----------------------+ +-------------------+ | | B::w() | | vtable for B-in-D |-------------|--------+ +-----------------------+ +-------------------+ | | | 0 (vbase_offset) | | vtable for C-in-D |-------------|-----+ | +-----------------------+ +-------------------+ | | | | -20 (top_offset) | | vtable for C-in-D |-------------|--+ | | +-----------------------+ +-------------------+ | | | | | ptr to typeinfo for B | | vtable for D |----------+ | | | +-&gt; +-----------------------+ +-------------------+ | | | | | A::v() | | vtable for D |-------+ | | | | +-----------------------+ +-------------------+ | | | | | | | | | | C-in-D | | | | | +-----------------------+ | | | | | | 12 (vbase_offset) | | | | | | +-----------------------+ | | | | | | 0 (top_offset) | | | | | | +-----------------------+ | | | | | | ptr to typeinfo for C | | | | | +----&gt; +-----------------------+ | | | | | C::x() | | | | | +-----------------------+ | | | | | 0 (vbase_offset) | | | | | +-----------------------+ | | | | | -12 (top_offset) | | | | | +-----------------------+ | | | | | ptr to typeinfo for C | | | | +-------&gt; +-----------------------+ | | | | A::v() | | | | +-----------------------+ | | | | | | D | | | +-----------------------+ | | | | 20 (vbase_offset) | | | | +-----------------------+ | | | | 0 (top_offset) | | | | +-----------------------+ | | | | ptr to typeinfo for D | | | +----------&gt; +-----------------------+ | | | B::w() | | | +-----------------------+ | | | D::y() | | | +-----------------------+ | | | 12 (vbase_offset) | | | +-----------------------+ | | | -8 (top_offset) | | | +-----------------------+ | | | ptr to typeinfo for D | +----------------&gt; +-----------------------+ | | C::x() | | +-----------------------+ | | 0 (vbase_offset) | | +-----------------------+ | | -20 (top_offset) | | +-----------------------+ | | ptr to typeinfo for D | +-------------&gt; +-----------------------+ | A::v() | +-----------------------+ D’s constructor passes a pointer into D’s VTT to B’s constructor (in this case, it passes in the address of the first B-in-D entry). And, indeed,the vtable that was used for the object layout above is a special vtable used just for the construction of B-in-D. Control is returned to the D constructor, and it calls the C constructor(with a VTT address parameter pointing to the “C-in-D+12” entry). When C’s constructor is done with the object it looks like this: B-in-D +-----------------------+ | 20 (vbase_offset) | +-----------------------+ | 0 (top_offset) | +-----------------------+ | ptr to typeinfo for B | +---------------------------------&gt; +-----------------------+ | | B::w() | | +-----------------------+ | C-in-D | 0 (vbase_offset) | | +-----------------------+ +-----------------------+ d --&gt; +----------+ | | 12 (vbase_offset) | | -20 (top_offset) | | vtable |--+ +-----------------------+ +-----------------------+ +----------+ | 0 (top_offset) | | ptr to typeinfo for B | | b | +-----------------------+ +-----------------------+ +----------+ | ptr to typeinfo for C | | A::v() | | vtable |--------&gt; +-----------------------+ +-----------------------+ +----------+ | C::x() | | c | +-----------------------+ +----------+ | 0 (vbase_offset) | | | +-----------------------+ +----------+ | -12 (top_offset) | | vtable |--+ +-----------------------+ +----------+ | | ptr to typeinfo for C | | a | +-----&gt; +-----------------------+ +----------+ | A::v() | +-----------------------+ As you see, C’s constructor again modified the embedded A’s vtable pointer.The embedded C and A objects are now using the special construction C-in-D vtable, and the embedded B object is using the special construction B-in-D vtable. Finally, D’s constructor finishes the job and we end up with the same diagram as before: +-----------------------+ | 20 (vbase_offset) | +-----------------------+ | 0 (top_offset) | +-----------------------+ | ptr to typeinfo for D | +----------&gt; +-----------------------+ d --&gt; +----------+ | | B::w() | | vtable |----+ +-----------------------+ +----------+ | D::y() | | b | +-----------------------+ +----------+ | 12 (vbase_offset) | | vtable |---------+ +-----------------------+ +----------+ | | -8 (top_offset) | | c | | +-----------------------+ +----------+ | | ptr to typeinfo for D | | d | +-----&gt; +-----------------------+ +----------+ | C::x() | | vtable |----+ +-----------------------+ +----------+ | | 0 (vbase_offset) | | a | | +-----------------------+ +----------+ | | -20 (top_offset) | | +-----------------------+ | | ptr to typeinfo for D | +----------&gt; +-----------------------+ | A::v() | +-----------------------+ Destruction occurs in the same fashion but in reverse. D’s destructor is invoked. After the user’s destruction code runs, the destructor calls C’s destructor and directs it to use the relevant portion of D’s VTT. C’s destructor manipulates the vtable pointers in the same way it did during construction; that is, the relevant vtable pointers now point into the C-in-D construction vtable. Then it runs the user’s destruction code for C and returns control to D’s destructor, which next invokes B’s destructor with a reference into D’s VTT. B’s destructor sets up the relevant portions of the object to refer into the B-in-D construction vtable. It runs the user’s destruction code for B and returns control to D’s destructor, which finally invokes A’s destructor. A’s destructor changes the vtable for the A portion of the object to refer into the vtable for A. Finally, control returns to D’s destructor and destruction of the object is complete. The memory once used by the object is returned to the system. 简单总结： 普通的一个派生类，赋值给一个基类对象，直接偏移就行了，派生类中基类的部分可以直接给独立的基类来用。但是对于含有虚基类的派生类来说，由于虚基类的内存分布在最底下，和中间类(B,C)独立时的布局是不一样的。对于对象赋值的偏移可以根据base指针，但是构造函数构造vtable的时候应该构造哪种vtable?当构造函数构造B,C的时候应该使用B,C独立状态下的vtable还是B-in-D,C-in-D时候的vtable,就需要VTT来保存多个虚指针和虚表随机应变了。(普通情况下派生类一张表就够了，现在得3张表了，7个虚指针：2+2+3) in-charge not-in-charge in-charge-delete续上面的文章： Now, in fact, the story is somewhat more complicated. Have you ever seen those “in-charge” and “not-in-charge” constructor and destructor specifications in GCC-produced warning and error messages or in GCC-produced binaries? Well, the fact is that there can be two constructor implementations and up to three destructor implementations. An “in-charge” (or complete object) constructor is one that constructs virtual bases, and a “not-in-charge” (or base object) constructor is one that does not. Consider our above example. If a B is constructed, its constructor needs to call A’s constructor to construct it. Similarly, C’s constructor needs to construct A. However, if B and C are constructed as part of a construction of a D, their constructors should not construct A, because A is a virtual base and D’s constructor will take care of constructing it exactly once for the instance of D. Consider the cases: If you do a new A, A’s “in-charge” constructor is invoked to construct A. When you do a new B, B’s “in-charge” constructor is invoked. It will call the “not-in-charge” constructor for A. new C is similar to new B. A new D invokes D’s “in-charge” constructor. Wewalked through this example. D’s “in-charge” constructor calls the”not-in-charge” versions of A’s, B’s, and C’s constructors (in thatorder). An “in-charge” destructor is the analogue of an “in-charge”constructor—it takes charge of destructing virtual bases. Similarly,a “not-in-charge” destructor is generated. But there’s a third one as well. An “in-charge deleting” destructor is one that deallocates the storage as well as destructing the object. So when is one called in preference to the other? Well, there are two kinds of objects that can be destructed—those allocated on the stack, and those allocated in the heap. Consider this code (given our diamond hierarchy with virtual-inheritance from before): D d; // allocates a D on the stack and constructs itD pd = new D; // allocates a D in the heap and constructs it/ … */delete pd; // calls “in-charge deleting” destructor for Dreturn; // calls “in-charge” destructor for stack-allocated DWe see that the actual delete operator isn’t invoked by the code doing the delete, but rather by the in-charge deleting destructor for the object being deleted. Why do it this way? Why not have the caller call the in-charge destructor, then delete the object? Then you’d have only two copies of destructor implementations instead of three… Well, the compiler could do such a thing, but it would be morecomplicated for other reasons. Consider this code (assuming a virtual destructor,which you always use, right?…right?!?): D *pd = new D; // allocates a D in the heap and constructs it C pc = d; // we have a pointer-to-C that points to our heap-allocated D / … */ delete pc; // call destructor thunk through vtable, but what about delete?If you didn’t have an “in-charge deleting” variety of D’s destructor, then the delete operation would need to adjust the pointer just like the destructor thunk does. Remember, the C object is embedded in a D, and so our pointer-to-C above is adjusted to point into the middle of our D object.We can’t just delete this pointer, since it isn’t the pointer that was returned by malloc() when we constructed it. So, if we didn’t have an in-charge deleting destructor, we’d have to have thunks to the delete operator (and represent them in our vtables), or something else similar. Thunks, Virtual and Non-Virtual This section not written yet. Multiple Inheritance with Virtual Methods on One Side Okay. One last exercise. What if we have a diamond inheritance hierarchy with virtual inheritance, as before, but only have virtual methods along one side of it? So: class A {public: int a;}; class B : public virtual A {public: int b; virtual void w();}; class C : public virtual A {public: int c;}; class D : public B, public C {public: int d; virtual void y();};In this case the object layout is the following: +-----------------------+ | 20 (vbase_offset) | +-----------------------+ | 0 (top_offset) | +-----------------------+ | ptr to typeinfo for D | +----------&gt; +-----------------------+ d --&gt; +----------+ | | B::w() | | vtable |----+ +-----------------------+ +----------+ | D::y() | | b | +-----------------------+ +----------+ | 12 (vbase_offset) | | vtable |---------+ +-----------------------+ +----------+ | | -8 (top_offset) | | c | | +-----------------------+ +----------+ | | ptr to typeinfo for D | | d | +-----&gt; +-----------------------+ +----------+ | a | +----------+ So you can see the C subobject, which has no virtual methods, still has a vtable (albeit empty). Indeed, all instances of C have an empty vtable. Thanks, Morgan Deters!! 再加上这个： https://stackoverflow.com/questions/6613870/gnu-gcc-g-why-does-it-generate-multiple-dtors First, the purposes of these functions are described in the Itanium C++ ABI; see definitions under “base object destructor”, “complete object destructor”, and “deleting destructor”. The mapping to mangled names is given in 5.1.4. Basically: D2 is the “base object destructor”. It destroys the object itself, as well as data members and non-virtual base classes. D1 is the “complete object destructor”. It additionally destroys virtual base classes. D0 is the “deleting object destructor”. It does everything the complete object destructor does, plus it calls operator delete to actually free the memory. If you have no virtual base classes, D2 and D1 are identical; GCC will, on sufficient optimization levels, actually alias the symbols to the same code for both. in-charge == complete object dtor not-in-charge == base object dtor in-charge-delete == deleting object dtor 12345678910111213//-C或--demangle：将低级符号名解码(demangle)成用户级名字。//这样可以使得C++函数名具有可读性。nm --demangle a.out0000000000400b7c T DerivedClass::~DerivedClass()0000000000400b04 T DerivedClass::~DerivedClass()0000000000400b04 T DerivedClass::~DerivedClass()0000000000400ada T BaseClass::someMethod()0000000000400c72 W BaseClass::BaseClass()0000000000400c72 W BaseClass::BaseClass()0000000000400ab0 T BaseClass::~BaseClass()0000000000400ab0 T BaseClass::~BaseClass() ending","categories":[],"tags":[{"name":"c++","slug":"c","permalink":"https://riverferry.site/tags/c/"}],"keywords":[]},{"title":"training","slug":"2020-07-26-training","date":"2020-07-26T00:00:00.000Z","updated":"2022-09-12T16:24:32.284Z","comments":true,"path":"2020-07-26-training/","link":"","permalink":"https://riverferry.site/2020-07-26-training/","excerpt":"20200726直接在leetcode做题吧，此文不再更新。","text":"20200726直接在leetcode做题吧，此文不再更新。 源起弱点，会被看穿，会被评价，会流下血与泪 参考leetcode 剑指offer 001 合并两个有序链表 题目 来源 完成时间 将两个升序链表合并为一个新的升序链表并返回 剑指offer 20200401 合并两个有序链表 将两个升序链表合并为一个新的升序链表并返回。新链表是通过拼接给定的两个链表的所有节点组成的。 示例： 输入：1-&gt;2-&gt;4, 1-&gt;3-&gt;4 输出：1-&gt;1-&gt;2-&gt;3-&gt;4-&gt;4 my unswer 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465/** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode(int x) : val(x), next(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: ListNode* mergeTwoLists(ListNode* l1, ListNode* l2) &#123; if (!l1) return l2; if (!l2) return l1; ListNode *p1 = l1; ListNode *p2 = l1; ListNode *p3 = NULL; while (l2) &#123; //p1 = l1 --&gt;A p1 = l1; while (p1 &amp;&amp; l2-&gt;val &gt;= p1-&gt;val) &#123; p3 = p1; p1 = p1-&gt;next; &#125; if (!p1) &#123; //right insert p3-&gt;next = l2; break; &#125; else &#123; //mid insert if (p1 != l1) &#123; p3-&gt;next = l2; //p3 = l2 --&gt;B //A，B保留一处 &#125; p2 = l2-&gt;next; l2-&gt;next = p1; //left insert if (p1 == l1) &#123; l1 = l2; p1 = l1; &#125; &#125; l2 = p2; &#125; return l1; &#125;&#125;; 002 数组中重复的数字 题目 来源 完成时间 找出数组中重复的数字 剑指offer 20200417 在一个长度为n的数组里的所有数字都在0 ~ n-1的范围内。数组中某些数字是重复的，但不知道有几个数字重复了，也不知道每个数字重复了几次。请找出数组中任意一个重复的数字。例如，如果输入长度为7的数组{2,3,1,0,2,5,3},那么对应的输出是数字2或者3 方法1：排序，排完序遍历数组 方法2：哈希表，插入判断是否重复 方法3：让数组索引值和数组的元素值相等，data[0] = 0, data[1] = 1,对应不上的不管 方法 时间复杂度 空间复杂度 排序 O(nlogn) O(n) 哈希 O(1) O(n) 数组索引 O(1) O(1) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788#include &lt;iostream&gt;using namespace std;void FuncFind(int data[], int n)&#123; if (data == nullptr || n &lt;= 0) &#123; cout &lt;&lt; &quot;Invalid param!&quot; &lt;&lt; endl; return ; &#125; //每个数组元素都要&gt;=0 &amp;&amp; &lt;n-1 for (int i = 0; i &lt; n; i++) &#123; if (data[i] &lt; 0 || data[i] &gt; n - 1) &#123; cout &lt;&lt; &quot;Invalid param!&quot; &lt;&lt; endl; return ; &#125; &#125; for (int i = 0; i &lt; n; ) &#123; if (data[i] != i) &#123; if (data[i] == data[data[i]]) &#123; cout &lt;&lt; data[i] &lt;&lt; endl; i++; &#125; else &#123; swap(data[i], data[data[i]]); &#125; &#125; else i++; &#125;&#125;void FuncFind2(int data[], int n)&#123; if (data == nullptr || n &lt;= 0) &#123; cout &lt;&lt; &quot;Invalid param!&quot; &lt;&lt; endl; return ; &#125; //每个数组元素都要&gt;=0 &amp;&amp; &lt;n-1 for (int i = 0; i &lt; n; i++) &#123; if (data[i] &lt; 0 || data[i] &gt; n - 1) &#123; cout &lt;&lt; &quot;Invalid param!&quot; &lt;&lt; endl; return ; &#125; &#125; for (int i = 0; i &lt; n; i++) &#123; while (data[i] != i) &#123; if (data[i] == data[data[i]]) &#123; cout &lt;&lt; data[i] &lt;&lt; endl; break; &#125; else &#123; swap(data[i], data[data[i]]); &#125; &#125; &#125;&#125;int main()&#123; int data[] = &#123;2,3,1,0,2,5,3,1,8,10,6,6&#125;; int n = sizeof(data)/sizeof(int); FuncFind(data, n); return 0;&#125; 2 3 1 3 6 Process returned 0 (0x0) execution time : 0.011 s Press any key to continue. 003 不修改数组找出数组中重复的数字 题目 来源 完成时间 不修改数组找出数组中重复的数字 剑指offer 20200418 读题： 在一个长度为n+1的数组里的所有数字都在1~n的范围内，所以数组中至少有一个数字是重复的。请找出数组中任意一个重复的数字，但不能修改输入的数组。 思路： 新建一个数组，复制过来，把数组值和数组索引对应上，则可以找出重复的元素 二分查找的方法，找出每个半区的元素个数是否刚好是半区总数，然后不断递归 思路2的实现： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#include &lt;iostream&gt;using namespace std;int FuncFind(int data[], int left, int right, int len)&#123; if(data == nullptr || len &lt;= 0) &#123; cout &lt;&lt; &quot;Invalid param!&quot; &lt;&lt; endl; return -1; &#125; int mid = (right + left) / 2; int lnum = 0; int rnum = 0; if (left &gt;= right) &#123; return mid; &#125; for (int i = 0; i &lt; len; i++) &#123; if (data[i] &gt; mid &amp;&amp; data[i] &lt;= right) rnum++; else if(data[i] &lt;= mid &amp;&amp; data[i] &gt;= left) lnum++; &#125; if (right - mid &lt; rnum) &#123; return FuncFind(data, mid + 1, right, len); &#125; else if (mid - left + 1 &lt; lnum) &#123; return FuncFind(data, left, mid, len); &#125; return -1;&#125;int main()&#123; int data[] = &#123;4,5,6,7,1,2,3,2&#125;; int n = sizeof(data)/sizeof(int); //1 ~ n-1 cout &lt;&lt; FuncFind(data, 1, n-1, n) &lt;&lt; endl; return 0;&#125; 004 不修改数组找出数组中重复的数字 题目 来源 完成时间 二维数组中的查找 剑指offer 20200418 读题 在一个二维数组中，每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个函数,输入这样的一个二维数组和一个整数，判断数组中是否含有该整数 思路 从右上角开始找 123456789101112131415161718192021222324252627282930313233343536373839404142#include &lt;iostream&gt;using namespace std;void FuncFind(int data[][4], int row, int col, int n)&#123; col--; int line = 0; while(line &lt; row &amp;&amp; col &gt;=0) &#123; if (n == data[line][col]) &#123; cout &lt;&lt; &quot;exist!&quot; &lt;&lt; endl; return; &#125; else if (n &gt; data[line][col]) line++; else col--; &#125; cout &lt;&lt; &quot;not exist!&quot; &lt;&lt; endl; return;&#125;int main()&#123; int data[][4] = &#123; 1, 2, 8, 9, 2, 4, 9, 12, 4, 7, 10, 13, 6, 8, 11, 15 &#125;; int n = 0; while(cin &gt;&gt; n) &#123; FuncFind(data, 4, 4, n); &#125; return 0;&#125; 005 从尾到头打印链表 题目 来源 完成时间 从尾到头打印链表 剑指offer 20200418 读题 输入一个链表的头节点，从头到尾反过来打印出每个节点的值。链表节点定义如下： struct ListNode &#123; int m_nKey; ListNode* m_npNext; &#125;; 思路： 栈是后进先出，可以放到栈数据结构中再取出来 采用函数递归，但要考虑到递归不易太深，否则会溢出 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162#include &lt;iostream&gt;#include &lt;stack&gt;using namespace std;struct ListNode&#123; int m_nKey; ListNode* m_npNext;&#125;;void ReversePrint(ListNode* pHead)&#123; if (pHead != NULL) &#123; if (pHead-&gt;m_npNext != NULL) ReversePrint(pHead-&gt;m_npNext); cout &lt;&lt; pHead-&gt;m_nKey &lt;&lt; &quot; &quot;; &#125;&#125;int main()&#123; int n = 0; ListNode *pHead = new ListNode; ListNode *pNode = pHead; //input while(cin &gt;&gt; n) &#123; pNode-&gt;m_nKey = n; pNode-&gt;m_npNext = NULL; if (cin.get() == &#x27;\\n&#x27;) break; pNode-&gt;m_npNext = new ListNode; pNode = pNode-&gt;m_npNext; &#125; //deal stack&lt;ListNode*&gt; oStack; pNode = pHead; while(pNode) &#123; oStack.push(pNode); pNode = pNode-&gt;m_npNext; &#125; //output pNode = pHead; while(!oStack.empty()) &#123; pNode = oStack.top(); cout &lt;&lt; pNode-&gt;m_nKey &lt;&lt; &quot; &quot;; oStack.pop(); &#125; cout &lt;&lt; endl; //ReversePrint(pHead); return 0;&#125; 006 替换空格 题目 来源 完成时间 替换空格 剑指offer 20200521 读题 请实现一个函数，把字符串中的每个空格替换成”%20”.例如，输入 “we are happy”, 则输出 “we%20are%20happy” 思路： ending","categories":[],"tags":[{"name":"面试","slug":"面试","permalink":"https://riverferry.site/tags/%E9%9D%A2%E8%AF%95/"}],"keywords":[]},{"title":"成员函数指针","slug":"2020-07-20-成员函数指针","date":"2020-07-20T00:00:00.000Z","updated":"2022-09-12T16:24:32.284Z","comments":true,"path":"2020-07-20-成员函数指针/","link":"","permalink":"https://riverferry.site/2020-07-20-%E6%88%90%E5%91%98%E5%87%BD%E6%95%B0%E6%8C%87%E9%92%88/","excerpt":"参考为什么 C++ 中成员函数指针是 16 字节？","text":"参考为什么 C++ 中成员函数指针是 16 字节？ demo1234567891011121314151617181920#include &lt;iostream&gt;using namespace std;class _Undefined_class&#123;public: void func(void);&#125;;void* _M_object;const void* _M_const_object;void (*_M_function_pointer)();void (_Undefined_class::*p4)();int main() &#123; cout &lt;&lt; sizeof(_M_object) &lt;&lt; &quot;\\n&quot; &lt;&lt; sizeof(_M_const_object) &lt;&lt; &quot;\\n&quot; &lt;&lt; sizeof(_M_function_pointer) &lt;&lt; &quot;\\n&quot; &lt;&lt; sizeof(&amp;_Undefined_class::func) &lt;&lt; &quot;\\n&quot; &lt;&lt; sizeof(p4) &lt;&lt; &quot;\\n&quot;;&#125; 8 8 8 16 16 成员函数中是可以使用this指针的，这个以前是知道的，但不够明确的是this指针的存放位置。按目前看的文章，this指针是占用成员函数指针大小的： A pointer to member function is a pair as follows: ptr: For a non-virtual function, this field is a simple function pointer. For a virtual function, it is 1 plus the virtual table offset (in bytes) of the function, represented as a ptrdiff_t. The value zero represents a NULL pointer, independent of the adjustment field value below. adj: The required adjustment to this, represented as a ptrdiff_t. 1234567891011121314151617181920212223242526272829303132333435363738#include &lt;iostream&gt;#include &lt;cstring&gt;using namespace std;struct A &#123; void foo() const &#123; std::cout &lt;&lt; &quot;A&#x27;s this:\\t&quot; &lt;&lt; this &lt;&lt; std::endl; &#125; char pad0[32];&#125;;struct B &#123; void bar() const &#123; std::cout &lt;&lt; &quot;B&#x27;s this:\\t&quot; &lt;&lt; this &lt;&lt; std::endl; &#125; char pad2[64];&#125;;struct C : A, B&#123; &#125;;void call_by_ptr(const C &amp;obj, void (C::*mem_func)() const)&#123; void *data[2]; std::memcpy(data, &amp;mem_func, sizeof(mem_func)); std::cout &lt;&lt; &quot;------------------------------\\n&quot; &quot;Object ptr:\\t&quot; &lt;&lt; &amp;obj &lt;&lt; &quot;\\nFunction ptr:\\t&quot; &lt;&lt; data[0] &lt;&lt; &quot;\\nPointer adj:\\t&quot; &lt;&lt; data[1] &lt;&lt; std::endl; (obj.*mem_func)();&#125;int main()&#123; C obj; call_by_ptr(obj, &amp;C::foo); call_by_ptr(obj, &amp;C::bar);&#125; ------------------------------ Object ptr: 0x7ffd3b46ec80 Function ptr: 0x400a56 Pointer adj: 0 A&#39;s this: 0x7ffd3b46ec80 ------------------------------ Object ptr: 0x7ffd3b46ec80 Function ptr: 0x400a90 Pointer adj: 0x20 B&#39;s this: 0x7ffd3b46eca0 ending","categories":[],"tags":[{"name":"c++","slug":"c","permalink":"https://riverferry.site/tags/c/"}],"keywords":[]},{"title":"enum hack","slug":"2020-07-17-enum hack","date":"2020-07-17T00:00:00.000Z","updated":"2022-09-12T16:24:32.283Z","comments":true,"path":"2020-07-17-enum hack/","link":"","permalink":"https://riverferry.site/2020-07-17-enum%20hack/","excerpt":"参考zhihu","text":"参考zhihu case1 static123456789101112class Game &#123;private: static const int GameTurn = 9; //ok int scores[GameTurn]; //ok&#125;;//const int Game::GameTurn = 10;int main()&#123;&#125; 这样是ok的，但有些老的编译期可能不允许在声明的时候给static变量赋值，就得做变通: 123456789101112class Game &#123;private: static const int GameTurn; //ok int scores[GameTurn]; //not ok&#125;;const int Game::GameTurn = 10;int main()&#123;&#125; 如此这般scores的数组大小就取不到了。形如case2 case2 const123456789101112class Game &#123;private: const int GameTurn = 10; //ok int scores[GameTurn]; //not ok&#125;;//const int Game::GameTurn = 10;int main()&#123;&#125; 由于类没有实例化，这里数组大小还是取不到，不像static是在类外实例化的。 case3 enum123456789101112class Game &#123;private: enum hack &#123;GameTurn = 10&#125;; int scores[GameTurn];&#125;;//const int Game::GameTurn = 10;int main()&#123;&#125; 如此这般可行，甚好。enum是在编译期求值得，可用于模板元编程，见下: 12345678910111213141516171819202122#include &lt;iostream&gt;template &lt;unsigned long long data&gt;struct test&#123; enum &#123; result = data + test&lt;data - 1&gt;::result &#125;;&#125;;template&lt;&gt;struct test&lt;1&gt;&#123; enum &#123; result = 1 &#125;;&#125;;int main()&#123; const unsigned long long num = 10; std::cout &lt;&lt; test&lt;num&gt;::result &lt;&lt; std::endl;&#125; ending","categories":[],"tags":[{"name":"c++","slug":"c","permalink":"https://riverferry.site/tags/c/"}],"keywords":[]},{"title":"tuple underlying_type","slug":"2020-07-17-tuple underlying_type","date":"2020-07-17T00:00:00.000Z","updated":"2022-09-12T16:24:32.283Z","comments":true,"path":"2020-07-17-tuple underlying_type/","link":"","permalink":"https://riverferry.site/2020-07-17-tuple%20underlying_type/","excerpt":"前言留的坑，以后填","text":"前言留的坑，以后填 TODOending","categories":[],"tags":[{"name":"坑","slug":"坑","permalink":"https://riverferry.site/tags/%E5%9D%91/"}],"keywords":[]},{"title":"function bind","slug":"2020-07-16-function bind","date":"2020-07-16T00:00:00.000Z","updated":"2022-09-12T16:24:32.283Z","comments":true,"path":"2020-07-16-function bind/","link":"","permalink":"https://riverferry.site/2020-07-16-function%20bind/","excerpt":"referencehttp://blog.bitfoc.us/p/525 STL 源码简析 – std::function Naive std::function implementation","text":"referencehttp://blog.bitfoc.us/p/525 STL 源码简析 – std::function Naive std::function implementation step1 匹配函数123456789101112131415161718192021#include &lt;iostream&gt;using namespace std;template &lt;typename T&gt;struct function&#123;&#125;;template &lt;typename ret, typename lhs, typename rhs&gt;struct function&lt;ret(lhs, rhs)&gt;&#123; enum &#123;values = 2&#125;;&#125;;int func(int, int)&#123; cout &lt;&lt; &quot;func ...&quot; &lt;&lt; endl;&#125;int main()&#123; cout &lt;&lt; function&lt;int(int, int)&gt;::values &lt;&lt; endl; //2&#125; step2 模板匹配分析1234567891011121314151617181920212223242526272829#include &lt;iostream&gt;using namespace std;template &lt;typename T&gt;struct function&#123;&#125;;template &lt;typename ret, typename lhs, typename rhs&gt;struct function&lt;ret(lhs, rhs)&gt;&#123; static const int values1 = std::is_same&lt;int, ret&gt;(); static const int values2 = std::is_same&lt;int, lhs&gt;(); static const int values3 = std::is_same&lt;int, rhs&gt;();&#125;;int func(int, int)&#123; cout &lt;&lt; &quot;func ...&quot; &lt;&lt; endl;&#125;int main()&#123; cout &lt;&lt; function&lt;int(int, int)&gt;::values1 &lt;&lt; endl; //1 cout &lt;&lt; function&lt;int(int, int)&gt;::values2 &lt;&lt; endl; //1 cout &lt;&lt; function&lt;int(int, int)&gt;::values3 &lt;&lt; endl; //1 cout &lt;&lt; function&lt;double(int, int)&gt;::values1 &lt;&lt; endl; //0 cout &lt;&lt; function&lt;int(double, int)&gt;::values2 &lt;&lt; endl; //0 cout &lt;&lt; function&lt;int(int, double)&gt;::values3 &lt;&lt; endl; //0&#125; step3 运行函数123456789101112131415161718192021222324252627282930313233#include &lt;iostream&gt;using namespace std;template &lt;typename T&gt;struct function&#123;&#125;;template &lt;typename ret, typename lhs, typename rhs&gt;struct function&lt;ret(lhs, rhs)&gt;&#123; using functype = ret (*)(lhs, rhs); functype callfunc; template&lt;typename T&gt; function(T param):callfunc(param)&#123; &#125; ret operator()(lhs l, rhs r)&#123; //函数调用运算符 return callfunc(l, r); &#125;&#125;;int func(int lhs, int rhs)&#123; cout &lt;&lt; &quot;func ...&quot; &lt;&lt; endl; cout &lt;&lt; lhs + rhs &lt;&lt; endl;&#125;int main()&#123; function&lt;int(int, int)&gt; test = &amp;func; test(1, 2);&#125; ending","categories":[],"tags":[{"name":"坑","slug":"坑","permalink":"https://riverferry.site/tags/%E5%9D%91/"}],"keywords":[]},{"title":"完美转发失败场景","slug":"2020-07-16-完美转发失败场景","date":"2020-07-16T00:00:00.000Z","updated":"2022-09-12T16:24:32.283Z","comments":true,"path":"2020-07-16-完美转发失败场景/","link":"","permalink":"https://riverferry.site/2020-07-16-%E5%AE%8C%E7%BE%8E%E8%BD%AC%E5%8F%91%E5%A4%B1%E8%B4%A5%E5%9C%BA%E6%99%AF/","excerpt":"前言留的坑，以后填","text":"前言留的坑，以后填 TODOending","categories":[],"tags":[{"name":"坑","slug":"坑","permalink":"https://riverferry.site/tags/%E5%9D%91/"}],"keywords":[]},{"title":"模板特化","slug":"2020-07-16-模板特化 SFINAE","date":"2020-07-16T00:00:00.000Z","updated":"2022-09-12T16:24:32.283Z","comments":true,"path":"2020-07-16-模板特化 SFINAE/","link":"","permalink":"https://riverferry.site/2020-07-16-%E6%A8%A1%E6%9D%BF%E7%89%B9%E5%8C%96%20SFINAE/","excerpt":"参考Substitution failure is not an error C++ Template的选择特化 C++模板进阶指南：SFINAE std::enable_if SFINAE","text":"参考Substitution failure is not an error C++ Template的选择特化 C++模板进阶指南：SFINAE std::enable_if SFINAE SFINAE 替换失败不是错误（SFINAE）是指C ++中模板参数的无效替换本身并不是错误的情况。David Vandevoorde首先引入了缩写词SFINAE来描述相关的编程技术。[1] 具体地，当创建用于重载解析的候选集时，该集合的一些（或全部）候选者可能是实例化模板的结果，该模板实例化了（可能推导的）模板参数来代替相应的模板参数。如果在将一组参数替换为任何给定模板的过程中发生错误，则编译器会从候选集中消除潜在的重载，而不会因编译错误而停止，前提是替换错误是C ++标准授予此类处理的错误。[2]如果剩下一个或多个候选并且重载解析成功，则调用格式正确 123456789101112131415struct Test &#123; typedef int foo;&#125;;template &lt;typename T&gt;void f(typename T::foo) &#123;&#125; // Definition #1template &lt;typename T&gt;void f(T) &#123;&#125; // Definition #2int main() &#123; f&lt;Test&gt;(10); // Call #1. f&lt;int&gt;(10); // Call #2. Without error (even though there is no int::foo) // thanks to SFINAE.&#125; 此规则在函数模板的重载解析期间适用：当用显式指定的或推导的类型代替template参数失败时，将从重载集中放弃专业化，而不会引起编译错误。 替代发生在: 函数类型中使用的所有类型（包括返回类型和所有参数的类型） 模板参数声明中使用的所有类型 //(自C ++ 11起） 函数类型中使用的所有表达式 模板参数声明中使用的所有表达式 //自C ++ 20起） 显式说明符中使用的所有表达式 模板特化123456789101112131415161718192021222324252627282930313233343536//typedef integral_constant&lt;bool,true&gt; true_type;//template &lt;class T, T v&gt;// struct integral_constant &#123;// static constexpr T value = v;// typedef T value_type;// typedef integral_constant&lt;T,v&gt; type;// constexpr operator T() &#123; return v; &#125;// &#125;;#include &lt;iostream&gt;struct mytrue &#123;public: static const int value = 1;&#125;;struct myfalse &#123;public: static const int value = 0;&#125;;template&lt;typename T&gt; // 主模板struct dd&#123;&#125;;template&lt;&gt;struct dd&lt;std::false_type&gt; : myfalse // 对 T = false_type 显式特化 &#123;&#125;;template&lt;&gt;struct dd&lt;std::true_type&gt; : mytrue // 对 T = true_type 显式特化&#123;&#125;;int main()&#123; std::cout &lt;&lt; dd&lt;std::true_type&gt;::value &lt;&lt; std::endl; std::cout &lt;&lt; dd&lt;std::false_type&gt;::value &lt;&lt; std::endl;&#125; enable_if1234567891011// Define a nested type if some predicate holds. // Primary template. /// enable_if template&lt;bool, typename _Tp = void&gt; //主模板 struct enable_if &#123; &#125;; // Partial specialization for true. template&lt;typename _Tp&gt; //特化模板 struct enable_if&lt;true, _Tp&gt; &#123; typedef _Tp type; &#125;; 1234567891011121314151617181920212223#include &lt;iostream&gt;template &lt;bool, typename T = void&gt; //主模板struct my_if&#123;&#125;;template &lt;typename T&gt;struct my_if&lt;true, T&gt;&#123; //特化模板 typedef T type;&#125;;template &lt;typename T&gt;struct my_if&lt;false, T&gt;&#123; //特化模板 typedef T* type;&#125;;int main()&#123; std::cout &lt;&lt; std::is_same&lt;void, my_if&lt;true&gt;::type&gt;() &lt;&lt; std::endl; std::cout &lt;&lt; std::is_same&lt;void *, my_if&lt;false&gt;::type&gt;() &lt;&lt; std::endl; std::cout &lt;&lt; std::is_same&lt;int, my_if&lt;true, int&gt;::type&gt;() &lt;&lt; std::endl; std::cout &lt;&lt; std::is_same&lt;int *, my_if&lt;false, int&gt;::type&gt;() &lt;&lt; std::endl;&#125; 总结模板特化和SFINAE挺复杂的，目前没有精力挖的太深，掌握大概就行了。 ending","categories":[],"tags":[{"name":"c++11","slug":"c-11","permalink":"https://riverferry.site/tags/c-11/"}],"keywords":[]},{"title":"特殊成员函数","slug":"2020-07-15-特殊成员函数","date":"2020-07-15T00:00:00.000Z","updated":"2022-09-12T16:24:32.283Z","comments":true,"path":"2020-07-15-特殊成员函数/","link":"","permalink":"https://riverferry.site/2020-07-15-%E7%89%B9%E6%AE%8A%E6%88%90%E5%91%98%E5%87%BD%E6%95%B0/","excerpt":"要点num 1 移动构造(赋值)函数，也会调用其基类的移动构造(赋值)函数(如果有的话);","text":"要点num 1 移动构造(赋值)函数，也会调用其基类的移动构造(赋值)函数(如果有的话); 1234567891011121314151617181920212223242526272829303132333435363738#include &lt;iostream&gt;using namespace std;class base &#123;public: base() = default; base(base &amp;)&#123; cout &lt;&lt; &quot;base: copy constructor&quot; &lt;&lt; endl; &#125; base(base &amp;&amp;) noexcept&#123; cout &lt;&lt; &quot;base: move constructor&quot; &lt;&lt; endl; &#125;&#125;;class derived:public base &#123;public: derived() = default; derived(derived &amp; param):base(param)&#123; cout &lt;&lt; &quot;derived: copy constructor&quot; &lt;&lt; endl; &#125; derived(derived &amp;&amp; param) noexcept :base(std::move(param))&#123; cout &lt;&lt; &quot;derived: move constructor&quot; &lt;&lt; endl; &#125;&#125;;int main()&#123; derived c; derived d = c; derived e = std::move(c); return 0;&#125;//output//base: copy constructor//derived: copy constructor//base: move constructor//derived: move constructor num 2 按成员移动是分两部分组成的，一部分是在支持移动操作的成员上执行的移动操作，另一部分是在不支持移动操作的成员上执行的复制操作 num 3 即使声明了复制构造/赋值操作符 函数的其中一个，当代码实现需要另一个的时候，编译期也会默认实现另一个(c++11称之为被废弃的行为) 如果声明了移动构造/赋值操作符 函数的其中一个，即使代码需要另一个的时候，编译期也不会默认实现另一个 如果声明了复制构造/赋值运算符函数，则不会生成默认的移动构造/移动赋值运算符函数。 如果声明了移动构造/移动赋值运算符函数，则不会声明默认的复制构造/赋值运算符函数。 123456789101112131415161718192021222324252627282930#include &lt;iostream&gt;using namespace std;class cc &#123;public: cc() = default; cc(cc &amp; ) &#123; cout &lt;&lt; &quot;copy construct&quot; &lt;&lt; endl; &#125;&#125;;class dd &#123;public: dd() = default; dd(dd &amp;&amp;) noexcept&#123; cout &lt;&lt; &quot;move construct&quot; &lt;&lt; endl; &#125;&#125;;int main()&#123; cc data; data = cc(); //no output dd data2; //note: ‘dd&amp; dd::operator=(const dd&amp;)’ is implicitly declared as deleted because ‘dd’ // declares a move constructor or move assignment operator data2 = std::move(dd()); return 0;&#125; num 4 如果声明了析构函数，复制构造和赋值操作符函数也会生成(c++11称之为被废弃的行为) 如果声明了析构函数，移动函数都不会生成 12345678910111213141516171819202122232425262728#include &lt;iostream&gt;using namespace std;class cc &#123;public: cc() = default; ~cc() &#123; cout &lt;&lt; &quot;destructor&quot; &lt;&lt; endl; &#125;&#125;;class dd &#123;public: dd() = default; ~dd() &#123; cout &lt;&lt; &quot;destructor&quot; &lt;&lt; endl; &#125;&#125;;int main()&#123; cc data; data = cc(); dd data2 = std::move(dd()); //const &amp; 拷贝构造函数 return 0;&#125; num 5 如果声明了构造函数/赋值运算符函数 的一种实现，则不再生成默认的实现 如果声明了基本构造函数，不会影响默认生成其他拷贝构造函数 1234567891011121314151617181920212223242526class cc &#123;public: cc(cc &amp;) &#123; cout &lt;&lt; &quot;constructor&quot; &lt;&lt; endl; &#125;&#125;;int main()&#123; cc data; //error: no matching function for call to ‘cc::cc()’ return 0;&#125;class cc &#123;public: cc() &#123; cout &lt;&lt; &quot;constructor&quot; &lt;&lt; endl; &#125;&#125;;int main()&#123; cc data = std::move(cc()); //ok return 0;&#125; num 6 c++11中析构函数默认都是noexcept num 7 模板拷贝构造函数，赋值运算符函数，不会阻止默认函数的实现 1234567891011121314151617181920212223242526#include &lt;iostream&gt;using namespace std;class cc &#123;public: template&lt;typename T&gt; cc(const T &amp;) &#123; &#125; template&lt;typename T&gt; cc&amp; operator=(const T &amp;) &#123; &#125;&#125;;int main()&#123; cc data = cc(); //模板成员函数会阻止默认构造函数生成 //但不会阻止默认拷贝/默认赋值操作符函数的生成 return 0;&#125; ending","categories":[],"tags":[{"name":"c++11","slug":"c-11","permalink":"https://riverferry.site/tags/c-11/"}],"keywords":[]},{"title":"move forward","slug":"2020-07-14-move forward","date":"2020-07-14T00:00:00.000Z","updated":"2022-09-12T16:24:32.283Z","comments":true,"path":"2020-07-14-move forward/","link":"","permalink":"https://riverferry.site/2020-07-14-move%20forward/","excerpt":"参考cppreference","text":"参考cppreference move123456789101112131415161718 /// remove_reference template&lt;typename _Tp&gt; struct remove_reference &#123; typedef _Tp type; &#125;; template&lt;typename _Tp&gt; struct remove_reference&lt;_Tp&amp;&gt; &#123; typedef _Tp type; &#125;; template&lt;typename _Tp&gt; struct remove_reference&lt;_Tp&amp;&amp;&gt; &#123; typedef _Tp type; &#125;;//std::movetemplate&lt;typename _Tp&gt; constexpr typename std::remove_reference&lt;_Tp&gt;::type&amp;&amp; move(_Tp&amp;&amp; __t) noexcept &#123; return static_cast&lt;typename std::remove_reference&lt;_Tp&gt;::type&amp;&amp;&gt;(__t); &#125; std::move只保证转换成右值，并不保证一定可以移动。如下,const导致的问题： 1234567891011121314151617181920212223242526272829303132333435#include &lt;iostream&gt;#include &lt;type_traits&gt;using namespace std;class bb&#123;public: bb() = default; bb(const bb&amp;)&#123; cout &lt;&lt; &quot;copy construct&quot; &lt;&lt; endl; &#125; bb(bb &amp;&amp;)&#123; cout &lt;&lt; &quot;move construct&quot; &lt;&lt; endl; &#125;&#125;;template&lt;class T1, class T2&gt;void print_is_same() &#123; std::cout &lt;&lt; std::is_same&lt;T1, T2&gt;() &lt;&lt; &#x27;\\n&#x27;;&#125;int main()&#123; const bb p1; bb p2 = std::move(p1); //copy construct print_is_same&lt;const bb &amp;, decltype(std::move(p1))&gt;(); //0 print_is_same&lt;bb &amp;&amp;, decltype(std::move(p1))&gt;(); //0 print_is_same&lt;const bb &amp;&amp;, decltype(std::move(p1))&gt;(); //1 const int b = 10; const int &amp; a = std::move(b); //const左值引用可以赋值为const的右值 return 0;&#125; forward12345678910111213141516171819202122232425/** * @brief Forward an lvalue. * @return The parameter cast to the specified type. * * This function is used to implement &quot;perfect forwarding&quot;. */ template&lt;typename _Tp&gt; constexpr _Tp&amp;&amp; forward(typename std::remove_reference&lt;_Tp&gt;::type&amp; __t) noexcept &#123; return static_cast&lt;_Tp&amp;&amp;&gt;(__t); &#125; /** * @brief Forward an rvalue. * @return The parameter cast to the specified type. * * This function is used to implement &quot;perfect forwarding&quot;. */ template&lt;typename _Tp&gt; constexpr _Tp&amp;&amp; forward(typename std::remove_reference&lt;_Tp&gt;::type&amp;&amp; __t) noexcept &#123; static_assert(!std::is_lvalue_reference&lt;_Tp&gt;::value, &quot;template argument&quot; &quot; substituting _Tp is an lvalue reference type&quot;); return static_cast&lt;_Tp&amp;&amp;&gt;(__t); &#125; 完美转发推导1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950#include &lt;iostream&gt;int makeint()&#123; return int();&#125;template &lt;typename T&gt;void func(T&amp;&amp; param)&#123; //test(std::forward&lt;T&gt;(param));&#125;//按书上的说法，右值引用经由通用引用后的T是int,这样推导的话forward没有用到第二种实现//网上有的地方说T是int&amp;&amp;,第二种forward的实现就用到了，做个问题留下来以后再说吧int main()&#123; //rvalue func(makeint());#if 0 //makeint()返回右值： int &amp;&amp; //T推导成int //完美转发 template&lt;typename int&gt; constexpr int&amp;&amp; forward(typename std::remove_reference&lt;int&gt;::type&amp; __t) noexcept &#123; return static_cast&lt;int&amp;&amp;&gt;(__t); &#125; //转换 constexpr int&amp;&amp; forward(typename int&amp; __t) noexcept &#123; return int&amp;&amp;(__t); &#125;#endif //lvalue int a; func(a);#if 0 //a是左值 //T推导成int &amp; //完美转发 template&lt;typename int&amp;&gt; constexpr int&amp;&amp;&amp; forward(typename std::remove_reference&lt;int&amp;&gt;::type&amp; __t) noexcept &#123; return static_cast&lt;int&amp;&amp;&amp;&gt;(__t); &#125; //转换 constexpr int&amp; forward(typename int&amp; __t) noexcept &#123; return int&amp;(__t); &#125;#endif&#125; 引用折叠引用折叠针对的是引用(a)的引用(b),a/b有一个是左值则结果是左值，反之是右值 引用折叠出现的场景 模板实例化(通用引用) auto型别生成 创建和运用typedef decltype ending","categories":[],"tags":[{"name":"c++11","slug":"c-11","permalink":"https://riverferry.site/tags/c-11/"}],"keywords":[]},{"title":"constexpr","slug":"2020-07-13-constexpr","date":"2020-07-13T00:00:00.000Z","updated":"2022-09-12T16:24:32.283Z","comments":true,"path":"2020-07-13-constexpr/","link":"","permalink":"https://riverferry.site/2020-07-13-constexpr/","excerpt":"参考wiki zhihu","text":"参考wiki zhihu 正文 constexpr是C++11引入的关键字，用于编译时的常量与常量函数。 声明为constexpr函数的意义是：如果其参数均为合适的编译期常量，则对这个constexpr函数的调用就可用于期望常量表达式的场合（如模板的非类型参数，或枚举常量的值）。如果参数的值在运行期才能确定，或者虽然参数的值是编译期常量，但不匹配这个函数的要求，则对这个函数调用的求值只能在运行期进行。 C++编译时可确定常量表达式的结果，因此可在编译时优化。C++规范在一些地方要求使用常量表达式，如声明数组的维数。但常量表达式不允许包含函数调用或者对象构造。因此下述代码无效： 12345678// error: array bound is not an integer constant before ‘]’ tokenconst int get_five() &#123;return 5;&#125;int some_value[get_five() + 7];int main()&#123;&#125; 12345678//okconstexpr int get_five() &#123;return 5;&#125;int some_value[get_five() + 7];int main()&#123;&#125; constexpr的对象，必须是常量类型的，const则没要求(拷贝副本)。 12345678int main()&#123; int a = 100; const int s = a; //ok constexpr int ss = a; //error constexpr int ss = 10; //ok&#125; c++11 constexpr函数必须满足下述限制： 函数返回值不能是void类型 函数体不能声明变量或定义新的类型 函数体只能包含声明、null语句或者一条return语句 在形参实参结合后，return语句中的表达式为常量表达式 C++14放松了这些限制。声明为constexpr的函数可以含有以下内容：[2] 任何声明，除了： static或thread_local变量。 没有初始化的变量声明。 条件分支语句if和switch。 所有的循环语句，包括基于范围的for循环。 表达式可以改变一个对象的值，只需该对象的生命期在声明为constexpr的函数内部开始。包括对有constexpr声明的任何非const非静态成员函数的调用。 goto仍然不允许在constexpr函数中出现。 constexpr支持编译期的递归。例如，可以写一个constexpr函数计算斐波那契数列。 *此外，C++11指出，所有被声明为constexpr的非静态成员函数也隐含声明为const（即函数不能修改this的值）(函数尾部的const,只读函数)。C++14已经删除此点，非静态成员函数可以为非const。** 123456789101112131415class cc&#123;public: int _m = 0; int func(int x = 0) const //不能修改*this &#123; _m = 2; //error: assignment of member ‘cc::_m’ in read-only object &#125; constexpr int func2(int x = 0) &#123; return ++_m ? x : x; // error: increment of member ‘cc::_m’ in read-only object &#125;&#125;; 总结 constexpr函数可以用在要求编译期常量的语境中。在这样的语境中，若你传给一个constexpr函数的实参值是在编译期已知的，则结果也会在编译期间计算出来。如果不能再编译期间计算得到，则编译不能通过 在调用constexpr函数时，若传入的值有一个或多个在编译期未知，则它的运作方式和普通函数无异，亦即它也是在运行期执行结果的计算。这意味着，如果函数执行的是同样的操作，仅仅应用的语境一个是要求在编译期常量的，一个是用于所有其他值的话，那就不用写两个函数。 ending","categories":[],"tags":[{"name":"c++11","slug":"c-11","permalink":"https://riverferry.site/tags/c-11/"}],"keywords":[]},{"title":"noexcept","slug":"2020-07-13-noexcept","date":"2020-07-13T00:00:00.000Z","updated":"2022-09-12T16:24:32.283Z","comments":true,"path":"2020-07-13-noexcept/","link":"","permalink":"https://riverferry.site/2020-07-13-noexcept/","excerpt":"参考C++11：noexcept异常说明 effective modern c++ wikipedia stackoverflow","text":"参考C++11：noexcept异常说明 effective modern c++ wikipedia stackoverflow wiki事实上，异常规格(throw这一特性在程序中很少被使用，因此在C++11中被弃用[2]。C++11定义了新的noexcept关键字。如果在函数声明后直接加上noexcept关键字，表示函数不会抛出异常。另外一种形式是noexcept关键字后跟常量表达式，其值转为布尔值，如果为真表示函数不会抛出异常，反之，则有可能抛出异常。 returnType funcDeclaration (args) noexcept(常量表达式) ; 如果保证不抛出异常的函数却实际上抛出异常，则会直接调用std::terminate中断程序的执行。 noexcept关键字还可以用作运算符，其后的操作数表达式如果有可能抛出异常，则运算符返回为false；如果操作数表达式保证不抛出异常，则运算符返回为true。这一运算符用于在定义模板函数时可以根据模板参数类型来确定是否传出异常。 对类析构函数，使用noexcept关键字也可以显式指明不剖出异常。类析构函数默认不抛出异常。如果声明为（或默认）不抛出异常的类析构函数在运行时抛出了异常，将导致调用std::terminate中断程序的执行。 以下两种等价： int f(x) throw(); //c++98 int f(x) noexcept(); //c++11 性能上，noexcept可以让编译器做更多的优化，因此： int f(x) noexcept(); //最优化 int f(x) throw(); //优化不够 int f(x); //优化不够 move_if_noexceptstl容器比如vector拥有强异常安全保证，比如vector重新调整大小的时候： 分配原来两倍的大小 拷贝原来的数据到新的空间 析构原来的数据 如果拷贝的过程出现异常，还可以还原到拷贝前的状态，放弃拷贝 c++11后有了移动操作，对于复制数据来说提升了性能，但可能导致强异常安全保证失效，因此只有在确保Move构造函数不会导致异常的情况下，容易才优先采用移动赋值函数而不是拷贝赋值函数，这里用到了move_if_noexcept stackoverflow: move_if_noexcept: move_if_move_ctor_is_noexcept_or_the_only_option 1234567891011121314151617181920212223242526272829303132struct A &#123; A (); A (A const&amp;);&#125;;A a1;A a2 (std::move_if_noexcept (a1)); // `A const&amp;` =&gt; copy-constructorstruct B &#123; B (); B (B const&amp;); B (B&amp;&amp;) noexcept;&#125;;B b1;B b2 (std::move_if_noexcept (b1)); // `B&amp;&amp;` =&gt; move-constructor // ^ it&#x27;s `noexcept`struct C &#123; C (); C (C&amp;&amp;);&#125;;C c1;C c2 (std::move_if_noexcept (c1)); // `C&amp;&amp;` =&gt; move-constructor // ^ the only viable alternativestruct D &#123; C (); C (C const&amp;) noexcept;&#125;;C c1;C c2 (std::move_if_noexcept (c1)); // C&amp;&amp; =&gt; copy-constructor // ^ can be invoked with `T&amp;&amp;` 值得注意的地方是move_if_noexcept是针对于构造函数而言的，判断拷贝构造函数和移动构造函数的存在以及异常性来决定的。 测试下vector: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182#include &lt;iostream&gt;#include &lt;vector&gt;using namespace std;class t_no&#123;public: t_no() = default; t_no(const t_no &amp;)&#123; cout &lt;&lt; &quot;copy constructor&quot; &lt;&lt; endl; &#125; t_no(t_no &amp;&amp;) noexcept &#123; cout &lt;&lt; &quot;move constructor&quot; &lt;&lt; endl; &#125;&#125;;class t&#123;public: t() = default; t(const t &amp;)&#123; cout &lt;&lt; &quot;copy constructor&quot; &lt;&lt; endl; &#125; t(t &amp;&amp;) &#123; cout &lt;&lt; &quot;move constructor&quot; &lt;&lt; endl; &#125;&#125;;int main()&#123; vector&lt;t_no&gt; v1; vector&lt;t&gt; v2; for (int i = 0; i &lt; 3; i++) &#123; t_no a; v1.push_back(a); cout &lt;&lt; v1.capacity() &lt;&lt; endl; cout &lt;&lt; &quot;-------------------&quot; &lt;&lt; endl; &#125; for (int i = 0; i &lt; 3; i++) &#123; t a; v2.push_back(a); cout &lt;&lt; v2.capacity() &lt;&lt; endl; cout &lt;&lt; &quot;-------------------&quot; &lt;&lt; endl; &#125;&#125;#if 0copy constructor1-------------------copy constructormove constructor2-------------------copy constructormove constructormove constructor4-------------------copy constructor1-------------------copy constructorcopy constructor2-------------------copy constructorcopy constructorcopy constructor4-------------------#endif swap中对于底层对象noexcept的要求： todo 总结 析构函数，内存释放释放默认都是noexcept的，除非显示指定noexcept(false) ending","categories":[],"tags":[{"name":"c++11","slug":"c-11","permalink":"https://riverferry.site/tags/c-11/"}],"keywords":[]},{"title":"enum class","slug":"2020-07-12-enum class","date":"2020-07-12T00:00:00.000Z","updated":"2022-09-12T16:24:32.283Z","comments":true,"path":"2020-07-12-enum class/","link":"","permalink":"https://riverferry.site/2020-07-12-enum%20class/","excerpt":"参考effective modern c++","text":"参考effective modern c++ 正文区别1 限定作用域c++98风格的enum类型的作用域： 123456789101112enum data &#123; one, two, three, max&#125;;int one; //错误 C2365 “one”: 重定义；以前的定义是“枚举数” int main() &#123; &#125; 枚举{}内的名字的作用域是在{}外面的范围内的。也叫做不限定作用域的枚举值。 c++11风格的enum类型的作用域： 123456789101112enum class data &#123; one, two, three, max&#125;;int one;int main() &#123; ::data a = data::one;&#125; 枚举{}内的名字的作用域是在{}内部的范围内的，也叫做限定作用域的枚举值。 区别2 提前声明c++98风格的枚举没有默认的型别，会根据实际表示范围决定采用合适的容得下的类型： 123456789101112131415161718using namespace std;int main() &#123; enum data &#123; one = 0, &#125;; enum data2 &#123; one2, two2, three2, max2 = 0XFFFFFFFF &#125;; cout &lt;&lt; sizeof(data) &lt;&lt; endl; //4 cout &lt;&lt; sizeof(data2) &lt;&lt; endl; //4&#125; 这个没有复现出来，不知道是不是因为字节对齐导致的还是什么原因，98，03，11编译后的结果都是4.按照书里的意思，98版本的枚举要根据实际范围决定采用什么类型，所以不能提前声明，具体如下： 12345678910111213#include &lt;iostream&gt;using namespace std;enum data; //gcc：错误：使用枚举‘data’前没有给出声明enum data &#123; one = 0,&#125;;int main() &#123;&#125; c++11可以显示指定类型，并且enum class有默认的类型int 123456789101112#include &lt;iostream&gt;using namespace std;enum data:uint8_t; //声明必须显示指定类型enum data:uint8_t &#123; one = 0,&#125;;int main() &#123; cout &lt;&lt; sizeof(::data) &lt;&lt; endl; //1&#125; 1234567891011using namespace std;enum class data; //声明可以不指定类型，默认intenum class data&#123; one = 0,&#125;;int main() &#123; cout &lt;&lt; sizeof(::data) &lt;&lt; endl; //4&#125; 区别3 隐式类型转换98风格的枚举会有隐式类型转换，c++11版本的不会隐式类型转换 12345678910111213141516171819202122using namespace std;enum data98&#123; one = 0,&#125;;enum class data11 &#123; max = 0,&#125;;void func(size_t param)&#123; ;&#125;int main() &#123; data98 d98; data11 d11; func(d98); //ok func(d11); //error //错误(活动) E0167 &quot;data11&quot; 类型的实参与 &quot;size_t&quot; 类型的形参不兼容&#125; ending","categories":[],"tags":[{"name":"c++11","slug":"c-11","permalink":"https://riverferry.site/tags/c-11/"}],"keywords":[]},{"title":"override final","slug":"2020-07-12-override final","date":"2020-07-12T00:00:00.000Z","updated":"2022-09-12T16:24:32.283Z","comments":true,"path":"2020-07-12-override final/","link":"","permalink":"https://riverferry.site/2020-07-12-override%20final/","excerpt":"参考虚函数函数重载有以下要求： 基类中的函数必须是虚函数 基类和派生类中的函数名字必须完全相同(析构函数例外)、 基类和派生类中的函数形参型别必须完全相同 基类和派生类中的函数常量性必须完全相同 基类和派生类中的函数返回值和异常规格必须兼容","text":"参考虚函数函数重载有以下要求： 基类中的函数必须是虚函数 基类和派生类中的函数名字必须完全相同(析构函数例外)、 基类和派生类中的函数形参型别必须完全相同 基类和派生类中的函数常量性必须完全相同 基类和派生类中的函数返回值和异常规格必须兼容 c++11又多了一条： 基类和派生类中的函数引用饰词必须完全相同 引用饰词12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849#include &lt;iostream&gt;using namespace std;class mydata&#123;public: mydata() &#123; cout &lt;&lt; &quot;constructor&quot; &lt;&lt; endl; &#125; ~mydata() &#123; cout &lt;&lt; &quot;destructor&quot; &lt;&lt; endl; &#125; mydata(mydata &amp;&amp; param) &#123; cout &lt;&lt; &quot;move constructor&quot; &lt;&lt; endl; &#125; mydata(mydata &amp; param) &#123; cout &lt;&lt; &quot;copy constructor&quot; &lt;&lt; endl; &#125; mydata operator =(mydata &amp;&amp; param) &#123; cout &lt;&lt; &quot;move operator = &quot; &lt;&lt; endl; &#125;&#125;;class myclass&#123;public: mydata _m; myclass():_m() &#123; &#125; mydata&amp; data() &amp; //*this是左值才调用 &#123; cout &lt;&lt; &quot;--data() &amp;&quot; &lt;&lt; endl; return this-&gt;_m; &#125; mydata data() &amp;&amp; //*this是右值才调用 &#123; cout &lt;&lt; &quot;--data() &amp;&amp;&quot; &lt;&lt; endl; return std::move(this-&gt;_m); &#125;&#125;;myclass makemyclass()&#123; return myclass();&#125;int main() &#123; myclass my; auto a1 = my.data(); auto a2 = makemyclass().data(); &#125; overridec++11允许在派生类的成员函数末尾添加override,表明派生类将要重写该函数，编译器会校验重写的规则，避免了一些隐晦的含义。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172#include &lt;iostream&gt;using namespace std;class base &#123;public: virtual void func1() const&#123; cout &lt;&lt; &quot;base: virtual void func1() const&quot; &lt;&lt; endl; &#125; virtual void func2(int x)&#123; cout &lt;&lt; &quot;base: virtual void func2(int x)&quot; &lt;&lt; endl; &#125; virtual void func3() &amp; &#123; cout &lt;&lt; &quot;base: virtual void func3() &amp;&quot; &lt;&lt; endl; &#125; void func4() const &#123; cout &lt;&lt; &quot;base: void func4() const&quot; &lt;&lt; endl; &#125;&#125;;class derived : public base &#123;public: virtual void func1() &#123; cout &lt;&lt; &quot;derived: virtual void func1()&quot; &lt;&lt; endl; &#125; virtual void func2(unsigned int x) &#123; cout &lt;&lt; &quot;derived: virtual void func2(unsigned int x)&quot; &lt;&lt; endl; &#125; virtual void func3() &amp;&amp; &#123; cout &lt;&lt; &quot;derived: virtual void func3() &amp;&amp;&quot; &lt;&lt; endl; &#125; void func4() const &#123; cout &lt;&lt; &quot;derived: void func4() const&quot; &lt;&lt; endl; &#125;&#125;;#if 0class derived2 : public base &#123;public: virtual void func1() override; //error virtual void func2(unsigned int x) override; //error virtual void func3() &amp;&amp; override; //error void func4() const override; //error&#125;;#endifclass derived3 : public base &#123;public: virtual void func1() const override; //ok virtual void func2(int x) override; //ok virtual void func3() &amp; override; //ok //void func4() const override; //需要修改基类 &#125;;derived makederived()&#123; return derived();&#125;int main() &#123; derived der; base *bas = &amp;der; bas-&gt;func1(); //base: virtual void func1() const unsigned int x = 0; bas-&gt;func2(x); //base : virtual void func2(int x) bas-&gt;func3(); //base : virtual void func3() &amp; bas-&gt;func4(); //base : void func4() const&#125; final final跟在类定义后面，表示该类不能被继承：class test1 final final不能修饰非虚函数 final在基类的虚函数后面，表示派生类不可以重载该函数 final在派生类的虚函数后面，表示派生类的其他派生类不能重载该派生类的此函数 1234567891011121314151617181920struct Base&#123; virtual void foo();&#125;; struct A : Base&#123; //#a void foo() final; // Base::foo is overridden and A::foo is the final override void bar() final; // Error: bar cannot be final as it is non-virtual&#125;; struct B final : A // struct B is final&#123; void foo() override; // Error: foo cannot be overridden as it is final in A&#125;; struct C : B // Error: B is final&#123;&#125;; 对于上面#a的解释: 12345678910111213141516171819202122232425#include &lt;iostream&gt;using namespace std;struct Base&#123; virtual void foo() &#123; cout &lt;&lt; &quot;base: foo()&quot; &lt;&lt; endl; &#125;&#125;;struct A : Base&#123; void foo() final // Base::foo is overridden and A::foo is the final override &#123; cout &lt;&lt; &quot;A: foo()&quot; &lt;&lt; endl; &#125; //void bar() final; // Error: bar cannot be final as it is non-virtual&#125;;int main() &#123; A a; Base *p = &amp;a; p-&gt;foo();&#125; A: foo() 总结 override与final都不是语言关键字（keyword），只有在特定的位置才有特别含意，其他地方仍旧可以作为一般指示字（identifier）使用。override仅出现在成员函数的末尾才有意义。其他地方使用意义就变了： 1234void override(void)&#123; cout &lt;&lt; &quot;override&quot; &lt;&lt; endl;&#125; 为意在重写的函数添加override 成员函数引用饰词使得对于左值和右值对象(*this)的处理能够区分开来 ending","categories":[],"tags":[{"name":"c++11","slug":"c-11","permalink":"https://riverferry.site/tags/c-11/"}],"keywords":[]},{"title":"typedef using","slug":"2020-07-12-typedef using","date":"2020-07-12T00:00:00.000Z","updated":"2022-09-12T16:24:32.283Z","comments":true,"path":"2020-07-12-typedef using/","link":"","permalink":"https://riverferry.site/2020-07-12-typedef%20using/","excerpt":"参考知无涯之C++ typename的起源与用法 为什么必须在何处以及为什么要放置“模板”和“类型名”关键字？ effective modern c++ wikipedia typedef wikipedia typename c++11FAQ","text":"参考知无涯之C++ typename的起源与用法 为什么必须在何处以及为什么要放置“模板”和“类型名”关键字？ effective modern c++ wikipedia typedef wikipedia typename c++11FAQ typedef 在C和C++编程语言中，typedef是一个关键字。它用来对一个数据类型取一个别名，目的是为了使源代码更易于阅读和理解。它通常用于简化声明复杂的类型组成的结构 ，但它也常常在各种长度的整数数据类型中看到，例如size_t和time_t。 定义数组 123456typedef char arrType[6]; // type name: arrType // new type: char[6]arrType arr=&#123;1,2,3,4,5,6&#125;; // same as: char arr[6]=&#123;1,2,3,4,5,6&#125;arrType *pArr; // same as: char (*pArr)[6]; 定义函数指针 123456//oldvoid (*signal(int sig, void (*func)(int)))(int);//newtypedef void (*sighandler_t)(int);sighandler_t signal(int sig, sighandler_t func); 类型转换 1234567891011//oldvoid *p = NULL;int (*x)(double) = (int (*)(double)) p; // This is legalint (*)(double) y = (int (*)(double)) p; // Left-hand side is not legalint (*z)(double) = (int (*p)(double)); // Right-hand side is not legal//newtypedef int (*funcptr)(double); // pointer to function taking a double returning intfuncptr x = (funcptr) NULL; // C or C++funcptr y = funcptr(NULL); // C++ onlyfuncptr z = static_cast&lt;funcptr&gt;(NULL); // C++ only using1234567891011121314151617181920212223242526template&lt;int&gt;// idea: int_exact_trait&lt;N&gt;::type用于表达含有N个bit的数值类型struct int_exact_traits &#123; typedef int type;&#125;;template&lt;&gt;struct int_exact_traits&lt;8&gt; &#123; typedef char type;&#125;;template&lt;&gt;struct int_exact_traits&lt;16&gt; &#123; typedef char[2] type;&#125;;// ...template&lt;int N&gt;// 定义别名用以简化书写// 译注：给模板的通用版本取别名，则其所有的特化版本自动获得该别名，// 例如对于8bit的特化版本，现在可直接使用别名 using int_exact = typename int_exact_traits&lt;N&gt;::type; // int_exact&lt;8&gt; 是含有8个bit的数值类型int_exact&lt;8&gt; a = 7; 除了在模板方面身担重任外，using语法也可作为对普通类型定义别名的另一种选择（相较于typedef更合吾意） 123typedef void (*PFD)(double); // C 样式using PF = void (*)(double); // using加上C样式的类型using P = [](double)-&gt;void; // using和函数返回类型后置语法 typenameinput 1234567891011121314151617181920212223template &lt;typename T&gt;void foo(const T&amp; t)&#123; // 声明一个指向某个类型为T::bar的对象的指针 T::bar * p;&#125;#if 1struct StructWithBarAsType &#123; typedef int bar;&#125;;#endif#if 0struct StructWithBarAsValue &#123; int bar;&#125;;#endifint main() &#123; StructWithBarAsType x; foo(x);&#125; output 错误 C3861 “p”: 找不到标识符 A name used in a template declaration or definition and that is dependent on a template-parameter is assumed not to name a type unless the applicable name lookup finds a type name or the name is qualified by the keyword typename. 意即出现上述歧义时(# if 0/ #if 1)，编译器将自动默认bar为一个变量名，而不是类型名 解决方案： 123456template &lt;typename T&gt;void foo(const T&amp; t)&#123; // 声明一个指向某个类型为T::bar的对象的指针 typename T::bar * p;&#125; 显示的说明T::bar是个类型 区别1 typedef不能直接用于模板，需要具体化模板类型或者嵌套在struct里面： 123456789template &lt;typename T&gt;typedef vector&lt;T&gt; vecint; //error C2823 typedef 模板 非法template &lt;typename T&gt;struct vec &#123; typedef vector&lt;T&gt; vecint; //ok&#125;;typedef vector&lt;int&gt; vecint; //ok 2 c++带依赖型别前面加typename typename仅允许在限定名称之前使用 123456789101112template &lt;typename T&gt;struct s1 &#123; typedef vector&lt;T&gt; type;&#125;;template &lt;typename T&gt;struct s2&#123; //typename typedef s1&lt;T&gt;::type type2; //ok typedef s1&lt;T&gt;::type type2; //警告 C4346 “type”: 依赖名称不是类型&#125;; ::这个是罪魁祸首，因为::有好几种解释： 静态成员 嵌套类/typedef 这种定义含糊的就需要手动加typename 3 使用using的时候，编译器知道后面的是一个型别的名字，就相当于隐士的加了typename. 1234567891011121314151617181920212223242526272829303132333435363738#include &quot;pch.h&quot;#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;string&gt;using namespace std;template &lt;typename T&gt;struct s1 &#123; typedef vector&lt;T&gt; type;&#125;;template &lt;typename T&gt;struct s2&#123; //typename typedef s1&lt;T&gt;::type type2; //typedef s1&lt;T&gt;::type type2; using type2 = typename s1&lt;T&gt;::type;&#125;;template &lt;typename T&gt;using t1 = vector&lt;T&gt;;template &lt;typename T&gt;using t2 = t1&lt;T&gt;;template &lt;typename T&gt;struct s3&#123; //gcc error vs ok using t3 = typename t1&lt;T&gt;; //gcc error：expected nested-name-specifier //using type3 = t1&lt;T&gt;;&#125;;int main() &#123; &#125; 4 支持c++11以后的话，优先选择using ending","categories":[],"tags":[{"name":"c++11","slug":"c-11","permalink":"https://riverferry.site/tags/c-11/"}],"keywords":[]},{"title":"c++ shared_ptr weak_ptr","slug":"2020-07-09-c++ shared_ptr weak_ptr","date":"2020-07-09T00:00:00.000Z","updated":"2022-09-12T16:24:32.282Z","comments":true,"path":"2020-07-09-c++ shared_ptr weak_ptr/","link":"","permalink":"https://riverferry.site/2020-07-09-c++%20shared_ptr%20weak_ptr/","excerpt":"源码分析","text":"源码分析 shared_ptr第一次创建123456789101112131415161718192021222324252627282930313233343536std::shared_ptr&lt;class&gt; a = make_shard&lt;class&gt;();//1template&lt;typename _Tp1&gt;explicit shared_ptr(_Tp1* __p) : __shared_ptr&lt;_Tp&gt;(__p) &#123; &#125;//2template&lt;typename _Tp1&gt;explicit __shared_ptr(_Tp1* __p) : _M_ptr(__p), _M_refcount(__p)&#123; __glibcxx_function_requires(_ConvertibleConcept&lt;_Tp1*, _Tp*&gt;) static_assert( sizeof(_Tp1) &gt; 0, &quot;incomplete type&quot; ); __enable_shared_from_this_helper(_M_refcount, __p, __p);&#125;//3template&lt;typename _Ptr&gt; explicit__shared_count(_Ptr __p) : _M_pi(0)&#123; __try &#123; _M_pi = new _Sp_counted_ptr&lt;_Ptr, _Lp&gt;(__p); &#125; __catch(...) &#123; delete __p; __throw_exception_again; &#125;&#125;//4_Sp_counted_base() noexcept : _M_use_count(1), _M_weak_count(1) &#123; &#125; shared_ptr互相赋值123456789101112131415161718192021222324252627//拷贝构造和赋值操作符类似，举一个例子//移动的就不看了，大致一样，rc和拷贝不同std::shared_ptr&lt;class&gt; b;std::shared_ptr&lt;class&gt; a = b;//1shared_ptr(const shared_ptr&lt;_Tp1&gt;&amp; __r) noexcept : __shared_ptr&lt;_Tp&gt;(__r) &#123; &#125;//2__shared_ptr(const __shared_ptr&lt;_Tp1, _Lp&gt;&amp; __r) noexcept : _M_ptr(__r._M_ptr), _M_refcount(__r._M_refcount) &#123; &#125;//3__shared_count(const __shared_count&amp; __r) noexcept : _M_pi(__r._M_pi) &#123; if (_M_pi != 0) _M_pi-&gt;_M_add_ref_copy(); &#125;//4void _M_add_ref_copy() &#123; __gnu_cxx::__atomic_add_dispatch(&amp;_M_use_count, 1); &#125; shared_ptr析构12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152//1~__shared_ptr() = default;~__shared_count() noexcept &#123; if (_M_pi != nullptr) _M_pi-&gt;_M_release(); &#125;//2void _M_release() noexcept &#123; // Be race-detector-friendly. For more info see bits/c++config. _GLIBCXX_SYNCHRONIZATION_HAPPENS_BEFORE(&amp;_M_use_count); if (__gnu_cxx::__exchange_and_add_dispatch(&amp;_M_use_count, -1) == 1) &#123; _GLIBCXX_SYNCHRONIZATION_HAPPENS_AFTER(&amp;_M_use_count); _M_dispose(); // There must be a memory barrier between dispose() and destroy() // to ensure that the effects of dispose() are observed in the // thread that runs destroy(). // See http://gcc.gnu.org/ml/libstdc++/2005-11/msg00136.html if (_Mutex_base&lt;_Lp&gt;::_S_need_barriers) &#123; _GLIBCXX_READ_MEM_BARRIER; _GLIBCXX_WRITE_MEM_BARRIER; &#125; // Be race-detector-friendly. For more info see bits/c++config. _GLIBCXX_SYNCHRONIZATION_HAPPENS_BEFORE(&amp;_M_weak_count); if (__gnu_cxx::__exchange_and_add_dispatch(&amp;_M_weak_count, -1) == 1) &#123; _GLIBCXX_SYNCHRONIZATION_HAPPENS_AFTER(&amp;_M_weak_count); _M_destroy(); &#125; &#125; &#125; //__exchange_and_add_dispatch 取出值，然后-1 //_M_use_count=1 析构模板对象的空间 //_M_weak_count=1 析构管理对象的对象//3virtual void _M_dispose() noexcept &#123; delete _M_ptr; &#125;virtual void _M_destroy() noexcept &#123; delete this; &#125; 其他其他函数之类的，记住就行了 循环引用1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253#include &lt;iostream&gt;#include &lt;memory&gt;using namespace std;class B;class A&#123;public: ~A() &#123; cout &lt;&lt; &quot;~A&quot; &lt;&lt; endl; &#125; std::shared_ptr&lt;B&gt; _a;&#125;;class B&#123;public: ~B() &#123; cout &lt;&lt; &quot;~B&quot; &lt;&lt; endl; &#125; std::shared_ptr&lt;A&gt; _b;&#125;;weak_ptr&lt;A&gt; wa;weak_ptr&lt;B&gt; wb;void func(void)&#123; shared_ptr&lt;A&gt; la = make_shared&lt;A&gt;(); shared_ptr&lt;B&gt; lb = make_shared&lt;B&gt;(); wa = la; wb = lb; cout &lt;&lt; &quot;A-&gt;rc = &quot; &lt;&lt; la.use_count() &lt;&lt; endl; cout &lt;&lt; &quot;B-&gt;rc = &quot; &lt;&lt; lb.use_count() &lt;&lt; endl; la-&gt;_a = lb; lb-&gt;_b = la; cout &lt;&lt; &quot;A-&gt;rc = &quot; &lt;&lt; la.use_count() &lt;&lt; endl; cout &lt;&lt; &quot;B-&gt;rc = &quot; &lt;&lt; lb.use_count() &lt;&lt; endl;&#125;int main()&#123; func(); cout &lt;&lt; wa.use_count() &lt;&lt; endl; cout &lt;&lt; wb.use_count() &lt;&lt; endl; return 0;&#125; A-&gt;rc = 1 B-&gt;rc = 1 A-&gt;rc = 2 B-&gt;rc = 2 1 1 由于weak_ptr不占用引用计数，用weak_ptr就不会存在此问题 总结 shared_ptr和weak_ptr两个类各自成员占用2个指针的大小 给shared_ptr传入裸指针会导致在堆中new一片管理空间的大小 usecount=1会析构模板对象的空间 weakcount=1会析构管理对象的空间 ENDDING","categories":[],"tags":[{"name":"c++11","slug":"c-11","permalink":"https://riverferry.site/tags/c-11/"}],"keywords":[]},{"title":"c++11 auto_ptr unique_ptr","slug":"2020-07-09-c++11 auto_ptr unique_ptr","date":"2020-07-09T00:00:00.000Z","updated":"2022-09-12T16:24:32.282Z","comments":true,"path":"2020-07-09-c++11 auto_ptr unique_ptr/","link":"","permalink":"https://riverferry.site/2020-07-09-c++11%20auto_ptr%20unique_ptr/","excerpt":"前言auto_ptr在c++11已经废弃，现在用unique_ptr替代","text":"前言auto_ptr在c++11已经废弃，现在用unique_ptr替代 区别auto_ptr出现的意义就是它是一个类，可以利用析构函数来释放内存，相当于内存守卫类。主要和unique_ptr的区别在于拷贝赋值的实现： auto_ptr 12345678910111213141516171819//auto_ptr拷贝构造函数auto_ptr(auto_ptr&amp; __a) throw() : _M_ptr(__a.release()) &#123; &#125;//operator =auto_ptr&amp; operator=(auto_ptr&amp; __a) throw() &#123; reset(__a.release()); return *this; &#125;//release函数element_type* release() throw() &#123; element_type* __tmp = _M_ptr; _M_ptr = 0; return __tmp; &#125; unique_ptr 12345678910111213141516// Move constructors. unique_ptr(unique_ptr&amp;&amp; __u) noexcept : _M_t(__u.release(), std::forward&lt;deleter_type&gt;(__u.get_deleter())) &#123; &#125;// Disable copy from lvalue. unique_ptr(const unique_ptr&amp;) = delete; unique_ptr&amp; operator=(const unique_ptr&amp;) = delete;//release pointer release() noexcept &#123; pointer __p = get(); std::get&lt;0&gt;(_M_t) = pointer(); return __p; &#125; 这样做的考虑是： 将auto_ptr可能的运行期错误在编译期暴露出来(悬空指针) unique_ptr是move-only的 unique_ptr支持数组元素作为模板( class unique_ptr&lt;_Tp[], _Dp&gt;) 好多地方说的很多，其实主要区别就是这样，至于其他的一些东西可能是无关本身的，引入了其他新的概念。真正麻烦的是shared_ptr,以后总结 deletortodo ENDDING","categories":[],"tags":[{"name":"c++11","slug":"c-11","permalink":"https://riverferry.site/tags/c-11/"}],"keywords":[]},{"title":"c++11类型推导","slug":"2020-07-09-c++11类型推导","date":"2020-07-09T00:00:00.000Z","updated":"2022-09-12T16:24:32.282Z","comments":true,"path":"2020-07-09-c++11类型推导/","link":"","permalink":"https://riverferry.site/2020-07-09-c++11%E7%B1%BB%E5%9E%8B%E6%8E%A8%E5%AF%BC/","excerpt":"参考effective modern c++ https://medium.com/@tjsw/%E6%BD%AE-c-11-universal-reference-rvalue-reference-move-semantics-1ea29f8cabdc C++11 新特性：decltype","text":"参考effective modern c++ https://medium.com/@tjsw/%E6%BD%AE-c-11-universal-reference-rvalue-reference-move-semantics-1ea29f8cabdc C++11 新特性：decltype 模板类型推导函数模板可以看成是这样： template&lt;typename T&gt; void f(ParamType param); ParamType param = expr 分三种情况： ParamType是一个指针或者引用(非通用universal reference引用) ParamType是一个通用引用(universal reference) ParamType既不是指针也不是引用 三种情况的推导规则：(推导规则推导的是T的类型) 1 ParamType是一个指针或者引用(非通用universal reference引用) 如果expr的类型是引用，忽略引用的部分 根据expr和ParamType对比来判断T的类型 2 ParamType是一个通用引用(universal reference) 如果expr是个左值，T和ParamType都会被推导成左值引用 如果expr是个右值，参考情况1 3 ParamType既不是指针也不是引用 如果expr的类型是引用，忽略引用的部分 expr是cv的，也要忽略cv类型 实际测试： case 112345678910template&lt;typename T&gt;void f(T&amp; param); // param是一个引用类型int x = 27;const int cx = x;const int&amp; rx = x;f(x); //T: int param: int &amp;f(cx); //T: const int param: const int &amp;f(rx); //T: const int param: const int &amp; case 21234567891011template&lt;typename T&gt;void f(T&amp;&amp; param);int x = 27;const int cx = x;const int&amp; rx = x;f(x); //T: int &amp; param: int &amp;f(cx); //T: const int &amp; param: const int &amp;f(rx); //T: const int &amp; param: const int &amp;f(27); //T: int&amp;&amp; param: int &amp;&amp; 引用折叠(Reference collapsing)A＆＆ --&gt; A＆ A＆&amp;&amp; --&gt; A＆ A&amp;&amp;＆ --&gt; A＆ A&amp;&amp; &amp;&amp; --&gt; A&amp;&amp; case2的param经过了引用折叠： int &amp; &amp;&amp; --&gt; int &amp; const int &amp; &amp;&amp; --&gt; const int &amp; const int &amp; &amp;&amp; --&gt; const int &amp; int &amp;&amp; &amp;&amp; --&gt; int &amp;&amp; case 312345678910template&lt;typename T&gt;void f(T param);int x = 27;const int cx = x;const int&amp; rx = x;f(x); //T: int param:intf(cx); //T: int param:intf(rx); //T: int param:int 数组参数数组会退化为指针： 1234567const char name[] = &quot;J. P. Briggs&quot;; // name的类型是const char[13] const char * ptrToName = name; //数组退化成指针template&lt;typename T&gt;void f(T param);f(name); //T: const char* 数组的引用会保留为数组形式： 1234const char name[] = &quot;J. P. Briggs&quot;; // name的类型是const char[13] template&lt;typename T&gt;void f(T &amp;param);f(name); //T: const char[13] param: const char (&amp;)[13] 函数参数函数类型退化成函数指针： 123456void someFunc(int， double); //void (int, double)template&lt;typename T&gt;void f1(T param);f1(someFunc); //T: void (*)(int, double) 函数引用会保留为函数形式： 123456void someFunc(int， double); //void (int, double)template&lt;typename T&gt;void f2(T&amp; param);f2(someFunc); //T: void (&amp;)(int, double) auto类型推导auto类型推导和模板类型推导基本一致，auto相当于T,只有一个例外:{} 1234567auto x1 = 27; //auto: int auto x2(27); //auto: intauto x3 = &#123;27&#125;; //auto: std::initializer_list&lt;int&gt;auto x4&#123; 27 &#125;; //auto: std::initializer_list&lt;int&gt;auto x5 = &#123; 1, 2, 3.0 &#125;; //编译失败，类型不一致 decltypedecltype可以表示变量或者表达式的类型 使用方式： 1decltype(expr) a; 注意点： 对一个变量名使用 decltype 得到这个变量名的声明类型。变量名属于左值表达式，但这并不 影响 decltype 的行为。然而，对于一个比变量名更复杂的左值表达式， decltype 保证返回 的类型是左值引用 123int x = 0;decltype(x) a; //a: intdecltype((x)) a; //a: int &amp; 尾随返回值类型123456789101112131415161718192021222324252627282930//c++11版本//auto作为函数返回值，不能推导出c和i的类型，因为这时候c和i还没有声明//通过--&gt; decltype(c[i])表示函数返回值类型在函数参数后声明template&lt;typename Container, typename Index&gt;auto authAndAccess(Container&amp; c, Index i)-&gt; decltype(c[i])&#123; authenticateUser(); return c[i];&#125;//c++14版本//c++14这样是可以编译过的，但是auto进行了类型推导并不和c[i]类型一致template&lt;typename Container, typename Index&gt;auto authAndAccess(Container &amp;c, Index i)&#123; authenticateUser(); return c[i];&#125;//c++14版本//返回值类型和c[i]保持一致template&lt;typename Container, typename Index&gt; decltype(auto) authAndAccess(Container &amp;c, Index i)&#123; authenticateUser(); return c[i];&#125;//使用完美转发更好，以后总结完美转发 特殊情况12345678910111213141516int main()&#123; int &amp;&amp;j = int(); int a = 10; auto &amp;&amp;b = std::move(a); auto &amp;&amp;c = j; j = 90; cout &lt;&lt; &amp;j &lt;&lt; endl; //dd&lt;decltype(j)&gt; s; //dd&lt;int&amp;&amp;&gt; s //dd&lt;decltype(std::move(a))&gt; s; //dd&lt;int&amp;&amp;&gt; s //dd&lt;decltype(b)&gt; s; //dd&lt;int&amp;&amp;&gt; s //dd&lt;decltype(c)&gt; s; //dd&lt;int&amp;&gt; s return 0;&#125; j是左值，类似函数实参(形参是右值的，实参是左值；有名的右值引用是左值)。auto &amp;&amp;这种就是模板的perfect reference ENDDING","categories":[],"tags":[{"name":"c++11","slug":"c-11","permalink":"https://riverferry.site/tags/c-11/"}],"keywords":[]},{"title":"unix域套接字","slug":"2020-07-09-unix域套接字","date":"2020-07-09T00:00:00.000Z","updated":"2022-09-12T16:24:32.283Z","comments":true,"path":"2020-07-09-unix域套接字/","link":"","permalink":"https://riverferry.site/2020-07-09-unix%E5%9F%9F%E5%A5%97%E6%8E%A5%E5%AD%97/","excerpt":"参考unp v1 概念wikipedia的解释： Unix domain socket 或者 IPC socket是一种终端，可以使同一台操作系统上的两个或多个进程进行数据通信。与管道相比，Unix domain sockets 既可以使用字节流，又可以使用数据队列，而管道通信则只能使用字节流。Unix domain sockets的接口和Internet socket很像，但它不使用网络底层协议来通信。Unix domain socket 的功能是POSIX操作系统里的一种组件。 Unix domain sockets 使用系统文件的地址来作为自己的身份。它可以被系统进程引用。所以两个进程可以同时打开一个Unix domain sockets来进行通信。不过这种通信方式是发生在系统内核里而不会在网络里传播。","text":"参考unp v1 概念wikipedia的解释： Unix domain socket 或者 IPC socket是一种终端，可以使同一台操作系统上的两个或多个进程进行数据通信。与管道相比，Unix domain sockets 既可以使用字节流，又可以使用数据队列，而管道通信则只能使用字节流。Unix domain sockets的接口和Internet socket很像，但它不使用网络底层协议来通信。Unix domain socket 的功能是POSIX操作系统里的一种组件。 Unix domain sockets 使用系统文件的地址来作为自己的身份。它可以被系统进程引用。所以两个进程可以同时打开一个Unix domain sockets来进行通信。不过这种通信方式是发生在系统内核里而不会在网络里传播。 demoserver 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657#include &lt;iostream&gt;#include &lt;sys/un.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/socket.h&gt;#include &lt;cstdlib&gt;#include &lt;errno.h&gt;using namespace std;int main(int argc, char **argv)&#123; if (argc != 2) return -1; int listfd = 0; int connfd = 0; socklen_t clilen = 0; struct sockaddr_un cliaddr = &#123;0&#125;; struct sockaddr_un seraddr = &#123;0&#125;; listfd = socket(AF_UNIX, SOCK_STREAM, 0); unlink(argv[1]); seraddr.sun_family = AF_UNIX; strncpy(seraddr.sun_path, argv[1], sizeof(seraddr.sun_path) - 1); bind(listfd, (sockaddr *)&amp;seraddr, sizeof(seraddr)); listen(listfd, 5); clilen = sizeof(cliaddr); connfd = accept(listfd, (sockaddr *)&amp;cliaddr, &amp;clilen); if (connfd &lt; 0) return -2; char buf[256] = &#123;0&#125;; int n = 0; while(1) &#123; n = read(connfd, buf, 256); cout &lt;&lt; n &lt;&lt; endl; if (n &gt; 0) &#123; cout &lt;&lt; buf &lt;&lt; endl; write(connfd, buf, n); &#125; else if (n &lt; 0 &amp;&amp; errno == EINTR) cout &lt;&lt; &quot;EINTR&quot; &lt;&lt; endl; else if (n &lt; 0) cout &lt;&lt; &quot;read err!&quot; &lt;&lt; endl; &#125; return 0;&#125; client 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#include &lt;iostream&gt;#include &lt;sys/un.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/socket.h&gt;#include &lt;cstdlib&gt;#include &lt;errno.h&gt;using namespace std;int main(int argc, char **argv)&#123; if (argc != 2) return -1; int sockfd = 0; struct sockaddr_un seraddr = &#123;0&#125;; sockfd = socket(AF_UNIX, SOCK_STREAM, 0); seraddr.sun_family = AF_UNIX; strncpy(seraddr.sun_path, argv[1], sizeof(seraddr.sun_path) - 1); int ret = connect(sockfd, (sockaddr *)&amp;seraddr, sizeof(seraddr)); if (ret &lt; 0) return -2; char buf[256] = &#123;0&#125;; int n = 0; while(cin &gt;&gt; buf) &#123; write(sockfd, buf, strlen(buf)); n = read(sockfd, buf, 256 - 1); if (n &gt; 0) cout &lt;&lt; &quot;rsp: &quot; &lt;&lt; buf &lt;&lt; endl; if (n &lt; 0 &amp;&amp; errno == EINTR) continue; else if (n &lt; 0) &#123; cout &lt;&lt; &quot;read err!&quot; &lt;&lt; endl; return -3; &#125; &#125; return 0;&#125; [root@riverwang1591252165612-0 ]# ./client /tmp/unixfd 111 rsp: 111 sss rsp: sss aaaaaaaa rsp: aaaaaaaa zzzzzzzzzzzz rsp: zzzzzzzzzzzz ENDDING","categories":[],"tags":[{"name":"unix","slug":"unix","permalink":"https://riverferry.site/tags/unix/"}],"keywords":[]},{"title":"rvo_copy_elision","slug":"2020-07-07-rvo_copy_elision","date":"2020-07-07T00:00:00.000Z","updated":"2022-09-12T16:24:32.282Z","comments":true,"path":"2020-07-07-rvo_copy_elision/","link":"","permalink":"https://riverferry.site/2020-07-07-rvo_copy_elision/","excerpt":"参考RVO VS std :: move (Named) Return Value Optimization move constructor not called when using ternary expression in return statement?","text":"参考RVO VS std :: move (Named) Return Value Optimization move constructor not called when using ternary expression in return statement? 概念 返回值优化（简称RVO）是一种编译器优化技术，它允许编译器在调用站点上构造函数的返回值。该技术也称为“清除”。C ++ 98/03标准不需要编译器提供RVO优化，但是大多数流行的C ++编译器都包含此优化技术 RVO使用12345678910111213141516171819202122232425262728#include &lt;iostream&gt;using namespace std;class BigObject &#123;public: BigObject() &#123; cout &lt;&lt; this &lt;&lt; &quot; constructor. &quot; &lt;&lt; endl; &#125; ~BigObject() &#123; cout &lt;&lt; this &lt;&lt; &quot; destructor.&quot;&lt;&lt; endl; &#125; BigObject(const BigObject&amp;) &#123; cout &lt;&lt; this &lt;&lt; &quot; copy constructor.&quot; &lt;&lt; endl; &#125; BigObject(const BigObject&amp;&amp;) noexcept&#123; cout &lt;&lt; this &lt;&lt; &quot; move constructor.&quot; &lt;&lt; endl; &#125;&#125;;BigObject foo() &#123; BigObject localObj; return localObj;&#125;int main() &#123; BigObject obj = foo(); //foo();&#125; output //g++ xxx.cpp -std=c++11 -fno-elide-constructors constructor. //localObj move constructor. //tmp destructor. //~localObj move constructor. //obj destructor. //~tmp destructor. //~obj 0x7ffff064f99f constructor. //localObj 0x7ffff064f9bf move constructor. //tmp 0x7ffff064f99f destructor. //~localObj 0x7ffff064f9be move constructor. //obj 0x7ffff064f9bf destructor. //~tmp 0x7ffff064f9be destructor. //~obj ////g++ xxx.cpp -std=c++11 0x7fffb212e72f constructor. //localObj 0x7fffb212e72f destructor. //~localObj RVO原理图片来自： RVO VS std :: move no rvo rvo 结合图示和前面的demo代码发现，rvo优化的时候函数内部并没有新建临时对象，return的就是自动变量。并且后面赋值的时候，main函数中的对象也用的是foo函数中自动变量的地址。 12345678910111213141516171819202122232425262728293031323334#include &lt;iostream&gt;using namespace std;class BigObject &#123;public: BigObject() &#123; cout &lt;&lt; this &lt;&lt; &quot; constructor. &quot; &lt;&lt; endl; &#125; ~BigObject() &#123; cout &lt;&lt; this &lt;&lt; &quot; destructor.&quot;&lt;&lt; endl; &#125; BigObject(const BigObject&amp;) &#123; cout &lt;&lt; this &lt;&lt; &quot; copy constructor.&quot; &lt;&lt; endl; &#125; BigObject(const BigObject&amp;&amp;) noexcept&#123; cout &lt;&lt; this &lt;&lt; &quot; move constructor.&quot; &lt;&lt; endl; &#125; void print() &#123; cout &lt;&lt; this &lt;&lt; endl; &#125;&#125;;BigObject foo() &#123; BigObject localObj; localObj.print(); return localObj;&#125;int main() &#123; BigObject obj = foo(); obj.print(); //foo();&#125; 0x7ffd4772908f constructor. 0x7ffd4772908f 0x7ffd4772908f 0x7ffd4772908f destructor. RVO适用范围引用自：(Named) Return Value Optimization 31. When certain criteria are met, an implementation is allowed to omit the copy/move construction of a class object, even if the constructor selected for the copy/move operation and/or the destructor for the object have side effects. In such cases, the implementation treats the source and target of the omitted copy/move operation as simply two different ways of referring to the same object, and the destruction of that object occurs at the later of the times when the two objects would have been destroyed without the optimization. This elision of copy/move operations, called copy elision, is permitted in the following circumstances (which may be combined to eliminate multiple copies): in a return statement in a function with a class return type, when the expression is the name of a non-volatile automatic object (other than a function or catch-clause parameter) with the same cv-unqualified type as the function return type, the copy/move operation can be omitted by constructing the automatic object directly into the function’s return value […] when a temporary class object that has not been bound to a reference (12.2) would be copied/moved to a class object with the same cv-unqualified type, the copy/move operation can be omitted by constructing the temporary object directly into the target of the omitted copy/move […] 1 return一个局部变量（必须直接返回同类型的变量名或匿名，不能是此函数或catch语句的参数，不能是条件表达式），可以更改变量直接构造在返回值里（临时对象）以节省一次复制/移动。 2 如果一个临时对象没有绑定在引用（左值或右值）上，这个临时对象可以直接构造在同类型的目标对象里（接收变量）以节省一次复制/移动。 以上2点可以同时发挥作用（1 + 2），不生成临时对象以节省两次复制/移动。 32. When the criteria for elision of a copy operation are met or would be met save for the fact that the sourceobject is a function parameter, and the object to be copied is designated by an lvalue, overload resolution toselect the constructor for the copy is first performed as if the object were designated by an rvalue. If overloadresolution fails, or if the type of the first parameter of the selected constructor is not an rvalue reference tothe object’s type (possibly cv-qualified), overload resolution is performed again, considering the object as anlvalue. [ Note: This two-stage overload resolution must be performed regardless of whether copy elision willoccur. It determines the constructor to be called if elision is not performed, and the selected constructormust be accessible even if the call is elided. – end note ] 当满足条件31的时候，即使被copy的对象是左值，也会被优先当作右值来决定选择copy还是move构造函数（不管是否会优化而不被调用到）。简单地说：当满足条件31（放宽：加上函数参数是值传递的情况）的时候，隐式的move-on-return会被调用，否则fallback为copy。即使可以省去copy/move构造函数的调用，copy/move构造函数也不能是私有。 总结 rvo可以减少对象拷贝，不调用构造函数生成临时对象，而是直接使用原来的对象，提升性能 可以禁用rvo -fno-elide-constructor 函数内的局部变量（必须直接返回同类型的变量名或匿名，不能是此函数或catch语句的参数，不能是条件表达式），可以更改变量直接构造在返回值里（临时对象）以节省一次复制/移动 如果一个临时对象没有绑定在引用（左值或右值）上，这个临时对象可以直接构造在同类型的目标对象里（接收变量）以节省一次复制/移动 rvo是很早就出现的技术，copy elision是c++11后基于rvo提出的 在满足rvo的条件下，会优先考虑move函数然后才是copy函数，这并不冲突，如果加了-fno-elide-constructor导致rvo失效，那么就能看到move函数被调用而不是copy函数。在rvo成功的情况下，这一原则不容易察觉到 测试代码来自：(Named) Return Value Optimization 仅对结果进行分析： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788#include &lt;iostream&gt;using namespace std;class A &#123;public: A() &#123; std::cout &lt;&lt; &quot;ctor&quot; &lt;&lt; std::endl; &#125; ~A() &#123; std::cout &lt;&lt; &quot;dtor&quot; &lt;&lt; std::endl; &#125; A(const A&amp;) &#123; std::cout &lt;&lt; &quot;cptor&quot; &lt;&lt; std::endl; &#125; A(A&amp;&amp;) &#123; std::cout &lt;&lt; &quot;mvtor&quot; &lt;&lt; std::endl; &#125;&#125;;A g;A f1() &#123; return A();&#125;A f2() &#123; A a; return a;&#125;A f3(const A&amp; a) &#123; return a;&#125;A f4(A a) &#123; return a;&#125;A f5() &#123; A a; return std::move(a);&#125;A&amp;&amp; f55() &#123; A a; return std::move(a);&#125;A f6(bool b = true) &#123; A a; return b ? a : a;&#125;A f66(bool b = true) &#123; A a; A aa; return b ? a : aa;&#125;A f7(bool b = true) &#123; A a; if (b) &#123; return a; &#125; else &#123; return a; &#125;&#125;A f8() &#123; return g;&#125;A&amp; f9() &#123; A a; return a;&#125;A&amp; f10(A a) &#123; return a;&#125;A&amp;&amp; f11() &#123; A a; return std::move(a);&#125; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788A x = f1(); //rvo ctor //g ctor //unnamed dtor dtorA x = f2(); //nrvo ctor //g ctor //a dtor dtorconst A&amp; x = f2(); //同上A&amp;&amp; x = f2(); //同上A x = f3(g); ctor //g cptor //a-&gt;tmp //a是函数参数，不符合31 //a是引用，非变量，不符合31，32 //x被赋值的时候使用了rvo dtor dtorA x = f4(g); ctor //g cptor //a //a是函数参数，不符合31 //a非return值,不符合32 mvtor //tmp a不符合31，但符合32 dtor dtor dtorA x = f5(); ctor //g ctor //a mvtor //std::move后的右值--&gt;tmp dtor dtor dtorA x = f55(); ctor //g ctor //a dtor //~a mvtor //x dtor dtorA x = f6(); //nrvo ctor //g ctor //a ? :的结果是确定的，符合rvo dtor dtorA x = f66(); ctor //g ctor //a ctor //aa cptor //return结果不确定，不符合31,32 //? : 的两个值都是左值，所以return左值。 dtor dtor dtor dtorA x = f7(); //rvoA x = f8(); ctor //g cptor //tmp //x执行了rvo dtor dtor myblog ending","categories":[],"tags":[{"name":"c++","slug":"c","permalink":"https://riverferry.site/tags/c/"}],"keywords":[]},{"title":"std::make_pair","slug":"2020-07-06-make_pair","date":"2020-07-06T00:00:00.000Z","updated":"2022-09-12T16:24:32.282Z","comments":true,"path":"2020-07-06-make_pair/","link":"","permalink":"https://riverferry.site/2020-07-06-make_pair/","excerpt":"参考What is the purpose of std::make_pair vs the constructor of std::pair?Ask std::make_pair 为什么不从构造函数推断模板参数？ 类模板的模板参数推导（修订版5）","text":"参考What is the purpose of std::make_pair vs the constructor of std::pair?Ask std::make_pair 为什么不从构造函数推断模板参数？ 类模板的模板参数推导（修订版5） 正文c++98 12345678template &lt;class T1, class T2&gt; pair&lt;T1,T2&gt; make_pair (T1 x, T2 y);template &lt;class T1,class T2&gt; pair&lt;T1,T2&gt; make_pair (T1 x, T2 y) &#123; return ( pair&lt;T1,T2&gt;(x,y) ); &#125; c++11 1234567891011template &lt;class T1, class T2&gt; pair&lt;V1,V2&gt; make_pair (T1&amp;&amp; x, T2&amp;&amp; y); // see below for definition of V1 and V2 The function returns: pair&lt;V1,V2&gt;(std::forward&lt;T1&gt;(x),std::forward&lt;T2&gt;(y))Where the types V1 and V2 are the decay(衰变) equivalents(等价物) of T1 and T2, respectively(分别) (except for reference_wrapper types, for which the corresponding reference type is used instead).If T1 and/or T2 are rvalue references, the objects are moved and x and/or y are left in an undefined but valid state. 1234567891011121314151617// make_pair example#include &lt;utility&gt; // std::pair#include &lt;iostream&gt; // std::coutint main () &#123; std::pair &lt;int,int&gt; foo; std::pair &lt;int,int&gt; bar; foo = std::make_pair (10,20); // ok: implicit conversion from pair&lt;double,char&gt; bar = std::make_pair (10.5,&#x27;A&#x27;); std::cout &lt;&lt; &quot;foo: &quot; &lt;&lt; foo.first &lt;&lt; &quot;, &quot; &lt;&lt; foo.second &lt;&lt; &#x27;\\n&#x27;; std::cout &lt;&lt; &quot;bar: &quot; &lt;&lt; bar.first &lt;&lt; &quot;, &quot; &lt;&lt; bar.second &lt;&lt; &#x27;\\n&#x27;; return 0;&#125; foo: 10, 20 bar: 10, 65 总结模板类的构造函数在c++17前是不能自动推导参数类型的，所以需要手动指定类型： std::pair &lt;int,int&gt; p(1,2); 而c++17后可以直接： std::pair p(1, &#39;a&#39;); 具体原因我也不是很懂，可以看参考的文章。但是普通函数是支持类型推导的，所以之前c++17以前实现了make_pair： template &lt;class T1,class T2&gt; pair&lt;T1,T2&gt; make_pair (T1 x, T2 y) &#123; return ( pair&lt;T1,T2&gt;(x,y) ); &#125; 这样写起来就不那么繁琐了： 12345MyClass o1;MyClass o2;auto p = std::make_pair(o1, o2);auto pp = std::pair&lt;MyClass, MyClass&gt; &#123; o1, o2 &#125;; 应该是编译器会根据实际的类型去生成一个一个make_pair匹配的实现函数，转换成pare&lt;&gt;的格式。 ending","categories":[],"tags":[{"name":"c++","slug":"c","permalink":"https://riverferry.site/tags/c/"}],"keywords":[]},{"title":"c++11-delete_default","slug":"2020-07-05-c++11-delete_default","date":"2020-07-05T00:00:00.000Z","updated":"2022-09-12T16:24:32.282Z","comments":true,"path":"2020-07-05-c++11-delete_default/","link":"","permalink":"https://riverferry.site/2020-07-05-c++11-delete_default/","excerpt":"参考C++11 标准新特性：Defaulted 和 Deleted 函数 deletec++的特殊成员函数：默认构造函数，默认拷贝构造函数，默认赋值操作符重载函数，默认析构函数。如果程序没有自己实现这些函数，但代码中需要用到的话，编译器会自己实现这些函数。有的时候不想要编译器自己实现，比如不希望有默认的拷贝构造和赋值操作符重载，就可以这样：","text":"参考C++11 标准新特性：Defaulted 和 Deleted 函数 deletec++的特殊成员函数：默认构造函数，默认拷贝构造函数，默认赋值操作符重载函数，默认析构函数。如果程序没有自己实现这些函数，但代码中需要用到的话，编译器会自己实现这些函数。有的时候不想要编译器自己实现，比如不希望有默认的拷贝构造和赋值操作符重载，就可以这样： 12345678910class myclass&#123; int _m;private: myclass(); ~myclass(); myclass(const myclass &amp; param); myclass &amp; operator=(myclass &amp; param);&#125;; 将拷贝构造函数和赋值操作符重载函数作为private,并且只声明而不实现，这样就避免了编译器自动生成，而自己又不必去实现。而c++11引入了delete关键字，使用如下： 12345678910class myclass&#123; int _m;private: myclass() = delete; ~myclass() = delete; myclass(const myclass &amp; param) = delete; myclass &amp; operator=(myclass &amp; param) = delete;&#125;; 这样带delete关键字的函数是不能被调用的，表示该函数被禁用。 注意： delete关键字可以用在类内，也可以用在类外。 并且delete函数也可以用在普通函数上，不一定是类的成员函数： 1234567void func(void) = delete;int main()&#123; func(); std::cout &lt;&lt; &quot;Hello World!\\n&quot;; &#125; 错误(活动) E1776 无法引用 函数 &quot;func()&quot; (已声明 所在行数:15) -- 它是已删除的函数 delete也可以用于限制一些特定的函数类型参数对应的函数实现，具体如下： 12345678910void func(int param)&#123; cout &lt;&lt; param &lt;&lt; endl;&#125;int main() &#123; func(true); //1 func(1.2); //1 func(&#x27;a&#x27;); //97&#125; 12345678910111213141516void func(int param)&#123; cout &lt;&lt; param &lt;&lt; endl;&#125;void func(bool param) = delete;void func(double param) = delete;void func(char param) = delete;int main() &#123; func(true); //无法引用 函数 &quot;func(bool param)&quot; (已声明 所在行数:12) -- 它是已删除的 float f = 1.2; //float--&gt;double func(f); //无法引用 函数 &quot;func(double param)&quot; (已声明 所在行数:13) -- 它是已删除 func(&#x27;a&#x27;); //无法引用 函数 &quot;func(char param)&quot; (已声明 所在行数:14) -- 它是已删除的 func(1);&#125; c++98版本的策略对于类的模板函数不能生效： 123456789101112131415161718192021222324252627#include &lt;iostream&gt;using namespace std;class myclass&#123;public: template &lt;typename T&gt; void func(T param) &#123; cout &lt;&lt; param &lt;&lt; endl; &#125;//private: template &lt;typename T&gt; //void func&lt;int&gt;(int param); //编译不过 void func(int param); //还是会调用模板函数，相当于没生效&#125;;int main() &#123; myclass m; char c = &#x27;c&#x27;; m.func(c); int i = 10; m.func(i);&#125; default还有一种情况，默认的这几个函数，如果代码中自己实现了，则编译器不会自己再去实现了。但有些时候希望用到默认的编译器可以自己实现的函数，因为这样不用自己写起来麻烦，并且编译器自己实现的函数性能比自己实现的要高： 1234567891011121314151617class myclass&#123; int _m;public: myclass(int n):_m(n) &#123; &#125; &#125;;int main()&#123; myclass a; return 0;&#125; 错误(活动) E0291 类 “myclass” 不存在默认构造函数 ConsoleApplication6 自己实现了带参数的构造函数，编译器不会再去自己实现无参构造函数了，可以这样： 1 带缺省参数的构造函数 123456public: myclass(int n = 0):_m(n) &#123; &#125; 2 另外实现无参构造函数 123456789101112131415161718192021class myclass&#123; int _m;public: myclass(int n):_m(n) &#123; &#125; myclass() &#123; &#125; &#125;;int main()&#123; myclass a; return 0;&#125; 3 什么构造函数都不实现，让编译器去实现默认的构造函数 1234567891011121314151617181920212223242526#include &quot;pch.h&quot;#include &lt;iostream&gt;class myclass&#123; int _m;public: //myclass(int n):_m(n) //&#123; //&#125; //myclass() //&#123; //&#125; &#125;;int main()&#123; myclass a; return 0;&#125; 4 根据需求这个类需要另外实现其他的构造函数，还想要使用编译器自己实现的构造函数 123456789101112131415161718class myclass&#123; int _m;public: myclass(int n):_m(n) &#123; &#125; myclass() = default; &#125;;int main()&#123; myclass a; return 0;&#125; default关键字可以让编译器去实现默认的函数 注意点： 只针对于这几种：默认构造函数，默认析构函数，拷贝/移动构造函数，赋值/移动赋值操作符重载函数。 不可用于类外 default的函数由编译器自己实现函数体，性能比自己写的性能要高 1234567891011121314151617181920class myclass&#123; int _m;public: myclass(int n):_m(n) &#123; &#125; myclass() = default; &#125;;void func(void) = default;int main()&#123; myclass a; return 0;&#125; 错误(活动) E1774 “= default”只能出现在默认构造函数、复制/移动构造函数、复制/移动赋值运算符和析构函数中 ending","categories":[],"tags":[{"name":"c++11","slug":"c-11","permalink":"https://riverferry.site/tags/c-11/"}],"keywords":[]},{"title":"copy_and_swap","slug":"2020-07-05-copy_and_swap","date":"2020-07-05T00:00:00.000Z","updated":"2022-09-12T16:24:32.282Z","comments":true,"path":"2020-07-05-copy_and_swap/","link":"","permalink":"https://riverferry.site/2020-07-05-copy_and_swap/","excerpt":"前言留的坑，以后填","text":"前言留的坑，以后填 TODOending","categories":[],"tags":[{"name":"坑","slug":"坑","permalink":"https://riverferry.site/tags/%E5%9D%91/"}],"keywords":[]},{"title":"emplace_back","slug":"2020-07-05-emplace_back","date":"2020-07-05T00:00:00.000Z","updated":"2022-09-12T16:24:32.282Z","comments":true,"path":"2020-07-05-emplace_back/","link":"","permalink":"https://riverferry.site/2020-07-05-emplace_back/","excerpt":"参考push_back和emplace_back emplace_back","text":"参考push_back和emplace_back emplace_back 函数定义123456789101112//c++11 -- c++17template&lt; class... Args &gt;void emplace_back( Args&amp;&amp;... args );//since c++17template&lt; class... Args &gt;reference emplace_back( Args&amp;&amp;... args );void push_back( const T&amp; value );//since c++11void push_back( T&amp;&amp; value ); 1234567891011121314151617181920// vector::emplace#include &lt;iostream&gt;#include &lt;vector&gt;int main ()&#123; std::vector&lt;int&gt; myvector = &#123;10,20,30&#125;; auto it = myvector.emplace ( myvector.begin()+1, 100 ); myvector.emplace ( it, 200 ); myvector.emplace ( myvector.end(), 300 ); std::cout &lt;&lt; &quot;myvector contains:&quot;; for (auto&amp; x: myvector) std::cout &lt;&lt; &#x27; &#x27; &lt;&lt; x; std::cout &lt;&lt; &#x27;\\n&#x27;; return 0;&#125; exampleinput: 12345678910111213141516171819202122232425262728293031323334353637383940414243#include &lt;vector&gt;#include &lt;string&gt;#include &lt;iostream&gt; struct President&#123; std::string name; std::string country; int year; President(std::string p_name, std::string p_country, int p_year) : name(std::move(p_name)), country(std::move(p_country)), year(p_year) &#123; std::cout &lt;&lt; &quot;I am being constructed.\\n&quot;; &#125; President(President&amp;&amp; other) : name(std::move(other.name)), country(std::move(other.country)), year(other.year) &#123; std::cout &lt;&lt; &quot;I am being moved.\\n&quot;; &#125; President&amp; operator=(const President&amp; other) = default;&#125;; int main()&#123; std::vector&lt;President&gt; elections; std::cout &lt;&lt; &quot;emplace_back:\\n&quot;; elections.emplace_back(&quot;Nelson Mandela&quot;, &quot;South Africa&quot;, 1994); std::vector&lt;President&gt; reElections; std::cout &lt;&lt; &quot;\\npush_back:\\n&quot;; reElections.push_back(President(&quot;Franklin Delano Roosevelt&quot;, &quot;the USA&quot;, 1936)); std::cout &lt;&lt; &quot;\\nContents:\\n&quot;; for (President const&amp; president: elections) &#123; std::cout &lt;&lt; president.name &lt;&lt; &quot; was elected president of &quot; &lt;&lt; president.country &lt;&lt; &quot; in &quot; &lt;&lt; president.year &lt;&lt; &quot;.\\n&quot;; &#125; for (President const&amp; president: reElections) &#123; std::cout &lt;&lt; president.name &lt;&lt; &quot; was re-elected president of &quot; &lt;&lt; president.country &lt;&lt; &quot; in &quot; &lt;&lt; president.year &lt;&lt; &quot;.\\n&quot;; &#125;&#125; output emplace_back: I am being constructed. push_back: I am being constructed. I am being moved. Contents: Nelson Mandela was elected president of South Africa in 1994. Franklin Delano Roosevelt was re-elected president of the USA in 1936. 总结c++11以后push_back也支持右值引用了，但和emplace_back的区别是：emplace_back支持可变参数列表的形式，可以在括号内直接赋值： elections.emplace_back(&quot;Nelson Mandela&quot;, &quot;South Africa&quot;, 1994); 而push_back必须有一个具体的实现(临时对象)，看得到的参数来匹配对应的拷贝构造函数，operator=函数： reElections.push_back(President(&quot;Franklin Delano Roosevelt&quot;, &quot;the USA&quot;, 1936)); push_back创建了一个临时对象President，然后通过移动构造函数把临时对象移动过来。而emplace直接通过括号的值来初始化对象。一步到位。 ending","categories":[],"tags":[{"name":"c++","slug":"c","permalink":"https://riverferry.site/tags/c/"}],"keywords":[]},{"title":"rule of three-five-zero","slug":"2020-07-05-rule of three-five-zero","date":"2020-07-05T00:00:00.000Z","updated":"2022-09-12T16:24:32.282Z","comments":true,"path":"2020-07-05-rule of three-five-zero/","link":"","permalink":"https://riverferry.site/2020-07-05-rule%20of%20three-five-zero/","excerpt":"参考The rule of three/five/zero","text":"参考The rule of three/five/zero rule of three1234567891011121314151617181920212223242526272829303132class rule_of_three&#123; char* cstring; // raw pointer used as a handle to a dynamically-allocated memory block void init(const char* s) &#123; std::size_t n = std::strlen(s) + 1; cstring = new char[n]; std::memcpy(cstring, s, n); // populate &#125; public: rule_of_three(const char* s = &quot;&quot;) &#123; init(s); &#125; ~rule_of_three() &#123; delete[] cstring; // deallocate &#125; rule_of_three(const rule_of_three&amp; other) // copy constructor &#123; init(other.cstring); &#125; rule_of_three&amp; operator=(const rule_of_three&amp; other) // copy assignment &#123; if(this != &amp;other) &#123; delete[] cstring; // deallocate init(other.cstring); &#125; return *this; &#125;&#125;; 析构函数，拷贝构造函数，赋值拷贝运算符函数，如果用户实现了其中一个，则应该实现所有的三个。主要针对类内成员作为指针指向对象或者是句柄，而导致的释放关闭问题。 如果只实现了析构函数，系统默认拷贝构造函数是浅拷贝，后面涉及多次析构同一地址 如果只实现了拷贝构造函数，析构 ending","categories":[],"tags":[{"name":"c++","slug":"c","permalink":"https://riverferry.site/tags/c/"}],"keywords":[]},{"title":"哈希表","slug":"2020-05-24-哈希表","date":"2020-05-24T00:00:00.000Z","updated":"2022-09-12T16:24:32.282Z","comments":true,"path":"2020-05-24-哈希表/","link":"","permalink":"https://riverferry.site/2020-05-24-%E5%93%88%E5%B8%8C%E8%A1%A8/","excerpt":"","text":"参考TODOending","categories":[],"tags":[{"name":"坑","slug":"坑","permalink":"https://riverferry.site/tags/%E5%9D%91/"}],"keywords":[]},{"title":"二叉搜索树","slug":"2020-05-23-二叉搜索树","date":"2020-05-23T00:00:00.000Z","updated":"2022-09-12T16:24:32.282Z","comments":true,"path":"2020-05-23-二叉搜索树/","link":"","permalink":"https://riverferry.site/2020-05-23-%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91/","excerpt":"数据结构","text":"数据结构 1234567struct BST&#123; int data; BST *left; BST *right; BST *parent;&#125;; 前序遍历：A,B,C 中序遍历：B,A,C 后续遍历：B,C,A 递归前序遍历123456789void PreOrderTraversal(BST *root)&#123; if (root == NULL) return; cout &lt;&lt; root-&gt;data &lt;&lt; &quot; &quot;; PreOrderTraversal(root-&gt;left); PreOrderTraversal(root-&gt;right);&#125; 中序遍历123456789void InOrderTraversal(BST *root)&#123; if (root == NULL) return; InOrderTraversal(root-&gt;left); cout &lt;&lt; root-&gt;data &lt;&lt; &quot; &quot;; InOrderTraversal(root-&gt;right);&#125; 后续遍历123456789void PostOrderTraversal(BST *root)&#123; if (root == NULL) return; PostOrderTraversal(root-&gt;left); PostOrderTraversal(root-&gt;right); cout &lt;&lt; root-&gt;data &lt;&lt; &quot; &quot;;&#125; 插入123456789101112131415161718192021222324252627282930BST* InsertBST(BST *root, int data)&#123; static BST *prev = NULL; if (root == NULL) &#123; BST *n = new BST; memset(n, 0, sizeof(BST)); n-&gt;data = data; if (prev == NULL) ; else if (data &gt; prev-&gt;data) prev-&gt;right = n; else prev-&gt;left = n; n-&gt;parent = prev; return n; &#125; prev = root; if (data &gt; root-&gt;data) InsertBST(root-&gt;right, data); else InsertBST(root-&gt;left, data); return root;&#125; 删除有三种情况： 删除的是叶子节点 删除节点包含1个孩子节点 删除节点包含2个孩子节点 删除1234void DeleteBST(int data)&#123;&#125; 非递归前序遍历1234void PreOrderTraversal&#123;&#125; 中序遍历1234void InOrderTraversal&#123;&#125; 后序遍历1234void PostOrderTraversal&#123;&#125; 插入12345678910111213141516171819202122232425262728293031BST* InsertBST(BST *root, int data)&#123; BST *n = new BST; memset(n, 0, sizeof(BST)); n-&gt;data = data; if (root == NULL) root = n; else &#123; BST *next = root; BST *prev = NULL; while(next) &#123; prev = next; if (data &gt; next-&gt;data) next = next-&gt;right; else next = next-&gt;left; &#125; if (data &gt; prev-&gt;data) prev-&gt;right = n; else prev-&gt;left = n; n-&gt;parent = prev; &#125; return n;&#125; 删除1234void DeleteBST(int data)&#123;&#125; DEMO123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257#include &quot;pch.h&quot;#include &lt;iostream&gt;#include &lt;memory.h&gt;using namespace std;class BST;void Delete(BST *root);BST *gRoot = NULL;class BST&#123;public: int data; BST *left; BST *right; BST *parent; BST() &#123; &#125; BST(int data) &#123; this-&gt;data = data; left = NULL; right = NULL; parent = NULL; &#125; ~BST() &#123; &#125;&#125;;#if 0BST* InsertBST(BST *root, int data)&#123; BST *n = new BST; memset(n, 0, sizeof(BST)); n-&gt;data = data; if (root == NULL) root = n; else &#123; BST *next = root; BST *prev = NULL; while (next) &#123; prev = next; if (data &gt; next-&gt;data) next = next-&gt;right; else next = next-&gt;left; &#125; if (data &gt; prev-&gt;data) prev-&gt;right = n; else prev-&gt;left = n; n-&gt;parent = prev; &#125; return n;&#125;#endifBST* InsertBST(BST *root, int data)&#123; static BST *prev = NULL; if (root == NULL) &#123; BST *n = new BST(data); if (prev == NULL) ; else if (data &gt; prev-&gt;data) prev-&gt;right = n; else prev-&gt;left = n; n-&gt;parent = prev; return n; &#125; prev = root; if (data &gt; root-&gt;data) InsertBST(root-&gt;right, data); else InsertBST(root-&gt;left, data); return root;&#125;void PreOrderTraversal(BST *root)&#123; if (root == NULL) return; cout &lt;&lt; root-&gt;data &lt;&lt; &quot; &quot;; PreOrderTraversal(root-&gt;left); PreOrderTraversal(root-&gt;right);&#125;void InOrderTraversal(BST *root)&#123; if (root == NULL) return; InOrderTraversal(root-&gt;left); cout &lt;&lt; root-&gt;data &lt;&lt; &quot; &quot;; InOrderTraversal(root-&gt;right);&#125;void PostOrderTraversal(BST *root)&#123; if (root == NULL) return; PostOrderTraversal(root-&gt;left); PostOrderTraversal(root-&gt;right); cout &lt;&lt; root-&gt;data &lt;&lt; &quot; &quot;;&#125;void DeleteBST(BST *root, int data)&#123; if (root == NULL) return; if (data == root-&gt;data) return Delete(root); else if (data &gt; root-&gt;data) DeleteBST(root-&gt;right, data); else DeleteBST(root-&gt;left, data);&#125;BST * RightAdjustNode(BST *node)&#123; while (node-&gt;left) node = node-&gt;left; return node;&#125;void Delete(BST *root)&#123; if (root == NULL) return; BST *AdjustNode = NULL; //status 1 删除叶子节点 if (root-&gt;left == NULL &amp;&amp; root-&gt;right == NULL) &#123; if (root-&gt;parent == NULL) ; else if (root-&gt;parent-&gt;left == root) root-&gt;parent-&gt;left = NULL; else root-&gt;parent-&gt;right = NULL; delete root; &#125; //status 2 有两个孩子节点 采用后驱节点 else if (root-&gt;left != NULL &amp;&amp; root-&gt;right != NULL) &#123; //查找后驱节点 AdjustNode = RightAdjustNode(root-&gt;right); //后驱节点替换删除节点的值 if (root-&gt;parent == NULL) gRoot-&gt;data = AdjustNode-&gt;data; else if (root-&gt;parent-&gt;left == root) root-&gt;parent-&gt;left-&gt;data = AdjustNode-&gt;data; else root-&gt;parent-&gt;right-&gt;data = AdjustNode-&gt;data; //删除后驱节点 Delete(AdjustNode); &#125; //status 3 有一个孩子节点 else &#123; //查找孩子节点 AdjustNode = (root-&gt;left != NULL ? root-&gt;left : root-&gt;right); //孩子节点替换删除节点 if (root-&gt;parent == NULL) gRoot = AdjustNode; else if (root-&gt;parent-&gt;left == root) root-&gt;parent-&gt;left = AdjustNode; else root-&gt;parent-&gt;right = AdjustNode; //删除孩子节点 delete root; &#125; return;&#125;int main()&#123; int data; bool flag = false; while (cin &gt;&gt; data) &#123; if (flag == false) &#123; gRoot = InsertBST(gRoot, data); flag = true; &#125; else &#123; InsertBST(gRoot, data); &#125; &#125; cout &lt;&lt; &quot;PreOrder &quot; &lt;&lt; endl; PreOrderTraversal(gRoot); cout &lt;&lt; endl; cout &lt;&lt; &quot;InOrder &quot; &lt;&lt; endl; InOrderTraversal(gRoot); cout &lt;&lt; endl; cout &lt;&lt; &quot;PostOrder &quot; &lt;&lt; endl; PostOrderTraversal(gRoot); cout &lt;&lt; endl; cout &lt;&lt; &quot;Input a data to delete:&quot; &lt;&lt; endl;#if 0 cout &lt;&lt; endl; cout &lt;&lt; &quot;delete 1&quot; &lt;&lt; endl; DeleteBST(gRoot, 1); InOrderTraversal(gRoot);#endif#if 0 cout &lt;&lt; endl; cout &lt;&lt; &quot;delete 3&quot; &lt;&lt; endl; DeleteBST(gRoot, 3); InOrderTraversal(gRoot);#endif#if 1 cout &lt;&lt; endl; cout &lt;&lt; &quot;delete 6&quot; &lt;&lt; endl; DeleteBST(gRoot, 6); InOrderTraversal(gRoot);#endif return 0;&#125; 1 3 5 2 6 ^Z PreOrder 1 3 2 5 6 InOrder 1 2 3 5 6 PostOrder 2 6 5 3 1 ending","categories":[],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://riverferry.site/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"keywords":[]},{"title":"红黑树","slug":"2020-05-16-红黑树","date":"2020-05-16T00:00:00.000Z","updated":"2022-09-12T16:24:32.282Z","comments":true,"path":"2020-05-16-红黑树/","link":"","permalink":"https://riverferry.site/2020-05-16-%E7%BA%A2%E9%BB%91%E6%A0%91/","excerpt":"参考漫画：什么是红黑树？ wikipedia 在线测试 Red Black Tree","text":"参考漫画：什么是红黑树？ wikipedia 在线测试 Red Black Tree 动机二叉搜索树(也叫二叉查找树，二叉排序树)利用二分法的思想，使得查找效率很高。最大查找次数是树的高度。但由于不平衡的原因，某些情况下，树的高度很高，查找近乎单链表遍历。AVL/红黑树就是为了均衡这种情况，让二叉搜索树变得稳定，可靠 性质红黑树是每个节点都带有颜色属性的二叉查找树，颜色为红色或黑色。在二叉查找树强制一般要求以外，对于任何有效的红黑树我们增加了如下的额外要求： 1 节点是红色或黑色。 2 根是黑色 3 所有叶子都是黑色（叶子是NIL节点） 4 每个红色节点必须有两个黑色的子节点。（从每个叶子到根的所有路径上不能有两个连续的红色节点）5 从任一节点到其每个叶子的所有简单路径都包含相同数目的黑色节点 变换规则插入的节点是红色节点(如果设为黑色，就会导致根到叶子的路径上有一条路上，多一个额外的黑节点，这个是很难调整的。但是设为红色节点后，可能会导致出现两个连续红色节点的冲突，那么可以通过颜色调换（color flips）和树旋转来调整。) 1.变颜色的情况：当前节点的父节点是红色，且它的叔叔节点也是红色. 把父节点设为黑色 把叔叔节点设为黑色 把祖父节点设为红色 把当前结点指向祖父结点 2.左旋：当前节点的父节点是红色，叔叔节点是黑色。且当前的节点是右子树。 左旋以父节点作为左旋 3.右旋：当前节点的父节点是红色，叔叔节点是黑色，且当前的节点是左子树。右旋 把父节点变为黑色 把祖父节点变为红色 以祖父节点旋转 实践before insert 1 after before insert 7 after before insert 6 step1 insert 6 step2 insert 6 step3 endding 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180#define RED BOOL_FLASE#define BLACK BOOL_TRUEclass Node&#123; int date; bool color; Node *left; Node *right; Node *parent; Node *root; public: Node(int &amp;date) &#123; this-&gt;date = data; &#125; //左旋以父节点作为左旋 void LeftRotation(Node *e) &#123; Node *s = e-&gt;right; if (e-&gt;parent == NULL) //e = root root = s; else if (e-&gt;parent-&gt;left = e) // e is left e-&gt;parent-&gt;left = s; else e-&gt;parent-&gt;right = s;// e is right if (s-&gt;left != NULL) s-&gt;left-&gt;parent = e; s-&gt;parent = e-&gt;parent; e-&gt;parent = s; e-&gt;right = s-&gt;left; s-&gt;left = e; &#125; //把父节点变为黑色 //把祖父节点变为红色 //以祖父节点旋转 //前两步在其他函数实现 void RightRotation(Node *s) &#123; Node *e = s-&gt;left; if (s-&gt;parent == NULL) root = e; else if (s-&gt;parent-&gt;left == s) s-&gt;parent-&gt;left = e; else if (s-&gt;parent-&gt;right == s) s-&gt;parent-&gt;right = e; if (e-&gt;right != NULL) e-&gt;right-&gt;parent = s; e-&gt;parent = s-&gt;parent; s-&gt;parent = e; s-&gt;left = e-&gt;right; e-&gt;right = s; &#125; //红黑树插入 递归 void InsertRBT(Node *root, int data) &#123; //this-&gt;root 默认不为空 if (data &gt; root-&gt;data) &#123; if (root-&gt;right == NULL) &#123; root-&gt;right = new Node(data); root-&gt;right.color = RED; &#125; else InsertRBT(root-&gt;right, data); &#125; else &#123; if (root-&gt;left == NULL) &#123; root-&gt;left = new Node(data); root-&gt;right.color = RED; &#125; else InsertRBT(root-&gt;left, data); &#125; InsertRBTFixedUp(); &#125; //红黑树插入 loop void InsertRBT(Node *root, int data) &#123; //this-&gt;root 默认不为空 Node *x = this-&gt;root; Node *y = NULL; Node *n = new Node(data); n.color = RED; while (x) &#123; y = x; if (data &gt; x-&gt;data) x = x-&gt;right; else x = x-&gt;left; &#125; if (!y) this-&gt;root = Node; else if (date &gt; y-&gt;date) y-&gt;right = n; else y-&gt;left = n; InsertRBTFixedUp(); &#125; //插入修正函数 InsertRBTFixedUp(Node *c) &#123; //parent is black, is ok while (c-&gt;parent-&gt;color == RED) &#123; //(uncle is left, and red) or (uncle is right, and red) if (c-&gt;parent-&gt;parent-&gt;left-&gt;color == RED &amp;&amp; c-&gt;parent-&gt;parent-&gt;right-&gt;color == RED) &#123; //变色 //把父节点设为黑色 //把叔叔节点设为黑色 //把祖父节点设为红色 //把当前结点指向祖父结点 c-&gt;parent-&gt;parent-&gt;right-&gt;color = BLACK; c-&gt;parent-&gt;parent-&gt;left-&gt;color = BLACK; c-&gt;parent-&gt;parent-&gt;color = RED; c = c-&gt;parent-&gt;parent; &#125; else if (c-&gt;parent-&gt;parent-&gt;left-&gt;color == BLACK || c-&gt;parent-&gt;parent-&gt;right-&gt;color == BLACK) &#123; //旋转 //右旋 if (c == c-&gt;parent-&gt;left) &#123; //把父节点变为黑色 //把祖父节点变为红色 //以祖父节点旋转 c-&gt;parent-&gt;color = BLACK; c-&gt;parent-&gt;parent = RED; RightRotation(c-&gt;parent-&gt;parent); &#125; //左旋 else &#123; //左旋以父节点作为左旋 LeftRotation(c-&gt;parent); &#125; &#125; &#125; root-&gt;color = BLACK; &#125; //todo: del void DeleteRBT(Node *root, int data) &#123; &#125; &#125; ending","categories":[],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://riverferry.site/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"keywords":[]},{"title":"常量折叠","slug":"2020-04-24-常量折叠","date":"2020-04-24T00:00:00.000Z","updated":"2022-09-12T16:24:32.282Z","comments":true,"path":"2020-04-24-常量折叠/","link":"","permalink":"https://riverferry.site/2020-04-24-%E5%B8%B8%E9%87%8F%E6%8A%98%E5%8F%A0/","excerpt":"参考C++常量折叠","text":"参考C++常量折叠 ending","categories":[],"tags":[{"name":"坑","slug":"坑","permalink":"https://riverferry.site/tags/%E5%9D%91/"}],"keywords":[]},{"title":"nagle算法和延迟确认","slug":"2020-04-22-nagle算法和延迟确认","date":"2020-04-22T00:00:00.000Z","updated":"2022-09-12T16:24:32.281Z","comments":true,"path":"2020-04-22-nagle算法和延迟确认/","link":"","permalink":"https://riverferry.site/2020-04-22-nagle%E7%AE%97%E6%B3%95%E5%92%8C%E5%BB%B6%E8%BF%9F%E7%A1%AE%E8%AE%A4/","excerpt":"标题 来源 完成时间 作者 环境 nagle算法和延迟确认 书籍 20200422 TheRiver kernel-3.10.1","text":"标题 来源 完成时间 作者 环境 nagle算法和延迟确认 书籍 20200422 TheRiver kernel-3.10.1 参考TCP-IP详解：Nagle算法 Linux下TCP延迟确认(Delayed Ack)机制导致的时延问题分析 ESX/ESXi 主机的某些存储阵列可能存在读取或写入性能问题 (1002598) tcp/ip 延时确认在许多情况下,TCP并不对每个到来的数据包都返回ACK,利用TCP的累积ACK字段就能实现该功能。累计确认可以允许TCP延迟一段时间发送ACK,以便将ACK和相同方向上需要传的数据结合发送。这种捎带传输的方法经常用于批量数据传输。 主机需求RFC1122指出，TCP实现ACK延迟的时延应小于500ms,实践中时延最大取200ms 这是一个ssh连接,客户端依次输入date \\n 后抓到的报文。可以看到： frame.number = 5 client send d to server frame.number = 6 server send ack to client frame.number = 7 senver send d to client(回显) frame.number = 8 clinet send ack to server frame.number = 18 client send t to server frame.number = 19 server send ack and t(回显) to client frame.number = 20 clinet send ack to server 4步是普通的报文，3步的是延迟确认。这里由于延迟很小，所以延迟确认回复比较快，体现出来只是报文数变少了。如果frame.number = 6等7号报文很久没等到，则客户端要一直等到服务端收到7号报文后才会发出ack确认(延迟确认没超时的情况下) Nagle算法Nagle算法要求，当一个TCP连接中有在传数据(即那些已发送但还未经确认的数据,长度小于mss)就不能被发送,直到所有的在传数据都收到ack,并且在收到ack后，将这些小包整合起来一起发送。 直观的说，Nagle就是在前面的小报文未被确认的时候，后面的小报文先不发送，直到收到前面小报文的ack了，把后面积累的小报文一起发送出去，这样就减少了小报文的传输。这些小报文有效负荷很低，每次都传输有点浪费带宽。 123456789101112131415/* Return false, if packet can be sent now without violation Nagle&#x27;s rules: * 1. It is full sized. * 2. Or it contains FIN. (already checked by caller) * 3. Or TCP_CORK is not set, and TCP_NODELAY is set. * 4. Or TCP_CORK is not set, and all sent packets are ACKed. * With Minshall&#x27;s modification: all sent small packets are ACKed. */static inline bool tcp_nagle_check(const struct tcp_sock *tp, const struct sk_buff *skb, unsigned int mss_now, int nonagle)&#123; return skb-&gt;len &lt; mss_now &amp;&amp; ((nonagle &amp; TCP_NAGLE_CORK) || (!nonagle &amp;&amp; tp-&gt;packets_out &amp;&amp; tcp_minshall_check(tp)));&#125; 1: 达到mss大小直接发送 2：是FIN报文 3：TCP_CORK未设置，TCP_NODELAY设置 4：TCP_CORK未设置，所有发送的小报文都收到了确认 每个小报文都要等到所有发送的小报文都收到了确认条件满足，才能发送。遗憾的是，这里构造实验环境没有抓包合并的小报文。 每组报文(发送到接收)都是一个rtt时间，113-114ms Nagle与延迟确认 客户端收到2个服务端发来的报文，由于延迟确认没有即刻回复ack.服务端由于Nagle算法，要等收到前面报文的ack才继续发送，于是导致了死锁。在延迟确认超时前一直阻塞。 总结 linux禁用延迟确认可以setsockopt函数设置TCP_QUICKACK linux禁用Nagle可以设置TCP_NODELAY 延迟确认和Nagle算法碰到一起可能导致死锁，需要谨慎 tcp.analysis.ack_rtt &gt; 0.2 and tcp.len == 0 过滤超过200ms的确认 得分情况，看是别人出发晚还是路上耽搁久，服务器如果是发了一条数据，然后等了&gt;0.2s后才发的ack，这就很有可能是延迟确认导致的 ending","categories":[],"tags":[{"name":"tcp","slug":"tcp","permalink":"https://riverferry.site/tags/tcp/"}],"keywords":[]},{"title":"list的splice与size","slug":"2020-04-21-list的splice与size","date":"2020-04-21T00:00:00.000Z","updated":"2022-09-12T16:24:32.281Z","comments":true,"path":"2020-04-21-list的splice与size/","link":"","permalink":"https://riverferry.site/2020-04-21-list%E7%9A%84splice%E4%B8%8Esize/","excerpt":"标题 来源 完成时间 作者 环境 stl的splice与size 工作接触 20200421 TheRiver gcc-4.8.8","text":"标题 来源 完成时间 作者 环境 stl的splice与size 工作接触 20200421 TheRiver gcc-4.8.8 参考坑爹的list容器size方法–为了splice居然把复杂度设计为O(N) list splice() function in C++ STL cplusplus https://gcc.gnu.org/ 前言工作之前有看过其他人提到size函数放到for循环中对性能的影响，只是有这个印象，实际原因并不清楚。今天看splice函数的时候网上看到跟此有关，作此记录 spliceThe list::splice() is a built-in function in C++ STL which is used to transfer elements from one list to another. The splice() function can be used in three ways: 1.Transfer all the elements of list x into another list at some position. 2.Transfer only the element pointed by i from list x into the list at some position. 3.Transfers the range [first, last) from list x into another list at some position. 12345list1_name.splice (iterator position, list2) list1_name.splice (iterator position, list2, iterator i) list1_name.splice (iterator position, list2, iterator first, iterator last) c++98 123456entire list (1) void splice (iterator position, list&amp; x);single element (2) void splice (iterator position, list&amp; x, iterator i);element range (3) void splice (iterator position, list&amp; x, iterator first, iterator last); c++11 1234567891011entire list (1) void splice (const_iterator position, list&amp; x);void splice (const_iterator position, list&amp;&amp; x);single element (2) void splice (const_iterator position, list&amp; x, const_iterator i);void splice (const_iterator position, list&amp;&amp; x, const_iterator i);element range (3) void splice (const_iterator position, list&amp; x, const_iterator first, const_iterator last);void splice (const_iterator position, list&amp;&amp; x, const_iterator first, const_iterator last); 2个参数 12345678910111213 void#if __cplusplus &gt;= 201103L splice(iterator __position, list&amp;&amp; __x)#else splice(iterator __position, list&amp; __x)#endif &#123; _GLIBCXX_DEBUG_VERIFY(&amp;__x != this, _M_message(__gnu_debug::__msg_self_splice) ._M_sequence(*this, &quot;this&quot;)); this-&gt;_M_transfer_from_if(__x, _Not_equal(__x._M_base().end())); _Base::splice(__position.base(), _GLIBCXX_MOVE(__x._M_base())); &#125; demo 1234567891011121314151617181920212223242526#include &lt;iostream&gt;#include &lt;list&gt;using namespace std;int main()&#123; list&lt;int&gt; list1; list&lt;int&gt; list2; for (int i = 0; i &lt; 10; i++) &#123; list1.push_back(i); list2.push_front(i); &#125; list1.splice(list1.end(), list2); list&lt;int&gt;::iterator it = list1.begin(); for (; it != list1.end(); it++) cout &lt;&lt; *it &lt;&lt; &quot; &quot;; cout &lt;&lt; endl; return 0;&#125; 0 1 2 3 4 5 6 7 8 9 9 8 7 6 5 4 3 2 1 0 Process returned 0 (0x0) execution time : 0.013 s Press any key to continue. 3个参数 12345678910111213141516171819202122232425 void#if __cplusplus &gt;= 201103L splice(iterator __position, list&amp;&amp; __x, iterator __i)#else splice(iterator __position, list&amp; __x, iterator __i)#endif &#123; __glibcxx_check_insert(__position); // We used to perform the splice_alloc check: not anymore, redundant // after implementing the relevant bits of N1599. _GLIBCXX_DEBUG_VERIFY(__i._M_dereferenceable(), _M_message(__gnu_debug::__msg_splice_bad) ._M_iterator(__i, &quot;__i&quot;)); _GLIBCXX_DEBUG_VERIFY(__i._M_attached_to(&amp;__x), _M_message(__gnu_debug::__msg_splice_other) ._M_iterator(__i, &quot;__i&quot;)._M_sequence(__x, &quot;__x&quot;)); // _GLIBCXX_RESOLVE_LIB_DEFECTS // 250. splicing invalidates iterators this-&gt;_M_transfer_from_if(__x, _Equal(__i.base())); _Base::splice(__position.base(), _GLIBCXX_MOVE(__x._M_base()), __i.base()); &#125; demo 1234567891011121314151617181920212223242526#include &lt;iostream&gt;#include &lt;list&gt;using namespace std;int main()&#123; list&lt;int&gt; list1; list&lt;int&gt; list2; for (int i = 0; i &lt; 10; i++) &#123; list1.push_back(i); list2.push_front(i); &#125; list1.splice(list1.end(), list2, list2.begin()); list&lt;int&gt;::iterator it = list1.begin(); for (; it != list1.end(); it++) cout &lt;&lt; *it &lt;&lt; &quot; &quot;; cout &lt;&lt; endl; return 0;&#125; 0 1 2 3 4 5 6 7 8 9 9 Process returned 0 (0x0) execution time : 0.065 s Press any key to continue. 4个参数 123456789101112131415161718192021222324252627282930313233343536373839void#if __cplusplus &gt;= 201103L splice(iterator __position, list&amp;&amp; __x, iterator __first, iterator __last)#else splice(iterator __position, list&amp; __x, iterator __first, iterator __last)#endif &#123; __glibcxx_check_insert(__position); __glibcxx_check_valid_range(__first, __last); _GLIBCXX_DEBUG_VERIFY(__first._M_attached_to(&amp;__x), _M_message(__gnu_debug::__msg_splice_other) ._M_sequence(__x, &quot;x&quot;) ._M_iterator(__first, &quot;first&quot;)); // We used to perform the splice_alloc check: not anymore, redundant // after implementing the relevant bits of N1599. for (_Base_iterator __tmp = __first.base(); __tmp != __last.base(); ++__tmp) &#123; _GLIBCXX_DEBUG_VERIFY(__tmp != _Base::end(), _M_message(__gnu_debug::__msg_valid_range) ._M_iterator(__first, &quot;first&quot;) ._M_iterator(__last, &quot;last&quot;)); _GLIBCXX_DEBUG_VERIFY(&amp;__x != this || __tmp != __position, _M_message(__gnu_debug::__msg_splice_overlap) ._M_iterator(__tmp, &quot;position&quot;) ._M_iterator(__first, &quot;first&quot;) ._M_iterator(__last, &quot;last&quot;)); // _GLIBCXX_RESOLVE_LIB_DEFECTS // 250. splicing invalidates iterators this-&gt;_M_transfer_from_if(__x, _Equal(__tmp)); &#125; _Base::splice(__position.base(), _GLIBCXX_MOVE(__x._M_base()), __first.base(), __last.base()); &#125; demo 1234567891011121314151617181920212223242526#include &lt;iostream&gt;#include &lt;list&gt;using namespace std;int main()&#123; list&lt;int&gt; list1; list&lt;int&gt; list2; for (int i = 0; i &lt; 10; i++) &#123; list1.push_back(i); list2.push_front(i); &#125; list1.splice(list1.end(), list2, ++list2.begin(), --list2.end()); list&lt;int&gt;::iterator it = list1.begin(); for (; it != list1.end(); it++) cout &lt;&lt; *it &lt;&lt; &quot; &quot;; cout &lt;&lt; endl; return 0;&#125; 0 1 2 3 4 5 6 7 8 9 8 7 6 5 4 3 2 1 Process returned 0 (0x0) execution time : 0.067 s Press any key to continue. sizec++98 1size_type size() const; c++11 1size_type size() const noexcept; 1234567891011121314151617181920212223242526272829303132333435363738394041/** Returns the number of elements in the %list. */ size_type size() const _GLIBCXX_NOEXCEPT &#123; return std::distance(begin(), end()); &#125;distance(_InputIterator __first, _InputIterator __last) &#123; return std::__distance(__first, __last, std::__iterator_category(__first));namespace std _GLIBCXX_VISIBILITY(default)&#123;_GLIBCXX_BEGIN_NAMESPACE_VERSION template&lt;typename _InputIterator&gt; inline typename iterator_traits&lt;_InputIterator&gt;::difference_type __distance(_InputIterator __first, _InputIterator __last, input_iterator_tag) &#123; // concept requirements __glibcxx_function_requires(_InputIteratorConcept&lt;_InputIterator&gt;) typename iterator_traits&lt;_InputIterator&gt;::difference_type __n = 0; while (__first != __last) &#123; ++__first; ++__n; &#125; return __n; &#125; template&lt;typename _RandomAccessIterator&gt; inline typename iterator_traits&lt;_RandomAccessIterator&gt;::difference_type __distance(_RandomAccessIterator __first, _RandomAccessIterator __last, random_access_iterator_tag) &#123; // concept requirements __glibcxx_function_requires(_RandomAccessIteratorConcept&lt; _RandomAccessIterator&gt;) return __last - __first; &#125;//......&#125; 当__distance的参数是iterator类型时，是通过遍历所有元素，统计个数的。这样写的原因见坑爹的list容器size方法–为了splice居然把复杂度设计为O(N),貌似是为了考虑到splice函数而故意为之。splice是剪切的作用，会对size大小有影响，如果size是遍历而不是取成员变量的值,那么splice的时候就不用遍历修改大小了，各有利弊吧。 ending","categories":[],"tags":[{"name":"stl","slug":"stl","permalink":"https://riverferry.site/tags/stl/"}],"keywords":[]},{"title":"snprintf返回值","slug":"2020-04-20-snprintf返回值","date":"2020-04-20T00:00:00.000Z","updated":"2022-09-12T16:24:32.281Z","comments":true,"path":"2020-04-20-snprintf返回值/","link":"","permalink":"https://riverferry.site/2020-04-20-snprintf%E8%BF%94%E5%9B%9E%E5%80%BC/","excerpt":"标题 来源 完成时间 作者 snprintf返回值 崩溃问题定位 20200420 TheRiver","text":"标题 来源 完成时间 作者 snprintf返回值 崩溃问题定位 20200420 TheRiver 前言今天调试程序崩溃了几次，后来定位是snprintf函数使用不恰当导致。这里把问题原因复现出来记录下 复现12345678910111213141516171819202122#include &lt;stdlib.h&gt;#include &lt;iostream&gt;#include &lt;cstdio&gt;using namespace std;int main(void)&#123; char *ps = (char*)malloc(8000); char buf[8191] = &#123;0&#125;; for (int i = 0 ; i &lt; 8191; i++) &#123; buf[i] = &#x27;1&#x27;; &#125; int n = snprintf(ps, 8191, &quot;%s&quot;, buf); cout &lt;&lt; n &lt;&lt; endl; free(ps); ps = NULL; return 0;&#125; [root@localhost ~]# ./a.out 8191 *** Error in `./a.out&#39;: free(): invalid next size (normal): 0x000000000247c010 *** ======= Backtrace: ========= /lib64/libc.so.6(+0x7d1fd)[0x7f49881dd1fd] ./a.out[0x4009d9] /lib64/libc.so.6(__libc_start_main+0xf5)[0x7f4988181af5] ./a.out[0x400859] ======= Memory map: ======== 00400000-00401000 r-xp 00000000 fd:01 148715783 /root/a.out 00600000-00601000 r--p 00000000 fd:01 148715783 /root/a.out 00601000-00602000 rw-p 00001000 fd:01 148715783 /root/a.out 0247c000-0249e000 rw-p 00000000 00:00 0 [heap] 7f4988160000-7f4988316000 r-xp 00000000 fd:01 134383134 /usr/lib64/libc-2.17.so 7f4988316000-7f4988516000 ---p 001b6000 fd:01 134383134 /usr/lib64/libc-2.17.so 7f4988516000-7f498851a000 r--p 001b6000 fd:01 134383134 /usr/lib64/libc-2.17.so 7f498851a000-7f498851c000 rw-p 001ba000 fd:01 134383134 /usr/lib64/libc-2.17.so 7f498851c000-7f4988521000 rw-p 00000000 00:00 0 7f4988521000-7f4988536000 r-xp 00000000 fd:01 146951362 /usr/lib64/libgcc_s-4.8.5-20150702.so.1 7f4988536000-7f4988735000 ---p 00015000 fd:01 146951362 /usr/lib64/libgcc_s-4.8.5-20150702.so.1 7f4988735000-7f4988736000 r--p 00014000 fd:01 146951362 /usr/lib64/libgcc_s-4.8.5-20150702.so.1 7f4988736000-7f4988737000 rw-p 00015000 fd:01 146951362 /usr/lib64/libgcc_s-4.8.5-20150702.so.1 7f4988737000-7f4988838000 r-xp 00000000 fd:01 134460818 /usr/lib64/libm-2.17.so 7f4988838000-7f4988a37000 ---p 00101000 fd:01 134460818 /usr/lib64/libm-2.17.so 7f4988a37000-7f4988a38000 r--p 00100000 fd:01 134460818 /usr/lib64/libm-2.17.so 7f4988a38000-7f4988a39000 rw-p 00101000 fd:01 134460818 /usr/lib64/libm-2.17.so 7f4988a39000-7f4988b22000 r-xp 00000000 fd:01 134383159 /usr/lib64/libstdc++.so.6.0.19 7f4988b22000-7f4988d21000 ---p 000e9000 fd:01 134383159 /usr/lib64/libstdc++.so.6.0.19 7f4988d21000-7f4988d29000 r--p 000e8000 fd:01 134383159 /usr/lib64/libstdc++.so.6.0.19 7f4988d29000-7f4988d2b000 rw-p 000f0000 fd:01 134383159 /usr/lib64/libstdc++.so.6.0.19 7f4988d2b000-7f4988d40000 rw-p 00000000 00:00 0 7f4988d40000-7f4988d61000 r-xp 00000000 fd:01 134384031 /usr/lib64/ld-2.17.so 7f4988f47000-7f4988f4c000 rw-p 00000000 00:00 0 7f4988f5e000-7f4988f61000 rw-p 00000000 00:00 0 7f4988f61000-7f4988f62000 r--p 00021000 fd:01 134384031 /usr/lib64/ld-2.17.so 7f4988f62000-7f4988f63000 rw-p 00022000 fd:01 134384031 /usr/lib64/ld-2.17.so 7f4988f63000-7f4988f64000 rw-p 00000000 00:00 0 7fff53ec2000-7fff53ee3000 rw-p 00000000 00:00 0 [stack] 7fff53ffe000-7fff54000000 r-xp 00000000 00:00 0 [vdso] ffffffffff600000-ffffffffff601000 r-xp 00000000 00:00 0 [vsyscall] 已放弃 源码12345678910int__snprintf (char *s, size_t maxlen, const char *format, ...)&#123; va_list arg; int done; va_start (arg, format); done = __vsnprintf_internal (s, maxlen, format, arg, 0); va_end (arg); return done;&#125; 总结snprintf的返回值是写入的大小，如果长度参数超过缓冲区大小也会继续写入，不过缓冲区末尾最后的字符会被snprintf填入结束符，所以strlen看到字符串大小还是缓冲区的大小，但如果是malloc的缓冲区，free的时候就可能出问题。 今天遇到的崩溃问题，最后的根因是消息体的起始位置算错了导致了，传给snprintf的长度参数倒是没问题，但总的写完还是越界了。并不能说这个问题的原因是snprintf,但是既然看到这里了，也可以关注下返回值的具体含义。snprintf的源码不好跟，就不费功夫了。 ending","categories":[],"tags":[{"name":"dump","slug":"dump","permalink":"https://riverferry.site/tags/dump/"}],"keywords":[]},{"title":"协程","slug":"2020-04-19-协程","date":"2020-04-19T00:00:00.000Z","updated":"2022-09-12T16:24:32.281Z","comments":true,"path":"2020-04-19-协程/","link":"","permalink":"https://riverferry.site/2020-04-19-%E5%8D%8F%E7%A8%8B/","excerpt":"参考协程的好处有哪些 协程原理解析(1) 云风的coroutine实现 协程那些事儿","text":"参考协程的好处有哪些 协程原理解析(1) 云风的coroutine实现 协程那些事儿 context族函数ucontext_t123456789101112131415161718192021222324252627282930/* Userlevel context. */typedef struct ucontext_t &#123; unsigned long int __ctx(uc_flags); struct ucontext_t *uc_link; stack_t uc_stack; mcontext_t uc_mcontext; sigset_t uc_sigmask; &#125; ucontext_t;/* Structure describing a signal stack. */typedef struct &#123; void *ss_sp; int ss_flags; size_t ss_size; &#125; stack_t;/* Context to describe whole processor state. */typedef struct &#123; gregset_t __ctx(gregs); /* Note that fpregs is a pointer. */ fpregset_t __ctx(fpregs); __extension__ unsigned long long __reserved1 [8];&#125; mcontext_t;typedef greg_t gregset_t[23];__extension__ typedef long long int greg_t;typedef struct _libc_fpstate *fpregset_t; getcontext123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114/* Get user context and store it in variable pointed to by UCP. */extern int getcontext (ucontext_t *__ucp) __THROWNL;/* Save current context. Copyright (C) 2002-2019 Free Software Foundation, Inc. This file is part of the GNU C Library. Contributed by Andreas Jaeger &lt;aj@suse.de&gt;, 2002. The GNU C Library is free software; you can redistribute it and/or modify it under the terms of the GNU Lesser General Public License as published by the Free Software Foundation; either version 2.1 of the License, or (at your option) any later version. The GNU C Library is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public License for more details. You should have received a copy of the GNU Lesser General Public License along with the GNU C Library; if not, see &lt;http://www.gnu.org/licenses/&gt;. */#include &lt;sysdep.h&gt;#include &lt;asm/prctl.h&gt;#include &quot;ucontext_i.h&quot;/* int __getcontext (ucontext_t *ucp) Saves the machine context in UCP such that when it is activated, it appears as if __getcontext() returned again. This implementation is intended to be used for *synchronous* context switches only. Therefore, it does not have to save anything other than the PRESERVED state. */ENTRY(__getcontext) /* Save the preserved registers, the registers used for passing args, and the return address. */ movq %rbx, oRBX(%rdi) movq %rbp, oRBP(%rdi) movq %r12, oR12(%rdi) movq %r13, oR13(%rdi) movq %r14, oR14(%rdi) movq %r15, oR15(%rdi) movq %rdi, oRDI(%rdi) movq %rsi, oRSI(%rdi) movq %rdx, oRDX(%rdi) movq %rcx, oRCX(%rdi) movq %r8, oR8(%rdi) movq %r9, oR9(%rdi) movq (%rsp), %rcx movq %rcx, oRIP(%rdi) leaq 8(%rsp), %rcx /* Exclude the return address. */ movq %rcx, oRSP(%rdi)#if SHSTK_ENABLED /* Check if shadow stack is enabled. */ testl $X86_FEATURE_1_SHSTK, %fs:FEATURE_1_OFFSET jz L(no_shstk) /* Save RDI in RDX which won&#x27;t be clobbered by syscall. */ movq %rdi, %rdx xorl %eax, %eax cmpq %fs:SSP_BASE_OFFSET, %rax jnz L(shadow_stack_bound_recorded) /* Get the base address and size of the default shadow stack which must be the current shadow stack since nothing has been recorded yet. */ sub $24, %RSP_LP mov %RSP_LP, %RSI_LP movl $ARCH_CET_STATUS, %edi movl $__NR_arch_prctl, %eax syscall testq %rax, %rax jz L(continue_no_err) /* This should never happen. */ hltL(continue_no_err): /* Record the base of the current shadow stack. */ movq 8(%rsp), %rax movq %rax, %fs:SSP_BASE_OFFSET add $24, %RSP_LP /* Restore RDI. */ movq %rdx, %rdiL(shadow_stack_bound_recorded): /* Get the current shadow stack pointer. */ rdsspq %rax /* NB: Save the caller&#x27;s shadow stack so that we can jump back to the caller directly. */ addq $8, %rax movq %rax, oSSP(%rdx) /* Save the current shadow stack base in ucontext. */ movq %fs:SSP_BASE_OFFSET, %rax movq %rax, (oSSP + 8)(%rdi)L(no_shstk):#endif /* We have separate floating-point register content memory on the stack. We use the __fpregs_mem block in the context. Set the links up correctly. */ leaq oFPREGSMEM(%rdi), %rcx movq %rcx, oFPREGS(%rdi) /* Save the floating-point environment. */ fnstenv (%rcx) fldenv (%rcx) stmxcsr oMXCSR(%rdi) /* Save the current signal mask with rt_sigprocmask (SIG_BLOCK, NULL, set,_NSIG/8). */ leaq oSIGMASK(%rdi), %rdx xorl %esi,%esi#if SIG_BLOCK == 0 xorl %edi, %edi#else movl $SIG_BLOCK, %edi#endif movl $_NSIG8,%r10d movl $__NR_rt_sigprocmask, %eax syscall cmpq $-4095, %rax /* Check %rax for error. */ jae SYSCALL_ERROR_LABEL /* Jump to error handler if error. */ /* All done, return 0 for success. */ xorl %eax, %eax retPSEUDO_END(__getcontext)weak_alias (__getcontext, getcontext) makecontext123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133/* Manipulate user context UCP to continue with calling functions FUNC and the ARGC-1 parameters following ARGC when the context is used the next time in `setcontext&#x27; or `swapcontext&#x27;. We cannot say anything about the parameters FUNC takes; `void&#x27; is as good as any other choice. */extern void makecontext (ucontext_t *__ucp, void (*__func) (void), int __argc, ...) __THROW; /* This implementation can handle any ARGC value but only normal integer parameters. makecontext sets up a stack and the registers for the user context. The stack looks like this: +-----------------------+ | next context | +-----------------------+ | parameter 7-n | +-----------------------+ | trampoline address | %rsp -&gt; +-----------------------+ The registers are set up like this: %rdi,%rsi,%rdx,%rcx,%r8,%r9: parameter 1 to 6 %rbx : address of next context %rsp : stack pointer.*//* XXX: This implementation currently only handles integer arguments. To handle long int and pointer arguments the va_arg arguments needs to be changed to long and also the stdlib/tst-setcontext.c file needs to be changed to pass long arguments to makecontext. */void__makecontext (ucontext_t *ucp, void (*func) (void), int argc, ...)&#123; extern void __start_context (void) attribute_hidden; extern void __push___start_context (ucontext_t *) attribute_hidden; greg_t *sp; unsigned int idx_uc_link; va_list ap; int i; /* Generate room on stack for parameter if needed and uc_link. */ sp = (greg_t *) ((uintptr_t) ucp-&gt;uc_stack.ss_sp + ucp-&gt;uc_stack.ss_size); sp -= (argc &gt; 6 ? argc - 6 : 0) + 1; /* Align stack and make space for trampoline address. */ sp = (greg_t *) ((((uintptr_t) sp) &amp; -16L) - 8); idx_uc_link = (argc &gt; 6 ? argc - 6 : 0) + 1; /* Setup context ucp. */ /* Address to jump to. */ ucp-&gt;uc_mcontext.gregs[REG_RIP] = (uintptr_t) func; /* Setup rbx.*/ ucp-&gt;uc_mcontext.gregs[REG_RBX] = (uintptr_t) &amp;sp[idx_uc_link]; ucp-&gt;uc_mcontext.gregs[REG_RSP] = (uintptr_t) sp; /* Setup stack. */#if SHSTK_ENABLED struct pthread *self = THREAD_SELF; unsigned int feature_1 = THREAD_GETMEM (self, header.feature_1); /* NB: We must check feature_1 before accessing __ssp since caller may be compiled against ucontext_t without __ssp. */ if ((feature_1 &amp; X86_FEATURE_1_SHSTK) != 0) &#123; /* Shadow stack is enabled. We need to allocate a new shadow stack. */ unsigned long ssp_size = (((uintptr_t) sp - (uintptr_t) ucp-&gt;uc_stack.ss_sp) &gt;&gt; STACK_SIZE_TO_SHADOW_STACK_SIZE_SHIFT); /* Align shadow stack to 8 bytes. */ ssp_size = ALIGN_UP (ssp_size, 8); ucp-&gt;__ssp[1] = ssp_size; ucp-&gt;__ssp[2] = ssp_size; /* Call __push___start_context to allocate a new shadow stack, push __start_context onto the new stack as well as the new shadow stack. NB: After __push___start_context returns, ucp-&gt;__ssp[0]: The new shadow stack pointer. ucp-&gt;__ssp[1]: The base address of the new shadow stack. ucp-&gt;__ssp[2]: The size of the new shadow stack. */ __push___start_context (ucp); &#125; else#endif sp[0] = (uintptr_t) &amp;__start_context; sp[idx_uc_link] = (uintptr_t) ucp-&gt;uc_link; va_start (ap, argc); /* Handle arguments. The standard says the parameters must all be int values. This is an historic accident and would be done differently today. For x86-64 all integer values are passed as 64-bit values and therefore extending the API to copy 64-bit values instead of 32-bit ints makes sense. It does not break existing functionality and it does not violate the standard which says that passing non-int values means undefined behavior. */ for (i = 0; i &lt; argc; ++i) switch (i) &#123; case 0: ucp-&gt;uc_mcontext.gregs[REG_RDI] = va_arg (ap, greg_t); break; case 1: ucp-&gt;uc_mcontext.gregs[REG_RSI] = va_arg (ap, greg_t); break; case 2: ucp-&gt;uc_mcontext.gregs[REG_RDX] = va_arg (ap, greg_t); break; case 3: ucp-&gt;uc_mcontext.gregs[REG_RCX] = va_arg (ap, greg_t); break; case 4: ucp-&gt;uc_mcontext.gregs[REG_R8] = va_arg (ap, greg_t); break; case 5: ucp-&gt;uc_mcontext.gregs[REG_R9] = va_arg (ap, greg_t); break; default: /* Put value on stack. */ sp[i - 5] = va_arg (ap, greg_t); break; &#125; va_end (ap);&#125; uc_link存放的是下一个要执行的上下文的地址，如果uc_link为NULL,则当前ucontext执行完，线程就退出了 uc_stack是即将运行的func使用的堆栈空间，不同于函数递归使用一个栈可能引起的栈溢出，这里栈空间可以自行分配 setcontext123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164/* Set user context from information of variable pointed to by UCP. */extern int setcontext (const ucontext_t *__ucp) __THROWNL;/* Install given context. Copyright (C) 2002-2019 Free Software Foundation, Inc. This file is part of the GNU C Library. Contributed by Andreas Jaeger &lt;aj@suse.de&gt;, 2002. The GNU C Library is free software; you can redistribute it and/or modify it under the terms of the GNU Lesser General Public License as published by the Free Software Foundation; either version 2.1 of the License, or (at your option) any later version. The GNU C Library is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public License for more details. You should have received a copy of the GNU Lesser General Public License along with the GNU C Library; if not, see &lt;http://www.gnu.org/licenses/&gt;. */#include &lt;sysdep.h&gt;#include &lt;asm/prctl.h&gt;#include &quot;ucontext_i.h&quot;/* int __setcontext (const ucontext_t *ucp) Restores the machine context in UCP and thereby resumes execution in that context. This implementation is intended to be used for *synchronous* context switches only. Therefore, it does not have to restore anything other than the PRESERVED state. */ENTRY(__setcontext) /* Save argument since syscall will destroy it. */ pushq %rdi cfi_adjust_cfa_offset(8) /* Set the signal mask with rt_sigprocmask (SIG_SETMASK, mask, NULL, _NSIG/8). */ leaq oSIGMASK(%rdi), %rsi xorl %edx, %edx movl $SIG_SETMASK, %edi movl $_NSIG8,%r10d movl $__NR_rt_sigprocmask, %eax syscall /* Pop the pointer into RDX. The choice is arbitrary, but leaving RDI and RSI available for use later can avoid shuffling values. */ popq %rdx cfi_adjust_cfa_offset(-8) cmpq $-4095, %rax /* Check %rax for error. */ jae SYSCALL_ERROR_LABEL /* Jump to error handler if error. */ /* Restore the floating-point context. Not the registers, only the rest. */ movq oFPREGS(%rdx), %rcx fldenv (%rcx) ldmxcsr oMXCSR(%rdx) /* Load the new stack pointer, the preserved registers and registers used for passing args. */ cfi_def_cfa(%rdx, 0) cfi_offset(%rbx,oRBX) cfi_offset(%rbp,oRBP) cfi_offset(%r12,oR12) cfi_offset(%r13,oR13) cfi_offset(%r14,oR14) cfi_offset(%r15,oR15) cfi_offset(%rsp,oRSP) cfi_offset(%rip,oRIP) movq oRSP(%rdx), %rsp movq oRBX(%rdx), %rbx movq oRBP(%rdx), %rbp movq oR12(%rdx), %r12 movq oR13(%rdx), %r13 movq oR14(%rdx), %r14 movq oR15(%rdx), %r15#if SHSTK_ENABLED /* Check if shadow stack is enabled. */ testl $X86_FEATURE_1_SHSTK, %fs:FEATURE_1_OFFSET jz L(no_shstk) /* If the base of the target shadow stack is the same as the base of the current shadow stack, we unwind the shadow stack. Otherwise it is a stack switch and we look for a restore token. */ movq oSSP(%rdx), %rsi movq %rsi, %rdi /* Get the base of the target shadow stack. */ movq (oSSP + 8)(%rdx), %rcx cmpq %fs:SSP_BASE_OFFSET, %rcx je L(unwind_shadow_stack)L(find_restore_token_loop): /* Look for a restore token. */ movq -8(%rsi), %rax andq $-8, %rax cmpq %rsi, %rax je L(restore_shadow_stack) /* Try the next slot. */ subq $8, %rsi jmp L(find_restore_token_loop)L(restore_shadow_stack): /* Pop return address from the shadow stack since setcontext will not return. */ movq $1, %rax incsspq %rax /* Use the restore stoken to restore the target shadow stack. */ rstorssp -8(%rsi) /* Save the restore token on the old shadow stack. NB: This restore token may be checked by setcontext or swapcontext later. */ saveprevssp /* Record the new shadow stack base that was switched to. */ movq (oSSP + 8)(%rdx), %rax movq %rax, %fs:SSP_BASE_OFFSETL(unwind_shadow_stack): rdsspq %rcx subq %rdi, %rcx je L(skip_unwind_shadow_stack) negq %rcx shrq $3, %rcx movl $255, %esiL(loop): cmpq %rsi, %rcx cmovb %rcx, %rsi incsspq %rsi subq %rsi, %rcx ja L(loop)L(skip_unwind_shadow_stack): movq oRSI(%rdx), %rsi movq oRDI(%rdx), %rdi movq oRCX(%rdx), %rcx movq oR8(%rdx), %r8 movq oR9(%rdx), %r9 /* Get the return address set with getcontext. */ movq oRIP(%rdx), %r10 /* Setup finally %rdx. */ movq oRDX(%rdx), %rdx /* Check if return address is valid for the case when setcontext is invoked from __start_context with linked context. */ rdsspq %rax cmpq (%rax), %r10 /* Clear RAX to indicate success. NB: Don&#x27;t use xorl to keep EFLAGS for jne. */ movl $0, %eax jne L(jmp) /* Return to the new context if return address valid. */ pushq %r10 retL(jmp): /* Jump to the new context directly. */ jmp *%r10L(no_shstk):#endif /* The following ret should return to the address set with getcontext. Therefore push the address on the stack. */ movq oRIP(%rdx), %rcx pushq %rcx movq oRSI(%rdx), %rsi movq oRDI(%rdx), %rdi movq oRCX(%rdx), %rcx movq oR8(%rdx), %r8 movq oR9(%rdx), %r9 /* Setup finally %rdx. */ movq oRDX(%rdx), %rdx /* End FDE here, we fall into another context. */ cfi_endproc cfi_startproc /* Clear rax to indicate success. */ xorl %eax, %eax retPSEUDO_END(__setcontext)weak_alias (__setcontext, setcontext) swapcontext123456789101112131415161718192021222324252627282930313233/* Save current context in context variable pointed to by OUCP and set context from variable pointed to by UCP. */extern int swapcontext (ucontext_t *__restrict __oucp, const ucontext_t *__restrict __ucp)//hppa实现int__swapcontext (ucontext_t *oucp, const ucontext_t *ucp)&#123; /* Save the current machine context to oucp. */ __getcontext (oucp); /* mark sc_sar flag to skip the setcontext call on reactivation. */ if (oucp-&gt;uc_mcontext.sc_sar == 0) &#123; oucp-&gt;uc_mcontext.sc_sar++; /* Restore the machine context in ucp. */ __setcontext (ucp); &#125; return 0;&#125;//ia64实现int__swapcontext (ucontext_t *oucp, const ucontext_t *ucp)&#123; struct rv rv = __getcontext (oucp); if (rv.first_return) __setcontext (ucp); return 0;&#125; 云风源码研读TODO coroutine.c123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192#include &quot;coroutine.h&quot;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;assert.h&gt;#include &lt;stddef.h&gt;#include &lt;string.h&gt;#include &lt;stdint.h&gt;#if __APPLE__ &amp;&amp; __MACH__ #include &lt;sys/ucontext.h&gt;#else #include &lt;ucontext.h&gt;#endif #define STACK_SIZE (1024*1024)#define DEFAULT_COROUTINE 16struct coroutine;struct schedule &#123; char stack[STACK_SIZE]; ucontext_t main; int nco; int cap; int running; struct coroutine **co;&#125;;struct coroutine &#123; coroutine_func func; void *ud; ucontext_t ctx; struct schedule * sch; ptrdiff_t cap; ptrdiff_t size; int status; char *stack;&#125;;struct coroutine * _co_new(struct schedule *S , coroutine_func func, void *ud) &#123; struct coroutine * co = malloc(sizeof(*co)); co-&gt;func = func; co-&gt;ud = ud; co-&gt;sch = S; co-&gt;cap = 0; co-&gt;size = 0; co-&gt;status = COROUTINE_READY; co-&gt;stack = NULL; return co;&#125;void_co_delete(struct coroutine *co) &#123; free(co-&gt;stack); free(co);&#125;struct schedule * coroutine_open(void) &#123; struct schedule *S = malloc(sizeof(*S)); S-&gt;nco = 0; S-&gt;cap = DEFAULT_COROUTINE; S-&gt;running = -1; S-&gt;co = malloc(sizeof(struct coroutine *) * S-&gt;cap); memset(S-&gt;co, 0, sizeof(struct coroutine *) * S-&gt;cap); return S;&#125;void coroutine_close(struct schedule *S) &#123; int i; for (i=0;i&lt;S-&gt;cap;i++) &#123; struct coroutine * co = S-&gt;co[i]; if (co) &#123; _co_delete(co); &#125; &#125; free(S-&gt;co); S-&gt;co = NULL; free(S);&#125;int coroutine_new(struct schedule *S, coroutine_func func, void *ud) &#123; struct coroutine *co = _co_new(S, func , ud); if (S-&gt;nco &gt;= S-&gt;cap) &#123; int id = S-&gt;cap; S-&gt;co = realloc(S-&gt;co, S-&gt;cap * 2 * sizeof(struct coroutine *)); memset(S-&gt;co + S-&gt;cap , 0 , sizeof(struct coroutine *) * S-&gt;cap); S-&gt;co[S-&gt;cap] = co; S-&gt;cap *= 2; ++S-&gt;nco; return id; &#125; else &#123; int i; for (i=0;i&lt;S-&gt;cap;i++) &#123; int id = (i+S-&gt;nco) % S-&gt;cap; if (S-&gt;co[id] == NULL) &#123; S-&gt;co[id] = co; ++S-&gt;nco; return id; &#125; &#125; &#125; assert(0); return -1;&#125;static voidmainfunc(uint32_t low32, uint32_t hi32) &#123; uintptr_t ptr = (uintptr_t)low32 | ((uintptr_t)hi32 &lt;&lt; 32); struct schedule *S = (struct schedule *)ptr; int id = S-&gt;running; struct coroutine *C = S-&gt;co[id]; C-&gt;func(S,C-&gt;ud); _co_delete(C); S-&gt;co[id] = NULL; --S-&gt;nco; S-&gt;running = -1;&#125;void coroutine_resume(struct schedule * S, int id) &#123; assert(S-&gt;running == -1); assert(id &gt;=0 &amp;&amp; id &lt; S-&gt;cap); struct coroutine *C = S-&gt;co[id]; if (C == NULL) return; int status = C-&gt;status; switch(status) &#123; case COROUTINE_READY: getcontext(&amp;C-&gt;ctx); C-&gt;ctx.uc_stack.ss_sp = S-&gt;stack; C-&gt;ctx.uc_stack.ss_size = STACK_SIZE; C-&gt;ctx.uc_link = &amp;S-&gt;main; S-&gt;running = id; C-&gt;status = COROUTINE_RUNNING; uintptr_t ptr = (uintptr_t)S; makecontext(&amp;C-&gt;ctx, (void (*)(void)) mainfunc, 2, (uint32_t)ptr, (uint32_t)(ptr&gt;&gt;32)); swapcontext(&amp;S-&gt;main, &amp;C-&gt;ctx); break; case COROUTINE_SUSPEND: memcpy(S-&gt;stack + STACK_SIZE - C-&gt;size, C-&gt;stack, C-&gt;size); S-&gt;running = id; C-&gt;status = COROUTINE_RUNNING; swapcontext(&amp;S-&gt;main, &amp;C-&gt;ctx); break; default: assert(0); &#125;&#125;static void_save_stack(struct coroutine *C, char *top) &#123; char dummy = 0; assert(top - &amp;dummy &lt;= STACK_SIZE); if (C-&gt;cap &lt; top - &amp;dummy) &#123; free(C-&gt;stack); C-&gt;cap = top-&amp;dummy; C-&gt;stack = malloc(C-&gt;cap); &#125; C-&gt;size = top - &amp;dummy; memcpy(C-&gt;stack, &amp;dummy, C-&gt;size);&#125;voidcoroutine_yield(struct schedule * S) &#123; int id = S-&gt;running; assert(id &gt;= 0); struct coroutine * C = S-&gt;co[id]; assert((char *)&amp;C &gt; S-&gt;stack); _save_stack(C,S-&gt;stack + STACK_SIZE); C-&gt;status = COROUTINE_SUSPEND; S-&gt;running = -1; swapcontext(&amp;C-&gt;ctx , &amp;S-&gt;main);&#125;int coroutine_status(struct schedule * S, int id) &#123; assert(id&gt;=0 &amp;&amp; id &lt; S-&gt;cap); if (S-&gt;co[id] == NULL) &#123; return COROUTINE_DEAD; &#125; return S-&gt;co[id]-&gt;status;&#125;int coroutine_running(struct schedule * S) &#123; return S-&gt;running;&#125; coroutine.h12345678910111213141516171819202122#ifndef C_COROUTINE_H#define C_COROUTINE_H#define COROUTINE_DEAD 0#define COROUTINE_READY 1#define COROUTINE_RUNNING 2#define COROUTINE_SUSPEND 3struct schedule;typedef void (*coroutine_func)(struct schedule *, void *ud);struct schedule * coroutine_open(void);void coroutine_close(struct schedule *);int coroutine_new(struct schedule *, coroutine_func, void *ud);void coroutine_resume(struct schedule *, int id);int coroutine_status(struct schedule *, int id);int coroutine_running(struct schedule *);void coroutine_yield(struct schedule *);#endif main.c1234567891011121314151617181920212223242526272829303132333435363738394041#include &quot;coroutine.h&quot;#include &lt;stdio.h&gt;struct args &#123; int n;&#125;;static voidfoo(struct schedule * S, void *ud) &#123; struct args * arg = ud; int start = arg-&gt;n; int i; for (i=0;i&lt;5;i++) &#123; printf(&quot;coroutine %d : %d\\n&quot;,coroutine_running(S) , start + i); coroutine_yield(S); &#125;&#125;static voidtest(struct schedule *S) &#123; struct args arg1 = &#123; 0 &#125;; struct args arg2 = &#123; 100 &#125;; int co1 = coroutine_new(S, foo, &amp;arg1); int co2 = coroutine_new(S, foo, &amp;arg2); printf(&quot;main start\\n&quot;); while (coroutine_status(S,co1) &amp;&amp; coroutine_status(S,co2)) &#123; coroutine_resume(S,co1); coroutine_resume(S,co2); &#125; printf(&quot;main end\\n&quot;);&#125;int main() &#123; struct schedule * S = coroutine_open(); test(S); coroutine_close(S); return 0;&#125; ending","categories":[],"tags":[{"name":"并发","slug":"并发","permalink":"https://riverferry.site/tags/%E5%B9%B6%E5%8F%91/"}],"keywords":[]},{"title":"singleton模式","slug":"2020-04-17-singleton模式","date":"2020-04-17T00:00:00.000Z","updated":"2022-09-12T16:24:32.281Z","comments":true,"path":"2020-04-17-singleton模式/","link":"","permalink":"https://riverferry.site/2020-04-17-singleton%E6%A8%A1%E5%BC%8F/","excerpt":"题目 来源 完成时间 实现singleton模式 剑指offer 20200418","text":"题目 来源 完成时间 实现singleton模式 剑指offer 20200418 参考C++函数内的静态变量初始化以及线程安全问题 设计模式之单例模式 概念单例模式，也叫单子模式，是一种常用的软件设计模式，属于创建型模式的一种。在应用这个模式时，单例对象的类必须保证只有一个实例存在。许多时候整个系统只需要拥有一个的全局对象，这样有利于我们协调系统整体的行为。比如在某个服务器程序中，该服务器的配置信息存放在一个文件中，这些配置数据由一个单例对象统一读取，然后服务进程中的其他对象再通过这个单例对象获取这些配置信息。这种方式简化了在复杂环境下的配置管理。 懒汉模式懒汉模式：指全局的单例实例在第一次被使用时构建。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667#include &lt;iostream&gt;#include &lt;mutex&gt;using namespace std;std::mutex g_mutex;class singleton&#123;private: singleton()&#123;&#125; ~singleton()&#123;&#125; singleton(const singleton&amp; single)&#123;&#125; const singleton&amp; operator=(const singleton&amp; single)&#123;&#125; static singleton* m_Instance;public: static singleton* GetInstance() &#123; //加锁与指针判空 std::lock_guard&lt;std::mutex&gt; lock(g_mutex); if (NULL == m_Instance) &#123; m_Instance = new singleton(); &#125; return m_Instance; &#125; void print() &#123; cout &lt;&lt; &quot;m_Instance:&quot; &lt;&lt; m_Instance &lt;&lt; endl; &#125;&#125;;singleton* singleton::m_Instance = nullptr;class singleton2&#123;private: singleton2()&#123;&#125; ~singleton2()&#123;&#125; singleton2(const singleton2&amp; single)&#123;&#125; const singleton2&amp; operator=(const singleton2&amp; single)&#123;&#125;public: static singleton2* GetInstance() &#123; //静态局部变量 static singleton2 m_Instance; return &amp;m_Instance; &#125; void print() &#123; cout &lt;&lt; &quot;m_Instance:&quot; &lt;&lt; this &lt;&lt; endl; &#125;&#125;;int main()&#123; singleton::GetInstance()-&gt;print(); singleton::GetInstance()-&gt;print(); singleton::GetInstance()-&gt;print(); return 0;&#125; 饿汉模式饿汉方式：指全局的单例实例在类装载时构建。 123456789101112131415161718192021222324252627282930313233#include &lt;iostream&gt;using namespace std;class singleton&#123;private: singleton() &#123;&#125; ~singleton() &#123;&#125; singleton(const singleton&amp; single) &#123;&#125; const singleton&amp; operator=(const singleton&amp; single) &#123;&#125; static singleton* m_Instance;public: static singleton* GetInstance() &#123; return m_Instance; &#125; void print() &#123; cout &lt;&lt; &quot;m_Instance:&quot; &lt;&lt; m_Instance &lt;&lt; endl; &#125;&#125;;singleton* singleton::m_Instance = new singleton;int main()&#123; singleton::GetInstance()-&gt;print(); singleton::GetInstance()-&gt;print(); singleton::GetInstance()-&gt;print(); return 0;&#125; 总结 懒汉模式是在类被第一次使用时构建，时间上比较慢 饿汉模式是在类被装载时构建，时间上较快 懒汉模式下，先判空再上锁，是不安全的 静态局部变量只被初始化一次，并且是线程安全的，但是在c++11以后才这样 ending","categories":[],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://riverferry.site/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}],"keywords":[]},{"title":"linux-消息队列","slug":"2020-04-13-linux-消息队列","date":"2020-04-13T00:00:00.000Z","updated":"2022-09-12T16:24:32.281Z","comments":true,"path":"2020-04-13-linux-消息队列/","link":"","permalink":"https://riverferry.site/2020-04-13-linux-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/","excerpt":"参考unp 进程间通信之POSIX消息队列 wikipedia","text":"参考unp 进程间通信之POSIX消息队列 wikipedia 概念在计算机科学中，消息队列（英语：Message queue）是一种进程间通信或同一进程的不同线程间的通信方式，软件的贮列用来处理一系列的输入，通常是来自用户。消息队列提供了异步的通信协议，每一个贮列中的纪录包含详细说明的数据，包含发生的时间，输入设备的种类，以及特定的输入参数，也就是说：消息的发送者和接收者不需要同时与消息队列交互。消息会保存在队列中，直到接收者取回它。[1] 实现实际上，消息队列常常保存在链表结构中。[2]拥有权限的进程可以向消息队列中写入或读取消息。 当前，有很多消息队列有很多开源的实现，包括JBoss Messaging、JORAM、Apache ActiveMQ、Sun Open Message Queue、RabbitMQ[3]、IBM MQ[4]、Apache Qpid[5]、Apache RocketMQ[6]和HTTPSQS。[7] 优缺点消息队列本身是异步的，它允许接收者在消息发送很长时间后再取回消息，这和大多数通信协议是不同的。例如WWW中使用的HTTP协议（HTTP/2之前）是同步的，因为客户端在发出请求后必须等待服务器回应。然而，很多情况下我们需要异步的通信协议。比如，一个进程通知另一个进程发生了一个事件，但不需要等待回应。但消息队列的异步特点，也造成了一个缺点，就是接收者必须轮询消息队列，才能收到最近的消息。 和信号相比，消息队列能够传递更多的信息。与管道相比，消息队列提供了有格式的数据，这可以减少开发人员的工作量。[2]但消息队列仍然有大小限制。 消息队列除了可以当不同线程或进程间的缓冲外，更可以透过消息队列当前消息数量来侦测接收线程或进程性能是否有问题。 使用数据结构12345678910typedef int mqd_t;struct mq_attr&#123; long int mq_flags; /* Message queue flags. */ long int mq_maxmsg; /* Maximum number of messages. */ long int mq_msgsize; /* Maximum message size. */ long int mq_curmsgs; /* Number of messages currently queued. */&#125;; mq_open123456789/* Establish connection between a process and a message queue NAME and return message queue descriptor or (mqd_t) -1 on error. OFLAG determines the type of access used. If O_CREAT is on OFLAG, the third argument is taken as a `mode_t&#x27;, the mode of the created message queue, and the fourth argument is taken as `struct mq_attr *&#x27;, pointer to message queue attributes. If the fourth argument is NULL, default attributes are used. */extern mqd_t mq_open (const char *__name, int __oflag, ...) __THROW __nonnull ((1)); mq_close123/* Removes the association between message queue descriptor MQDES and its message queue. */extern int mq_close (mqd_t __mqdes) __THROW; mq_getattr123/* Query status and attributes of message queue MQDES. */extern int mq_getattr (mqd_t __mqdes, struct mq_attr *__mqstat) __THROW __nonnull ((2)); mq_setattr123456/* Set attributes associated with message queue MQDES and if OMQSTAT is not NULL also query its old attributes. */extern int mq_setattr (mqd_t __mqdes, const struct mq_attr *__restrict __mqstat, struct mq_attr *__restrict __omqstat) __THROW __nonnull ((2)); mq_unlink12/* Remove message queue named NAME. */extern int mq_unlink (const char *__name) __THROW __nonnull ((1)); mq_notify1234/* Register notification issued upon message arrival to an empty message queue MQDES. */extern int mq_notify (mqd_t __mqdes, const struct sigevent *__notification) __THROW; mq_receive1234/* Receive the oldest from highest priority messages in message queue MQDES. */extern ssize_t mq_receive (mqd_t __mqdes, char *__msg_ptr, size_t __msg_len, unsigned int *__msg_prio) __nonnull ((2)); mq_send123/* Add message pointed by MSG_PTR to message queue MQDES. */extern int mq_send (mqd_t __mqdes, const char *__msg_ptr, size_t __msg_len, unsigned int __msg_prio) __nonnull ((2)); mq_timedreceive12345678#ifdef __USE_XOPEN2K/* Receive the oldest from highest priority messages in message queue MQDES, stop waiting if ABS_TIMEOUT expires. */extern ssize_t mq_timedreceive (mqd_t __mqdes, char *__restrict __msg_ptr, size_t __msg_len, unsigned int *__restrict __msg_prio, const struct timespec *__restrict __abs_timeout) __nonnull ((2, 5)); mq_timedsend1234567/* Add message pointed by MSG_PTR to message queue MQDES, stop blocking on full message queue if ABS_TIMEOUT expires. */extern int mq_timedsend (mqd_t __mqdes, const char *__msg_ptr, size_t __msg_len, unsigned int __msg_prio, const struct timespec *__abs_timeout) __nonnull ((2, 5));#endif DEMOsend.cpp12345678910111213141516171819202122232425262728293031323334353637383940#include &lt;iostream&gt;#include &lt;unistd.h&gt;#include &lt;mqueue.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;#include &lt;string&gt;#include &lt;time.h&gt;#include &lt;string.h&gt;using namespace std;int main()&#123; mqd_t mq = mq_open(&quot;/mymq&quot;, O_RDWR | O_CREAT, 0644, NULL); if (mq &lt; 0) cout &lt;&lt; &quot;open err!&quot; &lt;&lt; endl; time_t tt; char buf[100] = &#123;0&#125;; for (int i = 0; i &lt; 20; i++) &#123; time(&amp;tt); struct tm *ptm = nullptr; ptm = localtime(&amp;tt); strftime(buf, sizeof(buf), &quot;%Y %m %d %H %M %S&quot;, ptm); cout &lt;&lt; buf &lt;&lt; endl; mq_send(mq, buf, strlen(buf), 0); sleep(1); &#125; mq_close(mq); return 0;&#125; recv.cpp123456789101112131415161718192021222324252627282930313233343536373839404142434445#include &lt;iostream&gt;#include &lt;unistd.h&gt;#include &lt;mqueue.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;#include &lt;string&gt;#include &lt;time.h&gt;#include &lt;string.h&gt;using namespace std;int main()&#123; mqd_t mq = mq_open(&quot;/mymq&quot;, O_RDWR | O_CREAT, 0644, NULL); if (mq &lt; 0) cout &lt;&lt; &quot;open err!&quot; &lt;&lt; endl; mq_attr attr = &#123;0&#125;; ssize_t len = 0; mq_getattr(mq, &amp;attr); len = attr.mq_msgsize; char *psz = (char*)malloc(len); while (true) &#123; if (0 &gt; mq_receive(mq, psz, len, NULL)) &#123; cout &lt;&lt; &quot;recv err!&quot; &lt;&lt; endl; //free not use, just test free(psz); psz = NULL; return -1; &#125; cout &lt;&lt; psz &lt;&lt; endl; &#125; free(psz); psz = NULL; mq_close(mq); return 0;&#125; OUTPUT [root@localhost mq]# ./send 2020 04 14 23 03 23 2020 04 14 23 03 24 2020 04 14 23 03 25 2020 04 14 23 03 26 2020 04 14 23 03 27 2020 04 14 23 03 28 2020 04 14 23 03 29 2020 04 14 23 03 30 2020 04 14 23 03 31 2020 04 14 23 03 32 2020 04 14 23 03 33 2020 04 14 23 03 34 2020 04 14 23 03 35 2020 04 14 23 03 36 2020 04 14 23 03 37 2020 04 14 23 03 38 2020 04 14 23 03 39 2020 04 14 23 03 40 2020 04 14 23 03 41 2020 04 14 23 03 42 [root@localhost mq]# ./recv 2020 04 14 23 03 23 2020 04 14 23 03 24 2020 04 14 23 03 25 2020 04 14 23 03 26 2020 04 14 23 03 27 2020 04 14 23 03 28 2020 04 14 23 03 29 2020 04 14 23 03 30 2020 04 14 23 03 31 2020 04 14 23 03 32 2020 04 14 23 03 33 2020 04 14 23 03 34 2020 04 14 23 03 35 2020 04 14 23 03 36 2020 04 14 23 03 37 2020 04 14 23 03 38 2020 04 14 23 03 39 2020 04 14 23 03 40 2020 04 14 23 03 41 2020 04 14 23 03 42 ^C ending","categories":[],"tags":[{"name":"ipc","slug":"ipc","permalink":"https://riverferry.site/tags/ipc/"}],"keywords":[]},{"title":"c++11右值引用","slug":"2020-04-11-c++11右值引用","date":"2020-04-11T00:00:00.000Z","updated":"2022-09-12T16:24:32.281Z","comments":true,"path":"2020-04-11-c++11右值引用/","link":"","permalink":"https://riverferry.site/2020-04-11-c++11%E5%8F%B3%E5%80%BC%E5%BC%95%E7%94%A8/","excerpt":"参考右值引用与转移语义","text":"参考右值引用与转移语义 ending","categories":[],"tags":[{"name":"坑","slug":"坑","permalink":"https://riverferry.site/tags/%E5%9D%91/"}],"keywords":[]},{"title":"linux-管道和FIFO","slug":"2020-04-12-linux-管道和FIFO","date":"2020-04-11T00:00:00.000Z","updated":"2022-09-12T16:24:32.281Z","comments":true,"path":"2020-04-12-linux-管道和FIFO/","link":"","permalink":"https://riverferry.site/2020-04-12-linux-%E7%AE%A1%E9%81%93%E5%92%8CFIFO/","excerpt":"参考pipe函数内核实现 从内核源码聊聊pipe实现 linux 文件操作函数 mount-mknod-mkdir","text":"参考pipe函数内核实现 从内核源码聊聊pipe实现 linux 文件操作函数 mount-mknod-mkdir 管道在类Unix操作系统（以及一些其他借用了这个设计的操作系统，如Windows）中，管道（英语：Pipeline）是一系列将标准输入输出链接起来的进程，其中每一个进程的输出被直接作为下一个进程的输入。 每一个链接都由匿名管道实现[来源请求]。管道中的组成元素也被称作过滤程序。 12345678910111213141516#include &lt;unistd.h&gt; /* On Alpha, IA-64, MIPS, SuperH, and SPARC/SPARC64; see NOTES */ struct fd_pair &#123; long fd[2]; &#125;; struct fd_pair pipe(); /* On all other architectures */ int pipe(int pipefd[2]); #define _GNU_SOURCE /* See feature_test_macros(7) */ #include &lt;fcntl.h&gt; /* Obtain O_* constant definitions */ #include &lt;unistd.h&gt; int pipe2(int pipefd[2], int flags); 12345678910111213141516171819202122232425262728293031SYSCALL_DEFINE1(pipe, int __user *, fildes)&#123; return sys_pipe2(fildes, 0);&#125;/* * sys_pipe() is the normal C calling standard for creating * a pipe. It&#x27;s not the way Unix traditionally does this, though. */SYSCALL_DEFINE2(pipe2, int __user *, fildes, int, flags)&#123; struct file *files[2]; int fd[2]; int error; error = __do_pipe_flags(fd, files, flags); if (!error) &#123; if (unlikely(copy_to_user(fildes, fd, sizeof(fd)))) &#123; fput(files[0]); fput(files[1]); put_unused_fd(fd[0]); put_unused_fd(fd[1]); error = -EFAULT; &#125; else &#123; fd_install(fd[0], files[0]); fd_install(fd[1], files[1]); &#125; &#125; return error;&#125; pipe函数的输出型参数返回2个fd,fd[0]用于读，fd[1]用于写.通常的管道是半双工的，全双工实现的暂时不考虑。管道是没有名字的，不可用于进程间通信，除非通过其他方法传输fd,一般使用管道主要是父子进程间通信，其他无亲缘关系进程可以用FIFO有名管道通信 单向通信 双向通信 FIFO命名管道是计算机进程间的一种先进先出通信机制。是类Unix系统传统管道的扩展。传统管道属于匿名管道，其生存期不超过创建管道的进程的生存期。但命名管道的生存期可以与操作系统运行期一样长。 与传统的无名的shell管道不同，命名管道利用了文件系统。使用mkfifo()[1]或mknod()[2]创建命名管道。两个进程可以通过管道的名字打开、读写管道。 123456789#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;int mkfifo(const char *pathname, mode_t mode);#include &lt;fcntl.h&gt; /* Definition of AT_* constants */#include &lt;sys/stat.h&gt;int mkfifoat(int dirfd, const char *pathname, mode_t mode); 12345678910111213141516171819202122232425262728293031323334/* Create a named pipe (FIFO) named PATH with protections MODE. */intmkfifo (const char *path, mode_t mode)&#123; dev_t dev = 0; return __xmknod (_MKNOD_VER, path, mode | S_IFIFO, &amp;dev);&#125;//system V/* Create a device file named PATH, with permission and special bits MODE and device number DEV (which can be constructed from major and minor device numbers with the `makedev&#x27; macro above). */int__xmknod (int vers, const char *path, mode_t mode, dev_t *dev)&#123; unsigned long long int k_dev; if (vers != _MKNOD_VER) &#123; __set_errno (EINVAL); return -1; &#125; /* We must convert the value to dev_t type used by the kernel. */ k_dev = (*dev) &amp; ((1ULL &lt;&lt; 32) - 1); if (k_dev != *dev) &#123; __set_errno (EINVAL); return -1; &#125; return INLINE_SYSCALL (mknod, 3, CHECK_STRING (path), mode, (unsigned int) k_dev); 限制 OPEN_MAX 进程打开描述符限制 PIPE_BUF 可原子的写往一个管道或FIFO的最大数据量 1#define PATH_MAX 4096 /* # chars in a path name including nul */ [root@localhost /]# getconf OPEN_MAX 20000 [root@localhost /]# getconf PIPE_BUF / 4096 测试程序TODO ending","categories":[],"tags":[{"name":"ipc","slug":"ipc","permalink":"https://riverferry.site/tags/ipc/"}],"keywords":[]},{"title":"null和nullptr","slug":"2020-04-10-null和nullptr","date":"2020-04-10T00:00:00.000Z","updated":"2022-09-12T16:24:32.281Z","comments":true,"path":"2020-04-10-null和nullptr/","link":"","permalink":"https://riverferry.site/2020-04-10-null%E5%92%8Cnullptr/","excerpt":"参考【C++11新特性】 nullptr关键字 invalid conversion from void* to char* warning: passing NULL to non-pointer argument of ‘std::thread::thread nullptr","text":"参考【C++11新特性】 nullptr关键字 invalid conversion from void* to char* warning: passing NULL to non-pointer argument of ‘std::thread::thread nullptr 前言最近面试遇到的一个问题，平时没怎么注意到，今天研究了下，顺便记录下来. NULL1234567#ifndef NULL# if defined __STDC__ &amp;&amp; __STDC__# define NULL ((void *) 0)# else# define NULL 0# endif#endif nullptrnullptr是C++11语言标准用来表示空指针的常量值[1]，可以指派给任意类型的指针变量[2]。部分编译器将之视为一个关键字，例如Visual Studio[3]，部分使用旧标准的C++编译器则未实现需要自行定义[4]或引入额外的头文件[2]。 12345678910111213141516171819202122232425262728293031323334#ifndef _LIBCPP_NULLPTR#define _LIBCPP_NULLPTR#include &lt;__config&gt;#if !defined(_LIBCPP_HAS_NO_PRAGMA_SYSTEM_HEADER)#pragma GCC system_header#endif#ifdef _LIBCPP_HAS_NO_NULLPTR_LIBCPP_BEGIN_NAMESPACE_STDstruct _LIBCPP_TEMPLATE_VIS nullptr_t&#123; void* __lx; struct __nat &#123;int __for_bool_;&#125;; _LIBCPP_INLINE_VISIBILITY _LIBCPP_CONSTEXPR nullptr_t() : __lx(0) &#123;&#125; _LIBCPP_INLINE_VISIBILITY _LIBCPP_CONSTEXPR nullptr_t(int __nat::*) : __lx(0) &#123;&#125; _LIBCPP_INLINE_VISIBILITY _LIBCPP_CONSTEXPR operator int __nat::*() const &#123;return 0;&#125; template &lt;class _Tp&gt; _LIBCPP_INLINE_VISIBILITY _LIBCPP_CONSTEXPR operator _Tp* () const &#123;return 0;&#125; template &lt;class _Tp, class _Up&gt; _LIBCPP_INLINE_VISIBILITY operator _Tp _Up::* () const &#123;return 0;&#125; friend _LIBCPP_INLINE_VISIBILITY _LIBCPP_CONSTEXPR bool operator==(nullptr_t, nullptr_t) &#123;return true;&#125; friend _LIBCPP_INLINE_VISIBILITY _LIBCPP_CONSTEXPR bool operator!=(nullptr_t, nullptr_t) &#123;return false;&#125;&#125;;inline _LIBCPP_INLINE_VISIBILITY _LIBCPP_CONSTEXPR nullptr_t __get_nullptr_t() &#123;return nullptr_t(0);&#125;#define nullptr _VSTD::__get_nullptr_t()_LIBCPP_END_NAMESPACE_STD#else // _LIBCPP_HAS_NO_NULLPTRnamespace std&#123; typedef decltype(nullptr) nullptr_t;&#125;#endif // _LIBCPP_HAS_NO_NULLPTR#endif // _LIBCPP_NULLPTR 在c语言中,NULL是void*,在C++中NULL是0.C++ 11中使用nullptr来表示空指针. 代码C语言 1234567891011121314151617181920212223242526#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;void fun1(void* a)&#123; printf(&quot;void\\n&quot;);&#125;void fun2(int a)&#123; printf(&quot;int\\n&quot;);&#125;void fun3(char* a)&#123; printf(&quot;char*\\n&quot;);&#125;int main()&#123; //fun1(NULL); //void* //fun2(NULL); //expected &#x27;int&#x27; but argument is of type &#x27;void *&#x27;| fun3(NULL); //char* return 0;&#125; C++ 12345678910111213141516171819202122232425262728#include &lt;iostream&gt;using namespace std;void fun(void*)&#123; cout &lt;&lt; &quot;void&quot; &lt;&lt;endl;&#125;void fun(int )&#123; cout &lt;&lt; &quot;int&quot; &lt;&lt;endl;&#125;void fun2(char *)&#123; cout &lt;&lt; &quot;char*&quot; &lt;&lt; endl;&#125;int main()&#123; //fun(nullptr); //void* fun(NULL); //int //fun2(0); //char* //fun2((void*)0); //无法将参数 1 从“void *”转换为“char *” return 0;&#125; 原理nullptr是关键字，并且是个prvalue,类型是nullptr_t。nullptr_t的原理是通过operator类型转换函数配合模板来进行任意指针类型的转换： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859#include &quot;pch.h&quot;#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;string&gt;using namespace std;void func1(int*)&#123; cout &lt;&lt; &quot;int*&quot; &lt;&lt; endl;&#125;void func2(char*)&#123; cout &lt;&lt; &quot;char*&quot; &lt;&lt; endl;&#125;void func3(void*)&#123; cout &lt;&lt; &quot;void*&quot; &lt;&lt; endl;&#125;void func4(string*)&#123; cout &lt;&lt; &quot;string*&quot; &lt;&lt; endl;&#125;void func5(vector&lt;int&gt;*)&#123; cout &lt;&lt; &quot;vector&lt;int&gt;*\\n&quot;;&#125;class a&#123;public: template &lt;typename _Tp&gt; operator _Tp*() &#123; return 0; &#125;&#125;;int main()&#123; func1(nullptr); func2(nullptr); func3(nullptr); func4(nullptr); func5(nullptr); a aa; func1(aa); func2(aa); func3(aa); func4(aa); func5(aa); return 0;&#125; int* char* void* string* vector&lt;int&gt;* int* char* void* string* vector&lt;int&gt;* ending","categories":[],"tags":[{"name":"c++11","slug":"c-11","permalink":"https://riverferry.site/tags/c-11/"}],"keywords":[]},{"title":"EPOLLONESHOT","slug":"2020-04-07-EPOLLONESHOT","date":"2020-04-07T00:00:00.000Z","updated":"2022-09-12T16:24:32.279Z","comments":true,"path":"2020-04-07-EPOLLONESHOT/","link":"","permalink":"https://riverferry.site/2020-04-07-EPOLLONESHOT/","excerpt":"参考I/O代表之EPOLLONESHOT事件","text":"参考I/O代表之EPOLLONESHOT事件 ending","categories":[],"tags":[{"name":"坑","slug":"坑","permalink":"https://riverferry.site/tags/%E5%9D%91/"}],"keywords":[]},{"title":"dns解析","slug":"2020-04-07-dns解析","date":"2020-04-07T00:00:00.000Z","updated":"2022-09-12T16:24:32.279Z","comments":true,"path":"2020-04-07-dns解析/","link":"","permalink":"https://riverferry.site/2020-04-07-dns%E8%A7%A3%E6%9E%90/","excerpt":"参考DNS解析的过程是什么，求详细的？","text":"参考DNS解析的过程是什么，求详细的？ ending","categories":[],"tags":[{"name":"坑","slug":"坑","permalink":"https://riverferry.site/tags/%E5%9D%91/"}],"keywords":[]},{"title":"1号进程","slug":"2020-04-07-linux-1号进程","date":"2020-04-07T00:00:00.000Z","updated":"2022-09-12T16:24:32.279Z","comments":true,"path":"2020-04-07-linux-1号进程/","link":"","permalink":"https://riverferry.site/2020-04-07-linux-1%E5%8F%B7%E8%BF%9B%E7%A8%8B/","excerpt":"参考Linux下1号进程的前世(kernel_init)今生(init进程)—-Linux进程的管理与调度（六）","text":"参考Linux下1号进程的前世(kernel_init)今生(init进程)—-Linux进程的管理与调度（六） ending","categories":[],"tags":[{"name":"坑","slug":"坑","permalink":"https://riverferry.site/tags/%E5%9D%91/"}],"keywords":[]},{"title":"linux-posix共享内存","slug":"2020-04-07-linux-posxi共享内存","date":"2020-04-07T00:00:00.000Z","updated":"2022-09-12T16:24:32.280Z","comments":true,"path":"2020-04-07-linux-posxi共享内存/","link":"","permalink":"https://riverferry.site/2020-04-07-linux-posxi%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98/","excerpt":"内存映射文件内存映射文件（Memory-mapped file），或称“文件映射”、“映射文件”，是一段虚内存逐字节对应于一个文件或类文件的资源，使得应用程序处理映射部分如同访问主内存。","text":"内存映射文件内存映射文件（Memory-mapped file），或称“文件映射”、“映射文件”，是一段虚内存逐字节对应于一个文件或类文件的资源，使得应用程序处理映射部分如同访问主内存。 主要用处是增加I/O性能，特别是用于大文件。对于小文件，内存映射文件会导致碎片空间浪费，[1]因为内存映射总是要对齐页边界，这起码是4 KiB。因而一个5 KiB文件将会映射占用8 KiB内存，浪费了3 KiB内存。访问内存映射文件比直接文件读写要快几个数量级。 内存映射文件可以只加载一部分内容到用户的逻辑内存空间。这对非常大的文件特别有用。 使用内存映射文件可以避免颠簸：把相当大的文件直接加载到内存时，由于可用内存不足，使得一边读取文件内存，同时把部分已经加载的文件从内存写入硬盘虚存文件中。 内存映射文件由操作系统的内存管理程序负责，因此绕过了硬盘虚存的分页文件（page file）。[2] mmap函数//用户空间函数 void *mmap(void *start, size_t length, int prot, int flags, int fd, off_t offset); //内核空间函数 int mmap(struct file *filp, struct vm_area_struct *vma) 概念类的在之前的那篇文章已经写过了，这里把一些细致的点再梳理下。先看看函数参数： start: 指定被映射到的进程内空间的起始地址。它通常被指定为一个空指针，这样告诉内核自己去选择起始地址。无论哪种情况下，该函数的返回值都是描述符fd所映射到内存的起始地址. len: 是映射到调用进程地址空间中的字节数，它从被映射文件开头第offset个字节处开始算.offset通常被被设置为0 prot: 内存映射区的保护由prot参数指定. prot 说明 PROT_READ 数据可读 PROT_WRITE 数据可写 PROT_EXEC 数据可执行 PROT_NONE 数据不可访问 flags: MAP_SHARED和MAP_PRAVITE必须指定一个，并可有选择的或上MAP_FIXED MAP_PRIVATE：映射区域的修改只对当前进程有效，修改的时候类似写时复制，会拷贝一个映射区域的副本。如果内存不足，该区域将正常交换。由于私有映射在写入时会有效地还原为普通内存，因此，如果将此模式配合使用，则必须具有足够的虚拟内存来存储整个映射区域 MAP_SHARED：对映射区域的修改对所有共享的进程有效，实际是直接修改映射区在内存raw中的值，并且会写回到底层对象(文件)中，但不一定及时写。如果底层对象是只读打开，则会出现问题。 从移植性上考虑，MAP_FIXED不应该指定。如果没有指定该标志，但是start不是一个空指针，那么start如何处置取决于实现。不为空的start值通常被当作有关该内存区应如何具体定位的线索。可移植的代码应把start指定成一个空指针，并且不指定MAP_FIXED flags 说明 MAP_SHARED 变动是共享的 MAP_PRIVATE 变动是私自的 MAP_ANONYMOUS 建立匿名映射,此时会忽略参数fd MAP_FIXED 准确的解释start参数 fd: 文件描述符，可以为-1.表示匿名映射 offset: 偏移值，从文件的起始位置偏移多少字节 mmap分类 使用普通文件以提供内存映射IO 使用特殊文件提供匿名内存映射 使用shm_open提供无亲缘进程间的Posix共享内存区(和第一种差不多) 匿名内存映射看下程序启动阶段的mmap: mmap(NULL, 4096, PROT_READ|PROT_WRITE, MAP_PRIVATE|MAP_ANONYMOUS, -1, 0) = 0x7f7484b16000 12345678910111213141516171819202122232425262728293031323334353637#include &lt;iostream&gt;#include &lt;sys/mman.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/wait.h&gt;using namespace std;int main()&#123; int *ptr = static_cast&lt;int*&gt;(mmap(NULL, sizeof(int), PROT_READ | PROT_WRITE, MAP_PRIVATE | MAP_ANON, -1, 0)); /* int *ptr = static_cast&lt;int*&gt;(mmap(NULL, sizeof(int), PROT_READ | PROT_WRITE, MAP_SHARED | MAP_ANON, -1, 0)); */ *ptr = 100; pid_t pid = fork(); if (pid == 0) &#123; cout &lt;&lt; &quot;child:&quot; &lt;&lt; endl; cout &lt;&lt; ptr &lt;&lt; endl; cout &lt;&lt; *ptr &lt;&lt; endl; *ptr = 200; &#125; else if (pid &gt; 0) &#123; sleep(2); cout &lt;&lt; &quot;parent:&quot; &lt;&lt; endl; cout &lt;&lt; ptr &lt;&lt; endl; cout &lt;&lt; *ptr &lt;&lt; endl; wait(nullptr); &#125; return 0;&#125; MAP_PRIVATE child: 0x7f09d5b71000 100 parent: 0x7f09d5b71000 100 MAP_SHARED child: 0x7fba08864000 100 parent: 0x7fba08864000 200 实现匿名映射：有的系统可能不支持匿名映射，可以通过open /dev/zero来自己实现. /dev/zero在类UNIX系统中是一个特殊的设备文件，当你读它的时候，它会提供无限的空字符（NULL, ASCII NUL, 0x00）。其中的一个典型用法是用它提供的字符流来覆盖信息，另一个常见用法是产生一个特定大小的空白文件。BSD就是通过mmap把/dev/zero映射到虚地址空间实现共享内存的。可以使用mmap将/dev/zero映射到一个虚拟的内存空间，这个操作的效果等同于使用一段匿名的内存（没有和任何文件相关）。 1234567891011121314151617181920212223242526272829303132333435363738394041#include &lt;iostream&gt;#include &lt;sys/mman.h&gt;#include &lt;unistd.h&gt;#include &lt;sys/wait.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;#include &lt;sys/fcntl.h&gt;using namespace std;int main()&#123; int fd = open(&quot;/dev/zero&quot;, O_RDWR); if (fd &lt; 0) return -1; int *ptr = static_cast&lt;int*&gt;(mmap(NULL, sizeof(int), PROT_READ | PROT_WRITE, MAP_SHARED , fd, 0)); *ptr = 100; pid_t pid = fork(); if (pid == 0) &#123; cout &lt;&lt; &quot;child:&quot; &lt;&lt; endl; cout &lt;&lt; ptr &lt;&lt; endl; cout &lt;&lt; *ptr &lt;&lt; endl; *ptr = 200; &#125; else if (pid &gt; 0) &#123; sleep(2); cout &lt;&lt; &quot;parent:&quot; &lt;&lt; endl; cout &lt;&lt; ptr &lt;&lt; endl; cout &lt;&lt; *ptr &lt;&lt; endl; wait(nullptr); pause(); &#125; return 0;&#125; posix共享内存posix共享内存的实现也是映射文件，不过会给文件路径加上前缀：/dev/shm/. 从使用上来说就是把open替换成shm_open,不过shm_open内部还是调用了open,花里胡哨的 shm_open 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152#define _PATH_DEV &quot;/dev/&quot;#define SHMDIR (_PATH_DEV &quot;shm/&quot;)/* Open shared memory object. */intshm_open (const char *name, int oflag, mode_t mode)&#123; size_t namelen; char *fname; int fd; /* Construct the filename. */ while (name[0] == &#x27;/&#x27;) ++name; if (name[0] == &#x27;\\0&#x27;) &#123; /* The name &quot;/&quot; is not supported. */ __set_errno (EINVAL); return -1; &#125; namelen = strlen (name); fname = (char *) __alloca (sizeof SHMDIR - 1 + namelen + 1); __mempcpy (__mempcpy (fname, SHMDIR, sizeof SHMDIR - 1), name, namelen + 1); fd = open (name, oflag, mode); if (fd != -1) &#123; /* We got a descriptor. Now set the FD_CLOEXEC bit. */ int flags = fcntl (fd, F_GETFD, 0); if (__builtin_expect (flags, 0) != -1) &#123; flags |= FD_CLOEXEC; flags = fcntl (fd, F_SETFD, flags); &#125; if (flags == -1) &#123; /* Something went wrong. We cannot return the descriptor. */ int save_errno = errno; close (fd); fd = -1; __set_errno (save_errno); &#125; &#125; return fd;&#125; 测试程序 1234567891011121314151617181920212223242526272829303132333435#include &lt;iostream&gt;#include &lt;unistd.h&gt;#include &lt;sys/mman.h&gt;#include &lt;sys/types.h&gt;#include &lt;sys/stat.h&gt;#include &lt;time.h&gt;#include &lt;string.h&gt;#include &lt;fcntl.h&gt;using namespace std;int main()&#123; //shm_unlink(&quot;/ShareMemory&quot;); int fd = shm_open(&quot;/ShareMemory&quot;, O_RDWR | O_CREAT , 0); if (fd &lt; 0) cout &lt;&lt; fd &lt;&lt; endl; ftruncate(fd, 1024); char s[1024] = &#123;0&#125;; char *ptr = static_cast&lt;char*&gt;(mmap(NULL, 1024, PROT_READ | PROT_WRITE, MAP_SHARED, fd, 0 )); cout &lt;&lt; ptr &lt;&lt; endl; time_t ti = time(&amp;ti); struct tm *ptm = nullptr; ptm = localtime(&amp;ti); strftime(s, 1024, &quot;%Y %m %d %H %M %S&quot;, ptm); strcat(ptr, s); strcat(ptr, &quot;\\n&quot;); cout &lt;&lt; &quot;ok&quot; &lt;&lt; endl; close(fd); //shm_unlink(&quot;/ShareMemory&quot;); return 0;&#125; [root@localhost ~]# ./a.out 2020 04 11 22 54 59 2020 04 11 22 55 00 2020 04 11 22 55 01 2020 04 11 22 55 08 2020 04 11 22 55 08 2020 04 11 22 55 09 2020 04 11 22 55 49 2020 04 11 22 55 50 ok [root@localhost ~]# ./a.out 2020 04 11 22 54 59 2020 04 11 22 55 00 2020 04 11 22 55 01 2020 04 11 22 55 08 2020 04 11 22 55 08 2020 04 11 22 55 09 2020 04 11 22 55 49 2020 04 11 22 55 50 2020 04 11 22 56 19 ok [root@localhost ~]# ./a.out 2020 04 11 22 54 59 2020 04 11 22 55 00 2020 04 11 22 55 01 2020 04 11 22 55 08 2020 04 11 22 55 08 2020 04 11 22 55 09 2020 04 11 22 55 49 2020 04 11 22 55 50 2020 04 11 22 56 19 2020 04 11 22 56 31 ok [root@localhost shm]# pwd /dev/shm [root@localhost shm]# ls -lrt 总用量 24 -rw------- 1 postgres postgres 19916 4月 11 17:28 PostgreSQL.1900869883 ---------- 1 root root 1024 4月 11 22:56 ShareMemory [root@localhost shm]# cat ShareMemory 2020 04 11 22 54 59 2020 04 11 22 55 00 2020 04 11 22 55 01 2020 04 11 22 55 08 2020 04 11 22 55 08 2020 04 11 22 55 09 2020 04 11 22 55 49 2020 04 11 22 55 50 2020 04 11 22 56 19 2020 04 11 22 56 31 2020 04 11 22 56 32 总结 MAP_PRIVATE会创建内存副本，只对单个进程有效，不可用于共享 MAP_SHARED在内存只有一个映射对象，修改对所有共享进程生效。并且修改后会写入底层对象(文件)中 mmap匿名文件映射fd赋值-1, flag或上MAP_ANON.或者通过/dev/zero自己实现 shm_open作为posix标准的共享内存实现，内部也是open打开文件/dev/shm/youfilename来实现的 编译的时候 -lrt ending","categories":[],"tags":[{"name":"ipc","slug":"ipc","permalink":"https://riverferry.site/tags/ipc/"}],"keywords":[]},{"title":"linux-spinlock","slug":"2020-04-07-linux-spinlock","date":"2020-04-07T00:00:00.000Z","updated":"2022-09-12T16:24:32.280Z","comments":true,"path":"2020-04-07-linux-spinlock/","link":"","permalink":"https://riverferry.site/2020-04-07-linux-spinlock/","excerpt":"参考Linux内核同步机制之（四）：spin lock 内核锁定技术 What exactly are “spin-locks”? X86与ARM中的原子操作-原理及实现 原子操作对同步与互斥的意义 LINUX KERNEL SPINLOCK使用不当的后果 Linux 内核的排队自旋锁","text":"参考Linux内核同步机制之（四）：spin lock 内核锁定技术 What exactly are “spin-locks”? X86与ARM中的原子操作-原理及实现 原子操作对同步与互斥的意义 LINUX KERNEL SPINLOCK使用不当的后果 Linux 内核的排队自旋锁 概念wikepedia 自旋锁是计算机科学用于多线程同步的一种锁，线程反复检查锁变量是否可用。由于线程在这一过程中保持执行，因此是一种忙等待。一旦获取了自旋锁，线程会一直保持该锁，直至显式释放自旋锁。 自旋锁避免了进程上下文的调度开销，因此对于线程只会阻塞很短时间的场合是有效的。因此操作系统的实现在很多地方往往用自旋锁。Windows操作系统提供的轻型读写锁（SRW Lock）内部就用了自旋锁。显然，单核CPU不适于使用自旋锁，这里的单核CPU指的是单核单线程的CPU，因为，在同一时间只有一个线程是处在运行状态，假设运行线程A发现无法获取锁，只能等待解锁，但因为A自身不挂起，所以那个持有锁的线程B没有办法进入运行状态，只能等到操作系统分给A的时间片用完，才能有机会被调度。这种情况下使用自旋锁的代价很高。 获取、释放自旋锁，实际上是读写自旋锁的存储内存或寄存器。因此这种读写操作必须是原子的。通常用test-and-set等原子操作来实现 上面说通常使用TSL指令实现，之前总结过TSL指令是同步的硬件实现方式，会锁住CPU的地址总线，所以是对多核CPU生效的，并且内部实现是忙等待机制。 数据结构12345678910111213141516171819202122232425262728typedef struct spinlock &#123; union &#123; struct raw_spinlock rlock;#ifdef CONFIG_DEBUG_LOCK_ALLOC# define LOCK_PADSIZE (offsetof(struct raw_spinlock, dep_map)) struct &#123; u8 __padding[LOCK_PADSIZE]; struct lockdep_map dep_map; &#125;;#endif &#125;;&#125; spinlock_t;typedef struct raw_spinlock &#123; arch_spinlock_t raw_lock;#ifdef CONFIG_GENERIC_LOCKBREAK unsigned int break_lock;#endif#ifdef CONFIG_DEBUG_SPINLOCK unsigned int magic, owner_cpu; void *owner;#endif#ifdef CONFIG_DEBUG_LOCK_ALLOC struct lockdep_map dep_map;#endif&#125; raw_spinlock_t; 函数调用spin_lock/spin_unlock — 禁止内核抢占 spin_lock_irq/spin_unlock_irq — 禁止内核抢占并屏蔽中断 spin_lock_irqsave/spin_unlock_irqrestore — 禁止内核抢占并屏蔽中断，事先保存中断屏蔽位并事后恢复原状 内核版本：VERSION = 3PATCHLEVEL = 10SUBLEVEL = 1 spin_lock12345678910111213141516171819202122232425262728293031323334static inline void spin_lock(spinlock_t *lock)&#123; raw_spin_lock(&amp;lock-&gt;rlock);&#125;#define raw_spin_lock(lock) _raw_spin_lock(lock)#ifndef CONFIG_INLINE_SPIN_LOCKvoid __lockfunc _raw_spin_lock(raw_spinlock_t *lock)&#123; __raw_spin_lock(lock);&#125;static inline void __raw_spin_lock(raw_spinlock_t *lock)&#123; unsigned long tmp; __asm__ __volatile__( &quot; movi %0, 0\\n&quot; &quot; wsr %0, scompare1\\n&quot; &quot;1: movi %0, 1\\n&quot; &quot; s32c1i %0, %1, 0\\n&quot; &quot; bnez %0, 1b\\n&quot; : &quot;=&amp;a&quot; (tmp) : &quot;a&quot; (&amp;lock-&gt;slock) : &quot;memory&quot;);&#125;static inline void __raw_spin_lock(raw_spinlock_t *lock)&#123; preempt_disable(); spin_acquire(&amp;lock-&gt;dep_map, 0, 0, _RET_IP_); LOCK_CONTENDED(lock, do_raw_spin_trylock, do_raw_spin_lock);&#125; spin_unlock1234567891011121314151617181920212223242526272829303132static inline void spin_unlock(spinlock_t *lock)&#123; raw_spin_unlock(&amp;lock-&gt;rlock);&#125;#define raw_spin_unlock(lock) _raw_spin_unlock(lock)#ifdef CONFIG_UNINLINE_SPIN_UNLOCKvoid __lockfunc _raw_spin_unlock(raw_spinlock_t *lock)&#123; __raw_spin_unlock(lock);&#125;static inline void __raw_spin_unlock(raw_spinlock_t *lock)&#123; unsigned long tmp; __asm__ __volatile__( &quot; movi %0, 0\\n&quot; &quot; s32ri %0, %1, 0\\n&quot; : &quot;=&amp;a&quot; (tmp) : &quot;a&quot; (&amp;lock-&gt;slock) : &quot;memory&quot;);&#125;static inline void __raw_spin_unlock(raw_spinlock_t *lock)&#123; spin_release(&amp;lock-&gt;dep_map, 1, _RET_IP_); do_raw_spin_unlock(lock); preempt_enable();&#125; spin_lock_irq1234567891011121314151617181920static inline void spin_lock_irq(spinlock_t *lock)&#123; raw_spin_lock_irq(&amp;lock-&gt;rlock);&#125;#define raw_spin_lock_irq(lock) _raw_spin_lock_irq(lock)#ifndef CONFIG_INLINE_SPIN_LOCK_IRQvoid __lockfunc _raw_spin_lock_irq(raw_spinlock_t *lock)&#123; __raw_spin_lock_irq(lock);&#125;static inline void __raw_spin_lock_irq(raw_spinlock_t *lock)&#123; local_irq_disable(); preempt_disable(); spin_acquire(&amp;lock-&gt;dep_map, 0, 0, _RET_IP_); LOCK_CONTENDED(lock, do_raw_spin_trylock, do_raw_spin_lock);&#125; spin_unlock_irq1234567891011121314151617181920static inline void spin_unlock_irq(spinlock_t *lock)&#123; raw_spin_unlock_irq(&amp;lock-&gt;rlock);&#125;#define raw_spin_unlock_irq(lock) _raw_spin_unlock_irq(lock)#ifndef CONFIG_INLINE_SPIN_UNLOCK_IRQvoid __lockfunc _raw_spin_unlock_irq(raw_spinlock_t *lock)&#123; __raw_spin_unlock_irq(lock);&#125;static inline void __raw_spin_unlock_irq(raw_spinlock_t *lock)&#123; spin_release(&amp;lock-&gt;dep_map, 1, _RET_IP_); do_raw_spin_unlock(lock); local_irq_enable(); preempt_enable();&#125; spin_lock_irqsave12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152#define spin_lock_irqsave(lock, flags) \\do &#123; \\ raw_spin_lock_irqsave(spinlock_check(lock), flags); \\&#125; while (0)//#if#if defined(CONFIG_SMP) || defined(CONFIG_DEBUG_SPINLOCK)#define raw_spin_lock_irqsave(lock, flags) \\ do &#123; \\ typecheck(unsigned long, flags); \\ flags = _raw_spin_lock_irqsave(lock); \\ &#125; while (0)//#else#else#define raw_spin_lock_irqsave(lock, flags) \\ do &#123; \\ typecheck(unsigned long, flags); \\ _raw_spin_lock_irqsave(lock, flags); \\ &#125; while (0)//#endif#define _raw_spin_lock_irqsave(lock, flags) __LOCK_IRQSAVE(lock, flags)#ifdef CONFIG_INLINE_SPIN_LOCK_IRQSAVE#define _raw_spin_lock_irqsave(lock) __raw_spin_lock_irqsave(lock)#endif//#if#if !defined(CONFIG_GENERIC_LOCKBREAK) || defined(CONFIG_DEBUG_LOCK_ALLOC)static inline unsigned long __raw_spin_lock_irqsave(raw_spinlock_t *lock)&#123; unsigned long flags; local_irq_save(flags); preempt_disable(); spin_acquire(&amp;lock-&gt;dep_map, 0, 0, _RET_IP_); /* * On lockdep we dont want the hand-coded irq-enable of * do_raw_spin_lock_flags() code, because lockdep assumes * that interrupts are not re-enabled during lock-acquire: */#ifdef CONFIG_LOCKDEP LOCK_CONTENDED(lock, do_raw_spin_trylock, do_raw_spin_lock);#else do_raw_spin_lock_flags(lock, &amp;flags);#endif return flags;&#125; ...#endif spin_unlock_irqrestore1234567891011121314151617181920212223242526272829static inline void spin_unlock_irqrestore(spinlock_t *lock, unsigned long flags)&#123; raw_spin_unlock_irqrestore(&amp;lock-&gt;rlock, flags);&#125;#define raw_spin_unlock_irqrestore(lock, flags) \\ do &#123; \\ typecheck(unsigned long, flags); \\ _raw_spin_unlock_irqrestore(lock, flags); \\ &#125; while (0)#define _raw_spin_unlock_irqrestore(lock, flags) \\ __UNLOCK_IRQRESTORE(lock, flags)#ifndef CONFIG_INLINE_SPIN_UNLOCK_IRQRESTOREvoid __lockfunc _raw_spin_unlock_irqrestore(raw_spinlock_t *lock, unsigned long flags)&#123; __raw_spin_unlock_irqrestore(lock, flags);&#125;static inline void __raw_spin_unlock_irqrestore(raw_spinlock_t *lock, unsigned long flags)&#123; spin_release(&amp;lock-&gt;dep_map, 1, _RET_IP_); do_raw_spin_unlock(lock); local_irq_restore(flags); preempt_enable();&#125; 总结 spinlock比较底层，跟踪代码有多种实现不好界定，目前使用的比较少，就不继续深究了 spinlock可以禁用内核抢占，也可以禁用中断 spinlock底层通常用TSL实现 spinlock对多核cpu有效(TSL) uni core不适用spinlock,需要等待时间片用尽然后等待其他进程释放锁，代价高 spinlock是busy waiting,没有进程切换的代价，但是占用cpu,所以加锁时间不宜过长 ending","categories":[],"tags":[{"name":"ipc","slug":"ipc","permalink":"https://riverferry.site/tags/ipc/"}],"keywords":[]},{"title":"信号和信号处理函数","slug":"2020-04-07-linux-信号","date":"2020-04-07T00:00:00.000Z","updated":"2022-09-12T16:24:32.280Z","comments":true,"path":"2020-04-07-linux-信号/","link":"","permalink":"https://riverferry.site/2020-04-07-linux-%E4%BF%A1%E5%8F%B7/","excerpt":"参考Linux信号（signal) 机制分析 SIGSEGV 和 SIGBUS &amp; gdb看汇编","text":"参考Linux信号（signal) 机制分析 SIGSEGV 和 SIGBUS &amp; gdb看汇编 信号信号是软件中断,很多比较重要的应用程序都需处理信号.信号提供了一种处理异步事件的方法，例如,终端用户键入中断键，会通过信号机制停止一个程序，或及早终止管道中的下一个程序. 常见信号1) SIGHUP 2) SIGINT 3) SIGQUIT 4) SIGILL 5) SIGTRAP 6) SIGABRT 7) SIGBUS 8) SIGFPE 9) SIGKILL 10) SIGUSR1 11) SIGSEGV 12) SIGUSR2 13) SIGPIPE 14) SIGALRM 15) SIGTERM 16) SIGSTKFLT 17) SIGCHLD 18) SIGCONT 19) SIGSTOP 20) SIGTSTP 21) SIGTTIN 22) SIGTTOU 23) SIGURG 24) SIGXCPU 25) SIGXFSZ 26) SIGVTALRM 27) SIGPROF 28) SIGWINCH 29) SIGIO 30) SIGPWR 31) SIGSYS 34) SIGRTMIN 35) SIGRTMIN+1 36) SIGRTMIN+2 37) SIGRTMIN+3 38) SIGRTMIN+4 39) SIGRTMIN+5 40) SIGRTMIN+6 41) SIGRTMIN+7 42) SIGRTMIN+8 43) SIGRTMIN+9 44) SIGRTMIN+10 45) SIGRTMIN+11 46) SIGRTMIN+12 47) SIGRTMIN+13 48) SIGRTMIN+14 49) SIGRTMIN+15 50) SIGRTMAX-14 51) SIGRTMAX-13 52) SIGRTMAX-12 53) SIGRTMAX-11 54) SIGRTMAX-10 55) SIGRTMAX-9 56) SIGRTMAX-8 57) SIGRTMAX-7 58) SIGRTMAX-6 59) SIGRTMAX-5 60) SIGRTMAX-4 61) SIGRTMAX-3 62) SIGRTMAX-2 63) SIGRTMAX-1 64) SIGRTMAX 信号的分类前32种信号表示非实时信号，是不可靠的，信号不能排队，可能丢失 不知道为什么kill列出的信号没有32的值,但在signal.h中是SIGRTMIN=32 #define SIGRTMIN 32 后32个信号表示实时信号，是可靠的，支持排队 SIGHUP如果终端接口检测到一个连接断开,则将此信号送给与该终端相关的控制进程(会话首进程)。此信号被送给session结构中s_leader字段所指向的进程。仅当终端的CLOCAL标志没有设置时，在上述条件下才产生此信号。(详情以后研究)接到此信号的会话首进程也可能在后台，这区别与由终端正常产生的几个信号(中断，退出和挂起)，这些信号总是传递给前台进程组中的每一个进程如果会话首进程终止，也产生此信号。在这种情况下，此信号送给前台进程组中的每一个进程。通常用此信号通知守护进程再次读取他们的配置文件。选用SIGHUP的理由是，守护进程不会有控制终端，通常绝不会收到此种信号。 SIGINT当用户按中断键(一般采用DELETE/CRTL+C)时，终端驱动程序产生此信号并发送至前台进程组中的每一个进程。当一个进程在运行时失控，特别是它正在屏幕上产生大量不需要的输出时，常用此信号终止它。对后台进程不起作用 SIGQUIT当用户在终端上按退出键(一般采用CTRL+)时，中断驱动程序产生此信号，并发送给前台进程组的所有进程。此信号不仅终止前台进程组(如SIGINT所作的那样)，同时产生一个core文件。对后台进程不起作用 SIGILL此信号表示进程已执行一条非法硬件指令。 SIGTRAP表示一个实现定义的硬件故障 此信号名来自于PDP-11的TRAP指令。当执行断点指令时，实现常用此信号将控制转移至调试程序。gdb有时候会产生此信号,后续研究 SIGABRT调用abort（英 /əˈbɔːt/ ）函数产生此信号，进程异常终止 SIGBUS表示一个实现定义的硬件故障。当出现某些类型的内存故障时，实现常常产生此信号。所述SIGBUS信号被发送到时它会导致一流程总线错误。导致发送信号的条件是例如错误的内存访问对齐或不存在的物理地址。 SIGALRM在POSIX兼容的平台上，SIGALRM是在定时器终止时发送给进程的信号。它们的符号常量在头文件signal.h中定义。在不同的平台上，信号的编号可能发生变化，因此需要使用符号名称。 SIGCHLD当某一子进程结束、中断或恢复执行时，内核会发送SIGCHLD信号予其父进程。在默认情况下，父进程会以SIG_IGN函数忽略之 SIGFPE在POSIX兼容的平台上，SIGFPE是当一个进程执行了一个错误的算术操作(除0，浮点溢出)时发送给它的信号。SIGFPE的符号常量在头文件signal.h中定义。因为在不同平台上，信号数字可能变化，因此常使用信号名称 SIGIO and SIGPOLL当在明确监视的文件描述符上发生事件时，将发送SIGPOLL信号。[14]有效使用它会导致发出异步I / O请求，因为内核将轮询描述符代替调用者。它提供了主动轮询的替代方法。 SIGPIPESIGPIPE信号在尝试写入管道而没有另一端连接进程时将其发送到进程。 SIGSEGV如果进程尝试访问其虚拟地址空间之外的内存地址，则内核将通过SIGSEGV信号将该冲突通知进程 SIGKILLSIGKILL信号被发送到一个进程，以使其立即终止（kill）。与SIGTERM和SIGINT相比，此信号无法捕获或忽略，并且接收过程在接收到此信号后无法执行任何清理。下列例外情况适用： 僵尸进程无法被杀死，因为它们已经死亡并且正在等待其父进程获得它们。 处于阻塞状态的进程只有在再次唤醒后才会消失。 在初始化过程是特殊的：它没有得到信号，它不希望处理，因此可以忽略SIGKILL。[10]从这个规则的一个例外是当init的ptraced在Linux上。[11] [12] 一个不可中断睡眠过程中不得终止（并释放其资源）发送SIGKILL也是如此。这是为解决临时软件问题而必须重新引导UNIX系统的少数情况之一。 如果在大多数系统关闭过程中终止进程，并且没有响应SIGTERM而自动退出，则SIGKILL将用作最后的手段。为了加快计算机关闭过程的速度，Mac OS X 10.6（也称为Snow Leopard）会将SIGKILL发送给标记为“干净”的应用程序，从而缩短了关闭时间，并且没有不良影响。[13]该命令killall -9在Linux中执行时具有类似的危险效果。它不允许程序保存未保存的数据。它具有其他选择，并且没有其他选择使用更安全的SIGTERM信号。 SIGTERMSIGTERM信号被发送到进程以请求终止。与SIGKILL信号不同，该信号可以被过程捕获，解释或忽略。这允许进程执行适当的终止，以释放资源并在适当时保存状态。SIGINT与SIGTERM几乎相同。 SIGSTOP作业控制信号，停止一个进程，不能被捕捉或忽略 SIGTRAP发生异常（或陷阱）时，将SIGTRAP信号发送到进程：调试器已要求通知的条件-例如，当执行特定功能时，或当特定变量更改值时。 当执行断点指令时，实现常用此信号将控制转移到调试程序 SIGURG当套接字具有可读取的紧急或带外数据时，将SIGURG信号发送到进程。 SIGUSR1 and SIGUSR2SIGUSR1和SIGUSR2信号被发送到进程以指示用户定义的条件。 信号处理函数Fake signal functions1234/* Fake signal functions. */#define SIG_ERR ((__sighandler_t) -1) /* Error return. */#define SIG_DFL ((__sighandler_t) 0) /* Default action. */#define SIG_IGN ((__sighandler_t) 1) /* Ignore signal. */ signal12345/* Type of a signal handler. */typedef void (*__sighandler_t) (int);#ifdef __USE_BSDextern __sighandler_t signal (int __sig, __sighandler_t __handler) DEMO 123456789101112131415161718192021222324252627282930#include &lt;iostream&gt;#include &lt;unistd.h&gt;#include &lt;signal.h&gt;using namespace std;static void sig(int signo)&#123; if (SIGUSR1 == signo) cout &lt;&lt; &quot;recv SIGUSR1&quot; &lt;&lt; endl; else if (SIGUSR2 == signo) cout &lt;&lt; &quot;recv SIGUSR2&quot; &lt;&lt; endl; else cout &lt;&lt; &quot;signal num is &quot; &lt;&lt; signo &lt;&lt; endl;&#125;int main()&#123; if (signal(SIGUSR1, sig) == SIG_ERR) cout &lt;&lt; &quot;can,t catch SIGUSR1&quot; &lt;&lt; endl; if (signal(SIGUSR2, sig) == SIG_ERR) cout &lt;&lt; &quot;can,t catch SIGUSR2&quot; &lt;&lt; endl; while(true) pause(); return 0;&#125; [root@localhost signal]# kill -USR1 16747 [root@localhost signal]# recv SIGUSR1 ^C [root@localhost signal]# kill -USR2 16747 [root@localhost signal]# recv SIGUSR2 ^C sigactionsigemptyset1234//sigemptyset() initializes the signal set given by set to empty, with all signals excluded from the set.int sigemptyset(sigset_t *set); sigfillset123456//sigfillset() initializes set to full, including all signals.int sigfillset(sigset_t *set); sigaddset/sigdelset12345//sigaddset() and sigdelset() add and delete respectively signal signum from set.int sigaddset(sigset_t *set, int signum); int sigdelset(sigset_t *set, int signum); sigismember12345//sigismember() tests whether signum is a member of set.int sigismember(const sigset_t *set, int signum); ending","categories":[],"tags":[{"name":"ipc","slug":"ipc","permalink":"https://riverferry.site/tags/ipc/"}],"keywords":[]},{"title":"linux-文件系统","slug":"2020-04-07-linux-文件系统","date":"2020-04-07T00:00:00.000Z","updated":"2022-09-12T16:24:32.280Z","comments":true,"path":"2020-04-07-linux-文件系统/","link":"","permalink":"https://riverferry.site/2020-04-07-linux-%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/","excerpt":"参考深入理解 ext4 等 Linux 文件系统 认识 Linux 文件系统","text":"参考深入理解 ext4 等 Linux 文件系统 认识 Linux 文件系统 ending","categories":[],"tags":[{"name":"坑","slug":"坑","permalink":"https://riverferry.site/tags/%E5%9D%91/"}],"keywords":[]},{"title":"mmap共享内存","slug":"2020-04-07-mmap共享内存","date":"2020-04-07T00:00:00.000Z","updated":"2022-09-12T16:24:32.280Z","comments":true,"path":"2020-04-07-mmap共享内存/","link":"","permalink":"https://riverferry.site/2020-04-07-mmap%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98/","excerpt":"参考brk/mmap 认真分析mmap：是什么 为什么 怎么用 Linux内存分配小结–malloc、brk、mmap 十三 Linux内存管理之vma/malloc/mmap linux mmap 详解","text":"参考brk/mmap 认真分析mmap：是什么 为什么 怎么用 Linux内存分配小结–malloc、brk、mmap 十三 Linux内存管理之vma/malloc/mmap linux mmap 详解 函数定义//用户空间函数 void *mmap(void *start, size_t length, int prot, int flags, int fd, off_t offset); //内核空间函数 int mmap(struct file *filp, struct vm_area_struct *vma) task_struct结构是linux上pcb的实现，用户空间函数mmap创建vm_area_struct数据结构，映射到进程的虚拟地址空间内核空间函数mmap建立页表，将文件磁盘地址和虚拟空间地址进行映射 linux加载可执行程序(ELF)就是使用的mmap mmap和read/write的区别read/write是系统调用函数，用于内核态和用户态之间的数据读写。文件磁盘的数据–&gt;buffer/cache–&gt;用户空间而mmap函数本身只是建立了一种进程虚拟地址空间到文件磁盘的映射关系，实际访问映射的这块地址时，才发生缺页异常，由操作系统将文件内容复制到内存的一个区域。文件磁盘的数据-&gt;内存中的页框(用户空间可见) 性能差异主要是系统调用，额外的复制与页错误的差异。 mmap与malloc 1、brk是将数据段(.data)的最高地址指针_edata往高地址推；2、mmap是在进程的虚拟地址空间中（堆和栈中间，称为文件映射区域的地方）找一块空闲的虚拟内存。 brk/mmap各有优略 brk会造成一定程度的内存碎片问题，指针移到高位，地位已经释放的虚拟内存一定时间内未使用.但已经释放的虚拟内存不会立即返回给OS，有一定的缓存作用 mmap会造成多次缺页异常(size/4k),但是申请的虚拟内存是在栈和堆中间的区域，可以随时释放(munmap) mallopt() could set parameters to control behavior of malloc(), and there is a parameter named M_MMAP_THRESHOLD, in general: 如果请求的内存少于它，brk()将使用； 如果请求的内存大于或等于它，mmap()则将使用； brk/mmap实现 图片来自:十三 Linux内存管理之vma/malloc/mmap sys_brk sys_mmap brk/sbrk int brk(void *addr); brk() sets the end of the data segment to the value specified by addr, when that value is reasonable, the system has enough memory, and the process does not exceed its maximum data size. On success, brk() returns zero. On error, -1 is returned, and errno is set to ENOMEM. void *sbrk(intptr_t increment); sbrk() increments the program’s data space by increment bytes. Calling sbrk() with an increment of 0 can be used to find the current location of the program break. On success, sbrk() returns the previous program break. (If the break was increased, then this value is a pointer to the start of the newly allocated memory). On error, (void *) -1 is returned, and errno is set to ENOMEM. 要注意的问题1 映射文件的5000个字节实际映射到内存中的是2页(2*4k)，5000-8191之间在内存中值是0 2 文件5000字节，映射15000字节。实际内存中是2页(2*4k),8192-15000之间不可读(sigbus) 3 文件初始大小为0，映射10004K的大小,只要访问ptr指针前，扩展文件大小n字节(n&lt;10004k),则0-n之间的空间是可以读写并更新到文件的 free命令[root@localhost ~]# free total used free shared buffers cached Mem: 3869020 3439104 429916 61128 764 400284 -/+ buffers/cache: 3038056 830964 Swap: 4079612 0 4079612 第一行的used/free就是使用和剩余的实际内存,buffers/cached是内存中缓冲磁盘文件的区域，随时可能被换掉的 第二行的used/free是第一行中实际使用内存减去buffers/cached后剩余的空间下的[used/free used = 3439104 - 764 - 400284 = 3038056]swap是内存中没被当前使用的部分缓冲到磁盘中，作为back log的区域，在使用的时候再加载回内存 ending","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://riverferry.site/tags/linux/"}],"keywords":[]},{"title":"操作系统-文件系统","slug":"2020-04-07-操作系统-文件系统","date":"2020-04-07T00:00:00.000Z","updated":"2022-09-12T16:24:32.280Z","comments":true,"path":"2020-04-07-操作系统-文件系统/","link":"","permalink":"https://riverferry.site/2020-04-07-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/","excerpt":"参考硬盘基本知识（磁头、磁道、扇区、柱面）","text":"参考硬盘基本知识（磁头、磁道、扇区、柱面） ending","categories":[],"tags":[{"name":"坑","slug":"坑","permalink":"https://riverferry.site/tags/%E5%9D%91/"}],"keywords":[]},{"title":"类对象内存布局","slug":"2020-04-07-类对象内存布局","date":"2020-04-07T00:00:00.000Z","updated":"2022-09-12T16:24:32.281Z","comments":true,"path":"2020-04-07-类对象内存布局/","link":"","permalink":"https://riverferry.site/2020-04-07-%E7%B1%BB%E5%AF%B9%E8%B1%A1%E5%86%85%E5%AD%98%E5%B8%83%E5%B1%80/","excerpt":"参考C++ 对象的内存布局 图说C++对象模型：对象内存布局详解","text":"参考C++ 对象的内存布局 图说C++对象模型：对象内存布局详解 ending","categories":[],"tags":[{"name":"坑","slug":"坑","permalink":"https://riverferry.site/tags/%E5%9D%91/"}],"keywords":[]},{"title":"linux-posix信号量","slug":"2020-04-07-linux-posix信号量","date":"2020-04-07T00:00:00.000Z","updated":"2022-09-12T16:24:32.280Z","comments":true,"path":"2020-04-07-linux-posix信号量/","link":"","permalink":"https://riverferry.site/2020-04-07-linux-posix%E4%BF%A1%E5%8F%B7%E9%87%8F/","excerpt":"参考UNP 概述信号量（英语：semaphore）又称为信号标，是一个同步对象，用于保持在0至指定最大值之间的一个计数值。当线程完成一次对该semaphore对象的等待（wait）时，该计数值减一；当线程完成一次对semaphore对象的释放（release）时，计数值加一。当计数值为0，则线程等待该semaphore对象不再能成功直至该semaphore对象变成signaled状态。semaphore对象的计数值大于0，为signaled状态；计数值等于0，为nonsignaled状态.","text":"参考UNP 概述信号量（英语：semaphore）又称为信号标，是一个同步对象，用于保持在0至指定最大值之间的一个计数值。当线程完成一次对该semaphore对象的等待（wait）时，该计数值减一；当线程完成一次对semaphore对象的释放（release）时，计数值加一。当计数值为0，则线程等待该semaphore对象不再能成功直至该semaphore对象变成signaled状态。semaphore对象的计数值大于0，为signaled状态；计数值等于0，为nonsignaled状态. semaphore对象适用于控制一个仅支持有限个用户的共享资源，是一种不需要使用忙碌等待（busy waiting）的方法。 信号量的概念是由荷兰计算机科学家艾兹赫尔·戴克斯特拉（Edsger W. Dijkstra）发明的，广泛的应用于不同的操作系统中。在系统中，给予每一个进程一个信号量，代表每个进程当前的状态，未得到控制权的进程会在特定地方被强迫停下来，等待可以继续进行的信号到来。如果信号量是一个任意的整数，通常被称为计数信号量（Counting semaphore），或一般信号量（general semaphore）；如果信号量只有二进制的0或1，称为二进制信号量（binary semaphore）。在linux系统中，二进制信号量（binary semaphore）又称互斥锁 信号量的分类 POSIX有名信号量(基于文件的信号量) POSIX无名信号量(基于内存的信号量) System V信号量(暂时不研究) 如果信号量的实现用到了映射文件,那么信号量的真正值确实出现在某个文件中，而该文件是映射到所有让该信号量打开着的进程的地址空间的. 函数调用 123456789101112131415161718192021222324252627282930313233343536373839404142/* Initialize semaphore object SEM to VALUE. If PSHARED then share it with other processes. */extern int sem_init (sem_t *__sem, int __pshared, unsigned int __value) __THROW;/* Free resources associated with semaphore object SEM. */extern int sem_destroy (sem_t *__sem) __THROW;/* Open a named semaphore NAME with open flags OFLAG. */extern sem_t *sem_open (const char *__name, int __oflag, ...) __THROW;/* Close descriptor for named semaphore SEM. */extern int sem_close (sem_t *__sem) __THROW;/* Remove named semaphore NAME. */extern int sem_unlink (const char *__name) __THROW;/* Wait for SEM being posted. This function is a cancellation point and therefore not marked with __THROW. */extern int sem_wait (sem_t *__sem);#ifdef __USE_XOPEN2K/* Similar to `sem_wait&#x27; but wait only until ABSTIME. This function is a cancellation point and therefore not marked with __THROW. */extern int sem_timedwait (sem_t *__restrict __sem, const struct timespec *__restrict __abstime);#endif/* Test whether SEM is posted. */extern int sem_trywait (sem_t *__sem) __THROWNL;/* Post SEM. */extern int sem_post (sem_t *__sem) __THROWNL;/* Get current value of SEM and store it in *SVAL. */extern int sem_getvalue (sem_t *__restrict __sem, int *__restrict __sval) __THROW; 数据结构123456789101112131415161718192021#define __SIZEOF_SEM_T 16/* Value returned if `sem_open&#x27; failed. */#define SEM_FAILED ((sem_t *) 0)typedef union&#123; char __size[__SIZEOF_SEM_T]; long int __align;&#125; sem_t;/* Semaphore variable structure. */struct new_sem&#123; unsigned int value; int private; unsigned long int nwaiters;&#125;; sem_init1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162int__new_sem_init (sem, pshared, value) sem_t *sem; int pshared; unsigned int value;&#123; /* Parameter sanity check. */ if (__builtin_expect (value &gt; SEM_VALUE_MAX, 0)) &#123; __set_errno (EINVAL); return -1; &#125; /* Map to the internal type. */ struct new_sem *isem = (struct new_sem *) sem; /* Use the values the user provided. */ isem-&gt;value = value;#ifdef __ASSUME_PRIVATE_FUTEX isem-&gt;private = pshared ? 0 : FUTEX_PRIVATE_FLAG;#else isem-&gt;private = pshared ? 0 : THREAD_GETMEM (THREAD_SELF, header.private_futex);#endif isem-&gt;nwaiters = 0; return 0;&#125;versioned_symbol (libpthread, __new_sem_init, sem_init, GLIBC_2_1);#if SHLIB_COMPAT(libpthread, GLIBC_2_0, GLIBC_2_1)intattribute_compat_text_section__old_sem_init (sem, pshared, value) sem_t *sem; int pshared; unsigned int value;&#123; /* Parameter sanity check. */ if (__builtin_expect (value &gt; SEM_VALUE_MAX, 0)) &#123; __set_errno (EINVAL); return -1; &#125; /* Map to the internal type. */ struct old_sem *isem = (struct old_sem *) sem; /* Use the value the user provided. */ isem-&gt;value = value; /* We cannot store the PSHARED attribute. So we always use the operations needed for shared semaphores. */ return 0;&#125;compat_symbol (libpthread, __old_sem_init, sem_init, GLIBC_2_0);#endif sem_destroy123456789int__new_sem_destroy (sem) sem_t *sem;&#123; /* XXX Check for valid parameter. */ /* Nothing to do. */ return 0;&#125; sem_open123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184sem_t *sem_open (const char *name, int oflag, ...)&#123; char *finalname; sem_t *result = SEM_FAILED; int fd; /* Determine where the shmfs is mounted. */ __pthread_once (&amp;__namedsem_once, __where_is_shmfs); /* If we don&#x27;t know the mount points there is nothing we can do. Ever. */ if (mountpoint.dir == NULL) &#123; __set_errno (ENOSYS); return SEM_FAILED; &#125; /* Construct the filename. */ while (name[0] == &#x27;/&#x27;) ++name; if (name[0] == &#x27;\\0&#x27;) &#123; /* The name &quot;/&quot; is not supported. */ __set_errno (EINVAL); return SEM_FAILED; &#125; size_t namelen = strlen (name) + 1; /* Create the name of the final file. */ finalname = (char *) alloca (mountpoint.dirlen + namelen); __mempcpy (__mempcpy (finalname, mountpoint.dir, mountpoint.dirlen), name, namelen); /* If the semaphore object has to exist simply open it. */ if ((oflag &amp; O_CREAT) == 0 || (oflag &amp; O_EXCL) == 0) &#123; try_again: fd = __libc_open (finalname, (oflag &amp; ~(O_CREAT|O_ACCMODE)) | O_NOFOLLOW | O_RDWR); if (fd == -1) &#123; /* If we are supposed to create the file try this next. */ if ((oflag &amp; O_CREAT) != 0 &amp;&amp; errno == ENOENT) goto try_create; /* Return. errno is already set. */ &#125; else /* Check whether we already have this semaphore mapped and create one if necessary. */ result = check_add_mapping (name, namelen, fd, SEM_FAILED); &#125; else &#123; /* We have to open a temporary file first since it must have the correct form before we can start using it. */ char *tmpfname; mode_t mode; unsigned int value; va_list ap; try_create: va_start (ap, oflag); mode = va_arg (ap, mode_t); value = va_arg (ap, unsigned int); va_end (ap); if (value &gt; SEM_VALUE_MAX) &#123; __set_errno (EINVAL); return SEM_FAILED; &#125; /* Create the initial file content. */ union &#123; sem_t initsem; struct new_sem newsem; &#125; sem; sem.newsem.value = value; sem.newsem.private = 0; sem.newsem.nwaiters = 0; /* Initialize the remaining bytes as well. */ memset ((char *) &amp;sem.initsem + sizeof (struct new_sem), &#x27;\\0&#x27;, sizeof (sem_t) - sizeof (struct new_sem)); tmpfname = (char *) alloca (mountpoint.dirlen + 6 + 1); char *xxxxxx = __mempcpy (tmpfname, mountpoint.dir, mountpoint.dirlen); int retries = 0;#define NRETRIES 50 while (1) &#123; /* Add the suffix for mktemp. */ strcpy (xxxxxx, &quot;XXXXXX&quot;); /* We really want to use mktemp here. We cannot use mkstemp since the file must be opened with a specific mode. The mode cannot later be set since then we cannot apply the file create mask. */ if (mktemp (tmpfname) == NULL) return SEM_FAILED; /* Open the file. Make sure we do not overwrite anything. */ fd = __libc_open (tmpfname, O_RDWR | O_CREAT | O_EXCL, mode); if (fd == -1) &#123; if (errno == EEXIST) &#123; if (++retries &lt; NRETRIES) continue; __set_errno (EAGAIN); &#125; return SEM_FAILED; &#125; /* We got a file. */ break; &#125; if (TEMP_FAILURE_RETRY (__libc_write (fd, &amp;sem.initsem, sizeof (sem_t))) == sizeof (sem_t) /* Map the sem_t structure from the file. */ &amp;&amp; (result = (sem_t *) mmap (NULL, sizeof (sem_t), PROT_READ | PROT_WRITE, MAP_SHARED, fd, 0)) != MAP_FAILED) &#123; /* Create the file. Don&#x27;t overwrite an existing file. */ if (link (tmpfname, finalname) != 0) &#123; /* Undo the mapping. */ (void) munmap (result, sizeof (sem_t)); /* Reinitialize &#x27;result&#x27;. */ result = SEM_FAILED; /* This failed. If O_EXCL is not set and the problem was that the file exists, try again. */ if ((oflag &amp; O_EXCL) == 0 &amp;&amp; errno == EEXIST) &#123; /* Remove the file. */ (void) unlink (tmpfname); /* Close the file. */ (void) __libc_close (fd); goto try_again; &#125; &#125; else /* Insert the mapping into the search tree. This also determines whether another thread sneaked by and already added such a mapping despite the fact that we created it. */ result = check_add_mapping (name, namelen, fd, result); &#125; /* Now remove the temporary name. This should never fail. If it fails we leak a file name. Better fix the kernel. */ (void) unlink (tmpfname); &#125; /* Map the mmap error to the error we need. */ if (MAP_FAILED != (void *) SEM_FAILED &amp;&amp; result == MAP_FAILED) result = SEM_FAILED; /* We don&#x27;t need the file descriptor anymore. */ if (fd != -1) &#123; /* Do not disturb errno. */ INTERNAL_SYSCALL_DECL (err); INTERNAL_SYSCALL (close, err, 1, fd); &#125; return result;&#125; sem_close12345678910111213141516171819202122232425262728293031323334353637383940intsem_close (sem) sem_t *sem;&#123; int result = 0; /* Get the lock. */ lll_lock (__sem_mappings_lock, LLL_PRIVATE); /* Locate the entry for the mapping the caller provided. */ rec = NULL; the_sem = sem; twalk (__sem_mappings, walker); if (rec != NULL) &#123; /* Check the reference counter. If it is going to be zero, free all the resources. */ if (--rec-&gt;refcnt == 0) &#123; /* Remove the record from the tree. */ (void) tdelete (rec, &amp;__sem_mappings, __sem_search); result = munmap (rec-&gt;sem, sizeof (sem_t)); free (rec); &#125; &#125; else &#123; /* This is no valid semaphore. */ result = -1; __set_errno (EINVAL); &#125; /* Release the lock. */ lll_unlock (__sem_mappings_lock, LLL_PRIVATE); return result;&#125; sem_unlink1234567891011121314151617181920212223242526272829303132333435363738394041intsem_unlink (name) const char *name;&#123; char *fname; size_t namelen; /* Determine where the shmfs is mounted. */ __pthread_once (&amp;__namedsem_once, __where_is_shmfs); /* If we don&#x27;t know the mount points there is nothing we can do. Ever. */ if (mountpoint.dir == NULL) &#123; __set_errno (ENOSYS); return -1; &#125; /* Construct the filename. */ while (name[0] == &#x27;/&#x27;) ++name; if (name[0] == &#x27;\\0&#x27;) &#123; /* The name &quot;/&quot; is not supported. */ __set_errno (ENOENT); return -1; &#125; namelen = strlen (name); /* Create the name of the file. */ fname = (char *) alloca (mountpoint.dirlen + namelen + 1); __mempcpy (__mempcpy (fname, mountpoint.dir, mountpoint.dirlen), name, namelen + 1); /* Now try removing it. */ int ret = unlink (fname); if (ret &lt; 0 &amp;&amp; errno == EPERM) __set_errno (EACCES); return ret;&#125; sem_wait1234567891011121314151617181920212223242526272829303132333435363738int__new_sem_wait (sem_t *sem)&#123; struct sparc_new_sem *isem = (struct sparc_new_sem *) sem; int err; if (atomic_decrement_if_positive (&amp;isem-&gt;value) &gt; 0) return 0; atomic_increment (&amp;isem-&gt;nwaiters); pthread_cleanup_push (__sem_wait_cleanup, isem); while (1) &#123; err = do_futex_wait(isem); if (err != 0 &amp;&amp; err != -EWOULDBLOCK) &#123; __set_errno (-err); err = -1; break; &#125; if (atomic_decrement_if_positive (&amp;isem-&gt;value) &gt; 0) &#123; err = 0; break; &#125; &#125; pthread_cleanup_pop (0); atomic_decrement (&amp;isem-&gt;nwaiters); return err;&#125;versioned_symbol (libpthread, __new_sem_wait, sem_wait, GLIBC_2_1); sem_timedwait12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970intsem_timedwait (sem_t *sem, const struct timespec *abstime)&#123; struct new_sem *isem = (struct new_sem *) sem; int err; if (atomic_decrement_if_positive (&amp;isem-&gt;value) &gt; 0) return 0; if (abstime-&gt;tv_nsec &lt; 0 || abstime-&gt;tv_nsec &gt;= 1000000000) &#123; __set_errno (EINVAL); return -1; &#125; atomic_increment (&amp;isem-&gt;nwaiters); pthread_cleanup_push (__sem_wait_cleanup, isem); while (1) &#123; struct timeval tv; struct timespec rt; int sec, nsec; /* Get the current time. */ __gettimeofday (&amp;tv, NULL); /* Compute relative timeout. */ sec = abstime-&gt;tv_sec - tv.tv_sec; nsec = abstime-&gt;tv_nsec - tv.tv_usec * 1000; if (nsec &lt; 0) &#123; nsec += 1000000000; --sec; &#125; /* Already timed out? */ if (sec &lt; 0) &#123; __set_errno (ETIMEDOUT); err = -1; break; &#125; /* Do wait. */ rt.tv_sec = sec; rt.tv_nsec = nsec; err = do_futex_timed_wait(isem, &amp;rt); if (err != 0 &amp;&amp; err != -EWOULDBLOCK) &#123; __set_errno (-err); err = -1; break; &#125; if (atomic_decrement_if_positive (&amp;isem-&gt;value) &gt; 0) &#123; err = 0; break; &#125; &#125; pthread_cleanup_pop (0); atomic_decrement (&amp;isem-&gt;nwaiters); return err;&#125; sem_trywait1234567891011121314151617int__new_sem_trywait (sem_t *sem)&#123; int *futex = (int *) sem; int val; if (*futex &gt; 0) &#123; val = atomic_decrement_if_positive (futex); if (val &gt; 0) return 0; &#125; __set_errno (EAGAIN); return -1;&#125;versioned_symbol (libpthread, __new_sem_trywait, sem_trywait, GLIBC_2_1); sem_post123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051int__new_sem_post (sem_t *sem)&#123; struct new_sem *isem = (struct new_sem *) sem; __typeof (isem-&gt;value) cur; do &#123; cur = isem-&gt;value; if (isem-&gt;value == SEM_VALUE_MAX) &#123; __set_errno (EOVERFLOW); return -1; &#125; &#125; while (atomic_compare_and_exchange_bool_rel (&amp;isem-&gt;value, cur + 1, cur)); atomic_full_barrier (); if (isem-&gt;nwaiters &gt; 0) &#123; int err = lll_futex_wake (&amp;isem-&gt;value, 1, isem-&gt;private ^ FUTEX_PRIVATE_FLAG); if (__builtin_expect (err, 0) &lt; 0) &#123; __set_errno (-err); return -1; &#125; &#125; return 0;&#125;versioned_symbol (libpthread, __new_sem_post, sem_post, GLIBC_2_1);#if SHLIB_COMPAT (libpthread, GLIBC_2_0, GLIBC_2_1)intattribute_compat_text_section__old_sem_post (sem_t *sem)&#123; int *futex = (int *) sem; (void) atomic_increment_val (futex); /* We always have to assume it is a shared semaphore. */ int err = lll_futex_wake (futex, 1, LLL_SHARED); if (__builtin_expect (err, 0) &lt; 0) &#123; __set_errno (-err); return -1; &#125; return 0;&#125;compat_symbol (libpthread, __old_sem_post, sem_post, GLIBC_2_0); sem_getvalue1234567891011121314int__new_sem_getvalue (sem, sval) sem_t *sem; int *sval;&#123; struct new_sem *isem = (struct new_sem *) sem; /* XXX Check for valid SEM parameter. */ *sval = isem-&gt;value; return 0;&#125;versioned_symbol (libpthread, __new_sem_getvalue, sem_getvalue, GLIBC_2_1); 伪代码P wait P操作，荷兰语，尝试的意思 123while (semaphore_value &lt;= 0) ;semaphore_value--; V post V操作，荷兰语增加的意思 1semaphore_value++; 互斥锁and条件变量and信号量de差异 信号量增加和减少必须是原子操作atomic 互斥锁必须总是由给它上锁的线程解锁，信号量的挂出却不必由执行过它的等待操作的同一线程执行 互斥锁是二值信号量，要么锁住，要么解开，只有0和1的值，计数信号量的值可以很大 当向一个条件变量发送信号，如果没有线程等待在条件变量的队列，则信号会丢失。但是信号量的计数值会保存计数状态，不会丢失 当持有某个记录锁的进程没有释放它就终止时，内核自动释放锁。但内核不对信号量解锁（内核持续期间有效） 条件变量不是异步信号安全的，能够从信号处理程序中安全调用的唯一函数是sem_post 互斥锁也可以用于进程间，信号量也可以用于线程间，应该使用适合具体应用的那组原语 互斥锁是为上锁而优化的，条件变量是为等待而优化的，信号量既可以用于上锁，也可用于等待，因而可能导致更多的开销和更高的复杂性 有名信号量实现代码TODO 无名信号量实现代码TODO ending","categories":[],"tags":[{"name":"ipc","slug":"ipc","permalink":"https://riverferry.site/tags/ipc/"}],"keywords":[]},{"title":"linux-互斥锁和条件变量","slug":"2020-04-07-linux-posix互斥锁和条件变量 ","date":"2020-04-07T00:00:00.000Z","updated":"2022-09-12T16:24:32.280Z","comments":true,"path":"2020-04-07-linux-posix互斥锁和条件变量 /","link":"","permalink":"https://riverferry.site/2020-04-07-linux-posix%E4%BA%92%E6%96%A5%E9%94%81%E5%92%8C%E6%9D%A1%E4%BB%B6%E5%8F%98%E9%87%8F%20/","excerpt":"参考Posix线程编程指南(3) glibc nptl库pthread_mutex_lock和pthread_mutex_unlock浅析","text":"参考Posix线程编程指南(3) glibc nptl库pthread_mutex_lock和pthread_mutex_unlock浅析 概念互斥锁和条件变量出自posix.1线程标准，它们总是可用来同步一个进程内的各个线程的，如果一个互斥锁或条件变量存放在多个进程间共享的某个内存区内，那么posix还允许它用于这些个进程间的同步。 Posix mutex 互斥锁（英语：Mutual exclusion，缩写 Mutex）是一种用于多线程编程中，防止两条线程同时对同一公共资源（比如全局变量）进行读写的机制。该目的通过将代码切片成一个一个的临界区域（critical section）达成。临界区域指的是一块对公共资源进行访问的代码，并非一种机制或是算法。一个程序、进程、线程可以拥有多个临界区域，但是并不一定会应用互斥锁。 Posix Thread中的条件变量 pthread中，条件变量实际上是一个阻塞线程处于睡眠状态的线程队列。每个条件变量都必须与一个（且建议只能是一个）互斥锁配套使用。一个线程首先获得互斥锁，然后检查或者修改“条件”；如果条件不成立，则调用pthread_cond_wait()，依次实施3个操作： 1 对当前互斥锁解锁（以便其它线程可以访问或者修改“条件”）2 把线程自身阻塞挂起到互斥锁的线程队列中 3 被其它线程的信号从互斥锁的线程队列唤醒后，对当前配套的互斥锁申请加锁，如果加锁未能成功，则阻塞挂起到当前互斥锁上。pthread_cond_wait() 函数将不返回直到线程获得配套的互斥锁。 线程离开“条件”的临界区时，必须对当前互斥锁执行解锁。 NPTLNative POSIX Thread Library Native POSIX Thread Library（NPTL）是Linux内核中实践POSIX Threads标准的库 在Linux内核2.6出现之前进程是(最小)可调度的对象，当时的Linux不真正支持线程。但是Linux内核有一个系统调用指令clone()，这个指令产生一个调用调用的进程的复件，而且这个复件与原进程使用同一地址空间。LinuxThreads计划使用这个系统调用来提供一个内核级的线程支持。但是这个解决方法与真正的POSIX标准有一些不兼容的地方，尤其是在信号处理、进程调度和进程间同步原语方面。 要提高LinuxThreads的效应很明显需要提供内核支持以及必须重写线程函数库。为了解决这个问题出现了两个互相竞争的项目：一个IBM的组的项目叫做NGPT（Next Generation POSIX Threads，下一代POSIX线程），另一个组是由Red Hat程序员组成的。2003年中NGPT被放弃，几乎与此同时NPTL公布了。 NPTL首次是随Red Hat Linux 9发表的。此前老式的Linux POSIX线程偶尔会发生系统无法产生线程的毛病，这个毛病的原因是因为在新线程开始的时候系统没有借机先占。当时的Windows系统对这个问题的解决比较好。Red Hat在关于Red Hat Linux 9上的Java的网页上发表了一篇文章称NPTL解决了这个问题[3]。 从第3版开始NPTL是Red Hat Enterprise Linux的一部分，从Linux内核2.6开始它被纳入内核。当前它完全被结合入GNU C 库。 NPTL的解决方法与LinuxThreads类似，内核看到的首要抽象依然是一个进程，新线程是通过clone()系统调用产生的。但是NPTL需要特殊的内核支持来解决同步的原始类型之间互相竞争的状况。在这种情况下线程必须能够入眠和再复苏。用来完成这个任务的原始类型叫做futex。 NPTL是一个所谓的1×1线程函数库。用户产生的线程与内核能够分配的对象之间的联系是一对一的。这是所有线程程序中最简单的。 互斥锁GNU C Library (GNU libc) stable release version 2.17, by Roland McGrath et al. pthread_mutex_t1234567891011121314151617181920/* Data structures for mutex handling. The structure of the attribute type is deliberately not exposed. */typedef union&#123; struct __pthread_mutex_s &#123; int __lock; unsigned int __count; int __owner; unsigned int __nusers; /* KIND must stay at this position in the structure to maintain binary compatibility. */ int __kind; int __spins; __pthread_list_t __list;#define __PTHREAD_MUTEX_HAVE_PREV 1 &#125; __data; char __size[__SIZEOF_PTHREAD_MUTEX_T]; long int __align;&#125; pthread_mutex_t; PTHREAD_MUTEX_INITIALIZER静态初始化的宏 1234567static pthread_mutex_t mutex=PTHREAD_MUTEX_INITIALIZER; pthread_mutex_t mutex=PTHREAD_MUTEX_INITIALIZER;/* Mutex initializers. */#ifdef __PTHREAD_MUTEX_HAVE_PREV# define PTHREAD_MUTEX_INITIALIZER \\ &#123; &#123; 0, 0, 0, 0, 0, 0, &#123; 0, 0 &#125; &#125; &#125; pthread_mutex_init动态初始化的函数(malloc或者分配在共享内存区) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104int__pthread_mutex_init (mutex, mutexattr) pthread_mutex_t *mutex; const pthread_mutexattr_t *mutexattr;&#123; const struct pthread_mutexattr *imutexattr; assert (sizeof (pthread_mutex_t) &lt;= __SIZEOF_PTHREAD_MUTEX_T); imutexattr = (const struct pthread_mutexattr *) mutexattr ?: &amp;default_attr; /* Sanity checks. */ switch (__builtin_expect (imutexattr-&gt;mutexkind &amp; PTHREAD_MUTEXATTR_PROTOCOL_MASK, PTHREAD_PRIO_NONE &lt;&lt; PTHREAD_MUTEXATTR_PROTOCOL_SHIFT)) &#123; case PTHREAD_PRIO_NONE &lt;&lt; PTHREAD_MUTEXATTR_PROTOCOL_SHIFT: break; case PTHREAD_PRIO_INHERIT &lt;&lt; PTHREAD_MUTEXATTR_PROTOCOL_SHIFT:#ifndef __ASSUME_FUTEX_LOCK_PI if (__builtin_expect (tpi_supported == 0, 0)) &#123; int lock = 0; INTERNAL_SYSCALL_DECL (err); int ret = INTERNAL_SYSCALL (futex, err, 4, &amp;lock, FUTEX_UNLOCK_PI, 0, 0); assert (INTERNAL_SYSCALL_ERROR_P (ret, err)); tpi_supported = INTERNAL_SYSCALL_ERRNO (ret, err) == ENOSYS ? -1 : 1; &#125; if (__builtin_expect (tpi_supported &lt; 0, 0)) return ENOTSUP;#endif break; default: /* XXX: For now we don&#x27;t support robust priority protected mutexes. */ if (imutexattr-&gt;mutexkind &amp; PTHREAD_MUTEXATTR_FLAG_ROBUST) return ENOTSUP; break; &#125; /* Clear the whole variable. */ memset (mutex, &#x27;\\0&#x27;, __SIZEOF_PTHREAD_MUTEX_T); /* Copy the values from the attribute. */ mutex-&gt;__data.__kind = imutexattr-&gt;mutexkind &amp; ~PTHREAD_MUTEXATTR_FLAG_BITS; if ((imutexattr-&gt;mutexkind &amp; PTHREAD_MUTEXATTR_FLAG_ROBUST) != 0) &#123;#ifndef __ASSUME_SET_ROBUST_LIST if ((imutexattr-&gt;mutexkind &amp; PTHREAD_MUTEXATTR_FLAG_PSHARED) != 0 &amp;&amp; __set_robust_list_avail &lt; 0) return ENOTSUP;#endif mutex-&gt;__data.__kind |= PTHREAD_MUTEX_ROBUST_NORMAL_NP; &#125; switch (imutexattr-&gt;mutexkind &amp; PTHREAD_MUTEXATTR_PROTOCOL_MASK) &#123; case PTHREAD_PRIO_INHERIT &lt;&lt; PTHREAD_MUTEXATTR_PROTOCOL_SHIFT: mutex-&gt;__data.__kind |= PTHREAD_MUTEX_PRIO_INHERIT_NP; break; case PTHREAD_PRIO_PROTECT &lt;&lt; PTHREAD_MUTEXATTR_PROTOCOL_SHIFT: mutex-&gt;__data.__kind |= PTHREAD_MUTEX_PRIO_PROTECT_NP; int ceiling = (imutexattr-&gt;mutexkind &amp; PTHREAD_MUTEXATTR_PRIO_CEILING_MASK) &gt;&gt; PTHREAD_MUTEXATTR_PRIO_CEILING_SHIFT; if (! ceiling) &#123; if (__sched_fifo_min_prio == -1) __init_sched_fifo_prio (); if (ceiling &lt; __sched_fifo_min_prio) ceiling = __sched_fifo_min_prio; &#125; mutex-&gt;__data.__lock = ceiling &lt;&lt; PTHREAD_MUTEX_PRIO_CEILING_SHIFT; break; default: break; &#125; /* The kernel when waking robust mutexes on exit never uses FUTEX_PRIVATE_FLAG FUTEX_WAKE. */ if ((imutexattr-&gt;mutexkind &amp; (PTHREAD_MUTEXATTR_FLAG_PSHARED | PTHREAD_MUTEXATTR_FLAG_ROBUST)) != 0) mutex-&gt;__data.__kind |= PTHREAD_MUTEX_PSHARED_BIT; /* Default values: mutex not used yet. */ // mutex-&gt;__count = 0; already done by memset // mutex-&gt;__owner = 0; already done by memset // mutex-&gt;__nusers = 0; already done by memset // mutex-&gt;__spins = 0; already done by memset // mutex-&gt;__next = NULL; already done by memset LIBC_PROBE (mutex_init, 1, mutex); return 0;&#125; 比较复杂，不研究了 unp: 你可能会碰到省略了初始化操作的代码，因为它所在的实现把初始化常量定义为0(而且静态分配的变量被自动得初始化为0)，不过这是不正确的代码 __pthread_mutex_lock123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596//pthread_mutex_lock.cint__pthread_mutex_lock (mutex) pthread_mutex_t *mutex;&#123; assert (sizeof (mutex-&gt;__size) &gt;= sizeof (mutex-&gt;__data)); unsigned int type = PTHREAD_MUTEX_TYPE (mutex); LIBC_PROBE (mutex_entry, 1, mutex); if (__builtin_expect (type &amp; ~PTHREAD_MUTEX_KIND_MASK_NP, 0)) return __pthread_mutex_lock_full (mutex); pid_t id = THREAD_GETMEM (THREAD_SELF, tid); if (__builtin_expect (type, PTHREAD_MUTEX_TIMED_NP) == PTHREAD_MUTEX_TIMED_NP) &#123; simple: /* Normal mutex. */ LLL_MUTEX_LOCK (mutex); assert (mutex-&gt;__data.__owner == 0); &#125; else if (__builtin_expect (type == PTHREAD_MUTEX_RECURSIVE_NP, 1)) &#123; //递归锁 /* Recursive mutex. */ /* Check whether we already hold the mutex. */ if (mutex-&gt;__data.__owner == id) &#123; /* Just bump the counter. */ if (__builtin_expect (mutex-&gt;__data.__count + 1 == 0, 0)) /* Overflow of the counter. */ return EAGAIN; ++mutex-&gt;__data.__count; return 0; &#125; /* We have to get the mutex. */ LLL_MUTEX_LOCK (mutex); assert (mutex-&gt;__data.__owner == 0); mutex-&gt;__data.__count = 1; &#125; else if (__builtin_expect (type == PTHREAD_MUTEX_ADAPTIVE_NP, 1)) &#123; if (! __is_smp) goto simple; if (LLL_MUTEX_TRYLOCK (mutex) != 0) &#123; int cnt = 0; int max_cnt = MIN (MAX_ADAPTIVE_COUNT, mutex-&gt;__data.__spins * 2 + 10); do &#123; if (cnt++ &gt;= max_cnt) &#123; LLL_MUTEX_LOCK (mutex); break; &#125;#ifdef BUSY_WAIT_NOP BUSY_WAIT_NOP;#endif &#125; while (LLL_MUTEX_TRYLOCK (mutex) != 0); mutex-&gt;__data.__spins += (cnt - mutex-&gt;__data.__spins) / 8; &#125; assert (mutex-&gt;__data.__owner == 0); &#125; else &#123; assert (type == PTHREAD_MUTEX_ERRORCHECK_NP); /* Check whether we already hold the mutex. */ if (__builtin_expect (mutex-&gt;__data.__owner == id, 0)) return EDEADLK; goto simple; &#125; /* Record the ownership. */ mutex-&gt;__data.__owner = id;#ifndef NO_INCR ++mutex-&gt;__data.__nusers;#endif LIBC_PROBE (mutex_acquired, 1, mutex); return 0;&#125; 如果是普通锁，调用LLL_MUTEX_LOCK，进行CAS(Compare-and-Swap)操作，失败则执行系统调用sys_futex陷入内核态 如果是递归锁，判断是否是当前进程(线程)持有锁。然后将count计数器加一，如果count等于0，则return EAGAIN 如果是自适应锁，通过非阻塞的LLL_MUTEX_TRYLOCK自旋到最大次数后，执行LLL_MUTEX_LOCK 如果是检错锁，判断是否是当前进程(线程)重复加锁，返回EDEADLK __pthread_mutex_unlock123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657int__pthread_mutex_unlock (mutex) pthread_mutex_t *mutex;&#123; return __pthread_mutex_unlock_usercnt (mutex, 1);&#125;intinternal_function attribute_hidden__pthread_mutex_unlock_usercnt (mutex, decr) pthread_mutex_t *mutex; int decr;&#123; int type = PTHREAD_MUTEX_TYPE (mutex); if (__builtin_expect (type &amp; ~PTHREAD_MUTEX_KIND_MASK_NP, 0)) return __pthread_mutex_unlock_full (mutex, decr); if (__builtin_expect (type, PTHREAD_MUTEX_TIMED_NP) == PTHREAD_MUTEX_TIMED_NP) &#123; /* Always reset the owner field. */ normal: mutex-&gt;__data.__owner = 0; if (decr) /* One less user. */ --mutex-&gt;__data.__nusers; /* Unlock. */ lll_unlock (mutex-&gt;__data.__lock, PTHREAD_MUTEX_PSHARED (mutex)); LIBC_PROBE (mutex_release, 1, mutex); return 0; &#125; else if (__builtin_expect (type == PTHREAD_MUTEX_RECURSIVE_NP, 1)) &#123; /* Recursive mutex. */ if (mutex-&gt;__data.__owner != THREAD_GETMEM (THREAD_SELF, tid)) return EPERM; if (--mutex-&gt;__data.__count != 0) /* We still hold the mutex. */ return 0; goto normal; &#125; else if (__builtin_expect (type == PTHREAD_MUTEX_ADAPTIVE_NP, 1)) goto normal; else &#123; /* Error checking mutex. */ assert (type == PTHREAD_MUTEX_ERRORCHECK_NP); if (mutex-&gt;__data.__owner != THREAD_GETMEM (THREAD_SELF, tid) || ! lll_islocked (mutex-&gt;__data.__lock)) return EPERM; goto normal; &#125;&#125; 如果是普通锁，执行lll_unlock 如果是递归锁，判断是否是当前的进程(线程)持有锁，如果是，count计数器减一，count为0的话，返回 如果是自适应锁，执行lll_unlock 如果是检错锁，判断是否是当前的进程(线程)持有锁，如果是，执行lll_unlock。如果不是，返回EPERM __pthread_mutex_trylock123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356int__pthread_mutex_trylock (mutex) pthread_mutex_t *mutex;&#123; int oldval; pid_t id = THREAD_GETMEM (THREAD_SELF, tid); switch (__builtin_expect (PTHREAD_MUTEX_TYPE (mutex), PTHREAD_MUTEX_TIMED_NP)) &#123; /* Recursive mutex. */ case PTHREAD_MUTEX_RECURSIVE_NP: /* Check whether we already hold the mutex. */ if (mutex-&gt;__data.__owner == id) &#123; /* Just bump the counter. */ if (__builtin_expect (mutex-&gt;__data.__count + 1 == 0, 0)) /* Overflow of the counter. */ return EAGAIN; ++mutex-&gt;__data.__count; return 0; &#125; if (lll_trylock (mutex-&gt;__data.__lock) == 0) &#123; /* Record the ownership. */ mutex-&gt;__data.__owner = id; mutex-&gt;__data.__count = 1; ++mutex-&gt;__data.__nusers; return 0; &#125; break; case PTHREAD_MUTEX_ERRORCHECK_NP: case PTHREAD_MUTEX_TIMED_NP: case PTHREAD_MUTEX_ADAPTIVE_NP: /* Normal mutex. */ if (lll_trylock (mutex-&gt;__data.__lock) != 0) break; /* Record the ownership. */ mutex-&gt;__data.__owner = id; ++mutex-&gt;__data.__nusers; return 0; case PTHREAD_MUTEX_ROBUST_RECURSIVE_NP: case PTHREAD_MUTEX_ROBUST_ERRORCHECK_NP: case PTHREAD_MUTEX_ROBUST_NORMAL_NP: case PTHREAD_MUTEX_ROBUST_ADAPTIVE_NP: THREAD_SETMEM (THREAD_SELF, robust_head.list_op_pending, &amp;mutex-&gt;__data.__list.__next); oldval = mutex-&gt;__data.__lock; do &#123; again: if ((oldval &amp; FUTEX_OWNER_DIED) != 0) &#123; /* The previous owner died. Try locking the mutex. */ int newval = id | (oldval &amp; FUTEX_WAITERS); newval = atomic_compare_and_exchange_val_acq (&amp;mutex-&gt;__data.__lock, newval, oldval); if (newval != oldval) &#123; oldval = newval; goto again; &#125; /* We got the mutex. */ mutex-&gt;__data.__count = 1; /* But it is inconsistent unless marked otherwise. */ mutex-&gt;__data.__owner = PTHREAD_MUTEX_INCONSISTENT; ENQUEUE_MUTEX (mutex); THREAD_SETMEM (THREAD_SELF, robust_head.list_op_pending, NULL); /* Note that we deliberately exist here. If we fall through to the end of the function __nusers would be incremented which is not correct because the old owner has to be discounted. */ return EOWNERDEAD; &#125; /* Check whether we already hold the mutex. */ if (__builtin_expect ((oldval &amp; FUTEX_TID_MASK) == id, 0)) &#123; int kind = PTHREAD_MUTEX_TYPE (mutex); if (kind == PTHREAD_MUTEX_ROBUST_ERRORCHECK_NP) &#123; THREAD_SETMEM (THREAD_SELF, robust_head.list_op_pending, NULL); return EDEADLK; &#125; if (kind == PTHREAD_MUTEX_ROBUST_RECURSIVE_NP) &#123; THREAD_SETMEM (THREAD_SELF, robust_head.list_op_pending, NULL); /* Just bump the counter. */ if (__builtin_expect (mutex-&gt;__data.__count + 1 == 0, 0)) /* Overflow of the counter. */ return EAGAIN; ++mutex-&gt;__data.__count; return 0; &#125; &#125; oldval = lll_robust_trylock (mutex-&gt;__data.__lock, id); if (oldval != 0 &amp;&amp; (oldval &amp; FUTEX_OWNER_DIED) == 0) &#123; THREAD_SETMEM (THREAD_SELF, robust_head.list_op_pending, NULL); return EBUSY; &#125; if (__builtin_expect (mutex-&gt;__data.__owner == PTHREAD_MUTEX_NOTRECOVERABLE, 0)) &#123; /* This mutex is now not recoverable. */ mutex-&gt;__data.__count = 0; if (oldval == id) lll_unlock (mutex-&gt;__data.__lock, PTHREAD_ROBUST_MUTEX_PSHARED (mutex)); THREAD_SETMEM (THREAD_SELF, robust_head.list_op_pending, NULL); return ENOTRECOVERABLE; &#125; &#125; while ((oldval &amp; FUTEX_OWNER_DIED) != 0); ENQUEUE_MUTEX (mutex); THREAD_SETMEM (THREAD_SELF, robust_head.list_op_pending, NULL); mutex-&gt;__data.__owner = id; ++mutex-&gt;__data.__nusers; mutex-&gt;__data.__count = 1; return 0; case PTHREAD_MUTEX_PI_RECURSIVE_NP: case PTHREAD_MUTEX_PI_ERRORCHECK_NP: case PTHREAD_MUTEX_PI_NORMAL_NP: case PTHREAD_MUTEX_PI_ADAPTIVE_NP: case PTHREAD_MUTEX_PI_ROBUST_RECURSIVE_NP: case PTHREAD_MUTEX_PI_ROBUST_ERRORCHECK_NP: case PTHREAD_MUTEX_PI_ROBUST_NORMAL_NP: case PTHREAD_MUTEX_PI_ROBUST_ADAPTIVE_NP: &#123; int kind = mutex-&gt;__data.__kind &amp; PTHREAD_MUTEX_KIND_MASK_NP; int robust = mutex-&gt;__data.__kind &amp; PTHREAD_MUTEX_ROBUST_NORMAL_NP; if (robust) /* Note: robust PI futexes are signaled by setting bit 0. */ THREAD_SETMEM (THREAD_SELF, robust_head.list_op_pending, (void *) (((uintptr_t) &amp;mutex-&gt;__data.__list.__next) | 1)); oldval = mutex-&gt;__data.__lock; /* Check whether we already hold the mutex. */ if (__builtin_expect ((oldval &amp; FUTEX_TID_MASK) == id, 0)) &#123; if (kind == PTHREAD_MUTEX_ERRORCHECK_NP) &#123; THREAD_SETMEM (THREAD_SELF, robust_head.list_op_pending, NULL); return EDEADLK; &#125; if (kind == PTHREAD_MUTEX_RECURSIVE_NP) &#123; THREAD_SETMEM (THREAD_SELF, robust_head.list_op_pending, NULL); /* Just bump the counter. */ if (__builtin_expect (mutex-&gt;__data.__count + 1 == 0, 0)) /* Overflow of the counter. */ return EAGAIN; ++mutex-&gt;__data.__count; return 0; &#125; &#125; oldval = atomic_compare_and_exchange_val_acq (&amp;mutex-&gt;__data.__lock, id, 0); if (oldval != 0) &#123; if ((oldval &amp; FUTEX_OWNER_DIED) == 0) &#123; THREAD_SETMEM (THREAD_SELF, robust_head.list_op_pending, NULL); return EBUSY; &#125; assert (robust); /* The mutex owner died. The kernel will now take care of everything. */ int private = (robust ? PTHREAD_ROBUST_MUTEX_PSHARED (mutex) : PTHREAD_MUTEX_PSHARED (mutex)); INTERNAL_SYSCALL_DECL (__err); int e = INTERNAL_SYSCALL (futex, __err, 4, &amp;mutex-&gt;__data.__lock, __lll_private_flag (FUTEX_TRYLOCK_PI, private), 0, 0); if (INTERNAL_SYSCALL_ERROR_P (e, __err) &amp;&amp; INTERNAL_SYSCALL_ERRNO (e, __err) == EWOULDBLOCK) &#123; THREAD_SETMEM (THREAD_SELF, robust_head.list_op_pending, NULL); return EBUSY; &#125; oldval = mutex-&gt;__data.__lock; &#125; if (__builtin_expect (oldval &amp; FUTEX_OWNER_DIED, 0)) &#123; atomic_and (&amp;mutex-&gt;__data.__lock, ~FUTEX_OWNER_DIED); /* We got the mutex. */ mutex-&gt;__data.__count = 1; /* But it is inconsistent unless marked otherwise. */ mutex-&gt;__data.__owner = PTHREAD_MUTEX_INCONSISTENT; ENQUEUE_MUTEX (mutex); THREAD_SETMEM (THREAD_SELF, robust_head.list_op_pending, NULL); /* Note that we deliberately exit here. If we fall through to the end of the function __nusers would be incremented which is not correct because the old owner has to be discounted. */ return EOWNERDEAD; &#125; if (robust &amp;&amp; __builtin_expect (mutex-&gt;__data.__owner == PTHREAD_MUTEX_NOTRECOVERABLE, 0)) &#123; /* This mutex is now not recoverable. */ mutex-&gt;__data.__count = 0; INTERNAL_SYSCALL_DECL (__err); INTERNAL_SYSCALL (futex, __err, 4, &amp;mutex-&gt;__data.__lock, __lll_private_flag (FUTEX_UNLOCK_PI, PTHREAD_ROBUST_MUTEX_PSHARED (mutex)), 0, 0); THREAD_SETMEM (THREAD_SELF, robust_head.list_op_pending, NULL); return ENOTRECOVERABLE; &#125; if (robust) &#123; ENQUEUE_MUTEX_PI (mutex); THREAD_SETMEM (THREAD_SELF, robust_head.list_op_pending, NULL); &#125; mutex-&gt;__data.__owner = id; ++mutex-&gt;__data.__nusers; mutex-&gt;__data.__count = 1; return 0; &#125; case PTHREAD_MUTEX_PP_RECURSIVE_NP: case PTHREAD_MUTEX_PP_ERRORCHECK_NP: case PTHREAD_MUTEX_PP_NORMAL_NP: case PTHREAD_MUTEX_PP_ADAPTIVE_NP: &#123; int kind = mutex-&gt;__data.__kind &amp; PTHREAD_MUTEX_KIND_MASK_NP; oldval = mutex-&gt;__data.__lock; /* Check whether we already hold the mutex. */ if (mutex-&gt;__data.__owner == id) &#123; if (kind == PTHREAD_MUTEX_ERRORCHECK_NP) return EDEADLK; if (kind == PTHREAD_MUTEX_RECURSIVE_NP) &#123; /* Just bump the counter. */ if (__builtin_expect (mutex-&gt;__data.__count + 1 == 0, 0)) /* Overflow of the counter. */ return EAGAIN; ++mutex-&gt;__data.__count; return 0; &#125; &#125; int oldprio = -1, ceilval; do &#123; int ceiling = (oldval &amp; PTHREAD_MUTEX_PRIO_CEILING_MASK) &gt;&gt; PTHREAD_MUTEX_PRIO_CEILING_SHIFT; if (__pthread_current_priority () &gt; ceiling) &#123; if (oldprio != -1) __pthread_tpp_change_priority (oldprio, -1); return EINVAL; &#125; int retval = __pthread_tpp_change_priority (oldprio, ceiling); if (retval) return retval; ceilval = ceiling &lt;&lt; PTHREAD_MUTEX_PRIO_CEILING_SHIFT; oldprio = ceiling; oldval = atomic_compare_and_exchange_val_acq (&amp;mutex-&gt;__data.__lock, ceilval | 1, ceilval); if (oldval == ceilval) break; &#125; while ((oldval &amp; PTHREAD_MUTEX_PRIO_CEILING_MASK) != ceilval); if (oldval != ceilval) &#123; __pthread_tpp_change_priority (oldprio, -1); break; &#125; assert (mutex-&gt;__data.__owner == 0); /* Record the ownership. */ mutex-&gt;__data.__owner = id; ++mutex-&gt;__data.__nusers; mutex-&gt;__data.__count = 1; return 0; &#125; break; default: /* Correct code cannot set any other type. */ return EINVAL; &#125; return EBUSY;&#125; 非阻塞获取锁，具体不分析了 __pthread_mutex_destroy12345678910111213141516int__pthread_mutex_destroy (mutex) pthread_mutex_t *mutex;&#123; LIBC_PROBE (mutex_destroy, 1, mutex); if ((mutex-&gt;__data.__kind &amp; PTHREAD_MUTEX_ROBUST_NORMAL_NP) == 0 &amp;&amp; mutex-&gt;__data.__nusers != 0) return EBUSY; /* Set to an invalid value. */ mutex-&gt;__data.__kind = -1; return 0;&#125; 摧毁互斥锁 四种锁的属性Posix线程编程指南(3) 互斥锁的属性在创建锁的时候指定，在LinuxThreads实现中仅有一个锁类型属性，不同的锁类型在试图对一个已经被锁定的互斥锁加锁时表现不同。当前（glibc2.2.3,linuxthreads0.9）有四个值可供选择： PTHREAD_MUTEX_TIMED_NP，这是缺省值，也就是普通锁。当一个线程加锁以后，其余请求锁的线程将形成一个等待队列，并在解锁后按优先级获得锁。这种锁策略保证了资源分配的公平性 PTHREAD_MUTEX_RECURSIVE_NP,嵌套锁，允许同一个线程对同一个锁成功获得多次，并通过多次unlock解锁。如果是不同线程请求，则在加锁线程解锁时重新竞争。 PTHREAD_MUTEX_ADAPTIVE_NP 适应锁，动作最简单的锁类型，仅等待解锁后重新竞争。线程旋转直到达到最大旋转计数或获得锁定为止https://stackoverflow.com/questions/19863734/what-is-pthread-mutex-adaptive-np PTHREAD_MUTEX_ERRORCHECK_NP 检错锁，如果同一个线程请求同一个锁，则返回EDEADLK，否则与PTHREAD_MUTEX_TIMED_NP类型动作相同。这样就保证当不允许多次加锁时不会出现最简单情况下的死锁。 条件变量pthread_cond_t12345678910111213141516171819/* Data structure for conditional variable handling. The structure of the attribute type is deliberately not exposed. */typedef union&#123; struct &#123; int __lock; unsigned int __futex; __extension__ unsigned long long int __total_seq; __extension__ unsigned long long int __wakeup_seq; __extension__ unsigned long long int __woken_seq; void *__mutex; unsigned int __nwaiters; unsigned int __broadcast_seq; &#125; __data; char __size[__SIZEOF_PTHREAD_COND_T]; __extension__ long long int __align;&#125; pthread_cond_t; PTHREAD_COND_INITIALIZER123/* Conditional variable handling. */#define PTHREAD_COND_INITIALIZER &#123; &#123; 0, 0, 0, 0, 0, (void *) 0, 0, 0 &#125; &#125; 静态初始化 __pthread_cond_init123456789101112131415161718192021222324int__pthread_cond_init (cond, cond_attr) pthread_cond_t *cond; const pthread_condattr_t *cond_attr;&#123; struct pthread_condattr *icond_attr = (struct pthread_condattr *) cond_attr; cond-&gt;__data.__lock = LLL_LOCK_INITIALIZER; cond-&gt;__data.__futex = 0; cond-&gt;__data.__nwaiters = (icond_attr != NULL ? ((icond_attr-&gt;value &gt;&gt; 1) &amp; ((1 &lt;&lt; COND_NWAITERS_SHIFT) - 1)) : CLOCK_REALTIME); cond-&gt;__data.__total_seq = 0; cond-&gt;__data.__wakeup_seq = 0; cond-&gt;__data.__woken_seq = 0; cond-&gt;__data.__mutex = (icond_attr == NULL || (icond_attr-&gt;value &amp; 1) == 0 ? NULL : (void *) ~0l); cond-&gt;__data.__broadcast_seq = 0; LIBC_PROBE (cond_init, 2, cond, cond_attr); return 0;&#125; 动态初始化 __pthread_cond_wait123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103int__pthread_cond_wait (cond, mutex) pthread_cond_t *cond; pthread_mutex_t *mutex;&#123; struct _pthread_cleanup_buffer buffer; struct _condvar_cleanup_buffer cbuffer; int err; int pshared = (cond-&gt;__data.__mutex == (void *) ~0l) ? LLL_SHARED : LLL_PRIVATE; LIBC_PROBE (cond_wait, 2, cond, mutex); /* Make sure we are alone. */ lll_lock (cond-&gt;__data.__lock, pshared); /* Now we can release the mutex. */ err = __pthread_mutex_unlock_usercnt (mutex, 0); if (__builtin_expect (err, 0)) &#123; lll_unlock (cond-&gt;__data.__lock, pshared); return err; &#125; /* We have one new user of the condvar. */ ++cond-&gt;__data.__total_seq; ++cond-&gt;__data.__futex; cond-&gt;__data.__nwaiters += 1 &lt;&lt; COND_NWAITERS_SHIFT; /* Remember the mutex we are using here. If there is already a different address store this is a bad user bug. Do not store anything for pshared condvars. */ if (cond-&gt;__data.__mutex != (void *) ~0l) cond-&gt;__data.__mutex = mutex; /* Prepare structure passed to cancellation handler. */ cbuffer.cond = cond; cbuffer.mutex = mutex; /* Before we block we enable cancellation. Therefore we have to install a cancellation handler. */ __pthread_cleanup_push (&amp;buffer, __condvar_cleanup, &amp;cbuffer); /* The current values of the wakeup counter. The &quot;woken&quot; counter must exceed this value. */ unsigned long long int val; unsigned long long int seq; val = seq = cond-&gt;__data.__wakeup_seq; /* Remember the broadcast counter. */ cbuffer.bc_seq = cond-&gt;__data.__broadcast_seq; do &#123; unsigned int futex_val = cond-&gt;__data.__futex; /* Prepare to wait. Release the condvar futex. */ lll_unlock (cond-&gt;__data.__lock, pshared); /* Enable asynchronous cancellation. Required by the standard. */ cbuffer.oldtype = __pthread_enable_asynccancel (); /* Wait until woken by signal or broadcast. */ lll_futex_wait (&amp;cond-&gt;__data.__futex, futex_val, pshared); /* Disable asynchronous cancellation. */ __pthread_disable_asynccancel (cbuffer.oldtype); /* We are going to look at shared data again, so get the lock. */ lll_lock (cond-&gt;__data.__lock, pshared); /* If a broadcast happened, we are done. */ if (cbuffer.bc_seq != cond-&gt;__data.__broadcast_seq) goto bc_out; /* Check whether we are eligible for wakeup. */ val = cond-&gt;__data.__wakeup_seq; &#125; while (val == seq || cond-&gt;__data.__woken_seq == val); /* Another thread woken up. */ ++cond-&gt;__data.__woken_seq; bc_out: cond-&gt;__data.__nwaiters -= 1 &lt;&lt; COND_NWAITERS_SHIFT; /* If pthread_cond_destroy was called on this varaible already, notify the pthread_cond_destroy caller all waiters have left and it can be successfully destroyed. */ if (cond-&gt;__data.__total_seq == -1ULL &amp;&amp; cond-&gt;__data.__nwaiters &lt; (1 &lt;&lt; COND_NWAITERS_SHIFT)) lll_futex_wake (&amp;cond-&gt;__data.__nwaiters, 1, pshared); /* We are done with the condvar. */ lll_unlock (cond-&gt;__data.__lock, pshared); /* The cancellation handling is back to normal, remove the handler. */ __pthread_cleanup_pop (&amp;buffer, 0); /* Get the mutex before returning. */ return __pthread_mutex_cond_lock (mutex);&#125; 无条件等待pthread_cond_wait()，必须和一个互斥锁配合，以防止多个线程同时请求pthread_cond_wait()（或pthread_cond_timedwait()，下同）的竞争条件（Race Condition）。mutex互斥锁必须是普通锁（PTHREAD_MUTEX_TIMED_NP）或者适应锁（PTHREAD_MUTEX_ADAPTIVE_NP），且在调用pthread_cond_wait()前必须由本线程加锁（pthread_mutex_lock()），而在更新条件等待队列以前，mutex保持锁定状态，并在线程挂起进入等待前解锁。在条件满足从而离开pthread_cond_wait()之前，mutex将被重新加锁，以与进入pthread_cond_wait()前的加锁动作对应。 激发条件有两种形式，pthread_cond_signal()激活一个等待该条件的线程，存在多个等待线程时按入队顺序激活其中一个；而pthread_cond_broadcast()则激活所有等待线程。 __pthread_cond_timedwait123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175int__pthread_cond_timedwait (cond, mutex, abstime) pthread_cond_t *cond; pthread_mutex_t *mutex; const struct timespec *abstime;&#123; struct _pthread_cleanup_buffer buffer; struct _condvar_cleanup_buffer cbuffer; int result = 0; /* Catch invalid parameters. */ if (abstime-&gt;tv_nsec &lt; 0 || abstime-&gt;tv_nsec &gt;= 1000000000) return EINVAL; int pshared = (cond-&gt;__data.__mutex == (void *) ~0l) ? LLL_SHARED : LLL_PRIVATE; /* Make sure we are alone. */ lll_lock (cond-&gt;__data.__lock, pshared); /* Now we can release the mutex. */ int err = __pthread_mutex_unlock_usercnt (mutex, 0); if (err) &#123; lll_unlock (cond-&gt;__data.__lock, pshared); return err; &#125; /* We have one new user of the condvar. */ ++cond-&gt;__data.__total_seq; ++cond-&gt;__data.__futex; cond-&gt;__data.__nwaiters += 1 &lt;&lt; COND_NWAITERS_SHIFT; /* Work around the fact that the kernel rejects negative timeout values despite them being valid. */ if (__builtin_expect (abstime-&gt;tv_sec &lt; 0, 0)) goto timeout; /* Remember the mutex we are using here. If there is already a different address store this is a bad user bug. Do not store anything for pshared condvars. */ if (cond-&gt;__data.__mutex != (void *) ~0l) cond-&gt;__data.__mutex = mutex; /* Prepare structure passed to cancellation handler. */ cbuffer.cond = cond; cbuffer.mutex = mutex; /* Before we block we enable cancellation. Therefore we have to install a cancellation handler. */ __pthread_cleanup_push (&amp;buffer, __condvar_cleanup, &amp;cbuffer); /* The current values of the wakeup counter. The &quot;woken&quot; counter must exceed this value. */ unsigned long long int val; unsigned long long int seq; val = seq = cond-&gt;__data.__wakeup_seq; /* Remember the broadcast counter. */ cbuffer.bc_seq = cond-&gt;__data.__broadcast_seq; while (1) &#123;#if (!defined __ASSUME_FUTEX_CLOCK_REALTIME \\ || !defined lll_futex_timed_wait_bitset) struct timespec rt; &#123;# ifdef __NR_clock_gettime INTERNAL_SYSCALL_DECL (err); (void) INTERNAL_VSYSCALL (clock_gettime, err, 2, (cond-&gt;__data.__nwaiters &amp; ((1 &lt;&lt; COND_NWAITERS_SHIFT) - 1)), &amp;rt); /* Convert the absolute timeout value to a relative timeout. */ rt.tv_sec = abstime-&gt;tv_sec - rt.tv_sec; rt.tv_nsec = abstime-&gt;tv_nsec - rt.tv_nsec;# else /* Get the current time. So far we support only one clock. */ struct timeval tv; (void) gettimeofday (&amp;tv, NULL); /* Convert the absolute timeout value to a relative timeout. */ rt.tv_sec = abstime-&gt;tv_sec - tv.tv_sec; rt.tv_nsec = abstime-&gt;tv_nsec - tv.tv_usec * 1000;# endif &#125; if (rt.tv_nsec &lt; 0) &#123; rt.tv_nsec += 1000000000; --rt.tv_sec; &#125; /* Did we already time out? */ if (__builtin_expect (rt.tv_sec &lt; 0, 0)) &#123; if (cbuffer.bc_seq != cond-&gt;__data.__broadcast_seq) goto bc_out; goto timeout; &#125;#endif unsigned int futex_val = cond-&gt;__data.__futex; /* Prepare to wait. Release the condvar futex. */ lll_unlock (cond-&gt;__data.__lock, pshared); /* Enable asynchronous cancellation. Required by the standard. */ cbuffer.oldtype = __pthread_enable_asynccancel ();#if (!defined __ASSUME_FUTEX_CLOCK_REALTIME \\ || !defined lll_futex_timed_wait_bitset) /* Wait until woken by signal or broadcast. */ err = lll_futex_timed_wait (&amp;cond-&gt;__data.__futex, futex_val, &amp;rt, pshared);#else unsigned int clockbit = (cond-&gt;__data.__nwaiters &amp; 1 ? 0 : FUTEX_CLOCK_REALTIME); err = lll_futex_timed_wait_bitset (&amp;cond-&gt;__data.__futex, futex_val, abstime, clockbit, pshared);#endif /* Disable asynchronous cancellation. */ __pthread_disable_asynccancel (cbuffer.oldtype); /* We are going to look at shared data again, so get the lock. */ lll_lock (cond-&gt;__data.__lock, pshared); /* If a broadcast happened, we are done. */ if (cbuffer.bc_seq != cond-&gt;__data.__broadcast_seq) goto bc_out; /* Check whether we are eligible for wakeup. */ val = cond-&gt;__data.__wakeup_seq; if (val != seq &amp;&amp; cond-&gt;__data.__woken_seq != val) break; /* Not woken yet. Maybe the time expired? */ if (__builtin_expect (err == -ETIMEDOUT, 0)) &#123; timeout: /* Yep. Adjust the counters. */ ++cond-&gt;__data.__wakeup_seq; ++cond-&gt;__data.__futex; /* The error value. */ result = ETIMEDOUT; break; &#125; &#125; /* Another thread woken up. */ ++cond-&gt;__data.__woken_seq; bc_out: cond-&gt;__data.__nwaiters -= 1 &lt;&lt; COND_NWAITERS_SHIFT; /* If pthread_cond_destroy was called on this variable already, notify the pthread_cond_destroy caller all waiters have left and it can be successfully destroyed. */ if (cond-&gt;__data.__total_seq == -1ULL &amp;&amp; cond-&gt;__data.__nwaiters &lt; (1 &lt;&lt; COND_NWAITERS_SHIFT)) lll_futex_wake (&amp;cond-&gt;__data.__nwaiters, 1, pshared); /* We are done with the condvar. */ lll_unlock (cond-&gt;__data.__lock, pshared); /* The cancellation handling is back to normal, remove the handler. */ __pthread_cleanup_pop (&amp;buffer, 0); /* Get the mutex before returning. */ err = __pthread_mutex_cond_lock (mutex); return err ?: result;&#125; 超时等待__pthread_cond_timedwait()，必须和一个互斥锁配合，以防止多个线程同时请求pthread_cond_wait()（或pthread_cond_timedwait()，下同）的竞争条件（Race Condition）。mutex互斥锁必须是普通锁（PTHREAD_MUTEX_TIMED_NP）或者适应锁（PTHREAD_MUTEX_ADAPTIVE_NP），且在调用pthread_cond_wait()前必须由本线程加锁（pthread_mutex_lock()），而在更新条件等待队列以前，mutex保持锁定状态，并在线程挂起进入等待前解锁。在条件满足从而离开pthread_cond_wait()之前，mutex将被重新加锁，以与进入pthread_cond_wait()前的加锁动作对应。 激发条件有两种形式，pthread_cond_signal()激活一个等待该条件的线程，存在多个等待线程时按入队顺序激活其中一个；而pthread_cond_broadcast()则激活所有等待线程。 __pthread_cond_signal123456789101112131415161718192021222324252627282930313233int__pthread_cond_signal (cond) pthread_cond_t *cond;&#123; int pshared = (cond-&gt;__data.__mutex == (void *) ~0l) ? LLL_SHARED : LLL_PRIVATE; LIBC_PROBE (cond_signal, 1, cond); /* Make sure we are alone. */ lll_lock (cond-&gt;__data.__lock, pshared); /* Are there any waiters to be woken? */ if (cond-&gt;__data.__total_seq &gt; cond-&gt;__data.__wakeup_seq) &#123; /* Yes. Mark one of them as woken. */ ++cond-&gt;__data.__wakeup_seq; ++cond-&gt;__data.__futex; /* Wake one. */ if (! __builtin_expect (lll_futex_wake_unlock (&amp;cond-&gt;__data.__futex, 1, 1, &amp;cond-&gt;__data.__lock, pshared), 0)) return 0; lll_futex_wake (&amp;cond-&gt;__data.__futex, 1, pshared); &#125; /* We are done. */ lll_unlock (cond-&gt;__data.__lock, pshared); return 0;&#125; 唤醒单个线程lll_futex_wake (&amp;cond-&gt;__data.__futex, 1, pshared); __pthread_cond_broadcast1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162int__pthread_cond_broadcast (cond) pthread_cond_t *cond;&#123; LIBC_PROBE (cond_broadcast, 1, cond); int pshared = (cond-&gt;__data.__mutex == (void *) ~0l) ? LLL_SHARED : LLL_PRIVATE; /* Make sure we are alone. */ lll_lock (cond-&gt;__data.__lock, pshared); /* Are there any waiters to be woken? */ if (cond-&gt;__data.__total_seq &gt; cond-&gt;__data.__wakeup_seq) &#123; /* Yes. Mark them all as woken. */ cond-&gt;__data.__wakeup_seq = cond-&gt;__data.__total_seq; cond-&gt;__data.__woken_seq = cond-&gt;__data.__total_seq; cond-&gt;__data.__futex = (unsigned int) cond-&gt;__data.__total_seq * 2; int futex_val = cond-&gt;__data.__futex; /* Signal that a broadcast happened. */ ++cond-&gt;__data.__broadcast_seq; /* We are done. */ lll_unlock (cond-&gt;__data.__lock, pshared); /* Do not use requeue for pshared condvars. */ if (cond-&gt;__data.__mutex == (void *) ~0l) goto wake_all; /* Wake everybody. */ pthread_mutex_t *mut = (pthread_mutex_t *) cond-&gt;__data.__mutex; /* XXX: Kernel so far doesn&#x27;t support requeue to PI futex. */ /* XXX: Kernel so far can only requeue to the same type of futex, in this case private (we don&#x27;t requeue for pshared condvars). */ if (__builtin_expect (mut-&gt;__data.__kind &amp; (PTHREAD_MUTEX_PRIO_INHERIT_NP | PTHREAD_MUTEX_PSHARED_BIT), 0)) goto wake_all; /* lll_futex_requeue returns 0 for success and non-zero for errors. */ if (__builtin_expect (lll_futex_requeue (&amp;cond-&gt;__data.__futex, 1, INT_MAX, &amp;mut-&gt;__data.__lock, futex_val, LLL_PRIVATE), 0)) &#123; /* The requeue functionality is not available. */ wake_all: //INT_MAX 唤醒所有等待的线程 lll_futex_wake (&amp;cond-&gt;__data.__futex, INT_MAX, pshared); &#125; /* That&#x27;s all. */ return 0; &#125; /* We are done. */ lll_unlock (cond-&gt;__data.__lock, pshared); return 0;&#125; 唤醒所有等待的线程lll_futex_wake (&amp;cond-&gt;__data.__futex, INT_MAX, pshared); pthread_cond_destroy1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162int__pthread_cond_destroy (cond) pthread_cond_t *cond;&#123; int pshared = (cond-&gt;__data.__mutex == (void *) ~0l) ? LLL_SHARED : LLL_PRIVATE; LIBC_PROBE (cond_destroy, 1, cond); /* Make sure we are alone. */ lll_lock (cond-&gt;__data.__lock, pshared); if (cond-&gt;__data.__total_seq &gt; cond-&gt;__data.__wakeup_seq) &#123; /* If there are still some waiters which have not been woken up, this is an application bug. */ lll_unlock (cond-&gt;__data.__lock, pshared); return EBUSY; &#125; /* Tell pthread_cond_*wait that this condvar is being destroyed. */ cond-&gt;__data.__total_seq = -1ULL; /* If there are waiters which have been already signalled or broadcasted, but still are using the pthread_cond_t structure, pthread_cond_destroy needs to wait for them. */ unsigned int nwaiters = cond-&gt;__data.__nwaiters; if (nwaiters &gt;= (1 &lt;&lt; COND_NWAITERS_SHIFT)) &#123; /* Wake everybody on the associated mutex in case there are threads that have been requeued to it. Without this, pthread_cond_destroy could block potentially for a long time or forever, as it would depend on other thread&#x27;s using the mutex. When all threads waiting on the mutex are woken up, pthread_cond_wait only waits for threads to acquire and release the internal condvar lock. */ if (cond-&gt;__data.__mutex != NULL &amp;&amp; cond-&gt;__data.__mutex != (void *) ~0l) &#123; pthread_mutex_t *mut = (pthread_mutex_t *) cond-&gt;__data.__mutex; lll_futex_wake (&amp;mut-&gt;__data.__lock, INT_MAX, PTHREAD_MUTEX_PSHARED (mut)); &#125; do &#123; lll_unlock (cond-&gt;__data.__lock, pshared); lll_futex_wait (&amp;cond-&gt;__data.__nwaiters, nwaiters, pshared); lll_lock (cond-&gt;__data.__lock, pshared); nwaiters = cond-&gt;__data.__nwaiters; &#125; while (nwaiters &gt;= (1 &lt;&lt; COND_NWAITERS_SHIFT)); &#125; return 0;&#125; 在释放或废弃条件变量之前，需要毁坏它 总结 pthread_cleanup_push和pthread_cleanup_pop作为线程取消的回调函数，在wait函数中执行，防止线程退出导致的锁未释放，进而出现死锁的情况 条件变量机制不是异步信号安全的，也就是说，在信号处理函数中调用pthread_cond_signal()或者pthread_cond_broadcast()很可能引起死锁。 wait函数先解锁，然后加入睡眠列表，没有忙轮询的消耗，被其他线程”唤醒”后重新加锁 wait函数执行前当前线程必须已经对mutex加锁，并且锁的类型是普通锁或者适应锁 ending","categories":[],"tags":[{"name":"ipc","slug":"ipc","permalink":"https://riverferry.site/tags/ipc/"}],"keywords":[]},{"title":"操作系统-进程互斥的实现方案","slug":"2020-04-04-操作系统-进程互斥的实现方案","date":"2020-04-04T00:00:00.000Z","updated":"2022-09-12T16:24:32.279Z","comments":true,"path":"2020-04-04-操作系统-进程互斥的实现方案/","link":"","permalink":"https://riverferry.site/2020-04-04-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E8%BF%9B%E7%A8%8B%E4%BA%92%E6%96%A5%E7%9A%84%E5%AE%9E%E7%8E%B0%E6%96%B9%E6%A1%88/","excerpt":"参考陈向群操作系统","text":"参考陈向群操作系统 软件解法DEJKKER算法 PETERSON算法 硬件解法开关中断指令 开关中断指令属于特权级指令，用户态无法调用。 针对单个CPU有效 会导致开关中断时期CPU无法切换 XCHG指令 给寄存器置1 交换寄存器的值1和锁的值0/1 判断寄存器的值是否为0 busy waiting or return 对单个cpu有效 TSL指令 复制锁的值到寄存器，修改锁的值为1 判断寄存器的值是否为0 busy waiting or return 对多cpu有效,因为TSL指令会锁住cpu总线 ending","categories":[],"tags":[{"name":"OperatingSystem","slug":"OperatingSystem","permalink":"https://riverferry.site/tags/OperatingSystem/"}],"keywords":[]},{"title":"谷歌云搭建v2ray","slug":"2020-03-29-谷歌云搭建v2ray","date":"2020-03-29T00:00:00.000Z","updated":"2022-09-12T16:24:32.279Z","comments":true,"path":"2020-03-29-谷歌云搭建v2ray/","link":"","permalink":"https://riverferry.site/2020-03-29-%E8%B0%B7%E6%AD%8C%E4%BA%91%E6%90%AD%E5%BB%BAv2ray/","excerpt":"搭建VPSgcp首页","text":"搭建VPSgcp首页 V2Ray配置下载安装 xshell通过密钥登录服务器，切换到root(sudo -i) bash &lt;(curl -L -s https://install.direct/go.sh) 此脚本会自动安装以下文件： /usr/bin/v2ray/v2ray：V2Ray 程序； /usr/bin/v2ray/v2ctl：V2Ray 工具； /etc/v2ray/config.json：配置文件； /usr/bin/v2ray/geoip.dat：IP 数据文件 /usr/bin/v2ray/geosite.dat：域名数据文件 此脚本会配置自动运行脚本。自动运行脚本会在系统重启之后，自动运行 V2Ray。目前自动运行脚本只支持带有 Systemd 的系统，以及 Debian / Ubuntu 全系列。 运行脚本位于系统的以下位置： /etc/systemd/system/v2ray.service: Systemd /etc/init.d/v2ray: SysV 脚本运行完成后，你需要： 1 编辑 /etc/v2ray/config.json 文件来配置你需要的代理方式；2 运行 service v2ray start 来启动 V2Ray 进程； 3 之后可以使用 service v2ray start|stop|status|reload|restart|force-reload 控制 V2Ray 的运行。 下载客户端(windows) 下载链接 相关参数参考：/etc/v2ray/config.json ssr配置参考这篇文章 ending","categories":[],"tags":[{"name":"科学上网","slug":"科学上网","permalink":"https://riverferry.site/tags/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91/"}],"keywords":[]},{"title":"c++基础知识点","slug":"2020-03-29-c++基础知识点","date":"2020-03-29T00:00:00.000Z","updated":"2022-09-12T16:24:32.279Z","comments":true,"path":"2020-03-29-c++基础知识点/","link":"","permalink":"https://riverferry.site/2020-03-29-c++%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E7%82%B9/","excerpt":"前言以前面试准备的，比较凌乱，先放这里","text":"前言以前面试准备的，比较凌乱，先放这里 001 说一下static关键字的作用1. 全局静态变量 在全局变量前加上关键字static，全局变量就定义成一个全局静态变量. 静态存储区，在整个程序运行期间一直存在。 初始化：未经初始化的全局静态变量会被自动初始化为0（自动对象的值是任意的，除非他被显式初始化）； 作用域：全局静态变量在声明他的文件之外是不可见的，准确地说是从定义之处开始，到文件结尾。 2. 局部静态变量 在局部变量之前加上关键字static，局部变量就成为一个局部静态变量。 内存中的位置：静态存储区 初始化：未经初始化的全局静态变量会被自动初始化为0（自动对象的值是任意的，除非他被显式初始化）； 作用域：作用域仍为局部作用域，当定义它的函数或者语句块结束的时候，作用域结束。但是当局部静态变量离开作用域后，并没有销毁，而是仍然驻留在内存当中，只不过我们不能再对它进行访问，直到该函数再次被调用，并且值不变； 3. 静态函数 在函数返回类型前加static，函数就定义为静态函数。函数的定义和声明在默认情况下都是extern的，但静态函数只是在声明他的文件当中可见，不能被其他文件所用。 函数的实现使用static修饰，那么这个函数只可在本cpp内使用，不会同其他cpp中的同名函数引起冲突； warning：不要再头文件中声明static的全局函数，不要在cpp内声明非static的全局函数，如果你要在多个cpp中复用该函数，就把它的声明提到头文件里去，否则cpp内部声明需加上static修饰； 4. 类的静态成员 在类中，静态成员可以实现多个对象之间的数据共享，并且使用静态数据成员还不会破坏隐藏的原则，即保证了安全性。因此，静态成员是类的所有对象中共享的成员，而不是某个对象的成员。对多个对象来说，静态数据成员只存储一处，供所有对象共用 5. 类的静态函数 静态成员函数和静态数据成员一样，它们都属于类的静态成员，它们都不是对象成员。因此，对静态成员的引用不需要用对象名。 在静态成员函数的实现中不能直接引用类中说明的非静态成员，可以引用类中说明的静态成员（这点非常重要）。如果静态成员函数中要引用非静态成员时，可通过对象来引用。从中可看出，调用静态成员函数使用如下格式：&lt;类名&gt;::&lt;静态成员函数名&gt;(&lt;参数表&gt;); 002 extern关键字我们知道，程序的编译单位是源程序文件，一个源文件可以包含一个或若干个函数。在函数内定义的变量是局部变量，而在函数之外定义的变量则称为外部变量，外部变量也就是我们所讲的全局变量。它的存储方式为静态存储，其生存周期为整个程序的生存周期。全局变量可以为本文件中的其他函数所共用，它的有效范围为从定义变量的位置开始到本源文件结束。 然而，如果全局变量不在文件的开头定义，有效的作用范围将只限于其定义处到文件结束。如果在定义点之前的函数想引用该全局变量，则应该在引用之前用关键字 extern 对该变量作“外部变量声明”，表示该变量是一个已经定义的外部变量。有了此声明，就可以从“声明”处起，合法地使用该外部变量。 003 C++和C的区别设计思想上： C++是面向对象的语言，而C是面向过程的结构化编程语言 语法上： C++具有封装、继承和多态三种特性 C++相比C，增加多许多类型安全的功能，比如强制类型转换、 C++支持范式编程，比如模板类、函数模板等 004 说一说c++中四种cast转换C++中四种类型转换是：static_cast, dynamic_cast, const_cast, reinterpret_cast 1、const_cast 用于将const变量转为非const 2、static_cast 用于各种隐式转换，比如非const转const，void*转指针等, static_cast能用于多态向上转化，如果向下转能成功但是不安全，结果未知； 3、dynamic_cast 用于动态类型转换。只能用于含有虚函数的类，用于类层次间的向上和向下转化。只能转指针或引用。向下转化时，如果是非法的对于指针返回NULL，对于引用抛异常。要深入了解内部转换的原理。 向上转换：指的是子类向基类的转换 向下转换：指的是基类向子类的转换 它通过判断在执行到该语句的时候变量的运行时类型和要转换的类型是否相同来判断是否能够进行向下转换。 4、reinterpret_cast 几乎什么都可以转，比如将int转指针，可能会出问题，尽量少用； 5、为什么不使用C的强制转换？ C的强制转换表面上看起来功能强大什么都能转，但是转化不够明确，不能进行错误检查，容易出错。 005 请说一下C/C++ 中指针和引用的区别？1.指针有自己的一块空间，而引用只是一个别名；2.使用sizeof看一个指针的大小是4，而引用则是被引用对象的大小；3.指针可以被初始化为NULL，而引用必须被初始化且必须是一个已有对象 的引用；4.作为参数传递时，指针需要被解引用才可以对对象进行操作，而直接对引 用的修改都会改变引用所指向的对象；5.可以有const指针，但是没有const引用；6.指针在使用中可以指向其它对象，但是引用只能是一个对象的引用，不能 被改变；7.指针可以有多级指针（**p），而引用至于一级；8.指针和引用使用++运算符的意义不一样；9.如果返回动态内存分配的对象或者内存，必须使用指针，引用可能引起内存泄露。 006 智能指针007 指针和数组的主要区别如下数组和指针的比较和关系以及区别 008 请你回答一下野指针是什么？野指针就是指向一个已删除的对象或者未申请访问受限内存区域的指针 009 为什么析构函数必须是虚函数？为什么C++默认的析构函数不是虚函数 考点:虚函数 析构函数将可能会被继承的父类的析构函数设置为虚函数，可以保证当我们new一个子类，然后使用基类指针指向该子类对象，释放基类指针时可以释放掉子类的空间，防止内存泄漏。 C++默认的析构函数不是虚函数是因为虚函数需要额外的虚函数表和虚表指针，占用额外的内存。而对于不会被继承的类来说，其析构函数如果是虚函数，就会浪费内存。因此C++默认的析构函数不是虚函数，而是只有当需要当作父类时，设置为虚函数。 010 请你来说一下函数指针1、定义函数指针是指向函数的指针变量。 函数指针本身首先是一个指针变量，该指针变量指向一个具体的函数。这正如用指针变量可指向整型变量、字符型、数组一样，这里是指向函数。 C在编译时，每一个函数都有一个入口地址，该入口地址就是函数指针所指向的地址。有了指向函数的指针变量后，可用该指针变量调用函数，就如同用指针变量可引用其他类型变量一样，在这些概念上是大体一致的。 2、用途： 调用函数和做函数的参数，比如回调函数。 3、示例： char * fun(char * p) {…} // 函数fun char * (*pf)(char * p); // 函数指针pf pf = fun; // 函数指针pf指向函数fun pf(p); // 通过函数指针pf调用函数fun 011 请你来说一下fork函数Fork：创建一个和当前进程映像一样的进程可以通过fork( )系统调用：#include &lt;sys/types.h&gt; #include &lt;unistd.h&gt; pid_t fork(void); 成功调用fork( )会创建一个新的进程，它几乎与调用fork( )的进程一模一样，这两个进程都会继续运行。在子进程中，成功的fork( )调用会返回0。在父进程中fork( )返回子进程的pid。如果出现错误，fork( )返回一个负值。 最常见的fork( )用法是创建一个新的进程，然后使用exec( )载入二进制映像，替换当前进程的映像。这种情况下，派生（fork）了新的进程，而这个子进程会执行一个新的二进制可执行文件的映像。这种“派生加执行”的方式是很常见的。 在早期的Unix系统中，创建进程比较原始。当调用fork时，内核会把所有的内部数据结构复制一份，复制进程的页表项，然后把父进程的地址空间中的内容逐页的复制到子进程的地址空间中。但从内核角度来说，逐页的复制方式是十分耗时的。现代的Unix系统采取了更多的优化，例如Linux，采用了写时复制的方法，而不是对父进程空间进程整体复制。 012 请你来说一下C++中析构函数的作用析构函数与构造函数对应，当对象结束其生命周期，如对象所在的函数已调用完毕时，系统会自动执行析构函数。析构函数名也应与类名相同，只是在函数名前面加一个位取反符，例如stud( )，以区别于构造函数。它不能带任何参数，也没有返回值（包括void类型）。只能有一个析构函数，不能重载。 如果用户没有编写析构函数，编译系统会自动生成一个缺省的析构函数（即使自定义了析构函数，编译器也总是会为我们合成一个析构函数，并且如果自定义了析构函数，编译器在执行时会先调用自定义的析构函数再调用合成的析构函数），它也不进行任何操作。所以许多简单的类中没有用显式的析构函数。 如果一个类中有指针，且在使用的过程中动态的申请了内存，那么最好显示构造析构函数在销毁类之前，释放掉申请的内存空间，避免内存泄漏。 类析构顺序：1）派生类本身的析构函数；2）对象成员析构函数；3）基类析构函数。 013 请你来说一下静态函数和虚函数的区别静态函数在编译的时候就已经确定运行时机，虚函数在运行的时候动态绑定。虚函数因为用了虚函数表机制，调用的时候会增加一次内存开销 014 请你来说一说重载和覆盖重载：两个函数名相同，但是参数列表不同（个数，类型），返回值类型没有要求，在同一作用域中重写：子类继承了父类，父类中的函数是虚函数，在子类中重新定义了这个虚函数，这种情况是重写 C++的函数重载 015 请你说一说strcpy和strlenstrcpy是字符串拷贝函数，原型：char strcpy(char dest, const char *src); 从src逐字节拷贝到dest，直到遇到’\\0’结束，因为没有指定长度，可能会导致拷贝越界，造成缓冲区溢出漏洞,安全版本是strncpy函数。strlen函数是计算字符串长度的函数，返回从开始到’\\0’之间的字符个数。 016 请你说一说你理解的虚函数和多态多态的实现主要分为静态多态和动态多态，静态多态主要是重载，在编译的时候就已经确定；动态多态是用虚函数机制实现的，在运行期间动态绑定。举个例子：一个父类类型的指针指向一个子类对象时候，使用父类的指针去调用子类中重写了的父类中的虚函数的时候，会调用子类重写过后的函数，在父类中声明为加了virtual关键字的函数，在子类中重写时候不需要加virtual也是虚函数。虚函数的实现：在有虚函数的类中，类的最开始部分是一个虚函数表的指针，这个指针指向一个虚函数表，表中放了虚函数的地址，实际的虚函数在代码段(.text)中。当子类继承了父类的时候也会继承其虚函数表，当子类重写父类中虚函数时候，会将其继承到的虚函数表中的地址替换为重新写的函数地址。使用了虚函数，会增加访问内存开销，降低效率。 017 请你来回答一下++i和i++的区别++i先自增1，再返回，i++先返回i,再自增1 018 请你来写个函数在main函数执行前先运行1234__attribute((constructor))void before()&#123; printf(&quot;before main\\n&quot;);&#125; 019 以下四行代码的区别是什么？const char * arr = “123”; char * brr = “123”; const char crr[] = “123”; char drr[] = “123”; const char * arr = “123”;//字符串123保存在常量区，const本来是修饰arr指向的值不能通过arr去修改，但是字符串“123”在常量区，本来就不能改变，所以加不加const效果都一样 char * brr = “123”; //字符串123保存在常量区，这个arr指针指向的是同一个位置，同样不能通过brr去修改”123”的值 const char crr[] = “123”; //这里123本来是在栈上的，但是编译器可能会做某些优化，将其放到常量区 char drr[] = “123”; //字符串123保存在栈区，可以通过drr去修改 020 请你来说一下C++里是怎么定义常量的？常量存放在内存的哪个位置？常量在C++里的定义就是一个top-level const加上对象类型，常量定义必须初始化。对于局部对象，常量存放在栈区，对于全局对象，常量存放在全局/静态存储区。对于字面值常量，常量存放在常量存储区。 021 请你来回答一下const修饰成员函数的目的是什么？const修饰的成员函数表明函数调用不会对对象做出任何更改，事实上，如果确认不会对对象做更改，就应该为函数加上const限定，这样无论const对象还是普通对象都可以调用该函数。 022 如果同时定义了两个函数，一个带const，一个不带，会有问题吗？不会，这相当于函数的重载。 搜了下，这是一个牛客用户面经里的内容，小编直接复制粘贴过来了其中的一个片段。结合原文语境，这里的两个函数指的是一个类中两个成员函数，带const，const是放在函数后面的，也就是对this指针做const限定。所以说是重载 023 请你来说一说隐式类型转换024 请你来说一说C++函数栈空间的最大值默认是1M，不过可以调整 025 请你来说一说extern“C”C++调用C函数需要extern C，因为C语言没有函数重载。 026 请你回答一下new/delete与malloc/free的区别是什么首先，new/delete是C++的关键字，而malloc/free是C语言的库函数，后者使用必须指明申请内存空间的大小，对于类类型的对象，后者不会调用构造函数和析构函数 027 请你说说虚函数表具体是怎样实现运行时多态的?子类若重写父类虚函数，虚函数表中，该函数的地址会被替换，对于存在虚函数的类的对象，在VS中，对象的对象模型的头部存放指向虚函数表的指针，通过该机制实现多态。 028 请你说说C语言是怎么进行函数调用的？每一个函数调用都会分配函数栈，在栈内进行函数执行过程。调用前，先把返回地址压栈，然后把当前函数的esp指针压栈。 029 请你说说C语言参数压栈顺序？从右到左 030 请你说说C++如何处理返回值？生成一个临时变量，把它的引用作为函数参数传入函数内。 031 请你回答一下C++中拷贝赋值函数的形参能否进行值传递？不能。如果是这种情况下，调用拷贝构造函数的时候，首先要将实参传递给形参，这个传递的时候又要调用拷贝构造函数。。如此循环，无法完成拷贝，栈也会满。 032 请你回答一下malloc与new区别malloc需要给定申请内存的大小，返回的指针需要强转。new会调用构造函数，返回的指针不用强转。 区别是 new 失败了会掉一个 handler 做补救, 该 handler 默认是 nullptr.再一个是 new 失败了会丢 bad_alloc(如果没指定 nothrow 的话)再一个是 C++ 不许有 size 为 0 的对象, 所以这样的 new 会被强制转为 1 作者：a owensss链接：https://www.zhihu.com/question/30115922/answer/46819323来源：知乎著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。 033 请你说一说selectselect在使用前，先将需要监控的描述符对应的bit位置1，然后将其传给select,当有任何一个事件发生时，select将会返回所有的描述符，需要在应用程序自己遍历去检查哪个描述符上有事件发生，效率很低，并且其不断在内核态和用户态进行描述符的拷贝，开销很大 034 请你说说fork,wait,exec函数父进程产生子进程使用fork拷贝出来一个父进程的副本，此时只拷贝了父进程的页表，两个进程都读同一块内存，当有进程写的时候使用写实拷贝机制分配内存，exec函数可以加载一个elf文件去替换父进程，从此父进程和子进程就可以运行不同的程序了。fork从父进程返回子进程的pid，从子进程返回0.调用了wait的父进程将会发生阻塞，直到有子进程状态改变,执行成功返回0，错误返回-1。exec执行成功则子进程从新的程序开始运行，无返回值，执行失败返回-1 035 请你来说一下map和set有什么区别，分别又是怎么实现的？map和set都是C++的关联容器，其底层实现都是红黑树（RB-Tree）。由于 map 和set所开放的各种操作接口，RB-tree 也都提供了，所以几乎所有的 map 和set的操作行为，都只是转调 RB-tree 的操作行为。map和set区别在于： （1）map中的元素是key-value（关键字—值）对：关键字起到索引的作用，值则表示与索引相关联的数据；Set与之相对就是关键字的简单集合，set中每个元素只包含一个关键字。 （2）set的迭代器是const的，不允许修改元素的值；map允许修改value，但不允许修改key。其原因是因为map和set是根据关键字排序来保证其有序性的，如果允许修改key的话，那么首先需要删除该键，然后调节平衡，再插入修改后的键值，调节平衡，如此一来，严重破坏了map和set的结构，导致iterator失效，不知道应该指向改变前的位置，还是指向改变后的位置。所以STL中将set的迭代器设置成const，不允许修改迭代器的值；而map的迭代器则不允许修改key值，允许修改value值。 （3）map支持下标操作，set不支持下标操作。map可以用key做下标，map的下标运算符[ ]将关键码作为下标去执行查找，如果关键码不存在，则插入一个具有该关键码和mapped_type类型默认值的元素至map中，因此下标运算符[ ]在map应用中需要慎用，const_map不能用，只希望确定某一个关键值是否存在而不希望插入元素时也不应该使用，mapped_type类型没有默认值也不应该使用。如果find能解决需要，尽可能用find。 036 请你来介绍一下STL的allocaotrSTL的分配器用于封装STL容器在内存管理上的底层细节。在C++中，其内存配置和释放如下：new运算分两个阶段：(1)调用::operator new配置内存;(2)调用对象构造函数构造对象内容 delete运算分两个阶段：(1)调用对象希构函数；(2)掉员工::operator delete释放内存 为了精密分工，STL allocator将两个阶段操作区分开来：内存配置有alloc::allocate()负责，内存释放由alloc::deallocate()负责；对象构造由::construct()负责，对象析构由::destroy()负责。 同时为了提升内存管理的效率，减少申请小内存造成的内存碎片问题，SGI STL采用了两级配置器，当分配的空间大小超过128B时，会使用第一级空间配置器；当分配的空间大小小于128B时，将使用第二级空间配置器。第一级空间配置器直接使用malloc()、realloc()、free()函数进行内存空间的分配和释放，而第二级空间配置器采用了内存池技术，通过空闲链表来管理内存。 037 请你说一说STL中MAP数据存放形式红黑树。unordered map底层结构是哈希表 038 请你来说一说STL迭代器删除元素https://github.com/selfboot/CS_Offer/blob/master/C%2B%2B/STL_Iterator.md 039 请你讲讲STL有什么基本组成STL主要由：以下几部分组成：容器迭代器仿函数算法分配器配接器他们之间的关系：分配器给容器分配存储空间，算法通过迭代器获取容器中的内容，仿函数可以协助算法完成各种操作，配接器用来套接适配仿函数 040 请你说说STL中map与unordered_map和MultimapMultimap允许重复元素，map不允许重复。 map： map内部实现了一个红黑树，该结构具有自动排序的功能，因此map内部的所有元素都是有序的，红黑树的每一个节点都代表着map的一个元素，因此，对于map进行的查找，删除，添加等一系列的操作都相当于是对红黑树进行这样的操作，故红黑树的效率决定了map的效率。unordered_map: unordered_map内部实现了一个哈希表，因此其元素的排列顺序是杂乱的，无序的 041 请你说一说vector和list的区别，应用，越详细越好1、概念：1）Vector 连续存储的容器，动态数组，在堆上分配空间 底层实现：数组 两倍容量增长： vector 增加（插入）新元素时，如果未超过当时的容量，则还有剩余空间，那么直接添加到最后（插入指定位置），然后调整迭代器。 如果没有剩余空间了，则会重新配置原有元素个数的两倍空间，然后将原空间元素通过复制的方式初始化新空间，再向新空间增加元素，最后析构并释放原空间，之前的迭代器会失效。 性能： 访问：O(1) 插入：在最后插入（空间够）：很快 在最后插入（空间不够）：需要内存申请和释放，以及对之前数据进行拷贝。 在中间插入（空间够）：内存拷贝 在中间插入（空间不够）：需要内存申请和释放，以及对之前数据进行拷贝。 删除：在最后删除：很快 在中间删除：内存拷贝 适用场景：经常随机访问，且不经常对非尾节点进行插入删除。 2、List 动态链表，在堆上分配空间，每插入一个元数都会分配空间，每删除一个元素都会释放空间。 底层：双向链表 性能： 访问：随机访问性能很差，只能快速访问头尾节点。 插入：很快，一般是常数开销 删除：很快，一般是常数开销 适用场景：经常插入删除大量数据 2、区别： 1）vector底层实现是数组；list是双向 链表。 2）vector支持随机访问，list不支持。 3）vector是顺序内存，list不是。 4）vector在中间节点进行插入删除会导致内存拷贝，list不会。 5）vector一次性分配好内存，不够时才进行2倍扩容；list每次插入新节点都会进行内存申请。 6）vector随机访问性能好，插入删除性能差；list随机访问性能差，插入删除性能好。 3、应用 vector拥有一段连续的内存空间，因此支持随机访问，如果需要高效的随即访问，而不在乎插入和删除的效率，使用vector。 list拥有一段不连续的内存空间，如果需要高效的插入和删除，而不关心随机访问，则应使用list。 042 请你来说一下STL中迭代器的作用，有指针为何还要迭代器1、迭代器Iterator（迭代器）模式又称Cursor（游标）模式，用于提供一种方法顺序访问一个聚合对象中各个元素, 而又不需暴露该对象的内部表示。或者这样说可能更容易理解：Iterator模式是运用于聚合对象的一种模式，通过运用该模式，使得我们可以在不知道对象内部表示的情况下，按照一定顺序（由iterator提供的方法）访问聚合对象中的各个元素。 由于Iterator模式的以上特性：与聚合对象耦合，在一定程度上限制了它的广泛运用，一般仅用于底层聚合支持类，如STL的list、vector、stack等容器类及ostream_iterator等扩展iterator。 2、迭代器和指针的区别 迭代器不是指针，是类模板，表现的像指针。他只是模拟了指针的一些功能，通过重载了指针的一些操作符，-&gt;、*、++、–等。迭代器封装了指针，是一个“可遍历STL（ Standard Template Library）容器内全部或部分元素”的对象， 本质是封装了原生指针，是指针概念的一种提升（lift），提供了比指针更高级的行为，相当于一种智能指针，他可以根据不同类型的数据结构来实现不同的++，–等操作。 迭代器返回的是对象引用而不是对象的值，所以cout只能输出迭代器使用*取值后的值而不能直接输出其自身。 3、迭代器产生原因 Iterator类的访问方式就是把不同集合类的访问逻辑抽象出来，使得不用暴露集合内部的结构而达到循环遍历集合的效果。 043 请你回答一下STL里resize和reserve的区别resize()：改变当前容器内含有元素的数量(size())，eg: vectorv; v.resize(len);v的size变为len,如果原来v的size小于len，那么容器新增（len-size）个元素，元素的值为默认为0.当v.push_back(3);之后，则是3是放在了v的末尾，即下标为len，此时容器是size为len+1；reserve()：改变当前容器的最大容量（capacity）,它不会生成元素，只是确定这个容器允许放入多少对象，如果reserve(len)的值大于当前的capacity()，那么会重新分配一块能存len个对象的空间，然后把之前v.size()个对象通过copy construtor复制过来，销毁之前的内存； 044 请你来说一下C++中类成员的访问权限参考回答：C++通过 public、protected、private 三个关键字来控制成员变量和成员函数的访问权限，它们分别表示公有的、受保护的、私有的，被称为成员访问限定符。在类的内部（定义类的代码内部），无论成员被声明为 public、protected 还是 private，都是可以互相访问的，没有访问权限的限制。在类的外部（定义类的代码之外），只能通过对象访问成员，并且通过对象只能访问 public 属性的成员，不能访问 private、protected 属性的成员 045 请你来说一下C++中struct和class的区别1.默认的继承访问权。class默认的是private,strcut默认的是public。2.默认访问权限：struct作为数据结构的实现体，它默认的数据访问控制是public的，而class作为对象的实现体，它默认的成员变量访问控制是private的。3.“class”这个关键字还用于定义模板参数，就像“typename”。但关建字“struct”不用于定义模板参数 4.class和struct在使用大括号{ }上的区别关于使用大括号初始化1.）class和struct如果定义了构造函数的话，都不能用大括号进行初始化 2.）如果没有定义构造函数，struct可以用大括号初始化。 3.）如果没有定义构造函数，且所有成员变量全是public的话，class可以用大括号初始化 https://zhuanlan.zhihu.com/p/47808468 046 请你回答一下C++类内可以定义引用数据成员吗？可以，必须通过成员函数初始化列表初始化。 047 请你回答一下什么是右值引用，跟左值又有什么区别？右值引用是C++11中引入的新特性 , 它实现了转移语义和精确传递。它的主要目的有两个方面： 消除两个对象交互时不必要的对象拷贝，节省运算存储资源，提高效率。 能够更简洁明确地定义泛型函数。 左值和右值的概念： 左值：能对表达式取地址、或具名对象/变量。一般指表达式结束后依然存在的持久对象。 右值：不能对表达式取地址，或匿名对象。一般指表达式结束就不再存在的临时对象。 右值引用和左值引用的区别： 左值可以寻址，而右值不可以。 左值可以被赋值，右值不可以被赋值，可以用来给左值赋值。 左值可变,右值不可变（仅对基础类型适用，用户自定义类型右值引用可以通过成员函数改变）。 048 请你来说一下一个C++源文件从文本到可执行文件经历的过程？对于C++源文件，从文本到可执行文件一般需要四个过程：预处理阶段：对源代码文件中文件包含关系（头文件）、预编译语句（宏定义）进行分析和替换，生成预编译文件。 编译阶段：将经过预处理后的预编译文件转换成特定汇编代码，生成汇编文件 汇编阶段：将编译阶段生成的汇编文件转化成机器码，生成可重定位目标文件 链接阶段：将多个目标文件及所需要的库连接成最终的可执行目标文件 049 请你来回答一下include头文件的顺序以及双引号””和尖括号&lt;&gt;的区别？Include头文件的顺序：对于include的头文件来说，如果在文件a.h中声明一个在文件b.h中定义的变量，而不引用b.h。那么要在a.c文件中引用b.h文件，并且要先引用b.h，后引用a.h,否则汇报变量类型未声明错误。双引号和尖括号的区别：编译器预处理阶段查找头文件的路径不一样。 对于使用双引号包含的头文件，查找头文件路径的顺序为： 当前头文件目录 编译器设置的头文件路径（编译器可使用-I显式指定搜索路径） 系统变量CPLUS_INCLUDE_PATH/C_INCLUDE_PATH指定的头文件路径 对于使用尖括号包含的头文件，查找头文件的路径顺序为： 编译器设置的头文件路径（编译器可使用-I显式指定搜索路径） 系统变量CPLUS_INCLUDE_PATH/C_INCLUDE_PATH指定的头文件路径 050 请你回答一下malloc的原理，另外brk系统调用和mmap系统调用的作用分别是什么？Malloc函数用于动态分配内存。为了减少内存碎片和系统调用的开销，malloc其采用内存池的方式，先申请大块内存作为堆区，然后将堆区分为多个内存块，以块作为内存管理的基本单位。当用户申请内存时，直接从堆区分配一块合适的空闲块。Malloc采用隐式链表结构将堆区分成连续的、大小不一的块，包含已分配块和未分配块；同时malloc采用显示链表结构来管理所有的空闲块，即使用一个双向链表将空闲块连接起来，每一个空闲块记录了一个连续的、未分配的地址。当进行内存分配时，Malloc会通过隐式链表遍历所有的空闲块，选择满足要求的块进行分配；当进行内存合并时，malloc采用边界标记法，根据每个块的前后块是否已经分配来决定是否进行块合并。 Malloc在申请内存时，一般会通过brk或者mmap系统调用进行申请。其中当申请内存小于128K时，会使用系统函数brk在堆区中分配；而当申请内存大于128K时，会使用系统函数mmap在映射区分配。 051 请你说一说C++的内存管理是怎样的？在C++中，虚拟内存分为代码段、数据段、BSS段、堆区、文件映射区以及栈区六部分。代码段:包括只读存储区和文本区，其中只读存储区存储字符串常量，文本区存储程序的机器代码。 数据段：存储程序中已初始化的全局变量和静态变量 bss 段：存储未初始化的全局变量和静态变量（局部+全局），以及所有被初始化为0的全局变量和静态变量。 堆区：调用new/malloc函数时在堆区动态分配内存，同时需要调用delete/free来手动释放申请的内存。 映射区:存储动态链接库以及调用mmap函数进行的文件映射 栈：使用栈空间存储函数的返回地址、参数、局部变量、返回值 052 请你回答一下如何判断内存泄漏？内存泄漏通常是由于调用了malloc/new等内存申请的操作，但是缺少了对应的free/delete。为了判断内存是否泄露，我们一方面可以使用linux环境下的内存泄漏检查工具Valgrind,另一方面我们在写代码时可以添加内存申请和释放的统计功能，统计当前申请和释放的内存是否一致，以此来判断内存是否泄露。 053 请你来说一下什么时候会发生段错误段错误通常发生在访问非法内存地址的时候，具体来说分为以下几种情况：使用野指针 试图修改字符串常量的内容 054 请你来回答一下什么是memory leak，也就是内存泄漏内存泄漏(memory leak)是指由于疏忽或错误造成了程序未能释放掉不再使用的内存的情况。内存泄漏并非指内存在物理上的消失，而是应用程序分配某段内存后，由于设计错误，失去了对该段内存的控制，因而造成了内存的浪费。内存泄漏的分类： 堆内存泄漏 （Heap leak）。对内存指的是程序运行中根据需要分配通过malloc,realloc new等从堆中分配的一块内存，再是完成后必须通过调用对应的 free或者delete 删掉。如果程序的设计的错误导致这部分内存没有被释放，那么此后这块内存将不会被使用，就会产生Heap Leak. 系统资源泄露（Resource Leak）。主要指程序使用系统分配的资源比如 Bitmap,handle ,SOCKET等没有使用相应的函数释放掉，导致系统资源的浪费，严重可导致系统效能降低，系统运行不稳定。 没有将基类的析构函数定义为虚函数。当基类指针指向子类对象时，如果基类的析构函数不是virtual，那么子类的析构函数将不会被调用，子类的资源没有正确是释放，因此造成内存泄露。 055 请你来回答一下new和malloc的区别1、new分配内存按照数据类型进行分配，malloc分配内存按照指定的大小分配；2、new返回的是指定对象的指针，而malloc返回的是void*，因此malloc的返回值一般都需要进行类型转化。 3、new不仅分配一段内存，而且会调用构造函数，malloc不会。 4、new分配的内存要用delete销毁，malloc要用free来销毁；delete销毁的时候会调用对象的析构函数，而free则不会。 5、new是一个操作符可以重载，malloc是一个库函数。 6、malloc分配的内存不够的时候，可以用realloc扩容。扩容的原理？new没用这样操作。 7、new如果分配失败了会抛出bad_malloc的异常，而malloc失败了会返回NULL。 8、申请数组时： new[]一次分配所有内存，多次调用构造函数，搭配使用delete[]，delete[]多次调用析构函数，销毁数组中的每个对象。而malloc则只能sizeof(int) * n。 056 请你来说一下共享内存相关apiLinux允许不同进程访问同一个逻辑内存，提供了一组API，头文件在sys/shm.h中。1）新建共享内存shmget int shmget(key_t key,size_t size,int shmflg); key：共享内存键值，可以理解为共享内存的唯一性标记。 size：共享内存大小 shmflag：创建进程和其他进程的读写权限标识。 返回值：相应的共享内存标识符，失败返回-1 2）连接共享内存到当前进程的地址空间shmat void *shmat(int shm_id,const void *shm_addr,int shmflg); shm_id：共享内存标识符 shm_addr：指定共享内存连接到当前进程的地址，通常为0，表示由系统来选择。 shmflg：标志位 返回值：指向共享内存第一个字节的指针，失败返回-1 3）当前进程分离共享内存shmdt int shmdt(const void *shmaddr); 4）控制共享内存shmctl 和信号量的semctl函数类似，控制共享内存 int shmctl(int shm_id,int command,struct shmid_ds *buf); shm_id：共享内存标识符 command: 有三个值 IPC_STAT:获取共享内存的状态，把共享内存的shmid_ds结构复制到buf中。 IPC_SET:设置共享内存的状态，把buf复制到共享内存的shmid_ds结构。 IPC_RMID:删除共享内存 buf：共享内存管理结构体。 057 请你来说一下reactor模型组成reactor模型要求主线程只负责监听文件描述上是否有事件发生，有的话就立即将该事件通知工作线程，除此之外，主线程不做任何其他实质性的工作，读写数据、接受新的连接以及处理客户请求均在工作线程中完成。其模型组成如下： 1）Handle：即操作系统中的句柄，是对资源在操作系统层面上的一种抽象，它可以是打开的文件、一个连接(Socket)、Timer等。由于Reactor模式一般使用在网络编程中，因而这里一般指Socket Handle，即一个网络连接。 2）Synchronous Event Demultiplexer（同步事件复用器）：阻塞等待一系列的Handle中的事件到来，如果阻塞等待返回，即表示在返回的Handle中可以不阻塞的执行返回的事件类型。这个模块一般使用操作系统的select来实现。 3）Initiation Dispatcher：用于管理Event Handler，即EventHandler的容器，用以注册、移除EventHandler等；另外，它还作为Reactor模式的入口调用Synchronous Event Demultiplexer的select方法以阻塞等待事件返回，当阻塞等待返回时，根据事件发生的Handle将其分发给对应的Event Handler处理，即回调EventHandler中的handle_event()方法。 4）Event Handler：定义事件处理方法：handle_event()，以供InitiationDispatcher回调使用。 5）Concrete Event Handler：事件EventHandler接口，实现特定事件处理逻辑。 058 请自己设计一下如何采用单线程的方式处理高并发在单线程模型中，可以采用I/O复用来提高单线程处理多个请求的能力，然后再采用事件驱动模型，基于异步回调来处理事件来 059 请你说说select，epoll的区别，原理，性能，限制都说一说1）IO多路复用IO复用模型在阻塞IO模型上多了一个select函数，select函数有一个参数是文件描述符集合，意思就是对这些的文件描述符进行循环监听，当某个文件描述符就绪的时候，就对这个文件描述符进行处理。 这种IO模型是属于阻塞的IO。但是由于它可以对多个文件描述符进行阻塞监听，所以它的效率比阻塞IO模型高效。 IO多路复用就是我们说的select，poll，epoll。select/epoll的好处就在于单个process就可以同时处理多个网络连接的IO。它的基本原理就是select，poll，epoll这个function会不断的轮询所负责的所有socket，当某个socket有数据到达了，就通知用户进程。 当用户进程调用了select，那么整个进程会被block，而同时，kernel会“监视”所有select负责的socket，当任何一个socket中的数据准备好了，select就会返回。这个时候用户进程再调用read操作，将数据从kernel拷贝到用户进程。 所以，I/O 多路复用的特点是通过一种机制一个进程能同时等待多个文件描述符，而这些文件描述符（套接字描述符）其中的任意一个进入读就绪状态，select()函数就可以返回。 I/O多路复用和阻塞I/O其实并没有太大的不同，事实上，还更差一些。因为这里需要使用两个system call (select 和 recvfrom)，而blocking IO只调用了一个system call (recvfrom)。但是，用select的优势在于它可以同时处理多个connection。 所以，如果处理的连接数不是很高的话，使用select/epoll的web server不一定比使用multi-threading + blocking IO的web server性能更好，可能延迟还更大。select/epoll的优势并不是对于单个连接能处理得更快，而是在于能处理更多的连接。） 在IO multiplexing Model中，实际中，对于每一个socket，一般都设置成为non-blocking，但是，如上图所示，整个用户的process其实是一直被block的。只不过process是被select这个函数block，而不是被socket IO给block。 2、select select：是最初解决IO阻塞问题的方法。用结构体fd_set来告诉内核监听多个文件描述符，该结构体被称为描述符集。由数组来维持哪些描述符被置位了。对结构体的操作封装在三个宏定义中。通过轮寻来查找是否有描述符要被处理。 存在的问题： 内置数组的形式使得select的最大文件数受限与FD_SIZE； 每次调用select前都要重新初始化描述符集，将fd从用户态拷贝到内核态，每次调用select后，都需要将fd从内核态拷贝到用户态； 轮寻排查当文件描述符个数很多时，效率很低； 3、poll poll：通过一个可变长度的数组解决了select文件描述符受限的问题。数组中元素是结构体，该结构体保存描述符的信息，每增加一个文件描述符就向数组中加入一个结构体，结构体只需要拷贝一次到内核态。poll解决了select重复初始化的问题。轮寻排查的问题未解决。 4、epoll epoll：轮寻排查所有文件描述符的效率不高，使服务器并发能力受限。因此，epoll采用只返回状态发生变化的文件描述符，便解决了轮寻的瓶颈。 epoll对文件描述符的操作有两种模式：LT（level trigger）和ET（edge trigger）。LT模式是默认模式 LT模式 LT(level triggered)是缺省的工作方式，并且同时支持block和no-block socket.在这种做法中，内核告诉你一个文件描述符是否就绪了，然后你可以对这个就绪的fd进行IO操作。如果你不作任何操作，内核还是会继续通知你的。 ET模式 ET(edge-triggered)是高速工作方式，只支持no-block socket。在这种模式下，当描述符从未就绪变为就绪时，内核通过epoll告诉你。然后它会假设你知道文件描述符已经就绪，并且不会再为那个文件描述符发送更多的就绪通知，直到你做了某些操作导致那个文件描述符不再为就绪状态了(比如，你在发送，接收或者接收请求，或者发送接收的数据少于一定量时导致了一个EWOULDBLOCK 错误）。但是请注意，如果一直不对这个fd作IO操作(从而导致它再次变成未就绪)，内核不会发送更多的通知(only once) ET模式在很大程度上减少了epoll事件被重复触发的次数，因此效率要比LT模式高。epoll工作在ET模式的时候，必须使用非阻塞套接口，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。 3、LT模式与ET模式的区别如下：LT模式：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序可以不立即处理该事件。下次调用epoll_wait时，会再次响应应用程序并通知此事件。ET模式：当epoll_wait检测到描述符事件发生并将此事件通知应用程序，应用程序必须立即处理该事件。如果不处理，下次调用epoll_wait时，不会再次响应应用程序并通知此事件。 060 请你说一说C++ STL 的内存优化1）二级配置器结构STL内存管理使用二级内存配置器。1、第一级配置器第一级配置器以malloc()，free()，realloc()等C函数执行实际的内存配置、释放、重新配置等操作，并且能在内存需求不被满足的时候，调用一个指定的函数。一级空间配置器分配的是大于128字节的空间如果分配不成功，调用句柄释放一部分内存如果还不能分配成功，抛出异常2、第二级配置器在STL的第二级配置器中多了一些机制，避免太多小区块造成的内存碎片，小额区块带来的不仅是内存碎片，配置时还有额外的负担。区块越小，额外负担所占比例就越大。3、分配原则如果要分配的区块大于128bytes，则移交给第一级配置器处理。如果要分配的区块小于128bytes，则以内存池管理（memory pool），又称之次层配置（sub-allocation）：每次配置一大块内存，并维护对应的16个空闲链表（free-list）。下次若有相同大小的内存需求，则直接从free-list中取。如果有小额区块被释放，则由配置器回收到free-list中。当用户申请的空间小于128字节时，将字节数扩展到8的倍数，然后在自由链表中查找对应大小的子链表如果在自由链表查找不到或者块数不够，则向内存池进行申请，一般一次申请20块如果内存池空间足够，则取出内存如果不够分配20块，则分配最多的块数给自由链表，并且更新每次申请的块数如果一块都无法提供，则把剩余的内存挂到自由链表，然后向系统heap申请空间，如果申请失败，则看看自由链表还有没有可用的块，如果也没有，则最后调用一级空间配置器2）二级内存池二级内存池采用了16个空闲链表，这里的16个空闲链表分别管理大小为8、16、24……120、128的数据块。这里空闲链表节点的设计十分巧妙，这里用了一个联合体既可以表示下一个空闲数据块（存在于空闲链表中）的地址，也可以表示已经被用户使用的数据块（不存在空闲链表中）的地址。 1、空间配置函数allocate首先先要检查申请空间的大小，如果大于128字节就调用第一级配置器，小于128字节就检查对应的空闲链表，如果该空闲链表中有可用数据块，则直接拿来用（拿取空闲链表中的第一个可用数据块，然后把该空闲链表的地址设置为该数据块指向的下一个地址），如果没有可用数据块，则调用refill重新填充空间。2、空间释放函数deallocate首先先要检查释放数据块的大小，如果大于128字节就调用第一级配置器，小于128字节则根据数据块的大小来判断回收后的空间会被插入到哪个空闲链表。3、重新填充空闲链表refill在用allocate配置空间时，如果空闲链表中没有可用数据块，就会调用refill来重新填充空间，新的空间取自内存池。缺省取20个数据块，如果内存池空间不足，那么能取多少个节点就取多少个。从内存池取空间给空闲链表用是chunk_alloc的工作，首先根据end_free-start_free来判断内存池中的剩余空间是否足以调出nobjs个大小为size的数据块出去，如果内存连一个数据块的空间都无法供应，需要用malloc取堆中申请内存。假如山穷水尽，整个系统的堆空间都不够用了，malloc失败，那么chunk_alloc会从空闲链表中找是否有大的数据块，然后将该数据块的空间分给内存池（这个数据块会从链表中去除）。3、总结： 使用allocate向内存池请求size大小的内存空间，如果需要请求的内存大小大于128bytes，直接使用malloc。 如果需要的内存大小小于128bytes，allocate根据size找到最适合的自由链表。a. 如果链表不为空，返回第一个node，链表头改为第二个node。b. 如果链表为空，使用blockAlloc请求分配node。x. 如果内存池中有大于一个node的空间，分配竟可能多的node(但是最多20个)，将一个node返回，其他的node添加到链表中。y. 如果内存池只有一个node的空间，直接返回给用户。z. 若果如果连一个node都没有，再次向操作系统请求分配内存。①分配成功，再次进行b过程。②分配失败，循环各个自由链表，寻找空间。I. 找到空间，再次进行过程b。II. 找不到空间，抛出异常。 用户调用deallocate释放内存空间，如果要求释放的内存空间大于128bytes，直接调用free。 否则按照其大小找到合适的自由链表，并将其插入。 61 拷贝构造上面的定义的类Person显式的删除了拷贝构造函数和赋值运算符，在需要调用拷贝构造函数或者赋值运算符的地方，会提示_无法调用该函数，它是已删除的函数_。还有一点需要注意的是，拷贝构造函数必须以引用的方式传递参数。这是因为，在值传递的方式传递给一个函数的时候，会调用拷贝构造函数生成函数的实参。如果拷贝构造函数的参数仍然是以值的方式，就会无限循环的调用下去，直到函数的栈溢出。 何时调用拷贝构造函数和赋值运算符的行为比较相似，都是将一个对象的值复制给另一个对象；但是其结果却有些不同，拷贝构造函数使用传入对象的值生成一个新的对象的实例，而赋值运算符是将对象的值复制给一个已经存在的实例。这种区别从两者的名字也可以很轻易的分辨出来，拷贝构造函数也是一种构造函数，那么它的功能就是创建一个新的对象实例；赋值运算符是执行某种运算，将一个对象的值复制给另一个对象（已经存在的）。调用的是拷贝构造函数还是赋值运算符，主要是看是否有新的对象实例产生。如果产生了新的对象实例，那调用的就是拷贝构造函数；如果没有，那就是对已有的对象赋值，调用的是赋值运算符。 062 深拷贝、浅拷贝说到拷贝构造函数，就不得不提深拷贝和浅拷贝。通常，默认生成的拷贝构造函数和赋值运算符，只是简单的进行值的复制。例如：上面的Person类，字段只有int和string两种类型，这在拷贝或者赋值时进行值复制创建的出来的对象和源对象也是没有任何关联，对源对象的任何操作都不会影响到拷贝出来的对象。反之，假如Person有一个对象为int *，这时在拷贝时还只是进行值复制，那么创建出来的Person对象的int *的值就和源对象的int *指向的是同一个位置。任何一个对象对该值的修改都会影响到另一个对象，这种情况就是浅拷贝。 深拷贝和浅拷贝主要是针对类中的指针和动态分配的空间来说的，因为对于指针只是简单的值复制并不能分割开两个对象的关联，任何一个对象对该指针的操作都会影响到另一个对象。这时候就需要提供自定义的深拷贝的拷贝构造函数，消除这种影响。通常的原则是： 含有指针类型的成员或者有动态分配内存的成员都应该提供自定义的拷贝构造函数在提供拷贝构造函数的同时，还应该考虑实现自定义的赋值运算符对于拷贝构造函数的实现要确保以下几点： 对于值类型的成员进行值复制对于指针和动态分配的空间，在拷贝中应重新分配分配空间对于基类，要调用基类合适的拷贝方法，完成基类的拷贝 ending","categories":[],"tags":[{"name":"面试","slug":"面试","permalink":"https://riverferry.site/tags/%E9%9D%A2%E8%AF%95/"}],"keywords":[]},{"title":"华为机试1-30","slug":"2020-03-28-华为机试1-30","date":"2020-03-28T00:00:00.000Z","updated":"2022-09-12T16:24:32.279Z","comments":true,"path":"2020-03-28-华为机试1-30/","link":"","permalink":"https://riverferry.site/2020-03-28-%E5%8D%8E%E4%B8%BA%E6%9C%BA%E8%AF%951-30/","excerpt":"参考华为机试在线训练","text":"参考华为机试在线训练 001 字符串最后一个单词的长度计算字符串最后一个单词的长度，单词以空格隔开 1234567891011121314151617#include &lt;iostream&gt;#include &lt;string&gt;#include &lt;vector&gt;using namespace std;int main()&#123; string str; while(cin&gt;&gt;str) ; cout &lt;&lt; str.length() &lt;&lt; endl; return 0;&#125; 002 计算字符个数写出一个程序，接受一个由字母和数字组成的字符串，和一个字符，然后输出输入字符串中含有该字符的个数。不区分大小写。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#include &lt;iostream&gt;#include &lt;string&gt;using namespace std;int main()&#123; string str; int flag = 0; size_t pos = 0; int count = 0; char ch1 = 0; char ch2 = 0; while(cin&gt;&gt;str&gt;&gt;ch1) &#123; flag = 1; if (ch1 &gt;= &#x27;A&#x27; &amp;&amp; ch1 &lt;= &#x27;Z&#x27;) ch2 = ch1 + &#x27;a&#x27; - &#x27;A&#x27;; else if (ch1 &gt;= &#x27;a&#x27; &amp;&amp; ch1 &lt;= &#x27;z&#x27;) ch2 = ch1 - (&#x27;a&#x27; - &#x27;A&#x27;); else if (ch1 &gt;= &#x27;0&#x27; &amp;&amp; ch1 &lt;= &#x27;9&#x27;) ; else flag = 0; if (flag == 1) &#123; while((pos = str.find(ch1, pos)) != string::npos) &#123; count++; pos++; &#125; pos = 0; while((pos = str.find(ch2, pos)) != string::npos) &#123; count++; pos++; &#125; &#125; cout &lt;&lt; count &lt;&lt; endl; &#125; return 0;&#125; 003 明明的随机数明明想在学校中请一些同学一起做一项问卷调查，为了实验的客观性，他先用计算机生成了N个1到1000之间的随机整数（N≤1000），对于其中重复的数字，只保留一个，把其余相同的数去掉，不同的数对应着不同的学生的学号。然后再把这些数从小到大排序，按照排好的顺序去找同学做调查。请你协助明明完成“去重”与“排序”的工作(同一个测试用例里可能会有多组数据，希望大家能正确处理)。 Input Param n 输入随机数的个数 inputArray n个随机整数组成的数组 Return Value OutputArray 输出处理后的随机整数 注：测试用例保证输入参数的正确性，答题者无需验证。测试用例不止一组。 样例输入解释：样例有两组测试第一组是3个数字，分别是：2，2，1。第二组是11个数字，分别是：10，20，40，32，67，40，20，89，300，400，15。 123456789101112131415161718192021222324252627#include &lt;iostream&gt;#include &lt;set&gt;using namespace std;int main()&#123; int n = 0; set&lt;int&gt; inputArray; int num = 0; while(cin &gt;&gt; n) &#123; inputArray.clear(); while(n-- &amp;&amp; cin&gt;&gt;num) &#123; inputArray.insert(num); &#125; set&lt;int&gt;::iterator it = inputArray.begin(); for(; it != inputArray.end() ; it++) &#123; cout &lt;&lt; *it &lt;&lt; endl; &#125; &#125; return 0;&#125; 004 字符串分隔题目描述 连续输入字符串，请按长度为8拆分每个字符串后输出到新的字符串数组； 长度不是8整数倍的字符串请在后面补数字0，空字符串不处理。 1234567891011121314151617181920212223242526272829303132333435363738#include &lt;iostream&gt;#include &lt;string&gt;#include &lt;vector&gt;using namespace std;#define STEP 8int main()&#123; vector&lt;string&gt;arr; string str; string str2; int pos = 0; while(cin&gt;&gt;str) &#123; pos = 0; while((str2 = str.substr(pos, STEP)).length() &gt;= STEP) &#123; arr.push_back(str2); pos += STEP; &#125; if (str2.length() &gt; 0) &#123; str2.append(STEP - str2.length(),&#x27;0&#x27;); arr.push_back(str2); &#125; &#125; vector&lt;string&gt;::iterator it = arr.begin(); for(; it != arr.end(); it++) &#123; cout &lt;&lt; *it &lt;&lt; endl; &#125; return 0;&#125; 005 进制转换写出一个程序，接受一个十六进制的数，输出该数值的十进制表示。（多组同时输入 ） 1234567891011121314#include &lt;iostream&gt;using namespace std;int main()&#123; unsigned long long num = 0; while(cin &gt;&gt; hex &gt;&gt; num ) &#123; cout &lt;&lt; num &lt;&lt; endl; &#125; return 0;&#125; 123456789101112131415161718192021222324252627282930313233343536#include &lt;iostream&gt;#include &lt;string&gt;using namespace std;int main()&#123; unsigned long long num = 0; unsigned long long bbb = 0; char ch = 0; string str; while (cin &gt;&gt; str) &#123; string::reverse_iterator it = str.rbegin(); num = 0; bbb = 1; for (; it != str.rend(); it++) &#123; ch = *it; if (ch &gt;= &#x27;0&#x27; &amp;&amp; ch &lt;= &#x27;9&#x27;) ch -= &#x27;0&#x27;; else if (ch &gt;= &#x27;A&#x27; &amp;&amp; ch &lt;= &#x27;F&#x27;) ch = ch - &#x27;A&#x27; + 10; else break; num = num + ch * bbb; bbb *= 16; &#125; cout &lt;&lt; num &lt;&lt; endl; &#125; return 0;&#125; 006 质数因子007 取近似值写出一个程序，接受一个正浮点数值，输出该数值的近似整数值。如果小数点后数值大于等于5,向上取整；小于5，则向下取整。 12345678910111213141516171819202122#include &lt;iostream&gt;#include &lt;string&gt;#include &quot;stdlib.h&quot;using namespace std;int main()&#123; string str; string str2; long long n = 0; cin&gt;&gt;str; str2 = str.substr(0, str.find(&#x27;.&#x27;)); n = atoi(str2.c_str()); if (*(str.c_str() + str.find(&#x27;.&#x27;) + 1) &gt;= &#x27;5&#x27;) n++; cout &lt;&lt; n &lt;&lt; endl; return 0;&#125; 12345678#include &lt;stdio.h&gt;int main(void)&#123; double num; scanf(&quot;%lf&quot;,&amp;num); printf(&quot;%d&quot;,(int)(num + 0.5)); return 0;&#125; 008 合并表记录数据表记录包含表索引和数值（int范围的整数），请对表索引相同的记录进行合并，即将相同索引的数值进行求和运算，输出按照key值升序进行输出。 123456789101112131415161718192021222324252627282930#include &lt;iostream&gt;#include &lt;map&gt;using namespace std;int main()&#123; int count = 0; int key = 0; int value = 0; map&lt;int, int&gt;mapp; cin &gt;&gt; count; while(cin &gt;&gt; key &gt;&gt; value) &#123; if (mapp.find(key) != mapp.end()) mapp[key] += value; else mapp.insert(pair&lt;int, int&gt;(key, value)); &#125; map&lt;int, int&gt;::iterator it = mapp.begin(); for (; it != mapp.end(); it++) &#123; cout &lt;&lt; it-&gt;first &lt;&lt; &quot; &quot; &lt;&lt; it-&gt;second &lt;&lt; endl; &#125; return 0;&#125; 009 提取不重复的整数输入一个int型整数，按照从右向左的阅读顺序，返回一个不含重复数字的新的整数。 123456789101112131415161718192021222324#include &lt;iostream&gt;#include &lt;map&gt;#include &lt;string&gt;#include &lt;cstring&gt;using namespace std;int main()&#123; char s[30] = &#123;0&#125;; cin &gt;&gt; s; string str; int n = strlen(s); while(n--) &#123; if (str.find(s[n]) == string::npos) str += s[n]; &#125; cout &lt;&lt; str &lt;&lt; endl; return 0;&#125; 010 字符个数统计编写一个函数，计算字符串中含有的不同字符的个数。字符在ACSII码范围内(0~127)，换行表示结束符，不算在字符里。不在范围内的不作统计。 123456789101112131415161718192021222324252627#include &lt;iostream&gt;#include &lt;string&gt;using namespace std;int main()&#123; string str; string str2; int count = 0; cin &gt;&gt; str; for (int i = 0; i &lt; str.length(); i++) &#123; if(str[i] &gt;= 0 &amp;&amp; str[i] &lt;= 127 &amp;&amp; str[i] != &#x27;\\n&#x27;) &#123; if (str2.find(str[i]) == string::npos) &#123; str2 += str[i]; count++; &#125; &#125; &#125; cout &lt;&lt; count &lt;&lt; endl; return 0;&#125; ending","categories":[],"tags":[{"name":"笔试","slug":"笔试","permalink":"https://riverferry.site/tags/%E7%AC%94%E8%AF%95/"}],"keywords":[]},{"title":"linux-waitqueue","slug":"2020-03-24-linux-waitqueue","date":"2020-03-24T00:00:00.000Z","updated":"2022-09-12T16:24:32.278Z","comments":true,"path":"2020-03-24-linux-waitqueue/","link":"","permalink":"https://riverferry.site/2020-03-24-linux-waitqueue/","excerpt":"参考Linux设备驱动六 (1)等待队列 IO多路复用的几种实现机制的分析 select()/poll() 的内核实现 内核源码","text":"参考Linux设备驱动六 (1)等待队列 IO多路复用的几种实现机制的分析 select()/poll() 的内核实现 内核源码 数据结构wait_queue_head_t123456// /include/linux/wait.hstruct wait_queue_head &#123; spinlock_t lock; struct list_head head;&#125;;typedef struct wait_queue_head wait_queue_head_t; wait_queue_t1234567// /include/linux/wait.hstruct wait_queue_entry &#123; unsigned int flags; //唤醒方式 WQ_FLAG_EXCLUSIVE/0 void *private; //保存睡眠进程描述符地址task_struct wait_queue_func_t func; //唤醒方法 struct list_head entry;&#125;; 唤醒方式有 WQ_FLAG_EXCLUSIVE 或者 0；WQ_FLAG_EXCLUSIVE：表示节点对应进程对临界资源使用具有排他性。在唤醒是会唤醒所有非排他性进程和一定数量的排他性进程。 函数调用init_waitqueue_head123456789101112131415161718192021222324252627282930313233343536373839#define init_waitqueue_head(wq_head) \\ do &#123; \\ static struct lock_class_key __key; \\ \\ __init_waitqueue_head((wq_head), #wq_head, &amp;__key); \\ &#125; while (0)extern void __init_waitqueue_head(struct wait_queue_head *wq_head, const char *name, struct lock_class_key *); void __init_waitqueue_head(struct wait_queue_head *wq_head, const char *name, struct lock_class_key *key)&#123; spin_lock_init(&amp;wq_head-&gt;lock); lockdep_set_class_and_name(&amp;wq_head-&gt;lock, key, name); INIT_LIST_HEAD(&amp;wq_head-&gt;head);&#125;``` ----------------------------------### add_wait_queue```cvoid add_wait_queue(struct wait_queue_head *wq_head, struct wait_queue_entry *wq_entry)&#123; unsigned long flags; wq_entry-&gt;flags &amp;= ~WQ_FLAG_EXCLUSIVE; spin_lock_irqsave(&amp;wq_head-&gt;lock, flags); //自旋锁加锁并禁用中断 __add_wait_queue(wq_head, wq_entry); //wait_queue_entry添加到链表wait_queue_head spin_unlock_irqrestore(&amp;wq_head-&gt;lock, flags); //自旋锁解锁并开启中断&#125;EXPORT_SYMBOL(add_wait_queue);static inline void __add_wait_queue( struct wait_queue_head *wq_head, struct wait_queue_entry *wq_entry)&#123; list_add(&amp;wq_entry-&gt;entry, &amp;wq_head-&gt;head);&#125; add_wait_queue_exclusive123456789101112131415161718//Used for wake-one threads:void add_wait_queue_exclusive(struct wait_queue_head *wq_head, struct wait_queue_entry *wq_entry)&#123; unsigned long flags; wq_entry-&gt;flags |= WQ_FLAG_EXCLUSIVE; spin_lock_irqsave(&amp;wq_head-&gt;lock, flags); __add_wait_queue_entry_tail(wq_head, wq_entry); spin_unlock_irqrestore(&amp;wq_head-&gt;lock, flags);&#125;EXPORT_SYMBOL(add_wait_queue_exclusive);static inline void __add_wait_queue_entry_tail( struct wait_queue_head *wq_head, struct wait_queue_entry *wq_entry)&#123; list_add_tail(&amp;wq_entry-&gt;entry, &amp;wq_head-&gt;head);&#125; remove_wait_queue1234567891011121314void remove_wait_queue(struct wait_queue_head *wq_head, struct wait_queue_entry *wq_entry)&#123; unsigned long flags; spin_lock_irqsave(&amp;wq_head-&gt;lock, flags); __remove_wait_queue(wq_head, wq_entry); spin_unlock_irqrestore(&amp;wq_head-&gt;lock, flags);&#125;static inline void__remove_wait_queue(struct wait_queue_head *wq_head, struct wait_queue_entry *wq_entry)&#123; list_del(&amp;wq_entry-&gt;entry);&#125; wait_event1234567891011121314151617181920/** *********************************************** * wait_event - sleep until a condition gets true * @wq_head: the waitqueue to wait on * @condition: a C expression for the event to wait for * * The process is put to sleep (TASK_UNINTERRUPTIBLE) until the * @condition evaluates to true. The @condition is checked each time * the waitqueue @wq_head is woken up. * * wake_up() has to be called after changing any variable that could * change the result of the wait condition. */#define wait_event(wq_head, condition) \\do &#123; \\ might_sleep(); \\ if (condition) \\ break; \\ __wait_event(wq_head, condition); \\&#125; while (0) 12345//__wait_event ***********************************************//设置状态为不可打断#define __wait_event(wq_head, condition) \\ (void)___wait_event(wq_head, condition, TASK_UNINTERRUPTIBLE, 0, 0, \\ schedule()) 123456789101112131415161718192021222324252627282930313233343536//___wait_event ***********************************************/* * The below macro ___wait_event() has an explicit(明确的) shadow of the __ret * variable when used from the wait_event_*() macros. * * This is so that both can use the ___wait_cond_timeout() construct * to wrap the condition. * * The type inconsistency of the wait_event_*() __ret variable is also * on purpose; we use long where we can return timeout values and int * otherwise. */#define ___wait_event(wq_head, condition, state, exclusive, ret, cmd) \\(&#123; \\ __label__ __out; \\ struct wait_queue_entry __wq_entry; \\ long __ret = ret; /* explicit shadow */ \\ \\ init_wait_entry(&amp;__wq_entry, exclusive ? WQ_FLAG_EXCLUSIVE : 0); \\ for (;;) &#123; \\ long __int = prepare_to_wait_event(&amp;wq_head, &amp;__wq_entry, state);\\ \\ if (condition) \\ break; \\ \\ if (___wait_is_interruptible(state) &amp;&amp; __int) &#123; \\ __ret = __int; \\ goto __out; \\ &#125; \\ \\ cmd; \\ &#125; \\ finish_wait(&amp;wq_head, &amp;__wq_entry); \\__out: __ret; \\ condition为true时，是等待事件唤醒 condition为false时，是信号唤醒 prepare_to_wait_event123456789101112131415161718192021222324252627282930313233343536long prepare_to_wait_event( struct wait_queue_head *wq_head, struct wait_queue_entry *wq_entry, int state)&#123; unsigned long flags; long ret = 0; spin_lock_irqsave(&amp;wq_head-&gt;lock, flags); //加锁禁中断 if (signal_pending_state(state, current)) &#123; /* * Exclusive waiter must not fail if it was selected by wakeup, * it should &quot;consume&quot; the condition we were waiting for. * * The caller will recheck the condition and return success if * we were already woken up, we can not miss the event because * wakeup locks/unlocks the same wq_head-&gt;lock. * * But we need to ensure that set-condition + wakeup after that * can&#x27;t see us, it should wake up another exclusive waiter if * we fail. */ list_del_init(&amp;wq_entry-&gt;entry); ret = -ERESTARTSYS; &#125; else &#123; if (list_empty(&amp;wq_entry-&gt;entry)) &#123; if (wq_entry-&gt;flags &amp; WQ_FLAG_EXCLUSIVE) __add_wait_queue_entry_tail(wq_head, wq_entry); //加到等待链表，互斥 else __add_wait_queue(wq_head, wq_entry); //加到等待链表，不互斥 &#125; set_current_state(state); &#125; spin_unlock_irqrestore(&amp;wq_head-&gt;lock, flags); //解锁开中断 return ret;&#125;EXPORT_SYMBOL(prepare_to_wait_event); 引用自：Linux设备驱动六 (1)等待队列 当一个系统调用处于等待状态时，比如等待输入缓冲区不为空，此时产生了信号，这个信号仅仅是在该进程的thread_info结构中标识一下，就是所谓的“发信号”，然后唤醒进程的系统调用，系统调用醒来后，此时仅仅用signal_pending_state()检查一下是否有信号，这里，不处理信号的，当此时有信号，系统调用返回ERESTARTSYS，在从系统调用的返回用户空间时，会根据thread_info中信号标识位调用相应的信号处理函数，这里就是所谓的“接收信号”，对于Linux，上层库函数会根据系统调用的ERESTARTSYS返回值重启该系统调用。 __wake_up1234567891011121314151617//wake_flags永远是0/** * __wake_up - wake up threads blocked on a waitqueue. * @wq_head: the waitqueue * @mode: which threads * @nr_exclusive: how many wake-one or wake-many threads to wake up * @key: is directly passed to the wakeup function * * If this function wakes up a task, it executes a full memory barrier before * accessing the task state. */void __wake_up(struct wait_queue_head *wq_head, unsigned int mode, int nr_exclusive, void *key)&#123; __wake_up_common_lock(wq_head, mode, nr_exclusive, 0, key);&#125;EXPORT_SYMBOL(__wake_up); 123456789101112131415161718static void __wake_up_common_lock(struct wait_queue_head *wq_head, unsigned int mode, int nr_exclusive, int wake_flags, void *key)&#123; unsigned long flags; wait_queue_entry_t bookmark; bookmark.flags = 0; bookmark.private = NULL; bookmark.func = NULL; INIT_LIST_HEAD(&amp;bookmark.entry); do &#123; spin_lock_irqsave(&amp;wq_head-&gt;lock, flags); nr_exclusive = __wake_up_common(wq_head, mode, nr_exclusive, wake_flags, key, &amp;bookmark); spin_unlock_irqrestore(&amp;wq_head-&gt;lock, flags); &#125; while (bookmark.flags &amp; WQ_FLAG_BOOKMARK);&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556/* * The core wakeup function. Non-exclusive wakeups (nr_exclusive == 0) just * wake everything up. If it&#x27;s an exclusive wakeup (nr_exclusive == small +ve * number) then we wake all the non-exclusive tasks and one exclusive task. * * There are circumstances in which we can try to wake a task which has already * started to run but is not in state TASK_RUNNING. try_to_wake_up() returns * zero in this (rare) case, and we handle it by continuing to scan the queue. */ /* * 在某些情况下，我们可以尝试唤醒已经开始运行但未处于TASK_RUNNING状态的任务 */static int __wake_up_common(struct wait_queue_head *wq_head, unsigned int mode, int nr_exclusive, int wake_flags, void *key, wait_queue_entry_t *bookmark)&#123; wait_queue_entry_t *curr, *next; int cnt = 0; lockdep_assert_held(&amp;wq_head-&gt;lock); if (bookmark &amp;&amp; (bookmark-&gt;flags &amp; WQ_FLAG_BOOKMARK)) &#123; curr = list_next_entry(bookmark, entry); list_del(&amp;bookmark-&gt;entry); bookmark-&gt;flags = 0; &#125; else curr = list_first_entry(&amp;wq_head-&gt;head, wait_queue_entry_t, entry); if (&amp;curr-&gt;entry == &amp;wq_head-&gt;head) return nr_exclusive; list_for_each_entry_safe_from(curr, next, &amp;wq_head-&gt;head, entry) &#123; unsigned flags = curr-&gt;flags; int ret; if (flags &amp; WQ_FLAG_BOOKMARK) continue; //唤醒函数 ret = curr-&gt;func(curr, mode, wake_flags, key); if (ret &lt; 0) break; if (ret &amp;&amp; (flags &amp; WQ_FLAG_EXCLUSIVE) &amp;&amp; !--nr_exclusive) break; if (bookmark &amp;&amp; (++cnt &gt; WAITQUEUE_WALK_BREAK_CNT) &amp;&amp; (&amp;next-&gt;entry != &amp;wq_head-&gt;head)) &#123; bookmark-&gt;flags = WQ_FLAG_BOOKMARK; list_add_tail(&amp;bookmark-&gt;entry, &amp;next-&gt;entry); break; &#125; &#125; return nr_exclusive;&#125; __wake_up_sync12345678910//wake_flags永远是1 //#define WF_SYNC 0x01 /* Waker goes to sleep after wakeup *//* * __wake_up_sync - see __wake_up_sync_key() */void __wake_up_sync(struct wait_queue_head *wq_head, unsigned int mode)&#123; __wake_up_sync_key(wq_head, mode, NULL);&#125; 12345678910111213141516171819202122232425/** * __wake_up_sync_key - wake up threads blocked on a waitqueue. * @wq_head: the waitqueue * @mode: which threads * @key: opaque value to be passed to wakeup targets * * The sync wakeup differs that the waker knows that it will schedule * away soon, so while the target thread will be woken up, it will not * be migrated to another CPU - ie. the two threads are &#x27;synchronized&#x27; * with each other. This can prevent needless bouncing between CPUs. * * On UP it can prevent extra preemption. * * If this function wakes up a task, it executes a full memory barrier before * accessing the task state. */void __wake_up_sync_key(struct wait_queue_head *wq_head, unsigned int mode, void *key)&#123; if (unlikely(!wq_head)) return; //#define WF_SYNC 0x01 /* Waker goes to sleep after wakeup */ __wake_up_common_lock(wq_head, mode, 1, WF_SYNC, key);&#125; 123456789101112131415161718static void __wake_up_common_lock(struct wait_queue_head *wq_head, unsigned int mode, int nr_exclusive, int wake_flags, void *key)&#123; unsigned long flags; wait_queue_entry_t bookmark; bookmark.flags = 0; bookmark.private = NULL; bookmark.func = NULL; INIT_LIST_HEAD(&amp;bookmark.entry); do &#123; spin_lock_irqsave(&amp;wq_head-&gt;lock, flags); nr_exclusive = __wake_up_common(wq_head, mode, nr_exclusive, wake_flags, key, &amp;bookmark); spin_unlock_irqrestore(&amp;wq_head-&gt;lock, flags); &#125; while (bookmark.flags &amp; WQ_FLAG_BOOKMARK);&#125; 网上如是说：最终wake_flags 会传递给用户自己定义的wakeup的callback函数，这个wake_flags的意义就在于用户可以根据这个是0还是1判断当前thread是否被独占.待论证吧 EPOLL唤醒epoll_create创建epfd,这个epfd会有一个等待队列：epfd-&gt;wq(wait_queue_head_t). 队列的回调函数是怎么加入的： epoll_wait |-&gt;ep_poll |-&gt;init_waitqueue_entry(&amp;wait, current) |-&gt;default_wake_function(wake_up唤醒) 1234567static inline void init_waitqueue_entry(wait_queue_t *q, struct task_struct *p)&#123; q-&gt;flags = 0; q-&gt;private = p; //进程调度，加入可运行链表 q-&gt;func = default_wake_function;&#125; epoll_wait怎么被唤醒: wake_up |-&gt;__wake_up //执行回调函数 |-&gt;curr-&gt;func |-&gt;default_wake_function 再看ep_poll_callback： epoll_ctl |-&gt;do_epoll_ctl |-&gt;ep_find |-&gt;ep_insert |-&gt;ep_item_poll |-&gt;poll_wait(epi-&gt;ffd.file, &amp;ep-&gt;poll_wait, pt) |-&gt;ep_ptable_queue_proc |-&gt;waitqueue中 //poll_table添加唤醒回调函数ep_poll_callback |-&gt;add_wait_queue(将当前的waitqueue链入到epitem对应的等待列表) |-&gt;ep_scan_ready_list |-&gt;ep_remove |-&gt;ep_modify ep_poll_callback回调函数注入epfd-&gt;poll_wait(wait_queue_head_t)中每个epitm对应的fd的poll_table的回调函数。select/poll对应的回调是default_wake_function。然后哪个fd上面有事件了，就执行ep_poll_callback，ep_poll_callback一共有2个作用: 将epitem插入就绪链表 wake_up唤醒epoll_wait epfd的等待队列epfd-&gt;wq何时移除： 12345678910111213141516171819202122232425262728293031323334353637383940414243static int ep_poll(struct eventpoll *ep, struct epoll_event __user *events, int maxevents, long timeout)&#123;//省略................................fetch_events: spin_lock_irqsave(&amp;ep-&gt;lock, flags); if (!ep_events_available(ep)) &#123; init_waitqueue_entry(&amp;wait, current); __add_wait_queue_exclusive(&amp;ep-&gt;wq, &amp;wait); for (;;) &#123; set_current_state(TASK_INTERRUPTIBLE); if (ep_events_available(ep) || timed_out) break; if (signal_pending(current)) &#123; res = -EINTR; break; &#125; spin_unlock_irqrestore(&amp;ep-&gt;lock, flags); if (!schedule_hrtimeout_range(to, slack, HRTIMER_MODE_ABS)) timed_out = 1; spin_lock_irqsave(&amp;ep-&gt;lock, flags); &#125; //这里移除了 __remove_wait_queue(&amp;ep-&gt;wq, &amp;wait); set_current_state(TASK_RUNNING); &#125;check_events: eavail = ep_events_available(ep); spin_unlock_irqrestore(&amp;ep-&gt;lock, flags); if (!res &amp;&amp; eavail &amp;&amp; !(res = ep_send_events(ep, events, maxevents)) &amp;&amp; !timed_out) goto fetch_events; return res;&#125; select唤醒SYSCALL_DEFINE5 |-&gt;core_sys_select |-&gt;do_select |-&gt;poll_initwait |-&gt;init_poll_funcptr(&amp;pwq-&gt;pt, __pollwait) |-&gt;pollwake |-&gt;__pollwake |-&gt;default_wake_function |-&gt;f_op-&gt;poll |-&gt;poll_freewait poll唤醒SYSCALL_DEFINE3 |-&gt;do_sys_poll |-&gt;poll_initwait |-&gt;init_poll_funcptr(&amp;pwq-&gt;pt, __pollwait) |-&gt;pollwake |-&gt;__pollwake |-&gt;default_wake_function |-&gt;do_poll |-&gt;do_pollfd |-&gt;f.file-&gt;f_op-&gt;poll f_op-&gt;pollf_op-&gt;poll(设备驱动程序实现) |-&gt;poll_wait |-&gt;func(之前注册的回调函数ep_poll_callback/default_wake_function) ending","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://riverferry.site/tags/linux/"}],"keywords":[]},{"title":"webbench","slug":"2020-03-24-webbench","date":"2020-03-24T00:00:00.000Z","updated":"2022-09-12T16:24:32.279Z","comments":true,"path":"2020-03-24-webbench/","link":"","permalink":"https://riverferry.site/2020-03-24-webbench/","excerpt":"参考Centos7安装及使用webbench进行并发测试 EZLippi/WebBench 下载地址","text":"参考Centos7安装及使用webbench进行并发测试 EZLippi/WebBench 下载地址 介绍Web Bench是用于基准测试WWW或代理服务器的非常简单的工具。使用fork（）模拟多个客户端，并可以使用HTTP / 0.9-HTTP / 1.1请求。该基准不是很现实，但是它可以测试HTTPD是否确实可以一次处理多个客户端（尝试运行一些CGI）而不会导致计算机停机。显示页面/分钟和字节/秒。可以在带有-f开关的更激进的模式下使用。 基本原理webbench首先fork出多个子进程，每个子进程都循环做web访问测试。子进程把访问的结果通过pipe告诉父进程，父进程做最终的统计结果。 参数说明 参数 说明 -V 显示版本号 -t 运行webbench的时间,单位：秒 -c 创建多少个客户端，默认1个 -f 不需要等待服务器响应 源码webbench.c123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453/* * (C) Radim Kolar 1997-2004 * This is free software, see GNU Public License version 2 for * details. * * Simple forking WWW Server benchmark: * * Usage: * webbench --help * * Return codes: * 0 - sucess * 1 - benchmark failed (server is not on-line) * 2 - bad param * 3 - internal error, fork failed * */ #include &quot;socket.c&quot;#include &lt;unistd.h&gt;#include &lt;sys/param.h&gt;#include &lt;rpc/types.h&gt;#include &lt;getopt.h&gt;#include &lt;strings.h&gt;#include &lt;time.h&gt;#include &lt;signal.h&gt;/* values */volatile int timerexpired=0;int speed=0;int failed=0;int bytes=0;/* globals */int http10=1; /* 0 - http/0.9, 1 - http/1.0, 2 - http/1.1 *//* Allow: GET, HEAD, OPTIONS, TRACE */#define METHOD_GET 0#define METHOD_HEAD 1#define METHOD_OPTIONS 2#define METHOD_TRACE 3#define PROGRAM_VERSION &quot;1.5&quot;int method=METHOD_GET;int clients=1;int force=0;int force_reload=0;int proxyport=80;char *proxyhost=NULL;int benchtime=30;/* internal */int mypipe[2];char host[MAXHOSTNAMELEN];#define REQUEST_SIZE 2048char request[REQUEST_SIZE];static const struct option long_options[]=&#123; &#123;&quot;force&quot;,no_argument,&amp;force,1&#125;, &#123;&quot;reload&quot;,no_argument,&amp;force_reload,1&#125;, &#123;&quot;time&quot;,required_argument,NULL,&#x27;t&#x27;&#125;, &#123;&quot;help&quot;,no_argument,NULL,&#x27;?&#x27;&#125;, &#123;&quot;http09&quot;,no_argument,NULL,&#x27;9&#x27;&#125;, &#123;&quot;http10&quot;,no_argument,NULL,&#x27;1&#x27;&#125;, &#123;&quot;http11&quot;,no_argument,NULL,&#x27;2&#x27;&#125;, &#123;&quot;get&quot;,no_argument,&amp;method,METHOD_GET&#125;, &#123;&quot;head&quot;,no_argument,&amp;method,METHOD_HEAD&#125;, &#123;&quot;options&quot;,no_argument,&amp;method,METHOD_OPTIONS&#125;, &#123;&quot;trace&quot;,no_argument,&amp;method,METHOD_TRACE&#125;, &#123;&quot;version&quot;,no_argument,NULL,&#x27;V&#x27;&#125;, &#123;&quot;proxy&quot;,required_argument,NULL,&#x27;p&#x27;&#125;, &#123;&quot;clients&quot;,required_argument,NULL,&#x27;c&#x27;&#125;, &#123;NULL,0,NULL,0&#125;&#125;;/* prototypes */static void benchcore(const char* host,const int port, const char *request);static int bench(void);static void build_request(const char *url);static void alarm_handler(int signal)&#123; timerexpired=1;&#125; static void usage(void)&#123; fprintf(stderr, &quot;webbench [option]... URL\\n&quot; &quot; -f|--force Don&#x27;t wait for reply from server.\\n&quot; &quot; -r|--reload Send reload request - Pragma: no-cache.\\n&quot; &quot; -t|--time &lt;sec&gt; Run benchmark for &lt;sec&gt; seconds. Default 30.\\n&quot; &quot; -p|--proxy &lt;server:port&gt; Use proxy server for request.\\n&quot; &quot; -c|--clients &lt;n&gt; Run &lt;n&gt; HTTP clients at once. Default one.\\n&quot; &quot; -9|--http09 Use HTTP/0.9 style requests.\\n&quot; &quot; -1|--http10 Use HTTP/1.0 protocol.\\n&quot; &quot; -2|--http11 Use HTTP/1.1 protocol.\\n&quot; &quot; --get Use GET request method.\\n&quot; &quot; --head Use HEAD request method.\\n&quot; &quot; --options Use OPTIONS request method.\\n&quot; &quot; --trace Use TRACE request method.\\n&quot; &quot; -?|-h|--help This information.\\n&quot; &quot; -V|--version Display program version.\\n&quot; );&#125;;int main(int argc, char *argv[])&#123; int opt=0; int options_index=0; char *tmp=NULL; if(argc==1) &#123; usage(); return 2; &#125; while((opt=getopt_long(argc,argv,&quot;912Vfrt:p:c:?h&quot;,long_options,&amp;options_index))!=EOF ) &#123; switch(opt) &#123; case 0 : break; case &#x27;f&#x27;: force=1;break; case &#x27;r&#x27;: force_reload=1;break; case &#x27;9&#x27;: http10=0;break; case &#x27;1&#x27;: http10=1;break; case &#x27;2&#x27;: http10=2;break; case &#x27;V&#x27;: printf(PROGRAM_VERSION&quot;\\n&quot;);exit(0); case &#x27;t&#x27;: benchtime=atoi(optarg);break; case &#x27;p&#x27;: /* proxy server parsing server:port */ tmp=strrchr(optarg,&#x27;:&#x27;); proxyhost=optarg; if(tmp==NULL) &#123; break; &#125; if(tmp==optarg) &#123; fprintf(stderr,&quot;Error in option --proxy %s: Missing hostname.\\n&quot;,optarg); return 2; &#125; if(tmp==optarg+strlen(optarg)-1) &#123; fprintf(stderr,&quot;Error in option --proxy %s Port number is missing.\\n&quot;,optarg); return 2; &#125; *tmp=&#x27;\\0&#x27;; proxyport=atoi(tmp+1);break; case &#x27;:&#x27;: case &#x27;h&#x27;: case &#x27;?&#x27;: usage();return 2;break; case &#x27;c&#x27;: clients=atoi(optarg);break; &#125; &#125; if(optind==argc) &#123; fprintf(stderr,&quot;webbench: Missing URL!\\n&quot;); usage(); return 2; &#125; if(clients==0) clients=1; if(benchtime==0) benchtime=60; /* Copyright */ fprintf(stderr,&quot;Webbench - Simple Web Benchmark &quot;PROGRAM_VERSION&quot;\\n&quot; &quot;Copyright (c) Radim Kolar 1997-2004, GPL Open Source Software.\\n&quot; ); build_request(argv[optind]); /* print bench info */ printf(&quot;\\nBenchmarking: &quot;); switch(method) &#123; case METHOD_GET: default: printf(&quot;GET&quot;);break; case METHOD_OPTIONS: printf(&quot;OPTIONS&quot;);break; case METHOD_HEAD: printf(&quot;HEAD&quot;);break; case METHOD_TRACE: printf(&quot;TRACE&quot;);break; &#125; printf(&quot; %s&quot;,argv[optind]); switch(http10) &#123; case 0: printf(&quot; (using HTTP/0.9)&quot;);break; case 2: printf(&quot; (using HTTP/1.1)&quot;);break; &#125; printf(&quot;\\n&quot;); if(clients==1) printf(&quot;1 client&quot;); else printf(&quot;%d clients&quot;,clients); printf(&quot;, running %d sec&quot;, benchtime); if(force) printf(&quot;, early socket close&quot;); if(proxyhost!=NULL) printf(&quot;, via proxy server %s:%d&quot;,proxyhost,proxyport); if(force_reload) printf(&quot;, forcing reload&quot;); printf(&quot;.\\n&quot;); return bench();&#125;void build_request(const char *url)&#123; char tmp[10]; int i; bzero(host,MAXHOSTNAMELEN); bzero(request,REQUEST_SIZE); if(force_reload &amp;&amp; proxyhost!=NULL &amp;&amp; http10&lt;1) http10=1; if(method==METHOD_HEAD &amp;&amp; http10&lt;1) http10=1; if(method==METHOD_OPTIONS &amp;&amp; http10&lt;2) http10=2; if(method==METHOD_TRACE &amp;&amp; http10&lt;2) http10=2; switch(method) &#123; default: case METHOD_GET: strcpy(request,&quot;GET&quot;);break; case METHOD_HEAD: strcpy(request,&quot;HEAD&quot;);break; case METHOD_OPTIONS: strcpy(request,&quot;OPTIONS&quot;);break; case METHOD_TRACE: strcpy(request,&quot;TRACE&quot;);break; &#125; strcat(request,&quot; &quot;); if(NULL==strstr(url,&quot;://&quot;)) &#123; fprintf(stderr, &quot;\\n%s: is not a valid URL.\\n&quot;,url); exit(2); &#125; if(strlen(url)&gt;1500) &#123; fprintf(stderr,&quot;URL is too long.\\n&quot;); exit(2); &#125; if(proxyhost==NULL) if (0!=strncasecmp(&quot;http://&quot;,url,7)) &#123; fprintf(stderr,&quot;\\nOnly HTTP protocol is directly supported, set --proxy for others.\\n&quot;); exit(2); &#125; /* protocol/host delimiter */ i=strstr(url,&quot;://&quot;)-url+3; /* printf(&quot;%d\\n&quot;,i); */ if(strchr(url+i,&#x27;/&#x27;)==NULL) &#123; fprintf(stderr,&quot;\\nInvalid URL syntax - hostname don&#x27;t ends with &#x27;/&#x27;.\\n&quot;); exit(2); &#125; if(proxyhost==NULL) &#123; /* get port from hostname */ if(index(url+i,&#x27;:&#x27;)!=NULL &amp;&amp; index(url+i,&#x27;:&#x27;)&lt;index(url+i,&#x27;/&#x27;)) &#123; strncpy(host,url+i,strchr(url+i,&#x27;:&#x27;)-url-i); bzero(tmp,10); strncpy(tmp,index(url+i,&#x27;:&#x27;)+1,strchr(url+i,&#x27;/&#x27;)-index(url+i,&#x27;:&#x27;)-1); /* printf(&quot;tmp=%s\\n&quot;,tmp); */ proxyport=atoi(tmp); if(proxyport==0) proxyport=80; &#125; else &#123; strncpy(host,url+i,strcspn(url+i,&quot;/&quot;)); &#125; // printf(&quot;Host=%s\\n&quot;,host); strcat(request+strlen(request),url+i+strcspn(url+i,&quot;/&quot;)); &#125; else &#123; // printf(&quot;ProxyHost=%s\\nProxyPort=%d\\n&quot;,proxyhost,proxyport); strcat(request,url); &#125; if(http10==1) strcat(request,&quot; HTTP/1.0&quot;); else if (http10==2) strcat(request,&quot; HTTP/1.1&quot;); strcat(request,&quot;\\r\\n&quot;); if(http10&gt;0) strcat(request,&quot;User-Agent: WebBench &quot;PROGRAM_VERSION&quot;\\r\\n&quot;); if(proxyhost==NULL &amp;&amp; http10&gt;0) &#123; strcat(request,&quot;Host: &quot;); strcat(request,host); strcat(request,&quot;\\r\\n&quot;); &#125; if(force_reload &amp;&amp; proxyhost!=NULL) &#123; strcat(request,&quot;Pragma: no-cache\\r\\n&quot;); &#125; if(http10&gt;1) strcat(request,&quot;Connection: close\\r\\n&quot;); /* add empty line at end */ if(http10&gt;0) strcat(request,&quot;\\r\\n&quot;); // printf(&quot;Req=%s\\n&quot;,request);&#125;/* vraci system rc error kod */static int bench(void)&#123; int i,j,k; pid_t pid=0; FILE *f; /* check avaibility of target server */ i=Socket(proxyhost==NULL?host:proxyhost,proxyport); if(i&lt;0) &#123; fprintf(stderr,&quot;\\nConnect to server failed. Aborting benchmark.\\n&quot;); return 1; &#125; close(i); /* create pipe */ if(pipe(mypipe)) &#123; perror(&quot;pipe failed.&quot;); return 3; &#125; /* not needed, since we have alarm() in childrens */ /* wait 4 next system clock tick */ /* cas=time(NULL); while(time(NULL)==cas) sched_yield(); */ /* fork childs */ for(i=0;i&lt;clients;i++) &#123; pid=fork(); if(pid &lt;= (pid_t) 0) &#123; /* child process or error*/ sleep(1); /* make childs faster */ break; &#125; &#125; if( pid&lt; (pid_t) 0) &#123; fprintf(stderr,&quot;problems forking worker no. %d\\n&quot;,i); perror(&quot;fork failed.&quot;); return 3; &#125; if(pid== (pid_t) 0) &#123; /* I am a child */ if(proxyhost==NULL) benchcore(host,proxyport,request); else benchcore(proxyhost,proxyport,request); /* write results to pipe */ f=fdopen(mypipe[1],&quot;w&quot;); if(f==NULL) &#123; perror(&quot;open pipe for writing failed.&quot;); return 3; &#125; /* fprintf(stderr,&quot;Child - %d %d\\n&quot;,speed,failed); */ fprintf(f,&quot;%d %d %d\\n&quot;,speed,failed,bytes); fclose(f); return 0; &#125; else &#123; f=fdopen(mypipe[0],&quot;r&quot;); if(f==NULL) &#123; perror(&quot;open pipe for reading failed.&quot;); return 3; &#125; setvbuf(f,NULL,_IONBF,0); speed=0; failed=0; bytes=0; while(1) &#123; pid=fscanf(f,&quot;%d %d %d&quot;,&amp;i,&amp;j,&amp;k); if(pid&lt;2) &#123; fprintf(stderr,&quot;Some of our childrens died.\\n&quot;); break; &#125; speed+=i; failed+=j; bytes+=k; /* fprintf(stderr,&quot;*Knock* %d %d read=%d\\n&quot;,speed,failed,pid); */ if(--clients==0) break; &#125; fclose(f); printf(&quot;\\nSpeed=%d pages/min, %d bytes/sec.\\nRequests: %d susceed, %d failed.\\n&quot;, (int)((speed+failed)/(benchtime/60.0f)), (int)(bytes/(float)benchtime), speed, failed); &#125; return i;&#125;void benchcore(const char *host,const int port,const char *req)&#123; int rlen; char buf[1500]; int s,i; struct sigaction sa; /* setup alarm signal handler */ sa.sa_handler=alarm_handler; sa.sa_flags=0; if(sigaction(SIGALRM,&amp;sa,NULL)) exit(3); alarm(benchtime); rlen=strlen(req); nexttry:while(1) &#123; if(timerexpired) &#123; if(failed&gt;0) &#123; /* fprintf(stderr,&quot;Correcting failed by signal\\n&quot;); */ failed--; &#125; return; &#125; s=Socket(host,port); if(s&lt;0) &#123; failed++;continue;&#125; if(rlen!=write(s,req,rlen)) &#123;failed++;close(s);continue;&#125; if(http10==0) if(shutdown(s,1)) &#123; failed++;close(s);continue;&#125; if(force==0) &#123; /* read all available data from socket */ while(1) &#123; if(timerexpired) break; i=read(s,buf,1500); /* fprintf(stderr,&quot;%d\\n&quot;,i); */ if(i&lt;0) &#123; failed++; close(s); goto nexttry; &#125; else if(i==0) break; else bytes+=i; &#125; &#125; if(close(s)) &#123;failed++;continue;&#125; speed++; &#125;&#125; socket.c1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859/* $Id: socket.c 1.1 1995/01/01 07:11:14 cthuang Exp $ * * This module has been modified by Radim Kolar for OS/2 emx *//*********************************************************************** module: socket.c program: popclient SCCS ID: @(#)socket.c 1.5 4/1/94 programmer: Virginia Tech Computing Center compiler: DEC RISC C compiler (Ultrix 4.1) environment: DEC Ultrix 4.3 description: UNIX sockets code. ***********************************************************************/ #include &lt;sys/types.h&gt;#include &lt;sys/socket.h&gt;#include &lt;fcntl.h&gt;#include &lt;netinet/in.h&gt;#include &lt;arpa/inet.h&gt;#include &lt;netdb.h&gt;#include &lt;sys/time.h&gt;#include &lt;string.h&gt;#include &lt;unistd.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;stdarg.h&gt;int Socket(const char *host, int clientPort)&#123; int sock; unsigned long inaddr; struct sockaddr_in ad; struct hostent *hp; memset(&amp;ad, 0, sizeof(ad)); ad.sin_family = AF_INET; inaddr = inet_addr(host); if (inaddr != INADDR_NONE) memcpy(&amp;ad.sin_addr, &amp;inaddr, sizeof(inaddr)); else &#123; hp = gethostbyname(host); if (hp == NULL) return -1; memcpy(&amp;ad.sin_addr, hp-&gt;h_addr, hp-&gt;h_length); &#125; ad.sin_port = htons(clientPort); sock = socket(AF_INET, SOCK_STREAM, 0); if (sock &lt; 0) return sock; if (connect(sock, (struct sockaddr *)&amp;ad, sizeof(ad)) &lt; 0) return -1; return sock;&#125; ending","categories":[],"tags":[{"name":"tool","slug":"tool","permalink":"https://riverferry.site/tags/tool/"}],"keywords":[]},{"title":"字节对齐","slug":"2020-03-24-字节对齐","date":"2020-03-24T00:00:00.000Z","updated":"2022-09-12T16:24:32.279Z","comments":true,"path":"2020-03-24-字节对齐/","link":"","permalink":"https://riverferry.site/2020-03-24-%E5%AD%97%E8%8A%82%E5%AF%B9%E9%BD%90/","excerpt":"参考C++ sizeof 使用规则及陷阱分析 ５分钟搞定内存字节对齐","text":"参考C++ sizeof 使用规则及陷阱分析 ５分钟搞定内存字节对齐 ending","categories":[],"tags":[{"name":"坑","slug":"坑","permalink":"https://riverferry.site/tags/%E5%9D%91/"}],"keywords":[]},{"title":"epoll惊群","slug":"2020-03-23-epoll惊群","date":"2020-03-23T00:00:00.000Z","updated":"2022-09-12T16:24:32.278Z","comments":true,"path":"2020-03-23-epoll惊群/","link":"","permalink":"https://riverferry.site/2020-03-23-epoll%E6%83%8A%E7%BE%A4/","excerpt":"参考再谈Linux epoll惊群问题的原因和解决方案","text":"参考再谈Linux epoll惊群问题的原因和解决方案 accept惊群问题1234567891011121314151617181920212223242526272829303132333435363738394041424344static int __wake_up_common(struct wait_queue_head *wq_head, unsigned int mode, int nr_exclusive, int wake_flags, void *key, wait_queue_entry_t *bookmark)&#123; wait_queue_entry_t *curr, *next; int cnt = 0; lockdep_assert_held(&amp;wq_head-&gt;lock); if (bookmark &amp;&amp; (bookmark-&gt;flags &amp; WQ_FLAG_BOOKMARK)) &#123; curr = list_next_entry(bookmark, entry); list_del(&amp;bookmark-&gt;entry); bookmark-&gt;flags = 0; &#125; else curr = list_first_entry(&amp;wq_head-&gt;head, wait_queue_entry_t, entry); if (&amp;curr-&gt;entry == &amp;wq_head-&gt;head) return nr_exclusive; list_for_each_entry_safe_from(curr, next, &amp;wq_head-&gt;head, entry) &#123; unsigned flags = curr-&gt;flags; int ret; if (flags &amp; WQ_FLAG_BOOKMARK) continue; //唤醒函数 ret = curr-&gt;func(curr, mode, wake_flags, key); if (ret &lt; 0) break; if (ret &amp;&amp; (flags &amp; WQ_FLAG_EXCLUSIVE) &amp;&amp; !--nr_exclusive) break; if (bookmark &amp;&amp; (++cnt &gt; WAITQUEUE_WALK_BREAK_CNT) &amp;&amp; (&amp;next-&gt;entry != &amp;wq_head-&gt;head)) &#123; bookmark-&gt;flags = WQ_FLAG_BOOKMARK; list_add_tail(&amp;bookmark-&gt;entry, &amp;next-&gt;entry); break; &#125; &#125; return nr_exclusive;&#125; WQ_FLAG_EXCLUSIVE参数可以确保只wake one,而不是wake many.可以解决该问题 如果是WQ_FLAG_EXCLUSIVE，则wake一次就退出循环 epoll惊群问题linux 3.10.1 kernel 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051static int ep_send_events_proc(struct eventpoll *ep, struct list_head *head, void *priv)&#123; struct ep_send_events_data *esed = priv; int eventcnt; unsigned int revents; struct epitem *epi; struct epoll_event __user *uevent; struct wakeup_source *ws; poll_table pt; init_poll_funcptr(&amp;pt, NULL); for (eventcnt = 0, uevent = esed-&gt;events; !list_empty(head) &amp;&amp; eventcnt &lt; esed-&gt;maxevents;) &#123; epi = list_first_entry(head, struct epitem, rdllink); ws = ep_wakeup_source(epi); if (ws) &#123; if (ws-&gt;active) __pm_stay_awake(ep-&gt;ws); __pm_relax(ws); &#125; //先从就绪链表删除 list_del_init(&amp;epi-&gt;rdllink); revents = ep_item_poll(epi, &amp;pt); if (revents) &#123; if (__put_user(revents, &amp;uevent-&gt;events) || __put_user(epi-&gt;event.data, &amp;uevent-&gt;data)) &#123; list_add(&amp;epi-&gt;rdllink, head); ep_pm_stay_awake(epi); return eventcnt ? eventcnt : -EFAULT; &#125; eventcnt++; uevent++; if (epi-&gt;event.events &amp; EPOLLONESHOT) epi-&gt;event.events &amp;= EP_PRIVATE_BITS; else if (!(epi-&gt;event.events &amp; EPOLLET)) &#123; //LT模式下会继续加入就绪链表 list_add_tail(&amp;epi-&gt;rdllink, &amp;ep-&gt;rdllist); ep_pm_stay_awake(epi); &#125; &#125; &#125; return eventcnt;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051static int ep_scan_ready_list(struct eventpoll *ep, int (*sproc)(struct eventpoll *, struct list_head *, void *), void *priv, int depth)&#123; int error, pwake = 0; unsigned long flags; struct epitem *epi, *nepi; LIST_HEAD(txlist); mutex_lock_nested(&amp;ep-&gt;mtx, depth); spin_lock_irqsave(&amp;ep-&gt;lock, flags); list_splice_init(&amp;ep-&gt;rdllist, &amp;txlist); ep-&gt;ovflist = NULL; spin_unlock_irqrestore(&amp;ep-&gt;lock, flags); error = (*sproc)(ep, &amp;txlist, priv); //回调函数中判断如果是LT模式，则继续加入就绪链表 spin_lock_irqsave(&amp;ep-&gt;lock, flags); for (nepi = ep-&gt;ovflist; (epi = nepi) != NULL; nepi = epi-&gt;next, epi-&gt;next = EP_UNACTIVE_PTR) &#123; if (!ep_is_linked(&amp;epi-&gt;rdllink)) &#123; list_add_tail(&amp;epi-&gt;rdllink, &amp;ep-&gt;rdllist); ep_pm_stay_awake(epi); &#125; &#125; ep-&gt;ovflist = EP_UNACTIVE_PTR; if (!list_empty(&amp;ep-&gt;rdllist)) &#123; /* * Wake up (if active) both the eventpoll wait list and * the -&gt;poll() wait list (delayed after we release the lock). */ if (waitqueue_active(&amp;ep-&gt;wq)) wake_up_locked(&amp;ep-&gt;wq); if (waitqueue_active(&amp;ep-&gt;poll_wait)) pwake++; &#125; spin_unlock_irqrestore(&amp;ep-&gt;lock, flags); mutex_unlock(&amp;ep-&gt;mtx); //............................. return error;&#125; LT模式下惊群的原因：如果是水平触发，从就绪链表中取出后发送给用户空间然后又加入了就绪链表，然会判断队列非空，会唤醒其他阻塞在epoll_wait的进程/线程。这里的关键是epoll是怎么唤醒的 复现用这个作者再谈Linux epoll惊群问题的原因和解决方案的demo测试 里面有个值需要改大点才能复现出来，把这个彩蛋留下来，本文只复制人间的demo,不改 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157#include &lt;stdlib.h&gt;#include &lt;stdio.h&gt;#include &lt;unistd.h&gt;#include &lt;sys&#x2F;types.h&gt;#include &lt;sys&#x2F;socket.h&gt;#include &lt;sys&#x2F;epoll.h&gt;#include &lt;netdb.h&gt;#include &lt;fcntl.h&gt;#include &lt;sys&#x2F;wait.h&gt;#include &lt;time.h&gt;#include &lt;signal.h&gt;#define COUNT 1int mode &#x3D; 0;int slp &#x3D; 0;int pid[COUNT] &#x3D; &#123;0&#125;;int count &#x3D; 0;void server(int epfd) &#123; struct epoll_event *events; int num, i; struct timespec ts; events &#x3D; calloc(64, sizeof(struct epoll_event)); while (1) &#123; int sd, csd; struct sockaddr in_addr; num &#x3D; epoll_wait(epfd, events, 64, -1); if (num &lt;&#x3D; 0) &#123; continue; &#125; &#x2F;* ts.tv_sec &#x3D; 0; ts.tv_nsec &#x3D; 1; if(nanosleep(&amp;ts, NULL) !&#x3D; 0) &#123; perror(&quot;nanosleep&quot;); exit(1); &#125; *&#x2F; &#x2F;&#x2F; 用于测试ET模式下丢事件的情况 if (slp) &#123; sleep(slp); &#125; sd &#x3D; events[0].data.fd; socklen_t in_len &#x3D; sizeof(in_addr); csd &#x3D; accept(sd, &amp;in_addr, &amp;in_len); if (csd &#x3D;&#x3D; -1) &#123; &#x2F;&#x2F; 打印这个说明中了epoll LT惊群的招了。 printf(&quot;shit xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx:%d\\n&quot;, getpid()); continue; &#125; &#x2F;&#x2F; 本进程一共成功处理了多少个请求。 count ++; printf(&quot;get client:%d\\n&quot;, getpid()); close(csd); &#125;&#125;static void siguser_handler(int sig)&#123; &#x2F;&#x2F; 在主进程被Ctrl-C退出的时候，每一个子进程均要打印自己处理了多少个请求。 printf(&quot;pid:%d count:%d\\n&quot;, getpid(), count); exit(0);&#125;static void sigint_handler(int sig)&#123; int i &#x3D; 0; &#x2F;&#x2F; 给每一个子进程发信号，要求其打印自己处理了多少个请求。 for (i &#x3D; 0; i &lt; COUNT; i++) &#123; kill(pid[i], SIGUSR1); &#125;&#125;int main (int argc, char *argv[])&#123; int ret &#x3D; 0; int listener; int c &#x3D; 0; struct sockaddr_in saddr; int port; int status; int flags; int epfd; struct epoll_event event; if (argc &lt; 4) &#123; exit(1); &#125; &#x2F;&#x2F; 0为LT模式，1为ET模式 mode &#x3D; atoi(argv[1]); port &#x3D; atoi(argv[2]); &#x2F;&#x2F; 是否在处理accept之前耽搁一会儿，这个参数更容易重现问题 slp &#x3D; atoi(argv[3]); signal(SIGINT, sigint_handler); listener &#x3D; socket(PF_INET, SOCK_STREAM, 0); saddr.sin_family &#x3D; AF_INET; saddr.sin_port &#x3D; htons(port); saddr.sin_addr.s_addr &#x3D; INADDR_ANY; bind(listener, (struct sockaddr*)&amp;saddr, sizeof(saddr)); listen(listener, SOMAXCONN); flags &#x3D; fcntl (listener, F_GETFL, 0); flags |&#x3D; O_NONBLOCK; fcntl (listener, F_SETFL, flags); epfd &#x3D; epoll_create(64); if (epfd &#x3D;&#x3D; -1) &#123; perror(&quot;epoll_create&quot;); abort(); &#125; event.data.fd &#x3D; listener; event.events &#x3D; EPOLLIN; if (mode &#x3D;&#x3D; 1) &#123; event.events |&#x3D; EPOLLET; &#125; else if (mode &#x3D;&#x3D; 2) &#123; event.events |&#x3D; EPOLLONESHOT; &#125; ret &#x3D; epoll_ctl(epfd, EPOLL_CTL_ADD, listener, &amp;event); if (ret &#x3D;&#x3D; -1) &#123; perror(&quot;epoll_ctl&quot;); abort(); &#125; for(c &#x3D; 0; c &lt; COUNT; c++) &#123; int child; child &#x3D; fork(); if(child &#x3D;&#x3D; 0) &#123; &#x2F;&#x2F; 安装打印count值的信号处理函数 signal(SIGUSR1, siguser_handler); server(epfd); &#125; pid[c] &#x3D; child; printf(&quot;server:%d pid:%d\\n&quot;, c+1, child); &#125; wait(&amp;status); sleep(1000000); close (listener);&#125; 遗留问题 再有的服务器上测试上面的代码可以复现(试了kernel 2.6版本和3.10版本).但在我虚拟机(3.10 版本)死活复现不出来。不知道具体原因了。按照上面csdn那篇文章理解是会出现这种情况(前提是，一个epoll_wait释放了wait链后，其他epoll_wait的wait还是生效的，不过分析感觉应该是生效的，也可能跟进程还是线程监控有关系把)。这个留作以后有时间了再研究吧。 ending","categories":[],"tags":[{"name":"IO复用","slug":"IO复用","permalink":"https://riverferry.site/tags/IO%E5%A4%8D%E7%94%A8/"}],"keywords":[]},{"title":"sizeof","slug":"2020-03-23-sizeof","date":"2020-03-23T00:00:00.000Z","updated":"2022-09-12T16:24:32.278Z","comments":true,"path":"2020-03-23-sizeof/","link":"","permalink":"https://riverferry.site/2020-03-23-sizeof/","excerpt":"参考Why does sizeof(x++) not increment x? C++ sizeof 使用规则及陷阱分析","text":"参考Why does sizeof(x++) not increment x? C++ sizeof 使用规则及陷阱分析 sizeof The sizeof operator yields the size (in bytes) of its operand, which may be an expression or the parenthesized name of a type. The size is determined from the type of the operand. The result is an integer. If the type of the operand is a variable length array type, the operand is evaluated; otherwise, the operand is not evaluated and the result is an integer constant. 这段话有几个重要的点: sizeof是运算符，不是函数 如果操作数的类型是可变长度数组类型，则对操作数求值。否则不对操作数求值 基于以上两点，再细化下 cout &lt;&lt; sizeof(5) &lt;&lt; endl; // 4 cout &lt;&lt; sizeof 5 &lt;&lt; endl; // 4 上面两种方式都是正确的，但要注意，如果操作数是类型不是对象，则要加(). cout &lt;&lt; sizeof(int) &lt;&lt; endl; // 4 //cout &lt;&lt; sizeof int &lt;&lt; endl; //error sizeof(i++)问题： int i = 5; cout &lt;&lt; sizeof(i++) &lt;&lt; endl; //4 cout &lt;&lt; i &lt;&lt; endl; //5 原因开头也讲了:如果操作数的类型是可变长度数组类型，则对操作数求值。否则不对操作数求值. 陷阱记录下这篇文章中提到的一些sizeof容易搞错的点，挑了一部分 001 int a = 0; cout&lt;&lt;sizeof(a=3)&lt;&lt;endl; //4 cout&lt;&lt;a&lt;&lt;endl; //0 和上面的一样，不对操作数求值 002 int f1() &#123; return 0; &#125; void f3() &#123;&#125; cout &lt;&lt; sizeof(f3()) &lt;&lt; endl; //错误 C2070 “void”: 非法的 sizeof 操作数 cout &lt;&lt; sizeof(f1) &lt;&lt; endl; //错误 C2070 “int (void)”: 非法的 sizeof 操作数 不能求void的大小 不能求函数地址的大小(*f3或者f3()是正确的) 003 char a[] = &quot;abcdef&quot;; char b[] = &#123; &#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;, &#39;e&#39;, &#39;f&#39; &#125;; int c[20] = &#123; 3, 4 &#125;; char d[2][3] = &#123; &quot;aa&quot;, &quot;bb&quot; &#125;; cout &lt;&lt; sizeof(a) &lt;&lt; endl; // 7, 表示字符串 cout &lt;&lt; sizeof(b) &lt;&lt; endl; // 6， 仅表示字符数组 cout &lt;&lt; sizeof(c) &lt;&lt; endl; // 80 cout &lt;&lt; sizeof(d) &lt;&lt; endl; // 6 = 2*3 注意常量字符串的末尾的结束符 注意数组的大小是元素大小*元素个数 004 int *d = new int[10]; cout &lt;&lt; sizeof(d) &lt;&lt; endl; // 4 cout &lt;&lt; d &lt;&lt; endl; //014852D8 d实际还是指针 005 double* (*a)[3][6]; cout &lt;&lt; sizeof(a) &lt;&lt; endl; // 4 cout &lt;&lt; sizeof(*a) &lt;&lt; endl; // 72 cout &lt;&lt; sizeof(**a) &lt;&lt; endl; // 24 cout &lt;&lt; sizeof(***a) &lt;&lt; endl; // 4 cout &lt;&lt; sizeof(****a) &lt;&lt; endl; // 8 a是指针 a是二维数组的数组名 72 = 36*4 **a指向一维数组 24 = 6 * 4 ***a指向一维数组的第一个元素(指针) 4 ****a指向第一个指针指向的double类型的值 8 006 123456789101112131415void Sum(int i[])&#123; cout &lt;&lt; i &lt;&lt; endl; //0053F9A8 cout &lt;&lt; sizeof(i) &lt;&lt; endl; //4&#125;int main()&#123; int i[5] = &#123; 0 &#125;; Sum(i); return 0;&#125; 这里的i是存放地址的指针 OTHER 空类的大小是1 内存对齐的问题另外整理 ending","categories":[],"tags":[{"name":"sizeof","slug":"sizeof","permalink":"https://riverferry.site/tags/sizeof/"}],"keywords":[]},{"title":"操作系统-虚拟存储系统","slug":"2020-03-23-操作系统-虚拟存储系统","date":"2020-03-23T00:00:00.000Z","updated":"2022-09-12T16:24:32.278Z","comments":true,"path":"2020-03-23-操作系统-虚拟存储系统/","link":"","permalink":"https://riverferry.site/2020-03-23-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E8%99%9A%E6%8B%9F%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F/","excerpt":"参考虚拟内存的那点事儿 陈向群操作系统","text":"参考虚拟内存的那点事儿 陈向群操作系统 虚拟存储系统所谓虚拟存储技术是指：当进程运行时，先将其一部分装入内存，另一部分暂留在磁盘，当要执行的指令或访问的数据不在内存时，由操作系统自动完成将它们从磁盘调入内存的工作 虚拟地址空间 分配给进程的虚拟内存 虚拟页式存储即虚拟存储技术+页式存储管理方案 基本思想： 进程开始运行之前，不是装入全部页面，而是装入一个或零个页面 之后，根据进程运行的需要，动态装入其他页面 当内存空间已满，而又需要装入新的页面时，则根据某种算法置换内存中的某个页面，以便装入新的页面 页式存储 用户进程地址空间被划分为大小相等的部分，称为页（page）或页面，从0开始编号 内存空间按同样大小划分为大小相等的区域，称为页框（page frame），从0开始编号；也称为物理页面，页帧，内存块 以页为单位进行分配，并按进程需要的页数来分配；逻辑上相邻的页，物理上不一定相邻 页表项 记录了逻辑页号与页框号的对应关系 一级页表图片来源:虚拟内存的那点事儿 2级页表图片来源:虚拟内存的那点事儿 计算 2^10 * 2^10 * 2^12 = 1024 * 1024 * 4KB = 4G 多级页表 优势： 多级页表的第一层目录全部加载在内存，其余层部分加载，这样节省了内存 前面的目录项都是索引，如果第一层就不存在，后面也就不用继续遍历了，提高了查询效率 页表起始地址保存在何处？ mm_struct的pgd保存了进程的页表项起始地址，当执行一个进程的时候，页表项起始地址会被放到页表基址寄存器中。 页表保存在哪里？ 页表保存在磁盘，内存，MMU的TLB(快表)缓存中 地址转换MMU(memory management unit) 内存管理单元 TBL(translation lookaside buffer) 在CPU中引入的高速缓存（Cache），可以匹配CPU的处理速率和内存的访问速度 一种随机存取型存储器，除连线寻址机制外，还有接线逻辑，能按特定的匹配标志在一个存储周期内对所有的字同时进行比较 页错误 又称页面错误、页故障、页面失效 地址转换过程中硬件产生的异常 具体原因： 所访问的虚拟页面没有调入物理内存(缺页异常) 页面访问违反权限（读/写、用户/内核） 错误的访问地址 缺页异常 是一种Page Fault 在地址映射过程中，硬件检查页表时发现所要访问的页面不在内存，则产生该异常——缺页异常 操作系统执行缺页异常处理程序：获得磁盘地址，启动磁盘，将该页调入内存 交换技术内存空间紧张时，系统将内存中某些进程暂时移到外存，把外存中某些进程换进内存，占据前者所占用的区域（进程在内存与磁盘之间的动态调度） 进程的哪些内容要交换到磁盘？会遇到什么困难？ 运行时创建或修改的内容：栈和堆 在磁盘的什么位置保存被换出的进程？ 交换区：一般系统会指定一块特殊的磁盘区域作为交换空间（swap space），包含连续的磁道，操作系统可以使用底层的磁盘读写操作对其高效访问 交换时机？ 只要不用就换出（很少再用）；内存空间不够或有不够的危险时换出 如何选择被换出的进程？ 考虑进程的各种属性；不应换出处于等待I/O状态的进程 ending","categories":[],"tags":[{"name":"OperatingSystem","slug":"OperatingSystem","permalink":"https://riverferry.site/tags/OperatingSystem/"}],"keywords":[]},{"title":"Linux-fork和clone","slug":"2020-03-22-Linux-fork和clone","date":"2020-03-22T00:00:00.000Z","updated":"2022-09-12T16:24:32.278Z","comments":true,"path":"2020-03-22-Linux-fork和clone/","link":"","permalink":"https://riverferry.site/2020-03-22-Linux-fork%E5%92%8Cclone/","excerpt":"参考Linux fork那些隐藏的开销 Unix/Linux fork后传-clone Unix/Linux fork/exec的前世今生 朴素的UNIX之-进程/线程模型 线程库中的创建线程和退出线程 Linux中fork，vfork和clone详解（区别与联系）","text":"参考Linux fork那些隐藏的开销 Unix/Linux fork后传-clone Unix/Linux fork/exec的前世今生 朴素的UNIX之-进程/线程模型 线程库中的创建线程和退出线程 Linux中fork，vfork和clone详解（区别与联系） 正文fork()man-pages #include &lt;sys/types.h&gt; #include &lt;unistd.h&gt; pid_t fork(void); fork() creates a new process by duplicating(复制) the calling process. The new process is referred to as the child process. The calling process is referred to as the parent process. 图片来源： 链接 fork的开销 写时复制导致的内存开销 页目录和页表 vm_area_struct对象 死锁问题 写时复制导致的内存开销fork后exec前,父进程修改常驻内存中的值,因为写时复制的原因,子进程会讲这些在内存中建立一个新的副本.(如果父进程不修改这些值,写时复制下,就没有这样的开销).可以使用vfork避免(子进程和父进程公用地址空间,子进程先于父进程执行,直到子进程exit/exec后父进程执行) 页目录和页表fork后,在子进程exec执行前(刷新新的页目录，页表)，子进程会把父进程的页目录与页表进行复制，占用了内存，浪费了时间。具体参考Linux fork那些隐藏的开销 vm_area_struct对象fork后子进程也会复制父进程的vm_area_struct对象，如果父进程malloc/mmap很多，并且vm_area_struct对象都已经实际生成，则又造成大量的浪费。(exec前)具体参考Linux fork那些隐藏的开销 死锁具体参考Linux fork那些隐藏的开销 12345678910111213141516171819202122232425262728293031323334#include &lt;unistd.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;pthread.h&gt;pthread_mutex_t mutex;void *mmap_unmap(void *arg)&#123; while (1) &#123; pthread_mutex_lock(&amp;mutex); sleep (4); pthread_mutex_unlock(&amp;mutex); &#125;&#125;int main(int argc, char *argv[])&#123; pthread_t tid; pthread_mutex_init(&amp;mutex,NULL); pthread_create(&amp;tid, NULL, mmap_unmap, NULL); sleep(1); if (fork() == 0) &#123; pthread_mutex_lock(&amp;mutex); pthread_mutex_unlock(&amp;mutex); printf(&quot;未死锁!\\n\\n&quot;); &#125; sleep(1000); return 0;&#125; //父进程 103420 //父进程线程 103421 //子进程 103423 a.out(103420)─┬─a.out(103423) └─&#123;a.out&#125;(103421) Thread 2 (Thread 0x7f3e22f18700 (LWP 103421)): #0 0x00007f3e22fd648d in nanosleep () from /lib64/libc.so.6 #1 0x00007f3e22fd6324 in sleep () from /lib64/libc.so.6 #2 0x0000000000400820 in mmap_unmap(void*) () #3 0x00007f3e23b00df5 in start_thread () from /lib64/libpthread.so.0 #4 0x00007f3e2300f1ad in clone () from /lib64/libc.so.6 Thread 1 (Thread 0x7f3e23f1c740 (LWP 103420)): #0 0x00007f3e22fd648d in nanosleep () from /lib64/libc.so.6 #1 0x00007f3e22fd6324 in sleep () from /lib64/libc.so.6 #2 0x00000000004008a5 in main () //103423 #0 0x00007f3e23b06f7d in __lll_lock_wait () from /lib64/libpthread.so.0 #1 0x00007f3e23b02d32 in _L_lock_791 () from /lib64/libpthread.so.0 #2 0x00007f3e23b02c38 in pthread_mutex_lock () from /lib64/libpthread.so.0 #3 0x0000000000400887 in main () 子进程在持有锁的情况下，再次lock,导致死锁 (gdb) p mutex $1 = 2 (gdb) call pthread_mutex_unlock(&amp;mutex) $2 = 0 (gdb) p mutex $3 = 0 cloneman page #define _GNU_SOURCE #include &lt;sched.h&gt; int clone(int (*fn)(void *), void *stack, int flags, void *arg, ... /* pid_t *parent_tid, void *tls, pid_t *child_tid */ ); /* For the prototype of the raw clone() system call, see NOTES */ flags mask mask description CLONE_FILES 共享文件描述符 CLONE_PID 父子进程pid相同 CLONE_PTRACE 若父进程被trace，子进程也被trace CLONE_THREAD 支持POSIX线程标准，子进程与父进程共享相同的线程群(内核级线程) CLONE_SIGHAND 共享信号表 CLONE_VFORK 子进程先于父进程执行,类似vfrok CLONE_FILES 公用虚拟空间,mm_struct引用加一,不需要再复制一份vm_are_struct 与fork（2）相比，这些系统调用可以更精确地控制在 调用进程和子进程之间共享哪些执行上下文。例如，使用这些系统调用，调用者可以控制两个进程是否共享虚拟地址空间，文件描述符表和信号处理程序表。这些系统调用还允许将新的子进程放置在单独的namespaces（7）中。 CLONE_SIGHAND这里拷贝自:线程库中的创建线程和退出线程 如果CLONE_SIGHAND被设置，调用进程和子进程共享信号处理器表。如果某个进程修改了信号的行为(通过sigaction(2))，会影响到另外的一个进程。但调用进程和子进程仍然拥有独立的信号掩码和信号处理集。所以他们可以使用sigprocmask(2)来阻塞和释放信号而不影响另外一个。 如果CLONE_SIGHAND没有被设置，子进程只会继承调用进程的信号处理函数副本，两个进程修改信号的行为不会影响另一个进程。 从Linux2.6.0开始，如果CLONE_SIGHAND被设置了，那么CLONE_VM也需要被设置。 CLONE_VM这里拷贝自:线程库中的创建线程和退出线程 如果CLONE_VM被设置了，那么调用进程和子进程共享内存空间。特别的，两个进程的内存写操作对另一个进程是透明的。更进一步，任何内存映射和释放映射都会影响另一个进程。 如果CLONE_VM没有被设置，那么子进程和调用进程运行在不同的内存空间中，即不共享内存空间。对进程中的内存操作不会影响另外一个进程。 CLONE_THREAD这里拷贝自:线程库中的创建线程和退出线程 CLONE_THREAD如果被设置，那么这个clone出来的子进程会和调用clone的进程进一个线程组，这里的”线程”指的是线程组里的进程 线程组是Linux 2.4版本加入的，用来支持POSIX thread的一个概念，即一个线程组共享一个PID。在内部，这个共享PID被叫做线程组ID，即TGID。从Linux 2.4开始，getpid(2)会返回调用者的TGID。 如果clone(2)没有指定CLONE_THREAD，那么新线程将会自己一个作为一个新的线程组，其中，TGID = TID。这个线程是新线程的头儿。 带CLONE_THREAD新建的线程和clone(2)的调用者有着一样的父进程。表现为getppid(2)返回相同的值。当一个CLONE_THREAD线程终止时，创建它的线程不会发送SIGCHLD信号以及其他终止信号；终止线程的状态也不会被wait(2)捕捉。(线程称为分离的)。只有当线程组中的线程都终止时，父进程会收到SIGCHLD信号。 如果线程组中的线程执行了execve(2)，那么除了线程头外的所有线程会终止，并且这个execve执行的新程序会在线程组头执行。 如果线程组中的一个线程使用fork(2)，那么线程组中的所有线程能够wait(2)这个子进程。 从Linux2.5.35开始，如果CLONE_THREAD被设置，那么CLONE_SIGHAND也需要被设置。需要注意的是，从Linux 2.6.0开始，CLONE_VM也需要跟着CLONE_SIGHAND一起被设置。 使用kill(2)来向线程组所有线程发送信号，使用tgkill()来向特定的线程发送信号。 信号的处理和行为是进程范围的，比如一个未处理的信号发送给一个线程，那么这个信号会影响到线程组中的所有线程。 代码分析1234567891011121314151617181920212223#include &lt;unistd.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;pthread.h&gt;pthread_mutex_t mutex;void *mmap_unmap(void *arg)&#123; printf(&quot;hello!\\n&quot;);&#125;int main(int argc, char *argv[])&#123; pthread_t tid; pthread_create(&amp;tid, NULL, mmap_unmap, NULL); sleep(10); return 0;&#125; 关键的系统调用: clone(child_stack=0x7fccd9a28fb0, flags=CLONE_VM|CLONE_FS|CLONE_FILES|CLONE_SIGHAND|CLONE_THREAD|CLONE_SYSVSEM|CLONE_SETTLS|CLONE_PARENT_SETTID|CLONE_CHILD_CLEARTID, parent_tidptr=0x7fccd9a299d0, tls=0x7fccd9a29700, child_tidptr=0x7fccd9a299d0) = 109622 [pid 109622] exit(0) exit_group(0) = ? CLONE_THREAD会将新的”进程”和调用进程加入一个相同的线程组,TGID.线程组的头线程推出调用exit_group,其他线程推出调用exit.再结合CLONE_VM就是常见的线程的实现(内核级线程) 图片来自:Unix/Linux fork后传-clone linux内核级线程内核级线程： 内核级线程又称为内核支持的线程 内核管理所有线程管理，并向应用程序提供API接口 内核维护进程和线程的上下文 线程的切换需要内核支持 以线程为基础进行调度 例子：Windows 图片来源: https://blog.csdn.net/gatieme/article/details/51892437 linux下,进程线程都是task_struct,通过CLONE_THREAD,新的进程和调用者进程的TGID是一样的,都是线程组头线程的PID.从Linux 2.4开始，getpid(2)会返回调用者的TGID。所以看到的表象就是线程组内的进程都是一个进程ID,通过CLONE_VM,这些线程组内的进程还可以公用虚拟空间,没有地址隔离,和进程的概念完全区别了.最后,exit只推出当前的task_struct,而exit_group退出线程组内所有线程的task_struct. 结语本文参考了大量文章,有的地方也还不是特别清楚,没有亲自去验证,去看底层实现.只能站在别人的肩膀上瞧瞧了. ending","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://riverferry.site/tags/linux/"}],"keywords":[]},{"title":"c++11四种cast转换","slug":"2020-03-21-c++11四种cast转换","date":"2020-03-21T00:00:00.000Z","updated":"2022-09-12T16:24:32.278Z","comments":true,"path":"2020-03-21-c++11四种cast转换/","link":"","permalink":"https://riverferry.site/2020-03-21-c++11%E5%9B%9B%E7%A7%8Dcast%E8%BD%AC%E6%8D%A2/","excerpt":"参考C++类型转换 四种类型转换(cast)的关键字 详解 及 代码 C ++中的static_cast 类型转换运算符 C ++中的dynamic_cast和static_cast","text":"参考C++类型转换 四种类型转换(cast)的关键字 详解 及 代码 C ++中的static_cast 类型转换运算符 C ++中的dynamic_cast和static_cast const_cast const_cast用于移除类型的const、volatile和__unaligned属性。 const int a = 1; int *b = const_cast&lt;int*&gt;(&amp;a); int c = 1; const int *d = const_cast&lt;const int *&gt;(&amp;c); 注意点 如果变量原来是const类型的常量，新的指针或引用是非常量，解除const限定后再去修改值是未定义的行为，const_cast只是用于修改变量的const属性，使用者应该考虑清楚操作的安全性. INPUT 123456789101112131415int main() &#123; const int a = 1; int *b = const_cast&lt;int*&gt;(&amp;a); *b = 2; cout &lt;&lt; a &lt;&lt; endl; cout &lt;&lt; *b &lt;&lt; endl; cout &lt;&lt; &amp;a &lt;&lt; endl; cout &lt;&lt; b &lt;&lt; endl;&#125; OUTPUT 1 2 0139F748 0139F748 static_cast static_cast&lt; Type* &gt;(ptr) This takes the pointer in ptr and tries to safely cast it to a pointer of type Type*. This cast is done at compile time. It will only perform the cast if the type types are related. If the types are not related, you will get a compiler error. 主要用在： 类的上行转换(派生类转基类,public继承)，下行转换是不安全的，需要编码时确认清楚 基本数据类型的转换(int,char,double),安全性需要编码时确认 将void指针转换成非void指针 数据类型转换 INPUT 1234567891011#include &lt;iostream&gt; using namespace std; int main() &#123; float f = 3.5; int a = f; // this is how you do in C int b = static_cast&lt;int&gt;(f); cout &lt;&lt; b; &#125; OUTPUT 3 指针类型转换 INPUT 1234567891011121314#include &lt;iostream&gt; using namespace std; int main() &#123; int a = 10; char c = &#x27;a&#x27;; // pass at compile time, may fail at run time int* q = (int*)&amp;c; //c语言可以 int* p = static_cast&lt;int*&gt;(&amp;c); //c++的失败 return 0; &#125; OUTPUT 错误 C2440 “static_cast”: 无法从“char *”转换为“int *” test 空指针 12345678910#include &lt;iostream&gt; int main() &#123; int i = 10; void* v = static_cast&lt;void*&gt;(&amp;i); int* ip = static_cast&lt;int*&gt;(v); return 0; &#125; 类对象转换 INPUT 123456789101112131415#include &lt;iostream&gt; using namespace std; class Base &#123; &#125;; class Derived : private Base &#123; // Inherited private/protected not public &#125;; int main() &#123; Derived d1; Base* b1 = (Base*)(&amp;d1); // allowed Base* b2 = static_cast&lt;Base*&gt;(&amp;d1); return 0; &#125; OUTPUT 错误(活动) E0269 不允许对不可访问的基类 “Base” 进行转换 test **:**上行转换的时候，一定要是public继承，private/protected都会编译报错 dynamic_cast dynamic_cast&lt; Type* &gt;(ptr) 以下拷贝自:链接 This again tries to take the pointer in ptr and safely cast it to a pointer of type Type*. But this cast is executed at runtime, not compile time. Because this is a run-time cast, it is useful especially when combined with polymorphic classes. In fact, in certian cases the classes must be polymorphic in order for the cast to be legal. Casts can go in one of two directions: from base to derived (B2D) or from derived to base (D2B). It’s simple enough to see how D2B casts would work at runtime. Either ptr was derived from Type or it wasn’t. In the case of D2B dynamic_cast&lt;&gt;s, the rules are simple. You can try to cast anything to anything else, and if ptr was in fact derived from Type, you’ll get a Type* pointer back from dynamic_cast. Otherwise, you’ll get a NULL pointer. But B2D casts are a little more complicated. Consider the following code: INPUT 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#include &lt;iostream&gt;using namespace std;class Base&#123;public: virtual void DoIt() = 0; // pure virtual virtual ~Base() &#123;&#125;;&#125;;class Foo : public Base&#123;public: virtual void DoIt() &#123; cout &lt;&lt; &quot;Foo&quot;; &#125;; void FooIt() &#123; cout &lt;&lt; &quot;Fooing It...&quot;; &#125;&#125;;class Bar : public Base&#123;public : virtual void DoIt() &#123; cout &lt;&lt; &quot;Bar&quot;; &#125; void BarIt() &#123; cout &lt;&lt; &quot;baring It...&quot;; &#125;&#125;;Base* CreateRandom()&#123; if( (rand()%2) == 0 ) return new Foo; else return new Bar;&#125;int main()&#123; for( int n = 0; n &lt; 10; ++n ) &#123; Base* base = CreateRandom(); base-&gt;DoIt(); Bar* bar = (Bar*)base; bar-&gt;BarIt(); &#125; return 0;&#125; OUTPUT Bar baring It... --------------- Bar baring It... --------------- Foo baring It... --------------- Foo baring It... --------------- Bar baring It... --------------- Foo baring It... --------------- Foo baring It... --------------- Foo baring It... --------------- Foo baring It... --------------- Foo baring It... --------------- main() can’t tell what kind of object CreateRandom() will return, so the C-style cast Bar* bar = (Bar*)base; is decidedly not type-safe. How could you fix this? One way would be to add a function like bool AreYouABar() const = 0; to the base class and return true from Bar and false from Foo. But there is another way: use dynamic_cast&lt;&gt;: 1234567891011121314151617181920int main()&#123; for( int n = 0; n &lt; 10; ++n ) &#123; Base* base = CreateRandom(); base-&gt;DoIt(); Bar* bar = dynamic_cast&lt;Bar*&gt;(base); Foo* foo = dynamic_cast&lt;Foo*&gt;(base); if( bar ) bar-&gt;BarIt(); if( foo ) foo-&gt;FooIt(); &#125; return 0;&#125; The casts execute at runtime, and work by querying the object (no need to worry about how for now), asking it if it the type we’re looking for. If it is, dynamic_cast&lt;Type*&gt; returns a pointer; otherwise it returns NULL. In order for this base-to-derived casting to work using dynamic_cast&lt;&gt;, Base, Foo and Bar must be what the Standard calls polymorphic types. In order to be a polymorphic type, your class must have at least one virtual function. If your classes are not polymorphic types, the base-to-derived use of dynamic_cast will not compile. Example: 12345678910111213class Base &#123;&#125;;class Der : public Base &#123;&#125;;int main()&#123; Base* base = new Der; Der* der = dynamic_cast&lt;Der*&gt;(base); // ERROR - Won&#x27;t compile return 0;&#125; Adding a virtual function to base, such as a virtual dtor, will make both Base and Der polymorphic types: 1234567891011121314151617class Base &#123;public: virtual ~Base()&#123;&#125;;&#125;;class Der : public Base &#123;&#125;;int main()&#123; Base* base = new Der; Der* der = dynamic_cast&lt;Der*&gt;(base); // OK return 0;&#125; reinterpret_castreinterpret_cast is a type of casting operator used in C++. It is used to convert one pointer of another pointer of any type, no matter either the class is related to each other or not. It does not check if the pointer type and data pointed by the pointer is same or not. syntax: data_type *var_name = reinterpret_cast &lt;data_type *&gt;(pointer_variable); Return Type： It doesn’t have any return type. It simply converts the pointer type. Purpose for using reinterpret_cast: 1 reinterpret_cast is a very special and dangerous type of casting operator. And is suggested to use it using proper data type i.e., (pointer data type should be same as original data type). 2 It can typecast any pointer to any other data type. 3 It is used when we want to work with bits. 4 If we use this type of cast then it becomes a non-portable product. So, it is suggested not to use this concept unless required. 5 It is only used to typecast any pointer to its original type. 6 Boolean value will be converted into integer value i.e., 0 for false and 1 for true. 谷歌翻译 1 reinterpret_cast是一种非常特殊且危险的类型转换操作符。建议使用它的时候要是合适的数据类型（指针数据类型应与原始数据类型相同） 2 它可以将任何指针类型转换为任何其他数据类型 3 当我们要使用位时使用 4 如果我们使用这种类型的演员表，那么它将成为不可携带的产品。因此，建议除非必要，否则不要使用此概念 5 它仅用于将任何指针转换为原始类型 6 布尔值将转换为整数值，即0代表false和1代表true 总结static_cast,const_cast转换指针类型都会在编译期报错，这比c语言那种显示类型转换要安全 const_cast修改最初声明为const的值是未定义的行为 static_cast上行转换的时候，继承方式需要是public dynamic_cast运行期转换，向下转换是安全的(会抛出异常或返回空指针)，但是向下转换的时候基类必须是多态的 ending","categories":[],"tags":[{"name":"c++11","slug":"c-11","permalink":"https://riverferry.site/tags/c-11/"}],"keywords":[]},{"title":"拥塞控制(慢启动+拥塞避免+超时重传+快速重传+快速恢复)","slug":"2020-03-20-拥塞控制","date":"2020-03-20T00:00:00.000Z","updated":"2022-09-12T16:24:32.278Z","comments":true,"path":"2020-03-20-拥塞控制/","link":"","permalink":"https://riverferry.site/2020-03-20-%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6/","excerpt":"参考TCP-IP详解: 慢启动和拥塞控制 TCP/IP之RTO、RTT 如何测量和确定Linux系统中tcp初始发送窗口的大小？ 什么是CWND和RWND TCP复习拥塞控制","text":"参考TCP-IP详解: 慢启动和拥塞控制 TCP/IP之RTO、RTT 如何测量和确定Linux系统中tcp初始发送窗口的大小？ 什么是CWND和RWND TCP复习拥塞控制 拥塞控制当某一路由器在单位时间内接收到的数据量多于其可发送的数据量时，他就把多余的部分存储起来。假如这种情况持续，存储资源将会耗尽，最后路由器不得不丢弃一部分数据，这种现象成为拥塞。在TCP的两端看到的就是丢包现象，为避免或在一定情况下缓解这种情况，TCP通信的每一方都实行拥塞控制机制。TCP是全双工通信，每一方都可能发送数据，途经路由器，所以两个发送方(server/client)都应该支持拥塞控制，而上一篇文章的滑动窗口是接收方主动的一种行为。 说明 Tahoe 提出了 慢启动 拥塞避免 超时重传 Reno 在Tahoe的基础上增加了 快速重传 快速恢复 谷歌BBR TCP的发送窗口wnd = min(rwnd, cwnd*mss) rwnd:接收方的窗口大小 cwnd:发送方的窗口大小 RTT/RTORTT(Round Trip Time) 一个连接的往返时间，即数据发送时刻到接收到确认的时刻的差值； RTO(Retransmission Time Out) 重传超时时间，即从数据发送时刻算起，超过这个时间便执行重传, RTO协议实现值最小1s 状态切换当cwnd &lt; ssthresh，执行慢启动 当cwnd &gt; ssthresh, 执行拥塞避免 当cwnd = ssthresh, 执行慢启动/拥塞避免的一种 当超过RTO时间，触发超时重传当收到3个以上的重复ACK,就进入快速重传 图片来源TCP 拥塞控制算法 慢启动慢启动的时机 当一个新的TCP连接建立 检测到由重传超时(RTO)导致的丢包时 TCP发送端长时间处于空闲状态 慢启动的目的 使TCP在用拥塞避免探寻更多可用带宽之前得到CWND(拥塞窗口)值，以及帮助TCP建立ACK时钟。 cwnd变化 在慢启动拥塞控制中，TCP快速增加窗口的大小(指数增加)，以尽快达到最大传输速率(指数) 每当收到一个ACK，cwnd + 1;每当过了一个RTT，cwnd = cwnd*2; 不考虑ack丢失的情况，则是2，4，8的指数增加 图片来源TCP复习拥塞控制 拥塞避免当达到阈值，迅速调整发送速率 If cwnd &lt; ssthresh then Each time an Ack is received: cwnd = cwnd + 1 else /* cwnd &gt; ssthresh */ Each time an Ack is received: cwnd = cwnd + 1 / [ cwnd ] endif 每当收到一个ACK，cwnd = cwnd + 1 / cwnd； 每当过了一个RTT，cwnd = cwnd + 1; 超时重传最为早期的TCP Tahoe算法使用下面的算法，但效率较差 由于发生丢包，将慢启动阈值ssthresh设置为当前cwnd的一半，即ssthresh = cwnd / 2. cwnd重置为1 进入慢启动过程 图片来源TCP复习拥塞控制 快速重传Reno算法在超时重传的基础上，对于收到三次以上的重复ack后，直接进行处理，不用等待定时器超时(RTO),并且处理策略也进行了优化 cwnd大小缩小为当前的一半 ssthresh设置为缩小后的cwnd大小 然后进入快速恢复算法Fast Recovery。 快速恢复Reno引入了快速恢复算法 cwnd = cwnd + 3 * MSS，加3 * MSS的原因是因为收到3个重复的ACK。 重传DACKs(重复确认)指定的数据包。 如果再收到DACKs，那么cwnd大小增加一。 如果收到新的ACK，表明重传的包成功了，那么退出快速恢复算法。将cwnd设置为ssthresh，然后进入拥塞避免算法。 图片来源TCP 拥塞控制算法 收到第三个重复ack后 ssthresh=cwnd=6/2=3(快速重传) cwnd=3+3=6(快速恢复) 如果继续收到ack5,则cwnd++ 重传pkt5数据包 如果收到新的ack,则cwnd=ssthresh,进入拥塞避免 快速恢复cwnd&gt;ssthresh属于裸奔状态,是特事特办，在重传的同时可以发送新的包，在重传结束，需要快速切换回拥塞避免状态 ending","categories":[],"tags":[{"name":"TCP","slug":"TCP","permalink":"https://riverferry.site/tags/TCP/"}],"keywords":[]},{"title":"滑动窗口","slug":"2020-03-19-滑动窗口","date":"2020-03-19T00:00:00.000Z","updated":"2022-09-12T16:24:32.278Z","comments":true,"path":"2020-03-19-滑动窗口/","link":"","permalink":"https://riverferry.site/2020-03-19-%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3/","excerpt":"参考TCP协议的滑动窗口具体是怎样控制流量的？ TCP/IP详解","text":"参考TCP协议的滑动窗口具体是怎样控制流量的？ TCP/IP详解 正文流量控制 在接收方跟不上发送方的时候，会强迫发送方慢下来，这称为流量控制。流量控制通常有两种形式： 1 基于速率流量控制：给发送方指定某个速率，同时确保速率永远不会超过这个速率发送 2 基于窗口流量控制：使用滑动窗口(sliding window) 滑动窗口 TCP是全双工的协议，每一方都可以收发数据。连接的收发数据量是根据一组窗口结构维护的。 windows是一个16bit字段，代表滑动窗口的大小，默认最大是65535，可以根据option-kind,option-lenth,option-data进行扩厂。 每个TCP报文段(除了连接建立之初的包交换)都包含一个有效的序列号字段，一个ACK号或确认字段，以及一个窗口大小： clint-&gt;server: 31:31:31:0d:0a //frame number 56 32:32:32:0d:0a //frame number 67 发送方发了2次数据，每次5个字节，服务方回复6,11表示期待的下一个节点，通过此方法保证可靠传输 从图中也可以看出发送方窗口和接收方窗口的大小 接收方窗口 发送方窗口 发送方滑动窗口大小SND.WND = SND.UNA + SND.WND 如图所示，当4，5字节报文发送给接收方并收到接收方的ack=6,则发送方的滑动窗口右移： [4-9] -&gt; [6-11] 这是在SND.WND不变的情况下，实际上SND.WND可能是根据实际情况变化的。这个右移的过程是即将发送(可用窗口)变大的过程。如果发送者一直发，但收不到ack,或者ack的序号不对，则可用窗口变小，已发送未经确认窗口变大，直到接收方窗口已满,接收方会发给发送方调整窗口大小为0来阻止发送方继续发送。 注意 当发送方窗口 &gt; 接收方窗口：接收方的能力限制发送方的窗口大小 当发送方窗口 &lt; 接收方窗口：是网络拥塞限制发送方的窗口大小 零窗口演示 整个程序的逻辑：服务端accept后不recv,客户端一直发数据，最后客户端(发送方)窗口满，服务端(接收方)返回零窗口，客户端不再发送数据给服务端。 报文如下： 链接：https://pan.baidu.com/s/1Drh4_I42s0WIyebAvFvU5A 提取码：lti3 复制这段内容后打开百度网盘手机App，操作更方便哦 滑动窗口的作用 提供TCP的可靠性(依赖确认ack重传) 提供TCP的流控特性(第二种流量控制) ending","categories":[],"tags":[{"name":"TCP","slug":"TCP","permalink":"https://riverferry.site/tags/TCP/"}],"keywords":[]},{"title":"itchat构建微信自动回复","slug":"2020-03-17-itchat构建微信自动回复","date":"2020-03-17T00:00:00.000Z","updated":"2022-09-12T16:24:32.278Z","comments":true,"path":"2020-03-17-itchat构建微信自动回复/","link":"","permalink":"https://riverferry.site/2020-03-17-itchat%E6%9E%84%E5%BB%BA%E5%BE%AE%E4%BF%A1%E8%87%AA%E5%8A%A8%E5%9B%9E%E5%A4%8D/","excerpt":"前言本来想着做个微信菜单，自定义一些服务，增加点情趣。网上查了下发现python+itchat用起来很好上手，最后安装必要软件调试完成，扫二维码，and： 为了你的帐号安全，此微信号不能登录网页微信。你可以使用Windows微信或Mac微信在电脑端登录。Windows微信下载地址：https://pc.weixin.qq.com Mac微信下载地址：https://mac.weixin.qq.comStart auto replying. 网上查了下，大概是微信把网页登录的接口给禁用了，而我来的太晚了。可以在线测试下微信是否可以网页登录：微信网页版入口","text":"前言本来想着做个微信菜单，自定义一些服务，增加点情趣。网上查了下发现python+itchat用起来很好上手，最后安装必要软件调试完成，扫二维码，and： 为了你的帐号安全，此微信号不能登录网页微信。你可以使用Windows微信或Mac微信在电脑端登录。Windows微信下载地址：https://pc.weixin.qq.com Mac微信下载地址：https://mac.weixin.qq.comStart auto replying. 网上查了下，大概是微信把网页登录的接口给禁用了，而我来的太晚了。可以在线测试下微信是否可以网页登录：微信网页版入口 itchat使用步骤安装 yum install -y epel-release yum install python34-pip 具体步骤记不太全了，可以网上查下，安装完python+pip后，安装itchat pip3 install itchat --upgrade 这一步可能会报错： pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host=’files.pythonhosted.org’, port=443): Read timed out. 应该是网络不好，超时了，解决办法：Python报错pip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool解决方法 pip --default-timeout=10000 install itchat --upgrade 运行 1234567891011import itchat@itchat.msg_register(itchat.content.TEXT)def print_content(msg): print(msg[&#x27;Text&#x27;])itchat.auto_login()itchat.run() 执行： python3 test.py 然后报错： FileNotFoundError: [Errno 2] No such file or directory: ‘xdg-open’: ‘xdg-open’ 解决办法：安装xdg yum install xdg-utils 继续报错： xdg-open: no method available for opening ‘QR.png’ 解决办法：在当前路径下找QR.png这个图片打开，即是微信网页版登录的二维码，but,如前文所说，我来迟了，现在腾讯不给开这个接口了，所以我的美景(让别人开心，增加情趣)没有生效。暂时记录在这，日后有了闲情逸致再在此基础上继续探索。 后续 采用了微信公众号的方式，达到了一定的效果，具体不再多言. ending","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://riverferry.site/tags/python/"}],"keywords":[]},{"title":"ace-简单的server-client","slug":"2020-03-16-ace-简单的server-client","date":"2020-03-16T00:00:00.000Z","updated":"2022-09-12T16:24:32.277Z","comments":true,"path":"2020-03-16-ace-简单的server-client/","link":"","permalink":"https://riverferry.site/2020-03-16-ace-%E7%AE%80%E5%8D%95%E7%9A%84server-client/","excerpt":"参考ACE技术内幕：深入解析ACE架构设计与实现原理","text":"参考ACE技术内幕：深入解析ACE架构设计与实现原理 server123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657#include &quot;pch.h&quot;#include &lt;iostream&gt;#include &quot;ace/Log_Msg.h&quot;#include &quot;ace/INET_Addr.h&quot;#include &quot;ace/SOCK_Acceptor.h&quot;using namespace std;int main(int argc, char** argv)&#123; ACE_INET_Addr listen(6666); ACE_SOCK_ACCEPTOR acceptor; if (-1 == acceptor.open(listen, 1)) &#123; //ACE_ERROR_RETURN((LM_ERROR, ACE_TEXT(&quot;%p \\n&quot;), ACE_TEXT(&quot;acceptor.open()&quot;)), -1); cout &lt;&lt; &quot;acceptor.open error!&quot; &lt;&lt; endl; return -1; &#125; while (true) &#123; ACE_SOCK_Stream peer; ACE_INET_Addr peer_addr; if (-1 == acceptor.accept(peer, &amp;peer_addr)) &#123; cout &lt;&lt; &quot;acceptor.accept error!&quot; &lt;&lt; endl; return -1; &#125; else &#123; ACE_TCHAR peer_name[HOST_NAME_MAX]; peer_addr.addr_to_string(peer_name, HOST_NAME_MAX); cout &lt;&lt; &quot;connect from: &quot; &lt;&lt; peer_name &lt;&lt; endl; char buffer[4096] = &#123;0&#125;; ssize_t bytes_num = 0; while ((bytes_num = peer.recv(buffer, sizeof(buffer))) &gt; 0) &#123; buffer[bytes_num] = 0; cout &lt;&lt; buffer &lt;&lt; endl; &#125; peer.close(); cout &lt;&lt; &quot;close socket!&quot; &lt;&lt; endl; &#125; &#125; return 0;&#125; pic: client-tcp client1234567891011121314151617181920212223242526272829#include &quot;pch.h&quot;#include &lt;iostream&gt;#include &quot;ace/Log_Msg.h&quot;#include &quot;ace/INET_Addr.h&quot;#include &quot;ace/SOCK_Connector.h&quot;using namespace std;int main(int argc, char** argv)&#123; ACE_SOCK_CONNECTOR connector; ACE_SOCK_Stream peer; ACE_INET_Addr addr(5555, &quot;127.0.0.1&quot;); if (-1 == connector.connect(peer, addr)) &#123; cout &lt;&lt; &quot;connector.connect error!&quot; &lt;&lt; endl; return -1; &#125; char buffer[100] = &quot;This is a test!&quot;; peer.send_n(buffer, strlen(buffer)); peer.close(); return 0;&#125; pic: server-tcp endingpic: woman-in-black-high-heels-standing-next-to-a-car-picjumbo-com_lit","categories":[],"tags":[{"name":"ace","slug":"ace","permalink":"https://riverferry.site/tags/ace/"}],"keywords":[]},{"title":"ace在vs下编译","slug":"2020-03-16-ace在vs下编译","date":"2020-03-16T00:00:00.000Z","updated":"2022-09-12T16:24:32.277Z","comments":true,"path":"2020-03-16-ace在vs下编译/","link":"","permalink":"https://riverferry.site/2020-03-16-ace%E5%9C%A8vs%E4%B8%8B%E7%BC%96%E8%AF%91/","excerpt":"参考ACE在windows下的编译及配置 ACE_TEST1.obj : error LNK2019: 无法解析的外部符号 fatal error LNK1104: 无法打开文件”ACEd.lib”","text":"参考ACE在windows下的编译及配置 ACE_TEST1.obj : error LNK2019: 无法解析的外部符号 fatal error LNK1104: 无法打开文件”ACEd.lib” 步骤1 添加配置文件touch /ACE_wrappers/ace/config.h #define ACE_HAS_STANDARD_CPP_LIBRARY 1 #include &quot;ace/config-win32.h&quot; 2 编译aced库在/ACE_wrappers下选中对应版本的工程ACE_vs2017.sln.打开后选中ace项目进行编译，最终生成aced.lib aced.dll 3 环境变量添加环境变量 变量名：ACE_ROOT，变量值：/ACE_wrappers 4 vs中添加环境变量ACE_ROOT可执行文件目录 $(VC_ExecutablePath_x86);$(WindowsSDK_ExecutablePath);$(VS_ExecutablePath);$(MSBuild_ExecutablePath);$(SystemRoot)\\SysWow64;$(FxCopDir);$(PATH);$(ACE_ROOT); 包含目录 $(VC_IncludePath);$(WindowsSDK_IncludePath);$(ACE_ROOT); 库目录 $(VC_LibraryPath_x86);$(WindowsSDK_LibraryPath_x86);$(NETFXKitsDir)Lib\\um\\x86;$(ACE_ROOT); 5 新建项目编译新建控制台应用程序，将aced.dll/aced.lib加到项目路径下，main函数格式：int main(int argc, char** argv)，然后编译”hello world!” 12345678910111213#include &quot;pch.h&quot;#include &lt;iostream&gt;#include &quot;ace/Log_Msg.h&quot;int main(int argc, char** argv)&#123; ACE_TRACE(ACE_TEXT(&quot;main&quot;)); ACE_DEBUG((LM_INFO, ACE_TEXT(&quot;Hello world/n&quot;))); return 0;&#125; ending","categories":[],"tags":[{"name":"ace","slug":"ace","permalink":"https://riverferry.site/tags/ace/"}],"keywords":[]},{"title":"stl-reverse_iterator","slug":"2020-03-16-stl-reverse_iterator","date":"2020-03-16T00:00:00.000Z","updated":"2022-09-12T16:24:32.277Z","comments":true,"path":"2020-03-16-stl-reverse_iterator/","link":"","permalink":"https://riverferry.site/2020-03-16-stl-reverse_iterator/","excerpt":"参考","text":"参考 用法INPUT 123456789101112131415161718#include &quot;pch.h&quot;#include &lt;iostream&gt;#include &lt;vector&gt;int main()&#123; std::vector&lt;int&gt; myvector = &#123; 10,20,30,40,50 &#125;; std::cout &lt;&lt; &quot;myvector contains:&quot;; for (std::vector&lt;int&gt;::reverse_iterator it = myvector.rbegin(); it != myvector.rend(); ++it) std::cout &lt;&lt; &#x27; &#x27; &lt;&lt; *it; std::cout &lt;&lt; &#x27;\\n&#x27;; return 0;&#125; OUTPUT myvector contains: 50 40 30 20 10 原理123456789101112131415161718192021222324252627//end()const_iterator end() const _GLIBCXX_NOEXCEPT &#123; return const_iterator(this-&gt;_M_impl._M_finish); &#125;//begin()reverse_iterator rbegin() _GLIBCXX_NOEXCEPT &#123; return reverse_iterator(end()); &#125;//有参构造函数explicit reverse_iterator(iterator_type __x) : current(__x) &#123; &#125;//类声明，成员变量template&lt;typename _Iterator&gt; class reverse_iterator&#123; _Iterator current;&#125; rbegin把_M_finish作为初始化值传入reverse_iterator类的构造函数进行初始化，最后reverse_iterator的成员变量current是iterator类型的迭代器，值为_M_finish对应的某种类型。也就是说rbegin生成的迭代器对应的值是空，因为_M_finish是最后一个元素的后面的地址，那使用时候为什么察觉不到？原因在于operator的实现： 1234567891011121314151617181920212223242526272829303132// *reference operator*() const &#123; _Iterator __tmp = current; return *--__tmp; &#125;// -&gt;pointer operator-&gt;() const &#123; return &amp;(operator*()); &#125;// ++reverse_iterator&amp; operator++() &#123; --current; return *this; &#125;// --reverse_iterator&amp; operator--() &#123; ++current; return *this; &#125; 类似障眼法的东西，其本质还是iterator迭代器，不过实现方法上是相反的逻辑，也可以用base函数进行转换，变为正常的身份： 1234567iterator_type base() const &#123; return current; &#125; ending","categories":[],"tags":[{"name":"stl","slug":"stl","permalink":"https://riverferry.site/tags/stl/"}],"keywords":[]},{"title":"vs+linux编译环境","slug":"2020-03-10-vs+linux编译环境","date":"2020-03-10T00:00:00.000Z","updated":"2022-09-12T16:24:32.277Z","comments":true,"path":"2020-03-10-vs+linux编译环境/","link":"","permalink":"https://riverferry.site/2020-03-10-vs+linux%E7%BC%96%E8%AF%91%E7%8E%AF%E5%A2%83/","excerpt":"前言虚拟机的samba有点问题，恰好电脑之前装过vs 2017,就用了下vs的linux编译项目，也算是一种选择","text":"前言虚拟机的samba有点问题，恰好电脑之前装过vs 2017,就用了下vs的linux编译项目，也算是一种选择 正文step 1 step 2 调试-&gt;选项 step 3 step 4 step 5 ending","categories":[],"tags":[{"name":"tool","slug":"tool","permalink":"https://riverferry.site/tags/tool/"}],"keywords":[]},{"title":"select-poll的源码","slug":"2020-03-09-select-poll","date":"2020-03-09T00:00:00.000Z","updated":"2022-09-12T16:24:32.277Z","comments":true,"path":"2020-03-09-select-poll/","link":"","permalink":"https://riverferry.site/2020-03-09-select-poll/","excerpt":"参考select/poll/epoll对比分析 Linux进程管理(一) Linux内核中网络数据包的接收-第二部分 select/poll/epoll","text":"参考select/poll/epoll对比分析 Linux进程管理(一) Linux内核中网络数据包的接收-第二部分 select/poll/epoll select介绍man page 123#include &lt;sys/select.h&gt;int select(int nfds, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout); RETURN VALUE On success, select() and pselect() return the number of filedescriptors contained in the three returned descriptor sets (that is,the total number of bits that are set in readfds, writefds,exceptfds) which may be zero if the timeout expires before anythinginteresting happens. On error, -1 is returned, and errno is set toindicate the error; the file descriptor sets are unmodified, andtimeout becomes undefined. 成功返回三种类型的总的句柄数 超时返回0 异常返回-1 nfds nfds should be set to the highest-numbered file descriptor in any of the three sets, plus 1. The indicated file descriptors in each set are checked, up to this limit (but see BUGS). timeout 1234struct timeval &#123; __kernel_time_t tv_sec; /* seconds */ __kernel_suseconds_t tv_usec; /* microseconds 微妙*/&#125;; timeout = NULL //永久阻塞 timeout.tv_sec = 0 &amp;&amp; tv_sec.tv_usec = 0 //不阻塞，直接返回结果 timeout.tv_sec &gt; 0 &amp;&amp; tv_sec.tv_usec &gt; 0 //等待超时时间后返回 readfds/writefds/exceptfds Three independent sets of file descriptors are watched. The file descriptors listed in readfds will be watched to see if charactersbecome available for reading (more precisely, to see if a read willnot block; in particular, a file descriptor is also ready on end-of-file). The file descriptors in writefds will be watched to see ifspace is available for write (though a large write may still block). The file descriptors in exceptfds will be watched for exceptionalconditions. (For examples of some exceptional conditions, see thediscussion of POLLPRI in poll(2).) FD_SET 1234567#define __FD_SETSIZE 1024typedef struct &#123; unsigned long fds_bits[__FD_SETSIZE / (8 * sizeof(long))];&#125; __kernel_fd_set;typedef __kernel_fd_set fd_set; 64位系统中long是8字节。__FD_SETSIZE表示最大可以监控的句柄数，那么一位可以保存一个，数组大小是多少？__FD_SETSIZE / (8 * sizeof(unsigned long)。 1234void FD_CLR(int fd, fd_set *set);int FD_ISSET(int fd, fd_set *set);void FD_SET(int fd, fd_set *set);void FD_ZERO(fd_set *set); 引用自这里 FD_CLR(fd, &amp;fdset) Clears the bit for the file descriptor fd in the file descriptor set fdset. FD_ISSET(fd, &amp;fdset) Returns a non-zero value if the bit for the file descriptor fd is set in the file descriptor set pointed to by fdset, and 0 otherwise. FD_SET(fd, &amp;fdset) Sets the bit for the file descriptor fd in the file descriptor set fdset. FD_ZERO(&amp;fdset) Initializes the file descriptor set fdset to have zero bits for all file descriptors. select源码SYSCALL_DEFINE5 1234567891011121314151617181920212223SYSCALL_DEFINE5(select, int, n, fd_set __user *, inp, fd_set __user *, outp, fd_set __user *, exp, struct timeval __user *, tvp)&#123; struct timespec end_time, *to = NULL; struct timeval tv; int ret; if (tvp) &#123; if (copy_from_user(&amp;tv, tvp, sizeof(tv))) return -EFAULT; to = &amp;end_time; if (poll_select_set_timeout(to, tv.tv_sec + (tv.tv_usec / USEC_PER_SEC), (tv.tv_usec % USEC_PER_SEC) * NSEC_PER_USEC)) return -EINVAL; &#125; ret = core_sys_select(n, inp, outp, exp, to); ret = poll_select_copy_remaining(&amp;end_time, tvp, 1, ret); return ret;&#125; 主要把时间格式转换了timeval-&gt;timespec core_sys_select 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283/* * We can actually return ERESTARTSYS instead of EINTR, but I&#x27;d * like to be certain this leads to no problems. So I return * EINTR just for safety. * * Update: ERESTARTSYS breaks at least the xview clock binary, so * I&#x27;m trying ERESTARTNOHAND which restart only when you want to. */int core_sys_select(int n, fd_set __user *inp, fd_set __user *outp, fd_set __user *exp, struct timespec *end_time)&#123; fd_set_bits fds; void *bits; int ret, max_fds; unsigned int size; struct fdtable *fdt; /* Allocate small arguments on the stack to save memory and be faster */ long stack_fds[SELECT_STACK_ALLOC/sizeof(long)]; ret = -EINVAL; if (n &lt; 0) goto out_nofds; /* max_fds can increase, so grab it once to avoid race */ rcu_read_lock(); fdt = files_fdtable(current-&gt;files); max_fds = fdt-&gt;max_fds; rcu_read_unlock(); if (n &gt; max_fds) n = max_fds; /* * We need 6 bitmaps (in/out/ex for both incoming and outgoing), * since we used fdset we need to allocate memory in units of * long-words. */ size = FDS_BYTES(n); bits = stack_fds; if (size &gt; sizeof(stack_fds) / 6) &#123; /* Not enough space in on-stack array; must use kmalloc */ ret = -ENOMEM; bits = kmalloc(6 * size, GFP_KERNEL); if (!bits) goto out_nofds; &#125; fds.in = bits; fds.out = bits + size; fds.ex = bits + 2*size; fds.res_in = bits + 3*size; fds.res_out = bits + 4*size; fds.res_ex = bits + 5*size; if ((ret = get_fd_set(n, inp, fds.in)) || (ret = get_fd_set(n, outp, fds.out)) || (ret = get_fd_set(n, exp, fds.ex))) goto out; zero_fd_set(n, fds.res_in); zero_fd_set(n, fds.res_out); zero_fd_set(n, fds.res_ex); ret = do_select(n, &amp;fds, end_time); if (ret &lt; 0) goto out; if (!ret) &#123; ret = -ERESTARTNOHAND; if (signal_pending(current)) goto out; ret = 0; &#125; if (set_fd_set(n, inp, fds.res_in) || set_fd_set(n, outp, fds.res_out) || set_fd_set(n, exp, fds.res_ex)) ret = -EFAULT;out: if (bits != stack_fds) kfree(bits);out_nofds: return ret;&#125; do_select 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115int do_select(int n, fd_set_bits *fds, struct timespec *end_time)&#123; ktime_t expire, *to = NULL; struct poll_wqueues table; poll_table *wait; int retval, i, timed_out = 0; unsigned long slack = 0; rcu_read_lock(); retval = max_select_fd(n, fds); rcu_read_unlock(); if (retval &lt; 0) return retval; n = retval; poll_initwait(&amp;table); wait = &amp;table.pt; if (end_time &amp;&amp; !end_time-&gt;tv_sec &amp;&amp; !end_time-&gt;tv_nsec) &#123; wait-&gt;_qproc = NULL; timed_out = 1; &#125; if (end_time &amp;&amp; !timed_out) slack = select_estimate_accuracy(end_time); retval = 0; for (;;) &#123; unsigned long *rinp, *routp, *rexp, *inp, *outp, *exp; inp = fds-&gt;in; outp = fds-&gt;out; exp = fds-&gt;ex; rinp = fds-&gt;res_in; routp = fds-&gt;res_out; rexp = fds-&gt;res_ex; for (i = 0; i &lt; n; ++rinp, ++routp, ++rexp) &#123; unsigned long in, out, ex, all_bits, bit = 1, mask, j; unsigned long res_in = 0, res_out = 0, res_ex = 0; in = *inp++; out = *outp++; ex = *exp++; all_bits = in | out | ex; if (all_bits == 0) &#123; i += BITS_PER_LONG; continue; &#125; for (j = 0; j &lt; BITS_PER_LONG; ++j, ++i, bit &lt;&lt;= 1) &#123; struct fd f; if (i &gt;= n) break; if (!(bit &amp; all_bits)) continue; f = fdget(i); if (f.file) &#123; const struct file_operations *f_op; f_op = f.file-&gt;f_op; mask = DEFAULT_POLLMASK; if (f_op &amp;&amp; f_op-&gt;poll) &#123; wait_key_set(wait, in, out, bit); //核心函数 mask = (*f_op-&gt;poll)(f.file, wait); &#125; fdput(f); if ((mask &amp; POLLIN_SET) &amp;&amp; (in &amp; bit)) &#123; res_in |= bit; retval++; wait-&gt;_qproc = NULL; &#125; if ((mask &amp; POLLOUT_SET) &amp;&amp; (out &amp; bit)) &#123; res_out |= bit; retval++; wait-&gt;_qproc = NULL; &#125; if ((mask &amp; POLLEX_SET) &amp;&amp; (ex &amp; bit)) &#123; res_ex |= bit; retval++; wait-&gt;_qproc = NULL; &#125; &#125; &#125; if (res_in) *rinp = res_in; if (res_out) *routp = res_out; if (res_ex) *rexp = res_ex; cond_resched(); &#125; wait-&gt;_qproc = NULL; if (retval || timed_out || signal_pending(current)) break; if (table.error) &#123; retval = table.error; break; &#125; /* * If this is the first loop and we have a timeout * given, then we convert to ktime_t and set the to * pointer to the expiry value. */ if (end_time &amp;&amp; !to) &#123; expire = timespec_to_ktime(*end_time); to = &amp;expire; &#125; if (!poll_schedule_timeout(&amp;table, TASK_INTERRUPTIBLE, to, slack)) timed_out = 1; &#125; poll_freewait(&amp;table); return retval;&#125; 1234567891011void poll_initwait(struct poll_wqueues *pwq)&#123; init_poll_funcptr(&amp;pwq-&gt;pt, __pollwait); pwq-&gt;polling_task = current; pwq-&gt;triggered = 0; pwq-&gt;error = 0; pwq-&gt;table = NULL; pwq-&gt;inline_index = 0;&#125; 123456789101112131415/* Add a new entry */static void __pollwait(struct file *filp, wait_queue_head_t *wait_address, poll_table *p)&#123; struct poll_wqueues *pwq = container_of(p, struct poll_wqueues, pt); struct poll_table_entry *entry = poll_get_entry(pwq); if (!entry) return; entry-&gt;filp = get_file(filp); entry-&gt;wait_address = wait_address; entry-&gt;key = p-&gt;_key; init_waitqueue_func_entry(&amp;entry-&gt;wait, pollwake); entry-&gt;wait.private = pwq; add_wait_queue(wait_address, &amp;entry-&gt;wait);&#125; 123456789static int pollwake(wait_queue_t *wait, unsigned mode, int sync, void *key)&#123; struct poll_table_entry *entry; entry = container_of(wait, struct poll_table_entry, wait); if (key &amp;&amp; !((unsigned long)key &amp; entry-&gt;key)) return 0; return __pollwake(wait, mode, sync, key);&#125; 123456789101112131415161718192021222324252627static int __pollwake(wait_queue_t *wait, unsigned mode, int sync, void *key)&#123; struct poll_wqueues *pwq = wait-&gt;private; DECLARE_WAITQUEUE(dummy_wait, pwq-&gt;polling_task); /* * Although this function is called under waitqueue lock, LOCK * doesn&#x27;t imply write barrier and the users expect write * barrier semantics on wakeup functions. The following * smp_wmb() is equivalent to smp_wmb() in try_to_wake_up() * and is paired with set_mb() in poll_schedule_timeout. */ smp_wmb(); pwq-&gt;triggered = 1; /* * Perform the default wake up operation using a dummy * waitqueue. * * TODO: This is hacky but there currently is no interface to * pass in @sync. @sync is scheduled to be removed and once * that happens, wake_up_process() can be used directly. */ return default_wake_function(&amp;dummy_wait, mode, sync, key);&#125; 图片来自:Linux进程管理(一) SYSCALL_DEFINE5 |-&gt;core_sys_select |-&gt;do_select |-&gt;poll_initwait |-&gt;init_poll_funcptr(&amp;pwq-&gt;pt, __pollwait) |-&gt;pollwake |-&gt;__pollwake |-&gt;default_wake_function |-&gt;f_op-&gt;poll |-&gt;poll_freewait poll源码SYSCALL_DEFINE3 12345678910111213141516171819202122232425262728293031323334SYSCALL_DEFINE3(poll, struct pollfd __user *, ufds, unsigned int, nfds, int, timeout_msecs)&#123; struct timespec end_time, *to = NULL; int ret; if (timeout_msecs &gt;= 0) &#123; to = &amp;end_time; poll_select_set_timeout(to, timeout_msecs / MSEC_PER_SEC, NSEC_PER_MSEC * (timeout_msecs % MSEC_PER_SEC)); &#125; ret = do_sys_poll(ufds, nfds, to); if (ret == -EINTR) &#123; struct restart_block *restart_block; restart_block = &amp;current_thread_info()-&gt;restart_block; restart_block-&gt;fn = do_restart_poll; restart_block-&gt;poll.ufds = ufds; restart_block-&gt;poll.nfds = nfds; if (timeout_msecs &gt;= 0) &#123; restart_block-&gt;poll.tv_sec = end_time.tv_sec; restart_block-&gt;poll.tv_nsec = end_time.tv_nsec; restart_block-&gt;poll.has_timeout = 1; &#125; else restart_block-&gt;poll.has_timeout = 0; ret = -ERESTART_RESTARTBLOCK; &#125; return ret;&#125; do_sys_poll 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566int do_sys_poll(struct pollfd __user *ufds, unsigned int nfds, struct timespec *end_time)&#123; struct poll_wqueues table; int err = -EFAULT, fdcount, len, size; /* Allocate small arguments on the stack to save memory and be faster - use long to make sure the buffer is aligned properly on 64 bit archs to avoid unaligned access */ long stack_pps[POLL_STACK_ALLOC/sizeof(long)]; struct poll_list *const head = (struct poll_list *)stack_pps; struct poll_list *walk = head; unsigned long todo = nfds; if (nfds &gt; rlimit(RLIMIT_NOFILE)) return -EINVAL; len = min_t(unsigned int, nfds, N_STACK_PPS); for (;;) &#123; walk-&gt;next = NULL; walk-&gt;len = len; if (!len) break; if (copy_from_user(walk-&gt;entries, ufds + nfds-todo, sizeof(struct pollfd) * walk-&gt;len)) goto out_fds; todo -= walk-&gt;len; if (!todo) break; len = min(todo, POLLFD_PER_PAGE); size = sizeof(struct poll_list) + sizeof(struct pollfd) * len; walk = walk-&gt;next = kmalloc(size, GFP_KERNEL); if (!walk) &#123; err = -ENOMEM; goto out_fds; &#125; &#125; poll_initwait(&amp;table); fdcount = do_poll(nfds, head, &amp;table, end_time); poll_freewait(&amp;table); for (walk = head; walk; walk = walk-&gt;next) &#123; struct pollfd *fds = walk-&gt;entries; int j; for (j = 0; j &lt; walk-&gt;len; j++, ufds++) if (__put_user(fds[j].revents, &amp;ufds-&gt;revents)) goto out_fds; &#125; err = fdcount;out_fds: walk = head-&gt;next; while (walk) &#123; struct poll_list *pos = walk; walk = walk-&gt;next; kfree(pos); &#125; return err;&#125; do_poll 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869static int do_poll(unsigned int nfds, struct poll_list *list, struct poll_wqueues *wait, struct timespec *end_time)&#123; poll_table* pt = &amp;wait-&gt;pt; ktime_t expire, *to = NULL; int timed_out = 0, count = 0; unsigned long slack = 0; /* Optimise the no-wait case */ if (end_time &amp;&amp; !end_time-&gt;tv_sec &amp;&amp; !end_time-&gt;tv_nsec) &#123; pt-&gt;_qproc = NULL; timed_out = 1; &#125; if (end_time &amp;&amp; !timed_out) slack = select_estimate_accuracy(end_time); for (;;) &#123; struct poll_list *walk; for (walk = list; walk != NULL; walk = walk-&gt;next) &#123; struct pollfd * pfd, * pfd_end; pfd = walk-&gt;entries; pfd_end = pfd + walk-&gt;len; for (; pfd != pfd_end; pfd++) &#123; /* * Fish for events. If we found one, record it * and kill poll_table-&gt;_qproc, so we don&#x27;t * needlessly register any other waiters after * this. They&#x27;ll get immediately deregistered * when we break out and return. */ if (do_pollfd(pfd, pt)) &#123; count++; pt-&gt;_qproc = NULL; &#125; &#125; &#125; /* * All waiters have already been registered, so don&#x27;t provide * a poll_table-&gt;_qproc to them on the next loop iteration. */ pt-&gt;_qproc = NULL; if (!count) &#123; count = wait-&gt;error; if (signal_pending(current)) count = -EINTR; &#125; if (count || timed_out) break; /* * If this is the first loop and we have a timeout * given, then we convert to ktime_t and set the to * pointer to the expiry value. */ if (end_time &amp;&amp; !to) &#123; expire = timespec_to_ktime(*end_time); to = &amp;expire; &#125; if (!poll_schedule_timeout(wait, TASK_INTERRUPTIBLE, to, slack)) timed_out = 1; &#125; return count;&#125; do_pollfd 12345678910111213141516171819202122232425262728293031323334/* * Fish for pollable events on the pollfd-&gt;fd file descriptor. We&#x27;re only * interested in events matching the pollfd-&gt;events mask, and the result * matching that mask is both recorded in pollfd-&gt;revents and returned. The * pwait poll_table will be used by the fd-provided poll handler for waiting, * if pwait-&gt;_qproc is non-NULL. */static inline unsigned int do_pollfd(struct pollfd *pollfd, poll_table *pwait)&#123; unsigned int mask; int fd; mask = 0; fd = pollfd-&gt;fd; if (fd &gt;= 0) &#123; struct fd f = fdget(fd); mask = POLLNVAL; if (f.file) &#123; mask = DEFAULT_POLLMASK; if (f.file-&gt;f_op &amp;&amp; f.file-&gt;f_op-&gt;poll) &#123; pwait-&gt;_key = pollfd-&gt;events|POLLERR|POLLHUP; mask = f.file-&gt;f_op-&gt;poll(f.file, pwait); &#125; /* Mask out unneeded events. */ mask &amp;= pollfd-&gt;events | POLLERR | POLLHUP; fdput(f); &#125; &#125; pollfd-&gt;revents = mask; return mask;&#125; SYSCALL_DEFINE3 |-&gt;do_sys_poll |-&gt;poll_initwait |-&gt;do_poll |-&gt;do_pollfd |-&gt;f.file-&gt;f_op-&gt;poll 1unsigned int (*poll) (struct file *, struct poll_table_struct *); ending","categories":[],"tags":[{"name":"IO复用","slug":"IO复用","permalink":"https://riverferry.site/tags/IO%E5%A4%8D%E7%94%A8/"}],"keywords":[]},{"title":"stl-vector源码剖析","slug":"2020-03-09-stl-vector源码剖析","date":"2020-03-09T00:00:00.000Z","updated":"2022-09-12T16:24:32.277Z","comments":true,"path":"2020-03-09-stl-vector源码剖析/","link":"","permalink":"https://riverferry.site/2020-03-09-stl-vector%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90/","excerpt":"参考STL源码剖析.pdf STL源码剖析（批注版）.pdf cplusplus-vector","text":"参考STL源码剖析.pdf STL源码剖析（批注版）.pdf cplusplus-vector 正文 思维导图TODO 源码gcc-9.2.0 stl_vector.h 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071081091101111121131141151161171181191201211221231241251261271281291301311321331341351361371381391401411421431441451461471481491501511521531541551561571581591601611621631641651661671681691701711721731741751761771781791801811821831841851861871881891901911921931941951961971981992002012022032042052062072082092102112122132142152162172182192202212222232242252262272282292302312322332342352362372382392402412422432442452462472482492502512522532542552562572582592602612622632642652662672682692702712722732742752762772782792802812822832842852862872882892902912922932942952962972982993003013023033043053063073083093103113123133143153163173183193203213223233243253263273283293303313323333343353363373383393403413423433443453463473483493503513523533543553563573583593603613623633643653663673683693703713723733743753763773783793803813823833843853863873883893903913923933943953963973983994004014024034044054064074084094104114124134144154164174184194204214224234244254264274284294304314324334344354364374384394404414424434444454464474484494504514524534544554564574584594604614624634644654664674684694704714724734744754764774784794804814824834844854864874884894904914924934944954964974984995005015025035045055065075085095105115125135145155165175185195205215225235245255265275285295305315325335345355365375385395405415425435445455465475485495505515525535545555565575585595605615625635645655665675685695705715725735745755765775785795805815825835845855865875885895905915925935945955965975985996006016026036046056066076086096106116126136146156166176186196206216226236246256266276286296306316326336346356366376386396406416426436446456466476486496506516526536546556566576586596606616626636646656666676686696706716726736746756766776786796806816826836846856866876886896906916926936946956966976986997007017027037047057067077087097107117127137147157167177187197207217227237247257267277287297307317327337347357367377387397407417427437447457467477487497507517527537547557567577587597607617627637647657667677687697707717727737747757767777787797807817827837847857867877887897907917927937947957967977987998008018028038048058068078088098108118128138148158168178188198208218228238248258268278288298308318328338348358368378388398408418428438448458468478488498508518528538548558568578588598608618628638648658668678688698708718728738748758768778788798808818828838848858868878888898908918928938948958968978988999009019029039049059069079089099109119129139149159169179189199209219229239249259269279289299309319329339349359369379389399409419429439449459469479489499509519529539549559569579589599609619629639649659669679689699709719729739749759769779789799809819829839849859869879889899909919929939949959969979989991000100110021003100410051006100710081009101010111012101310141015101610171018101910201021102210231024102510261027102810291030103110321033103410351036103710381039104010411042104310441045104610471048104910501051105210531054105510561057105810591060106110621063106410651066106710681069107010711072107310741075107610771078107910801081108210831084108510861087108810891090109110921093109410951096109710981099110011011102110311041105110611071108110911101111111211131114111511161117111811191120112111221123112411251126112711281129113011311132113311341135113611371138113911401141114211431144114511461147114811491150115111521153115411551156115711581159116011611162116311641165116611671168116911701171117211731174117511761177117811791180118111821183118411851186118711881189119011911192119311941195119611971198119912001201120212031204120512061207120812091210121112121213121412151216121712181219122012211222122312241225122612271228122912301231123212331234123512361237123812391240124112421243124412451246124712481249125012511252125312541255125612571258 // ....................................................... template&lt;typename _Tp, typename _Alloc = std::allocator&lt;_Tp&gt; &gt; class vector : protected _Vector_base&lt;_Tp, _Alloc&gt; &#123; // ....................................................... typedef _Vector_base&lt;_Tp, _Alloc&gt; _Base; typedef typename _Base::_Tp_alloc_type _Tp_alloc_type; typedef __gnu_cxx::__alloc_traits&lt;_Tp_alloc_type&gt; _Alloc_traits; public: typedef _Tp value_type; typedef typename _Base::pointer pointer; typedef typename _Alloc_traits::const_pointer const_pointer; typedef typename _Alloc_traits::reference reference; typedef typename _Alloc_traits::const_reference const_reference; typedef __gnu_cxx::__normal_iterator&lt;pointer, vector&gt; iterator; typedef __gnu_cxx::__normal_iterator&lt;const_pointer, vector&gt; const_iterator; typedef std::reverse_iterator&lt;const_iterator&gt; const_reverse_iterator; typedef std::reverse_iterator&lt;iterator&gt; reverse_iterator; typedef size_t size_type; typedef ptrdiff_t difference_type; typedef _Alloc allocator_type; private: // C++11 // ....................................................... protected: using _Base::_M_allocate; using _Base::_M_deallocate; using _Base::_M_impl; using _Base::_M_get_Tp_allocator; public: // [23.2.4.1] construct/copy/destroy // (assign() and get_allocator() are also listed in this section) //无参构造#if __cplusplus &gt;= 201103L vector() = default;#else vector() &#123; &#125;#endif /** * @brief Creates a %vector with no elements. * @param __a An allocator object. */ explicit vector(const allocator_type&amp; __a) _GLIBCXX_NOEXCEPT : _Base(__a) &#123; &#125; //有参构造，vector(n, m) n个元素，每个元素的值是m#if __cplusplus &gt;= 201103L // C++11 // .......................................................#else /** * @brief Creates a %vector with copies of an exemplar element. * @param __n The number of elements to initially create. * @param __value An element to copy. * @param __a An allocator. */ explicit vector(size_type __n, const value_type&amp; __value = value_type(), const allocator_type&amp; __a = allocator_type()) : _Base(_S_check_init_len(__n, __a), __a) &#123; _M_fill_initialize(__n, __value); &#125;#endif //拷贝构造 /** * @brief %Vector copy constructor. * @param __x A %vector of identical element and allocator types. * * All the elements of @a __x are copied, but any unused capacity in * @a __x will not be copied * (i.e. capacity() == size() in the new %vector). * * The newly-created %vector uses a copy of the allocator object used * by @a __x (unless the allocator traits dictate a different object). */ vector(const vector&amp; __x) : _Base(__x.size(), _Alloc_traits::_S_select_on_copy(__x._M_get_Tp_allocator())) &#123; this-&gt;_M_impl._M_finish = std::__uninitialized_copy_a(__x.begin(), __x.end(), this-&gt;_M_impl._M_start, _M_get_Tp_allocator()); &#125;#if __cplusplus &gt;= 201103L // C++11 // .......................................................#endif //接收范围参数的构造函数 /** * @brief Builds a %vector from a range. * @param __first An input iterator. * @param __last An input iterator. * @param __a An allocator. * * Create a %vector consisting of copies of the elements from * [first,last). * * If the iterators are forward, bidirectional, or * random-access, then this will call the elements&#x27; copy * constructor N times (where N is distance(first,last)) and do * no memory reallocation. But if only input iterators are * used, then this will do at most 2N calls to the copy * constructor, and logN memory reallocations. */#if __cplusplus &gt;= 201103L // C++11 // .......................................................#else template&lt;typename _InputIterator&gt; vector(_InputIterator __first, _InputIterator __last, const allocator_type&amp; __a = allocator_type()) : _Base(__a) &#123; // Check whether it&#x27;s an integral type. If so, it&#x27;s not an iterator. typedef typename std::__is_integer&lt;_InputIterator&gt;::__type _Integral; _M_initialize_dispatch(__first, __last, _Integral()); &#125;#endif /** * The dtor only erases the elements, and note that if the * elements themselves are pointers, the pointed-to memory is * not touched in any way. Managing the pointer is the user&#x27;s * responsibility. */ //_Destroy仅擦除元素，并请注意，如果元素本身是指针，则不会以任何方式访问指向的内存 //管理指针是用户的责任 ~vector() _GLIBCXX_NOEXCEPT &#123; std::_Destroy(this-&gt;_M_impl._M_start, this-&gt;_M_impl._M_finish, _M_get_Tp_allocator()); _GLIBCXX_ASAN_ANNOTATE_BEFORE_DEALLOC; &#125; //运算符重载，= /** * @brief %Vector assignment operator. * @param __x A %vector of identical element and allocator types. * * All the elements of @a __x are copied, but any unused capacity in * @a __x will not be copied. * * Whether the allocator is copied depends on the allocator traits. */ vector&amp; operator=(const vector&amp; __x);#if __cplusplus &gt;= 201103L // C++11 // .......................................................#endif //assign函数，具体见下文 //给vector分配__n个元素，每个元素的值为__val void assign(size_type __n, const value_type&amp; __val) &#123; _M_fill_assign(__n, __val); &#125; //把模板类型的__first到__last范围的值复制给vector#if __cplusplus &gt;= 201103L // C++11 // .......................................................#else template&lt;typename _InputIterator&gt; void assign(_InputIterator __first, _InputIterator __last) &#123; // Check whether it&#x27;s an integral type. If so, it&#x27;s not an iterator. typedef typename std::__is_integer&lt;_InputIterator&gt;::__type _Integral; _M_assign_dispatch(__first, __last, _Integral()); &#125;#endif#if __cplusplus &gt;= 201103L // C++11 // .......................................................#endif /// Get a copy of the memory allocation object. using _Base::get_allocator; // iterators /** * Returns a read/write iterator that points to the first * element in the %vector. Iteration is done in ordinary * element order. */ iterator begin() _GLIBCXX_NOEXCEPT &#123; return iterator(this-&gt;_M_impl._M_start); &#125; /** * Returns a read-only (constant) iterator that points to the * first element in the %vector. Iteration is done in ordinary * element order. */ const_iterator begin() const _GLIBCXX_NOEXCEPT &#123; return const_iterator(this-&gt;_M_impl._M_start); &#125; /** * Returns a read/write iterator that points one past the last * element in the %vector. Iteration is done in ordinary * element order. */ iterator end() _GLIBCXX_NOEXCEPT &#123; return iterator(this-&gt;_M_impl._M_finish); &#125; /** * Returns a read-only (constant) iterator that points one past * the last element in the %vector. Iteration is done in * ordinary element order. */ const_iterator end() const _GLIBCXX_NOEXCEPT &#123; return const_iterator(this-&gt;_M_impl._M_finish); &#125; /** * Returns a read/write reverse iterator that points to the * last element in the %vector. Iteration is done in reverse * element order. */ reverse_iterator rbegin() _GLIBCXX_NOEXCEPT &#123; return reverse_iterator(end()); &#125; /** * Returns a read-only (constant) reverse iterator that points * to the last element in the %vector. Iteration is done in * reverse element order. */ const_reverse_iterator rbegin() const _GLIBCXX_NOEXCEPT &#123; return const_reverse_iterator(end()); &#125; /** * Returns a read/write reverse iterator that points to one * before the first element in the %vector. Iteration is done * in reverse element order. */ reverse_iterator rend() _GLIBCXX_NOEXCEPT &#123; return reverse_iterator(begin()); &#125; /** * Returns a read-only (constant) reverse iterator that points * to one before the first element in the %vector. Iteration * is done in reverse element order. */ const_reverse_iterator rend() const _GLIBCXX_NOEXCEPT &#123; return const_reverse_iterator(begin()); &#125;#if __cplusplus &gt;= 201103L /** * Returns a read-only (constant) iterator that points to the * first element in the %vector. Iteration is done in ordinary * element order. */ const_iterator cbegin() const noexcept &#123; return const_iterator(this-&gt;_M_impl._M_start); &#125; /** * Returns a read-only (constant) iterator that points one past * the last element in the %vector. Iteration is done in * ordinary element order. */ const_iterator cend() const noexcept &#123; return const_iterator(this-&gt;_M_impl._M_finish); &#125; /** * Returns a read-only (constant) reverse iterator that points * to the last element in the %vector. Iteration is done in * reverse element order. */ const_reverse_iterator crbegin() const noexcept &#123; return const_reverse_iterator(end()); &#125; /** * Returns a read-only (constant) reverse iterator that points * to one before the first element in the %vector. Iteration * is done in reverse element order. */ const_reverse_iterator crend() const noexcept &#123; return const_reverse_iterator(begin()); &#125;#endif // [23.2.4.2] capacity /** Returns the number of elements in the %vector. */ size_type size() const _GLIBCXX_NOEXCEPT &#123; return size_type(this-&gt;_M_impl._M_finish - this-&gt;_M_impl._M_start); &#125; /** Returns the size() of the largest possible %vector. */ size_type max_size() const _GLIBCXX_NOEXCEPT &#123; return _S_max_size(_M_get_Tp_allocator()); &#125;#if __cplusplus &gt;= 201103L /** * @brief Resizes the %vector to the specified number of elements. * @param __new_size Number of elements the %vector should contain. * * This function will %resize the %vector to the specified * number of elements. If the number is smaller than the * %vector&#x27;s current size the %vector is truncated, otherwise * default constructed elements are appended. */ void resize(size_type __new_size) &#123; if (__new_size &gt; size()) _M_default_append(__new_size - size()); else if (__new_size &lt; size()) _M_erase_at_end(this-&gt;_M_impl._M_start + __new_size); &#125; /** * @brief Resizes the %vector to the specified number of elements. * @param __new_size Number of elements the %vector should contain. * @param __x Data with which new elements should be populated. * * This function will %resize the %vector to the specified * number of elements. If the number is smaller than the * %vector&#x27;s current size the %vector is truncated, otherwise * the %vector is extended and new elements are populated with * given data. */ void resize(size_type __new_size, const value_type&amp; __x) &#123; if (__new_size &gt; size()) _M_fill_insert(end(), __new_size - size(), __x); else if (__new_size &lt; size()) _M_erase_at_end(this-&gt;_M_impl._M_start + __new_size); &#125;#else /** * @brief Resizes the %vector to the specified number of elements. * @param __new_size Number of elements the %vector should contain. * @param __x Data with which new elements should be populated. * * This function will %resize the %vector to the specified * number of elements. If the number is smaller than the * %vector&#x27;s current size the %vector is truncated, otherwise * the %vector is extended and new elements are populated with * given data. */ void resize(size_type __new_size, value_type __x = value_type()) &#123; if (__new_size &gt; size()) _M_fill_insert(end(), __new_size - size(), __x); else if (__new_size &lt; size()) _M_erase_at_end(this-&gt;_M_impl._M_start + __new_size); &#125;#endif#if __cplusplus &gt;= 201103L /** A non-binding request to reduce capacity() to size(). */ void shrink_to_fit() &#123; _M_shrink_to_fit(); &#125;#endif /** * Returns the total number of elements that the %vector can * hold before needing to allocate more memory. */ size_type capacity() const _GLIBCXX_NOEXCEPT &#123; return size_type(this-&gt;_M_impl._M_end_of_storage - this-&gt;_M_impl._M_start); &#125; /** * Returns true if the %vector is empty. (Thus begin() would * equal end().) */ _GLIBCXX_NODISCARD bool empty() const _GLIBCXX_NOEXCEPT &#123; return begin() == end(); &#125; /** * @brief Attempt to preallocate enough memory for specified number of * elements. * @param __n Number of elements required. * @throw std::length_error If @a n exceeds @c max_size(). * * This function attempts to reserve enough memory for the * %vector to hold the specified number of elements. If the * number requested is more than max_size(), length_error is * thrown. * * The advantage of this function is that if optimal code is a * necessity and the user can determine the number of elements * that will be required, the user can reserve the memory in * %advance, and thus prevent a possible reallocation of memory * and copying of %vector data. */ void reserve(size_type __n); // element access /** * @brief Subscript access to the data contained in the %vector. * @param __n The index of the element for which data should be * accessed. * @return Read/write reference to data. * * This operator allows for easy, array-style, data access. * Note that data access with this operator is unchecked and * out_of_range lookups are not defined. (For checked lookups * see at().) */ reference operator[](size_type __n) _GLIBCXX_NOEXCEPT &#123; __glibcxx_requires_subscript(__n); return *(this-&gt;_M_impl._M_start + __n); &#125; /** * @brief Subscript access to the data contained in the %vector. * @param __n The index of the element for which data should be * accessed. * @return Read-only (constant) reference to data. * * This operator allows for easy, array-style, data access. * Note that data access with this operator is unchecked and * out_of_range lookups are not defined. (For checked lookups * see at().) */ const_reference operator[](size_type __n) const _GLIBCXX_NOEXCEPT &#123; __glibcxx_requires_subscript(__n); return *(this-&gt;_M_impl._M_start + __n); &#125; protected: /// Safety check used only from at(). void _M_range_check(size_type __n) const &#123; if (__n &gt;= this-&gt;size()) __throw_out_of_range_fmt(__N(&quot;vector::_M_range_check: __n &quot; &quot;(which is %zu) &gt;= this-&gt;size() &quot; &quot;(which is %zu)&quot;), __n, this-&gt;size()); &#125; public: /** * @brief Provides access to the data contained in the %vector. * @param __n The index of the element for which data should be * accessed. * @return Read/write reference to data. * @throw std::out_of_range If @a __n is an invalid index. * * This function provides for safer data access. The parameter * is first checked that it is in the range of the vector. The * function throws out_of_range if the check fails. */ reference at(size_type __n) &#123; _M_range_check(__n); return (*this)[__n]; &#125; /** * @brief Provides access to the data contained in the %vector. * @param __n The index of the element for which data should be * accessed. * @return Read-only (constant) reference to data. * @throw std::out_of_range If @a __n is an invalid index. * * This function provides for safer data access. The parameter * is first checked that it is in the range of the vector. The * function throws out_of_range if the check fails. */ const_reference at(size_type __n) const &#123; _M_range_check(__n); return (*this)[__n]; &#125; /** * Returns a read/write reference to the data at the first * element of the %vector. */ reference front() _GLIBCXX_NOEXCEPT &#123; __glibcxx_requires_nonempty(); return *begin(); &#125; /** * Returns a read-only (constant) reference to the data at the first * element of the %vector. */ const_reference front() const _GLIBCXX_NOEXCEPT &#123; __glibcxx_requires_nonempty(); return *begin(); &#125; /** * Returns a read/write reference to the data at the last * element of the %vector. */ reference back() _GLIBCXX_NOEXCEPT &#123; __glibcxx_requires_nonempty(); return *(end() - 1); &#125; /** * Returns a read-only (constant) reference to the data at the * last element of the %vector. */ const_reference back() const _GLIBCXX_NOEXCEPT &#123; __glibcxx_requires_nonempty(); return *(end() - 1); &#125; // _GLIBCXX_RESOLVE_LIB_DEFECTS // DR 464. Suggestion for new member functions in standard containers. // data access /** * Returns a pointer such that [data(), data() + size()) is a valid * range. For a non-empty %vector, data() == &amp;front(). */ _Tp* data() _GLIBCXX_NOEXCEPT &#123; return _M_data_ptr(this-&gt;_M_impl._M_start); &#125; const _Tp* data() const _GLIBCXX_NOEXCEPT &#123; return _M_data_ptr(this-&gt;_M_impl._M_start); &#125; // [23.2.4.3] modifiers /** * @brief Add data to the end of the %vector. * @param __x Data to be added. * * This is a typical stack operation. The function creates an * element at the end of the %vector and assigns the given data * to it. Due to the nature of a %vector this operation can be * done in constant time if the %vector has preallocated space * available. */ void push_back(const value_type&amp; __x) &#123; if (this-&gt;_M_impl._M_finish != this-&gt;_M_impl._M_end_of_storage) &#123; _GLIBCXX_ASAN_ANNOTATE_GROW(1); _Alloc_traits::construct(this-&gt;_M_impl, this-&gt;_M_impl._M_finish, __x); ++this-&gt;_M_impl._M_finish; _GLIBCXX_ASAN_ANNOTATE_GREW(1); &#125; else _M_realloc_insert(end(), __x); &#125;#if __cplusplus &gt;= 201103L void push_back(value_type&amp;&amp; __x) &#123; emplace_back(std::move(__x)); &#125; template&lt;typename... _Args&gt;#if __cplusplus &gt; 201402L reference#else void#endif emplace_back(_Args&amp;&amp;... __args);#endif /** * @brief Removes last element. * * This is a typical stack operation. It shrinks the %vector by one. * * Note that no data is returned, and if the last element&#x27;s * data is needed, it should be retrieved before pop_back() is * called. */ void pop_back() _GLIBCXX_NOEXCEPT &#123; __glibcxx_requires_nonempty(); --this-&gt;_M_impl._M_finish; _Alloc_traits::destroy(this-&gt;_M_impl, this-&gt;_M_impl._M_finish); _GLIBCXX_ASAN_ANNOTATE_SHRINK(1); &#125;#if __cplusplus &gt;= 201103L /** * @brief Inserts an object in %vector before specified iterator. * @param __position A const_iterator into the %vector. * @param __args Arguments. * @return An iterator that points to the inserted data. * * This function will insert an object of type T constructed * with T(std::forward&lt;Args&gt;(args)...) before the specified location. * Note that this kind of operation could be expensive for a %vector * and if it is frequently used the user should consider using * std::list. */ template&lt;typename... _Args&gt; iterator emplace(const_iterator __position, _Args&amp;&amp;... __args) &#123; return _M_emplace_aux(__position, std::forward&lt;_Args&gt;(__args)...); &#125; /** * @brief Inserts given value into %vector before specified iterator. * @param __position A const_iterator into the %vector. * @param __x Data to be inserted. * @return An iterator that points to the inserted data. * * This function will insert a copy of the given value before * the specified location. Note that this kind of operation * could be expensive for a %vector and if it is frequently * used the user should consider using std::list. */ iterator insert(const_iterator __position, const value_type&amp; __x);#else /** * @brief Inserts given value into %vector before specified iterator. * @param __position An iterator into the %vector. * @param __x Data to be inserted. * @return An iterator that points to the inserted data. * * This function will insert a copy of the given value before * the specified location. Note that this kind of operation * could be expensive for a %vector and if it is frequently * used the user should consider using std::list. */ iterator insert(iterator __position, const value_type&amp; __x);#endif#if __cplusplus &gt;= 201103L /** * @brief Inserts given rvalue into %vector before specified iterator. * @param __position A const_iterator into the %vector. * @param __x Data to be inserted. * @return An iterator that points to the inserted data. * * This function will insert a copy of the given rvalue before * the specified location. Note that this kind of operation * could be expensive for a %vector and if it is frequently * used the user should consider using std::list. */ iterator insert(const_iterator __position, value_type&amp;&amp; __x) &#123; return _M_insert_rval(__position, std::move(__x)); &#125; /** * @brief Inserts an initializer_list into the %vector. * @param __position An iterator into the %vector. * @param __l An initializer_list. * * This function will insert copies of the data in the * initializer_list @a l into the %vector before the location * specified by @a position. * * Note that this kind of operation could be expensive for a * %vector and if it is frequently used the user should * consider using std::list. */ iterator insert(const_iterator __position, initializer_list&lt;value_type&gt; __l) &#123; auto __offset = __position - cbegin(); _M_range_insert(begin() + __offset, __l.begin(), __l.end(), std::random_access_iterator_tag()); return begin() + __offset; &#125;#endif#if __cplusplus &gt;= 201103L /** * @brief Inserts a number of copies of given data into the %vector. * @param __position A const_iterator into the %vector. * @param __n Number of elements to be inserted. * @param __x Data to be inserted. * @return An iterator that points to the inserted data. * * This function will insert a specified number of copies of * the given data before the location specified by @a position. * * Note that this kind of operation could be expensive for a * %vector and if it is frequently used the user should * consider using std::list. */ iterator insert(const_iterator __position, size_type __n, const value_type&amp; __x) &#123; difference_type __offset = __position - cbegin(); _M_fill_insert(begin() + __offset, __n, __x); return begin() + __offset; &#125;#else /** * @brief Inserts a number of copies of given data into the %vector. * @param __position An iterator into the %vector. * @param __n Number of elements to be inserted. * @param __x Data to be inserted. * * This function will insert a specified number of copies of * the given data before the location specified by @a position. * * Note that this kind of operation could be expensive for a * %vector and if it is frequently used the user should * consider using std::list. */ void insert(iterator __position, size_type __n, const value_type&amp; __x) &#123; _M_fill_insert(__position, __n, __x); &#125;#endif#if __cplusplus &gt;= 201103L /** * @brief Inserts a range into the %vector. * @param __position A const_iterator into the %vector. * @param __first An input iterator. * @param __last An input iterator. * @return An iterator that points to the inserted data. * * This function will insert copies of the data in the range * [__first,__last) into the %vector before the location specified * by @a pos. * * Note that this kind of operation could be expensive for a * %vector and if it is frequently used the user should * consider using std::list. */ template&lt;typename _InputIterator, typename = std::_RequireInputIter&lt;_InputIterator&gt;&gt; iterator insert(const_iterator __position, _InputIterator __first, _InputIterator __last) &#123; difference_type __offset = __position - cbegin(); _M_insert_dispatch(begin() + __offset, __first, __last, __false_type()); return begin() + __offset; &#125;#else /** * @brief Inserts a range into the %vector. * @param __position An iterator into the %vector. * @param __first An input iterator. * @param __last An input iterator. * * This function will insert copies of the data in the range * [__first,__last) into the %vector before the location specified * by @a pos. * * Note that this kind of operation could be expensive for a * %vector and if it is frequently used the user should * consider using std::list. */ template&lt;typename _InputIterator&gt; void insert(iterator __position, _InputIterator __first, _InputIterator __last) &#123; // Check whether it&#x27;s an integral type. If so, it&#x27;s not an iterator. typedef typename std::__is_integer&lt;_InputIterator&gt;::__type _Integral; _M_insert_dispatch(__position, __first, __last, _Integral()); &#125;#endif /** * @brief Remove element at given position. * @param __position Iterator pointing to element to be erased. * @return An iterator pointing to the next element (or end()). * * This function will erase the element at the given position and thus * shorten the %vector by one. * * Note This operation could be expensive and if it is * frequently used the user should consider using std::list. * The user is also cautioned that this function only erases * the element, and that if the element is itself a pointer, * the pointed-to memory is not touched in any way. Managing * the pointer is the user&#x27;s responsibility. */ iterator#if __cplusplus &gt;= 201103L erase(const_iterator __position) &#123; return _M_erase(begin() + (__position - cbegin())); &#125;#else erase(iterator __position) &#123; return _M_erase(__position); &#125;#endif /** * @brief Remove a range of elements. * @param __first Iterator pointing to the first element to be erased. * @param __last Iterator pointing to one past the last element to be * erased. * @return An iterator pointing to the element pointed to by @a __last * prior to erasing (or end()). * * This function will erase the elements in the range * [__first,__last) and shorten the %vector accordingly. * * Note This operation could be expensive and if it is * frequently used the user should consider using std::list. * The user is also cautioned that this function only erases * the elements, and that if the elements themselves are * pointers, the pointed-to memory is not touched in any way. * Managing the pointer is the user&#x27;s responsibility. */ iterator#if __cplusplus &gt;= 201103L erase(const_iterator __first, const_iterator __last) &#123; const auto __beg = begin(); const auto __cbeg = cbegin(); return _M_erase(__beg + (__first - __cbeg), __beg + (__last - __cbeg)); &#125;#else erase(iterator __first, iterator __last) &#123; return _M_erase(__first, __last); &#125;#endif /** * @brief Swaps data with another %vector. * @param __x A %vector of the same element and allocator types. * * This exchanges the elements between two vectors in constant time. * (Three pointers, so it should be quite fast.) * Note that the global std::swap() function is specialized such that * std::swap(v1,v2) will feed to this function. * * Whether the allocators are swapped depends on the allocator traits. */ void swap(vector&amp; __x) _GLIBCXX_NOEXCEPT &#123;#if __cplusplus &gt;= 201103L __glibcxx_assert(_Alloc_traits::propagate_on_container_swap::value || _M_get_Tp_allocator() == __x._M_get_Tp_allocator());#endif this-&gt;_M_impl._M_swap_data(__x._M_impl); _Alloc_traits::_S_on_swap(_M_get_Tp_allocator(), __x._M_get_Tp_allocator()); &#125; /** * Erases all the elements. Note that this function only erases the * elements, and that if the elements themselves are pointers, the * pointed-to memory is not touched in any way. Managing the pointer is * the user&#x27;s responsibility. */ void clear() _GLIBCXX_NOEXCEPT &#123; _M_erase_at_end(this-&gt;_M_impl._M_start); &#125; protected: /** * Memory expansion handler. Uses the member allocation function to * obtain @a n bytes of memory, and then copies [first,last) into it. */ template&lt;typename _ForwardIterator&gt; pointer _M_allocate_and_copy(size_type __n, _ForwardIterator __first, _ForwardIterator __last) &#123; pointer __result = this-&gt;_M_allocate(__n); __try &#123; std::__uninitialized_copy_a(__first, __last, __result, _M_get_Tp_allocator()); return __result; &#125; __catch(...) &#123; _M_deallocate(__result, __n); __throw_exception_again; &#125; &#125; // Internal constructor functions follow. // Called by the range constructor to implement [23.1.1]/9#if __cplusplus &lt; 201103L // _GLIBCXX_RESOLVE_LIB_DEFECTS // 438. Ambiguity in the &quot;do the right thing&quot; clause template&lt;typename _Integer&gt; void _M_initialize_dispatch(_Integer __n, _Integer __value, __true_type) &#123; this-&gt;_M_impl._M_start = _M_allocate(_S_check_init_len( static_cast&lt;size_type&gt;(__n), _M_get_Tp_allocator())); this-&gt;_M_impl._M_end_of_storage = this-&gt;_M_impl._M_start + static_cast&lt;size_type&gt;(__n); _M_fill_initialize(static_cast&lt;size_type&gt;(__n), __value); &#125; // Called by the range constructor to implement [23.1.1]/9 template&lt;typename _InputIterator&gt; void _M_initialize_dispatch(_InputIterator __first, _InputIterator __last, __false_type) &#123; _M_range_initialize(__first, __last, std::__iterator_category(__first)); &#125;#endif // Called by the second initialize_dispatch above template&lt;typename _InputIterator&gt; void _M_range_initialize(_InputIterator __first, _InputIterator __last, std::input_iterator_tag) &#123; __try &#123; for (; __first != __last; ++__first)#if __cplusplus &gt;= 201103L emplace_back(*__first);#else push_back(*__first);#endif &#125; __catch(...) &#123; clear(); __throw_exception_again; &#125; &#125; // Called by the second initialize_dispatch above template&lt;typename _ForwardIterator&gt; void _M_range_initialize(_ForwardIterator __first, _ForwardIterator __last, std::forward_iterator_tag) &#123; const size_type __n = std::distance(__first, __last); this-&gt;_M_impl._M_start = this-&gt;_M_allocate(_S_check_init_len(__n, _M_get_Tp_allocator())); this-&gt;_M_impl._M_end_of_storage = this-&gt;_M_impl._M_start + __n; this-&gt;_M_impl._M_finish = std::__uninitialized_copy_a(__first, __last, this-&gt;_M_impl._M_start, _M_get_Tp_allocator()); &#125; // Called by the first initialize_dispatch above and by the // vector(n,value,a) constructor. void _M_fill_initialize(size_type __n, const value_type&amp; __value) &#123; this-&gt;_M_impl._M_finish = std::__uninitialized_fill_n_a(this-&gt;_M_impl._M_start, __n, __value, _M_get_Tp_allocator()); &#125;#if __cplusplus &gt;= 201103L // Called by the vector(n) constructor. void _M_default_initialize(size_type __n) &#123; this-&gt;_M_impl._M_finish = std::__uninitialized_default_n_a(this-&gt;_M_impl._M_start, __n, _M_get_Tp_allocator()); &#125;#endif // Internal assign functions follow. The *_aux functions do the actual // assignment work for the range versions. // Called by the range assign to implement [23.1.1]/9 // _GLIBCXX_RESOLVE_LIB_DEFECTS // 438. Ambiguity in the &quot;do the right thing&quot; clause template&lt;typename _Integer&gt; void _M_assign_dispatch(_Integer __n, _Integer __val, __true_type) &#123; _M_fill_assign(__n, __val); &#125; // Called by the range assign to implement [23.1.1]/9 template&lt;typename _InputIterator&gt; void _M_assign_dispatch(_InputIterator __first, _InputIterator __last, __false_type) &#123; _M_assign_aux(__first, __last, std::__iterator_category(__first)); &#125; // Called by the second assign_dispatch above template&lt;typename _InputIterator&gt; void _M_assign_aux(_InputIterator __first, _InputIterator __last, std::input_iterator_tag); // Called by the second assign_dispatch above template&lt;typename _ForwardIterator&gt; void _M_assign_aux(_ForwardIterator __first, _ForwardIterator __last, std::forward_iterator_tag); // Called by assign(n,t), and the range assign when it turns out // to be the same thing. void _M_fill_assign(size_type __n, const value_type&amp; __val); // Internal insert functions follow. // Called by the range insert to implement [23.1.1]/9 // _GLIBCXX_RESOLVE_LIB_DEFECTS // 438. Ambiguity in the &quot;do the right thing&quot; clause template&lt;typename _Integer&gt; void _M_insert_dispatch(iterator __pos, _Integer __n, _Integer __val, __true_type) &#123; _M_fill_insert(__pos, __n, __val); &#125; // Called by the range insert to implement [23.1.1]/9 template&lt;typename _InputIterator&gt; void _M_insert_dispatch(iterator __pos, _InputIterator __first, _InputIterator __last, __false_type) &#123; _M_range_insert(__pos, __first, __last, std::__iterator_category(__first)); &#125; // Called by the second insert_dispatch above template&lt;typename _InputIterator&gt; void _M_range_insert(iterator __pos, _InputIterator __first, _InputIterator __last, std::input_iterator_tag); // Called by the second insert_dispatch above template&lt;typename _ForwardIterator&gt; void _M_range_insert(iterator __pos, _ForwardIterator __first, _ForwardIterator __last, std::forward_iterator_tag); // Called by insert(p,n,x), and the range insert when it turns out to be // the same thing. void _M_fill_insert(iterator __pos, size_type __n, const value_type&amp; __x);#if __cplusplus &gt;= 201103L // Called by resize(n). void _M_default_append(size_type __n); bool _M_shrink_to_fit();#endif#if __cplusplus &lt; 201103L // Called by insert(p,x) void _M_insert_aux(iterator __position, const value_type&amp; __x); void _M_realloc_insert(iterator __position, const value_type&amp; __x);#else // A value_type object constructed with _Alloc_traits::construct() // and destroyed with _Alloc_traits::destroy(). struct _Temporary_value &#123; template&lt;typename... _Args&gt; explicit _Temporary_value(vector* __vec, _Args&amp;&amp;... __args) : _M_this(__vec) &#123; _Alloc_traits::construct(_M_this-&gt;_M_impl, _M_ptr(), std::forward&lt;_Args&gt;(__args)...); &#125; ~_Temporary_value() &#123; _Alloc_traits::destroy(_M_this-&gt;_M_impl, _M_ptr()); &#125; value_type&amp; _M_val() &#123; return *_M_ptr(); &#125; private: _Tp* _M_ptr() &#123; return reinterpret_cast&lt;_Tp*&gt;(&amp;__buf); &#125; vector* _M_this; typename aligned_storage&lt;sizeof(_Tp), alignof(_Tp)&gt;::type __buf; &#125;; // Called by insert(p,x) and other functions when insertion needs to // reallocate or move existing elements. _Arg is either _Tp&amp; or _Tp. template&lt;typename _Arg&gt; void _M_insert_aux(iterator __position, _Arg&amp;&amp; __arg); template&lt;typename... _Args&gt; void _M_realloc_insert(iterator __position, _Args&amp;&amp;... __args); // Either move-construct at the end, or forward to _M_insert_aux. iterator _M_insert_rval(const_iterator __position, value_type&amp;&amp; __v); // Try to emplace at the end, otherwise forward to _M_insert_aux. template&lt;typename... _Args&gt; iterator _M_emplace_aux(const_iterator __position, _Args&amp;&amp;... __args); // Emplacing an rvalue of the correct type can use _M_insert_rval. iterator _M_emplace_aux(const_iterator __position, value_type&amp;&amp; __v) &#123; return _M_insert_rval(__position, std::move(__v)); &#125;#endif // Called by _M_fill_insert, _M_insert_aux etc. size_type _M_check_len(size_type __n, const char* __s) const &#123; if (max_size() - size() &lt; __n) __throw_length_error(__N(__s)); const size_type __len = size() + (std::max)(size(), __n); return (__len &lt; size() || __len &gt; max_size()) ? max_size() : __len; &#125; // Called by constructors to check initial size. static size_type _S_check_init_len(size_type __n, const allocator_type&amp; __a) &#123; if (__n &gt; _S_max_size(_Tp_alloc_type(__a))) __throw_length_error( __N(&quot;cannot create std::vector larger than max_size()&quot;)); return __n; &#125; static size_type _S_max_size(const _Tp_alloc_type&amp; __a) _GLIBCXX_NOEXCEPT &#123; // std::distance(begin(), end()) cannot be greater than PTRDIFF_MAX, // and realistically we can&#x27;t store more than PTRDIFF_MAX/sizeof(T) // (even if std::allocator_traits::max_size says we can). const size_t __diffmax = __gnu_cxx::__numeric_traits&lt;ptrdiff_t&gt;::__max / sizeof(_Tp); const size_t __allocmax = _Alloc_traits::max_size(__a); return (std::min)(__diffmax, __allocmax); &#125; // Internal erase functions follow. // Called by erase(q1,q2), clear(), resize(), _M_fill_assign, // _M_assign_aux. void _M_erase_at_end(pointer __pos) _GLIBCXX_NOEXCEPT &#123; if (size_type __n = this-&gt;_M_impl._M_finish - __pos) &#123; std::_Destroy(__pos, this-&gt;_M_impl._M_finish, _M_get_Tp_allocator()); this-&gt;_M_impl._M_finish = __pos; _GLIBCXX_ASAN_ANNOTATE_SHRINK(__n); &#125; &#125; iterator _M_erase(iterator __position); iterator _M_erase(iterator __first, iterator __last);#if __cplusplus &gt;= 201103L private: // Constant-time move assignment when source object&#x27;s memory can be // moved, either because the source&#x27;s allocator will move too // or because the allocators are equal. void _M_move_assign(vector&amp;&amp; __x, true_type) noexcept &#123; vector __tmp(get_allocator()); this-&gt;_M_impl._M_swap_data(__x._M_impl); __tmp._M_impl._M_swap_data(__x._M_impl); std::__alloc_on_move(_M_get_Tp_allocator(), __x._M_get_Tp_allocator()); &#125; // Do move assignment when it might not be possible to move source // object&#x27;s memory, resulting in a linear-time operation. void _M_move_assign(vector&amp;&amp; __x, false_type) &#123; if (__x._M_get_Tp_allocator() == this-&gt;_M_get_Tp_allocator()) _M_move_assign(std::move(__x), true_type()); else &#123; // The rvalue&#x27;s allocator cannot be moved and is not equal, // so we need to individually move each element. this-&gt;assign(std::__make_move_if_noexcept_iterator(__x.begin()), std::__make_move_if_noexcept_iterator(__x.end())); __x.clear(); &#125; &#125;#endif template&lt;typename _Up&gt; _Up* _M_data_ptr(_Up* __ptr) const _GLIBCXX_NOEXCEPT &#123; return __ptr; &#125;#if __cplusplus &gt;= 201103L template&lt;typename _Ptr&gt; typename std::pointer_traits&lt;_Ptr&gt;::element_type* _M_data_ptr(_Ptr __ptr) const &#123; return empty() ? nullptr : std::__to_address(__ptr); &#125;#else template&lt;typename _Up&gt; _Up* _M_data_ptr(_Up* __ptr) _GLIBCXX_NOEXCEPT &#123; return __ptr; &#125; template&lt;typename _Ptr&gt; value_type* _M_data_ptr(_Ptr __ptr) &#123; return empty() ? (value_type*)0 : __ptr.operator-&gt;(); &#125; template&lt;typename _Ptr&gt; const value_type* _M_data_ptr(_Ptr __ptr) const &#123; return empty() ? (const value_type*)0 : __ptr.operator-&gt;(); &#125;#endif &#125; assigninput: 123456789101112131415161718192021222324252627282930313233343536373839404142#include &lt;iostream&gt;#include &lt;vector&gt;using namespace std;void func_print(std::vector&lt;int&gt; &amp;ovec)&#123; std::vector&lt;int&gt;::iterator it = ovec.begin(); for(it; it != ovec.end(); it++) &#123; cout &lt;&lt; &quot; &quot; &lt;&lt; *it ; &#125; cout &lt;&lt; endl; return ;&#125;int main ()&#123; std::vector&lt;int&gt; first; std::vector&lt;int&gt; second; std::vector&lt;int&gt; third; first.assign (7,100); // 7 ints with a value of 100 std::vector&lt;int&gt;::iterator it; it=first.begin()+1; second.assign (it,first.end()-1); // the 5 central values of first int myints[] = &#123;1776,7,4&#125;; third.assign (myints,myints+3); // assigning from array. std::cout &lt;&lt; &quot;Size of first: &quot; &lt;&lt; int (first.size()) &lt;&lt; &#x27;\\n&#x27;; func_print(first); std::cout &lt;&lt; &quot;Size of second: &quot; &lt;&lt; int (second.size()) &lt;&lt; &#x27;\\n&#x27;; func_print(second); std::cout &lt;&lt; &quot;Size of third: &quot; &lt;&lt; int (third.size()) &lt;&lt; &#x27;\\n&#x27;; func_print(third); return 0;&#125; output: Size of first: 7 100 100 100 100 100 100 100 Size of second: 5 100 100 100 100 100 Size of third: 3 1776 7 4 Process returned 0 (0x0) execution time : 0.015 s Press any key to continue. 总结 assgin有2个实现： void assign (InputIterator first, InputIterator last); void assign (size_type n, const value_type&amp; val); 带范围的assign的最后一个参数是不会被复制的，如first = it, last = it + 5, 则一共复制5个值 it, it+1, it+2, it+3, it+4 end()函数是vector最后一个元素的后一个元素，一般值为0 cout打印iterator的地址： &amp;*it push_bask() void push_back (const value_type&amp; val); Adds a new element at the end of the vector, after its current last element. The content of val is copied (or moved) to the new element. This effectively increases the container size by one, which causes an automatic reallocation of the allocated storage space if -and only if- the new vector size surpasses the current vector capacity. void push_back(const value_type&amp; __x) &#123; if (this-&gt;_M_impl._M_finish != this-&gt;_M_impl._M_end_of_storage) &#123; _GLIBCXX_ASAN_ANNOTATE_GROW(1); _Alloc_traits::construct(this-&gt;_M_impl, this-&gt;_M_impl._M_finish, __x); ++this-&gt;_M_impl._M_finish; _GLIBCXX_ASAN_ANNOTATE_GREW(1); &#125; else _M_realloc_insert(end(), __x); &#125; 扩容实现见下文空间配置实现 pop_back()void pop_back（）; Removes the last element in the vector, effectively reducing the container size by one. This destroys the removed element. void pop_back() _GLIBCXX_NOEXCEPT &#123; __glibcxx_requires_nonempty(); --this-&gt;_M_impl._M_finish; _Alloc_traits::destroy(this-&gt;_M_impl, this-&gt;_M_impl._M_finish); _GLIBCXX_ASAN_ANNOTATE_SHRINK(1); &#125; 从最后删除一个元素，这并不会导致vector的总容量变化 size()size_type size() const; Returns the number of elements in the vector. This is the number of actual objects held in the vector, which is not necessarily equal to its storage capacity. size_type size() const _GLIBCXX_NOEXCEPT &#123; return size_type(this-&gt;_M_impl._M_finish - this-&gt;_M_impl._M_start); &#125; begin()iterator begin(); const_iterator begin() const; Returns an iterator pointing to the first element in the vector. Notice that, unlike member vector::front, which returns a reference to the first element, this function returns a random access iterator pointing to it. If the container is empty, the returned iterator value shall not be dereferenced. iterator begin() _GLIBCXX_NOEXCEPT &#123; return iterator(this-&gt;_M_impl._M_start); &#125; const_iterator begin() const _GLIBCXX_NOEXCEPT &#123; return const_iterator(this-&gt;_M_impl._M_start); &#125; front()reference front(); const_reference front() const; Access first elementReturns a reference to the first element in the vector. Unlike member vector::begin, which returns an iterator to this same element, this function returns a direct reference. Calling this function on an empty container causes undefined behavior. reference front() _GLIBCXX_NOEXCEPT &#123; __glibcxx_requires_nonempty(); return *begin(); &#125; const_reference front() const _GLIBCXX_NOEXCEPT &#123; __glibcxx_requires_nonempty(); return *begin(); &#125; front返回的是*begin(),是引用 back()reference back(); const_reference back() const; Returns a reference to the last element in the vector. reference back() _GLIBCXX_NOEXCEPT &#123; __glibcxx_requires_nonempty(); return *(end() - 1); &#125; const_reference back() const _GLIBCXX_NOEXCEPT &#123; __glibcxx_requires_nonempty(); return *(end() - 1); back返回最后一个值，返回值是reference end返回最后一个元素的下一个元素，是iterator end()iterator end(); const_iterator end() const; Returns an iterator referring to the past-the-end element in the vector container. iterator end() _GLIBCXX_NOEXCEPT &#123; return iterator(this-&gt;_M_impl._M_finish); &#125; const_iterator end() const _GLIBCXX_NOEXCEPT &#123; return const_iterator(this-&gt;_M_impl._M_finish); &#125; rbegin()const_iterator cbegin() const noexcept; Return const_iterator to beginning reverse_iterator rbegin() _GLIBCXX_NOEXCEPT &#123; return reverse_iterator(end()); &#125; const_reverse_iterator rbegin() const _GLIBCXX_NOEXCEPT &#123; return const_reverse_iterator(end()); &#125; rend()TODO 空间配置原则 template&lt;typename _Tp, typename _Alloc = std::allocator&lt;_Tp&gt; &gt; class vector : protected _Vector_base&lt;_Tp, _Alloc&gt; &#123; ... &#125; template&lt;typename _Tp, typename _Alloc&gt; struct _Vector_base &#123; struct _Vector_impl_data &#123; pointer _M_start; //表示目前使用空间的头 pointer _M_finish; //表示目前使用空间的尾 pointer _M_end_of_storage; //表示目前可用空间的尾 ... &#125; &#125; input 123456789101112131415161718192021222324252627282930313233343536#include &lt;iostream&gt;#include &lt;vector&gt;using namespace std;int main()&#123; std::vector&lt;int&gt; vec ; vec.push_back(8); vec.push_back(6); vec.push_back(7); vec.end();&#125;/* stl_vector.h gcc 4.8.5 c++ 98900 void901 push_back(const value_type&amp; __x)902 &#123;903 if (this-&gt;_M_impl._M_finish != this-&gt;_M_impl._M_end_of_storage)904 &#123;905 _Alloc_traits::construct(this-&gt;_M_impl, this-&gt;_M_impl._M_finish,906 __x);907 ++this-&gt;_M_impl._M_finish;908 &#125;909 else910 #if __cplusplus &gt;= 201103L911 _M_emplace_back_aux(__x);912 #else913 _M_insert_aux(end(), __x);914 #endif915 &#125;*/ output Breakpoint 5, std::vector&lt;int, std::allocator&lt;int&gt; &gt;::push_back (this=0x7fffffffe220, __x=@0x7fffffffe244: 8) at /usr/include/c++/4.8.2/bits/stl_vector.h:915 915 &#125; (gdb) p (this-&gt;_M_impl._M_start) $17 = (std::_Vector_base&lt;int, std::allocator&lt;int&gt; &gt;::pointer) 0x604010 (gdb) p (this-&gt;_M_impl._M_finish) $18 = (std::_Vector_base&lt;int, std::allocator&lt;int&gt; &gt;::pointer) 0x604014 (gdb) p (this-&gt;_M_impl._M_end_of_storage) $19 = (std::_Vector_base&lt;int, std::allocator&lt;int&gt; &gt;::pointer) 0x604014 (gdb) p (this-&gt;_M_impl._M_end_of_storage-this-&gt;_M_impl._M_start) $20 = 1 (gdb) p *(this-&gt;_M_impl._M_start) $21 = 8 (gdb) c Continuing. Breakpoint 4, std::vector&lt;int, std::allocator&lt;int&gt; &gt;::push_back (this=0x7fffffffe220, __x=@0x7fffffffe248: 6) at /usr/include/c++/4.8.2/bits/stl_vector.h:903 903 if (this-&gt;_M_impl._M_finish != this-&gt;_M_impl._M_end_of_storage) (gdb) c Continuing. Breakpoint 5, std::vector&lt;int, std::allocator&lt;int&gt; &gt;::push_back (this=0x7fffffffe220, __x=@0x7fffffffe248: 6) at /usr/include/c++/4.8.2/bits/stl_vector.h:915 915 &#125; (gdb) p (this-&gt;_M_impl._M_start) $22 = (std::_Vector_base&lt;int, std::allocator&lt;int&gt; &gt;::pointer) 0x604030 (gdb) p (this-&gt;_M_impl._M_finish) $23 = (std::_Vector_base&lt;int, std::allocator&lt;int&gt; &gt;::pointer) 0x604038 (gdb) p (this-&gt;_M_impl._M_end_of_storage) $24 = (std::_Vector_base&lt;int, std::allocator&lt;int&gt; &gt;::pointer) 0x604038 (gdb) p (this-&gt;_M_impl._M_end_of_storage-this-&gt;_M_impl._M_start) $25 = 2 (gdb) p *(this-&gt;_M_impl._M_start) $26 = 8 (gdb) p *(this-&gt;_M_impl._M_start+1) $27 = 6 (gdb) p (this-&gt;_M_impl._M_start+1) $28 = (int *) 0x604034 (gdb) c Continuing. Breakpoint 4, std::vector&lt;int, std::allocator&lt;int&gt; &gt;::push_back (this=0x7fffffffe220, __x=@0x7fffffffe24c: 7) at /usr/include/c++/4.8.2/bits/stl_vector.h:903 903 if (this-&gt;_M_impl._M_finish != this-&gt;_M_impl._M_end_of_storage) (gdb) c Continuing. Breakpoint 5, std::vector&lt;int, std::allocator&lt;int&gt; &gt;::push_back (this=0x7fffffffe220, __x=@0x7fffffffe24c: 7) at /usr/include/c++/4.8.2/bits/stl_vector.h:915 915 &#125; (gdb) p (this-&gt;_M_impl._M_start) $29 = (std::_Vector_base&lt;int, std::allocator&lt;int&gt; &gt;::pointer) 0x604010 (gdb) p (this-&gt;_M_impl._M_finish) $30 = (std::_Vector_base&lt;int, std::allocator&lt;int&gt; &gt;::pointer) 0x60401c (gdb) p (this-&gt;_M_impl._M_end_of_storage-this-&gt;_M_impl._M_start) $31 = 4 (gdb) p (this-&gt;_M_impl._M_end_of_storage) $32 = (std::_Vector_base&lt;int, std::allocator&lt;int&gt; &gt;::pointer) 0x604020 (gdb) p *(this-&gt;_M_impl._M_start+2) $33 = 7 (gdb) p (this-&gt;_M_impl._M_start+2) $34 = (int *) 0x604018 (gdb) q 空间配置实现//*******************vector constructor explicit vector(size_type __n, const value_type&amp; __value = value_type(), const allocator_type&amp; __a = allocator_type()) : _Base(_S_check_init_len(__n, __a), __a) &#123; _M_fill_initialize(__n, __value); &#125; //*******************_M_fill_initialize // Called by the first initialize_dispatch above and by the // vector(n,value,a) constructor. void _M_fill_initialize(size_type __n, const value_type&amp; __value) &#123; this-&gt;_M_impl._M_finish = std::__uninitialized_fill_n_a(this-&gt;_M_impl._M_start, __n, __value, _M_get_Tp_allocator()); &#125; //*******************__uninitialized_fill_n_a //__uninitialized_fill_n_a会根据第一参数的型别特性（type traits）， //决定使用算法 fill_n()或反复呼叫 construct() 来完成任务 template&lt;typename _ForwardIterator, typename _Size, typename _Tp, typename _Allocator&gt; _ForwardIterator __uninitialized_fill_n_a(_ForwardIterator __first, _Size __n, const _Tp&amp; __x, _Allocator&amp; __alloc) &#123; _ForwardIterator __cur = __first; __try &#123; typedef __gnu_cxx::__alloc_traits&lt;_Allocator&gt; __traits; for (; __n &gt; 0; --__n, (void) ++__cur) __traits::construct(__alloc, std::__addressof(*__cur), __x); return __cur; &#125; __catch(...) &#123; std::_Destroy(__first, __cur, __alloc); __throw_exception_again; &#125; &#125; //__uninitialized_fill_n_a使用uninitialized_fill_n template&lt;typename _ForwardIterator, typename _Size, typename _Tp, typename _Tp2&gt; inline _ForwardIterator __uninitialized_fill_n_a(_ForwardIterator __first, _Size __n, const _Tp&amp; __x, allocator&lt;_Tp2&gt;&amp;) &#123; return std::uninitialized_fill_n(__first, __n, __x); &#125; constructor 与 ++ –ending","categories":[],"tags":[{"name":"stl","slug":"stl","permalink":"https://riverferry.site/tags/stl/"}],"keywords":[]},{"title":"epoll的源码","slug":"2020-03-07-epoll的源码","date":"2020-03-07T00:00:00.000Z","updated":"2022-09-12T16:24:32.277Z","comments":true,"path":"2020-03-07-epoll的源码/","link":"","permalink":"https://riverferry.site/2020-03-07-epoll%E7%9A%84%E6%BA%90%E7%A0%81/","excerpt":"参考从linux源码看epoll epoll源码解析翻译——说使用了mmap的都是骗子 –是否使用了mmap还存疑，源码分析中有看到mmap的函数，todo linux内核源码","text":"参考从linux源码看epoll epoll源码解析翻译——说使用了mmap的都是骗子 –是否使用了mmap还存疑，源码分析中有看到mmap的函数，todo linux内核源码 源码epoll_create123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657SYSCALL_DEFINE1(epoll_create, int, size)&#123; if (size &lt;= 0) return -EINVAL; return do_epoll_create(0);&#125;static int do_epoll_create(int flags)&#123; int error, fd; struct eventpoll *ep = NULL; struct file *file; /* Check the EPOLL_* constant for consistency. */ BUILD_BUG_ON(EPOLL_CLOEXEC != O_CLOEXEC); if (flags &amp; ~EPOLL_CLOEXEC) return -EINVAL; /* * Create the internal data structure (&quot;struct eventpoll&quot;). */ error = ep_alloc(&amp;ep); /* 在内核空间申请eventpoll内存 */ if (error &lt; 0) return error; /* * Creates all the items needed to setup an eventpoll file. That is, * a file structure and a free file descriptor. */ fd = get_unused_fd_flags(O_RDWR | (flags &amp; O_CLOEXEC)); /* 获取一个可用的文件描述符 */ if (fd &lt; 0) &#123; error = fd; goto out_free_ep; &#125; /* 在匿名inode文件系统中分配一个inode,并得到其file结构体 */ /* file-&gt;private_data = ep; */ /* file-&gt;f_op = &amp;eventpoll_fops */ file = anon_inode_getfile(&quot;[eventpoll]&quot;, &amp;eventpoll_fops, ep, O_RDWR | (flags &amp; O_CLOEXEC)); if (IS_ERR(file)) &#123; error = PTR_ERR(file); goto out_free_fd; &#125; ep-&gt;file = file; /* 将file填入文件描述符数组 */ fd_install(fd, file); return fd;out_free_fd: put_unused_fd(fd);out_free_ep: ep_free(ep); return error;&#125; eventpoll_fops 123456789101112131415161718192021222324252627282930313233343536373839404142434445static const struct file_operations eventpoll_fops;struct file_operations &#123; struct module *owner; loff_t (*llseek) (struct file *, loff_t, int); ssize_t (*read) (struct file *, char __user *, size_t, loff_t *); ssize_t (*write) (struct file *, const char __user *, size_t, loff_t *); ssize_t (*read_iter) (struct kiocb *, struct iov_iter *); ssize_t (*write_iter) (struct kiocb *, struct iov_iter *); int (*iopoll)(struct kiocb *kiocb, bool spin); int (*iterate) (struct file *, struct dir_context *); int (*iterate_shared) (struct file *, struct dir_context *); __poll_t (*poll) (struct file *, struct poll_table_struct *); long (*unlocked_ioctl) (struct file *, unsigned int, unsigned long); long (*compat_ioctl) (struct file *, unsigned int, unsigned long); int (*mmap) (struct file *, struct vm_area_struct *); unsigned long mmap_supported_flags; int (*open) (struct inode *, struct file *); int (*flush) (struct file *, fl_owner_t id); int (*release) (struct inode *, struct file *); int (*fsync) (struct file *, loff_t, loff_t, int datasync); int (*fasync) (int, struct file *, int); int (*lock) (struct file *, int, struct file_lock *); ssize_t (*sendpage) (struct file *, struct page *, int, size_t, loff_t *, int); unsigned long (*get_unmapped_area)(struct file *, unsigned long, unsigned long, unsigned long, unsigned long); int (*check_flags)(int); int (*flock) (struct file *, int, struct file_lock *); ssize_t (*splice_write)(struct pipe_inode_info *, struct file *, loff_t *, size_t, unsigned int); ssize_t (*splice_read)(struct file *, loff_t *, struct pipe_inode_info *, size_t, unsigned int); int (*setlease)(struct file *, long, struct file_lock **, void **); long (*fallocate)(struct file *file, int mode, loff_t offset, loff_t len); void (*show_fdinfo)(struct seq_file *m, struct file *f);#ifndef CONFIG_MMU unsigned (*mmap_capabilities)(struct file *);#endif ssize_t (*copy_file_range)(struct file *, loff_t, struct file *, loff_t, size_t, unsigned int); loff_t (*remap_file_range)(struct file *file_in, loff_t pos_in, struct file *file_out, loff_t pos_out, loff_t len, unsigned int remap_flags); int (*fadvise)(struct file *, loff_t, loff_t, int); 总结 epoll_create |-&gt;do_epoll_create |-&gt;file-&gt;private_data = ep |-&gt;fd_install epoll_create最主要创建一个eventpoll结构体 epfd-&gt;file-&gt;private_date = eventpoll epfd-&gt;file-&gt;f_op = eventpoll_fops epoll_create的函数参数，在内核某个版本后已经没什么用了，只需要填入大于0的数即可。 eventpoll的rdllink链表节点是epitem的rdllink成员，哪个epitem就绪了就把自己的rdllink加到双向链表rdllink中 eventpoll的rbr红黑树节点是epitem的rbn成员，每个监控的epitem都要加到红黑树中 epoll_create执行后的主要结构： 图片来源: 从linux源码看epoll 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116/** * anon_inode_getfile - creates a new file instance by hooking it up to an * anonymous inode, and a dentry that describe the &quot;class&quot; * of the file * * @name: [in] name of the &quot;class&quot; of the new file * @fops: [in] file operations for the new file * @priv: [in] private data for the new file (will be file&#x27;s private_data) * @flags: [in] flags * * Creates a new file by hooking it on a single inode. This is useful for files * that do not need to have a full-fledged inode in order to operate correctly. * All the files created with anon_inode_getfile() will share a single inode, * hence saving memory and avoiding code duplication for the file/inode/dentry * setup. Returns the newly created file* or an error pointer. *//* 通过将其挂接到单个inode 上来创建一个新文件。这对于文件*不需要完整的inode才能正常运行非常有用。*使用anon_inode_getfile（）创建的所有文件将共享一个inode，从而节省内存并避免文件/ inode / dentry的代码重复 */struct file *anon_inode_getfile(const char *name, const struct file_operations *fops, void *priv, int flags)&#123; struct file *file; if (IS_ERR(anon_inode_inode)) return ERR_PTR(-ENODEV); if (fops-&gt;owner &amp;&amp; !try_module_get(fops-&gt;owner)) return ERR_PTR(-ENOENT); /* * We know the anon_inode inode count is always greater than zero, * so ihold() is safe. */ ihold(anon_inode_inode); file = alloc_file_pseudo(anon_inode_inode, anon_inode_mnt, name, flags &amp; (O_ACCMODE | O_NONBLOCK), fops); if (IS_ERR(file)) goto err; file-&gt;f_mapping = anon_inode_inode-&gt;i_mapping; file-&gt;private_data = priv; return file;err: iput(anon_inode_inode); module_put(fops-&gt;owner); return file;&#125;struct file *alloc_file_pseudo(struct inode *inode, struct vfsmount *mnt, const char *name, int flags, const struct file_operations *fops)&#123; static const struct dentry_operations anon_ops = &#123; .d_dname = simple_dname &#125;; struct qstr this = QSTR_INIT(name, strlen(name)); struct path path; struct file *file; path.dentry = d_alloc_pseudo(mnt-&gt;mnt_sb, &amp;this); if (!path.dentry) return ERR_PTR(-ENOMEM); if (!mnt-&gt;mnt_sb-&gt;s_d_op) d_set_d_op(path.dentry, &amp;anon_ops); path.mnt = mntget(mnt); d_instantiate(path.dentry, inode); file = alloc_file(&amp;path, flags, fops); if (IS_ERR(file)) &#123; ihold(inode); path_put(&amp;path); &#125; return file;&#125;/** * alloc_file - allocate and initialize a &#x27;struct file&#x27; * * @path: the (dentry, vfsmount) pair for the new file * @flags: O_... flags with which the new file will be opened * @fop: the &#x27;struct file_operations&#x27; for the new file */static struct file *alloc_file(const struct path *path, int flags, const struct file_operations *fop)&#123; struct file *file; file = alloc_empty_file(flags, current_cred()); if (IS_ERR(file)) return file; file-&gt;f_path = *path; file-&gt;f_inode = path-&gt;dentry-&gt;d_inode; file-&gt;f_mapping = path-&gt;dentry-&gt;d_inode-&gt;i_mapping; file-&gt;f_wb_err = filemap_sample_wb_err(file-&gt;f_mapping); if ((file-&gt;f_mode &amp; FMODE_READ) &amp;&amp; likely(fop-&gt;read || fop-&gt;read_iter)) file-&gt;f_mode |= FMODE_CAN_READ; if ((file-&gt;f_mode &amp; FMODE_WRITE) &amp;&amp; likely(fop-&gt;write || fop-&gt;write_iter)) file-&gt;f_mode |= FMODE_CAN_WRITE; file-&gt;f_mode |= FMODE_OPENED; file-&gt;f_op = fop; if ((file-&gt;f_mode &amp; (FMODE_READ | FMODE_WRITE)) == FMODE_READ) i_readcount_inc(path-&gt;dentry-&gt;d_inode); return file;&#125; epoll_event 123456struct epoll_event &#123; __poll_t events; //事件 __u64 data; //fd&#125; EPOLL_PACKED; struct epitem 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364/* * Each file descriptor added to the eventpoll interface will * have an entry of this type linked to the &quot;rbr&quot; RB tree. * Avoid increasing the size of this struct, there can be many thousands * of these on a server and we do not want this to take another cache line. *///每一个添加到eventpoll的文件描述符都有一个epitem这样的条目链接到红黑树节点//避免增加此结构的大小，服务器上可能有成千上万个这样的结构，我们不希望这占用另一个缓存行。struct epitem &#123; union &#123; /* RB tree node links this structure to the eventpoll RB tree */ //RB树节点将此结构链接到eventpoll RB树 struct rb_node rbn; /* Used to free the struct epitem */ struct rcu_head rcu; &#125;; /* List header used to link this structure to the eventpoll ready list */ //用来连接到eventpoll的就绪队列链表头 struct list_head rdllink; /* * Works together &quot;struct eventpoll&quot;-&gt;ovflist in keeping the * single linked chain of items. */ //和eventpoll结构体的ovflist成员一起工作保持连接所有item成员 struct epitem *next; /* The file descriptor information this item refers to */ //引用文件描述符信息 //epoll_ctrl add时候在红黑树中查找是否存在就是通过这个值 struct epoll_filefd ffd; /* Number of active wait queue attached to poll operations */ //附加到轮询操作的活跃等待队列数 int nwait; /* List containing poll wait queues */ //poll 等待队列的链表头 struct list_head pwqlist; /* The &quot;container&quot; of this item */ //指向eventpoll struct eventpoll *ep; /* List header used to link this item to the &quot;struct file&quot; items list */ //file结构链表的链表头 struct list_head fllink; /* wakeup_source used when EPOLLWAKEUP is set */ //设置EPOLLWAKEUP时使用 struct wakeup_source __rcu *ws; /* The structure that describe the interested events and the source fd */ //保存被触发的事件和相应的fd的值 //EPOLLIN：表示对应的文件描述符可以读； //EPOLLOUT：表示对应的文件描述符可以写； //EPOLLPRI：表示对应的文件描述符有紧急的数可读； //EPOLLERR：表示对应的文件描述符发生错误； //EPOLLHUP：表示对应的文件描述符被挂断； //EPOLLET： 表示ET的epoll工作模式； struct epoll_event event;&#125;; struct eventpoll 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667/* * This structure is stored inside the &quot;private_data&quot; member of the file * structure and represents the main data structure for the eventpoll * interface. */struct eventpoll &#123; /* * This mutex is used to ensure that files are not removed * while epoll is using them. This is held during the event * collection loop, the file cleanup path, the epoll file exit * code and the ctl operations. */ // 这个互斥锁是为了保证在eventloop使用对应的文件描述符的时候，文件描述符不会被移除掉 struct mutex mtx; /* Wait queue used by sys_epoll_wait() */ // epoll_wait使用的等待队列，和进程唤醒有关 wait_queue_head_t wq; /* Wait queue used by file-&gt;poll() */ // file-&gt;poll使用的等待队列，和进程唤醒有关 wait_queue_head_t poll_wait; /* List of ready file descriptors */ /* 就绪队列，双向链表 */ //链表中每个节点都是基于epitem中的rdllink struct list_head rdllist; /* Lock which protects rdllist and ovflist */ //保护rdllist和ovflist的读写锁 rwlock_t lock; /* RB tree root used to store monitored fd structs */ /* 存储fd的红黑树的root节点 */ //红黑树中每个节点都是基于epitm中的rbn struct rb_root_cached rbr; /* * This is a single linked list that chains all the &quot;struct epitem&quot; that * happened while transferring ready events to userspace w/out * holding -&gt;lock. */ /* 这是一个单链表，链接了在向用户空间传输就绪事件的时候的所有eptem结构体 */ struct epitem *ovflist; /* wakeup_source used when ep_scan_ready_list is running */ //ep_scan_ready_list运行时wakeup_source被使用 struct wakeup_source *ws; /* The user that created the eventpoll descriptor */ //用户 struct user_struct *user; //文件指针，epoll_create创建的那个file,即epfd对应的file struct file *file; /* used to optimize loop detection check */ //用于优化回路检测检查 int visited; struct list_head visited_list_link;#ifdef CONFIG_NET_RX_BUSY_POLL /* used to track busy poll napi_id */ unsigned int napi_id;#endif&#125;; epoll_ctl123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177/* * The following function implements the controller interface for * the eventpoll file that enables the insertion/removal/change of * file descriptors inside the interest set. */SYSCALL_DEFINE4(epoll_ctl, int, epfd, int, op, int, fd, struct epoll_event __user *, event)&#123; struct epoll_event epds; if (ep_op_has_event(op) &amp;&amp; copy_from_user(&amp;epds, event, sizeof(struct epoll_event))) return -EFAULT; return do_epoll_ctl(epfd, op, fd, &amp;epds, false);&#125;int do_epoll_ctl(int epfd, int op, int fd, struct epoll_event *epds, bool nonblock)&#123; int error; int full_check = 0; struct fd f, tf; struct eventpoll *ep; struct epitem *epi; struct eventpoll *tep = NULL; error = -EBADF; f = fdget(epfd); if (!f.file) goto error_return; /* Get the &quot;struct file *&quot; for the target file */ tf = fdget(fd); if (!tf.file) goto error_fput; /* The target file descriptor must support poll */ error = -EPERM; if (!file_can_poll(tf.file)) goto error_tgt_fput; /* Check if EPOLLWAKEUP is allowed */ if (ep_op_has_event(op)) ep_take_care_of_epollwakeup(epds); /* * We have to check that the file structure underneath the file descriptor * the user passed to us _is_ an eventpoll file. And also we do not permit * adding an epoll file descriptor inside itself. */ error = -EINVAL; if (f.file == tf.file || !is_file_epoll(f.file)) goto error_tgt_fput; /* * epoll adds to the wakeup queue at EPOLL_CTL_ADD time only, * so EPOLLEXCLUSIVE is not allowed for a EPOLL_CTL_MOD operation. * Also, we do not currently supported nested exclusive wakeups. */ if (ep_op_has_event(op) &amp;&amp; (epds-&gt;events &amp; EPOLLEXCLUSIVE)) &#123; if (op == EPOLL_CTL_MOD) goto error_tgt_fput; if (op == EPOLL_CTL_ADD &amp;&amp; (is_file_epoll(tf.file) || (epds-&gt;events &amp; ~EPOLLEXCLUSIVE_OK_BITS))) goto error_tgt_fput; &#125; /* * At this point it is safe to assume that the &quot;private_data&quot; contains * our own data structure. */ ep = f.file-&gt;private_data; /* * When we insert an epoll file descriptor, inside another epoll file * descriptor, there is the change of creating closed loops, which are * better be handled here, than in more critical paths. While we are * checking for loops we also determine the list of files reachable * and hang them on the tfile_check_list, so we can check that we * haven&#x27;t created too many possible wakeup paths. * * We do not need to take the global &#x27;epumutex&#x27; on EPOLL_CTL_ADD when * the epoll file descriptor is attaching directly to a wakeup source, * unless the epoll file descriptor is nested. The purpose of taking the * &#x27;epmutex&#x27; on add is to prevent complex toplogies such as loops and * deep wakeup paths from forming in parallel through multiple * EPOLL_CTL_ADD operations. */ error = epoll_mutex_lock(&amp;ep-&gt;mtx, 0, nonblock); if (error) goto error_tgt_fput; if (op == EPOLL_CTL_ADD) &#123; if (!list_empty(&amp;f.file-&gt;f_ep_links) || is_file_epoll(tf.file)) &#123; mutex_unlock(&amp;ep-&gt;mtx); error = epoll_mutex_lock(&amp;epmutex, 0, nonblock); if (error) goto error_tgt_fput; full_check = 1; if (is_file_epoll(tf.file)) &#123; error = -ELOOP; if (ep_loop_check(ep, tf.file) != 0) &#123; clear_tfile_check_list(); goto error_tgt_fput; &#125; &#125; else list_add(&amp;tf.file-&gt;f_tfile_llink, &amp;tfile_check_list); error = epoll_mutex_lock(&amp;ep-&gt;mtx, 0, nonblock); if (error) &#123;out_del: list_del(&amp;tf.file-&gt;f_tfile_llink); goto error_tgt_fput; &#125; if (is_file_epoll(tf.file)) &#123; tep = tf.file-&gt;private_data; error = epoll_mutex_lock(&amp;tep-&gt;mtx, 1, nonblock); if (error) &#123; mutex_unlock(&amp;ep-&gt;mtx); goto out_del; &#125; &#125; &#125; &#125; /* * Try to lookup the file inside our RB tree, Since we grabbed &quot;mtx&quot; * above, we can be sure to be able to use the item looked up by * ep_find() till we release the mutex. */ epi = ep_find(ep, tf.file, fd); error = -EINVAL; switch (op) &#123; case EPOLL_CTL_ADD: if (!epi) &#123; epds-&gt;events |= EPOLLERR | EPOLLHUP; error = ep_insert(ep, epds, tf.file, fd, full_check); &#125; else error = -EEXIST; if (full_check) clear_tfile_check_list(); break; case EPOLL_CTL_DEL: if (epi) error = ep_remove(ep, epi); else error = -ENOENT; break; case EPOLL_CTL_MOD: if (epi) &#123; if (!(epi-&gt;event.events &amp; EPOLLEXCLUSIVE)) &#123; epds-&gt;events |= EPOLLERR | EPOLLHUP; error = ep_modify(ep, epi, epds); &#125; &#125; else error = -ENOENT; break; &#125; if (tep != NULL) mutex_unlock(&amp;tep-&gt;mtx); mutex_unlock(&amp;ep-&gt;mtx);error_tgt_fput: if (full_check) mutex_unlock(&amp;epmutex); fdput(tf);error_fput: fdput(f);error_return: return error;&#125; ep_find 12345678910111213141516171819202122232425262728293031/* * Search the file inside the eventpoll tree. The RB tree operations * are protected by the &quot;mtx&quot; mutex, and ep_find() must be called with * &quot;mtx&quot; held. */static struct epitem *ep_find(struct eventpoll *ep, struct file *file, int fd)&#123; int kcmp; struct rb_node *rbp; struct epitem *epi, *epir = NULL; struct epoll_filefd ffd; ep_set_ffd(&amp;ffd, file, fd); //红黑树中查找节点是否已经存在 for (rbp = ep-&gt;rbr.rb_root.rb_node; rbp; ) &#123; epi = rb_entry(rbp, struct epitem, rbn); kcmp = ep_cmp_ffd(&amp;ffd, &amp;epi-&gt;ffd); if (kcmp &gt; 0) rbp = rbp-&gt;rb_right; else if (kcmp &lt; 0) rbp = rbp-&gt;rb_left; else &#123; epir = epi; break; &#125; &#125; return epir;&#125; ep_pqueue 12345678910111213141516/* Wrapper struct used by poll queueing */struct ep_pqueue &#123; poll_table pt; struct epitem *epi;&#125;;/* * Do not touch the structure directly, use the access functions * poll_does_not_wait() and poll_requested_events() instead. */typedef struct poll_table_struct &#123; poll_queue_proc _qproc; __poll_t _key;&#125; poll_table; ep_insert 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144/* * Must be called with &quot;mtx&quot; held. */static int ep_insert(struct eventpoll *ep, const struct epoll_event *event, struct file *tfile, int fd, int full_check)&#123; int error, pwake = 0; __poll_t revents; long user_watches; //初始化epitem struct epitem *epi; struct ep_pqueue epq; lockdep_assert_irqs_enabled(); user_watches = atomic_long_read(&amp;ep-&gt;user-&gt;epoll_watches); if (unlikely(user_watches &gt;= max_user_watches)) return -ENOSPC; if (!(epi = kmem_cache_alloc(epi_cache, GFP_KERNEL))) return -ENOMEM; /* Item initialization follow here ... */ INIT_LIST_HEAD(&amp;epi-&gt;rdllink); INIT_LIST_HEAD(&amp;epi-&gt;fllink); INIT_LIST_HEAD(&amp;epi-&gt;pwqlist); epi-&gt;ep = ep; ep_set_ffd(&amp;epi-&gt;ffd, tfile, fd); epi-&gt;event = *event; epi-&gt;nwait = 0; epi-&gt;next = EP_UNACTIVE_PTR; if (epi-&gt;event.events &amp; EPOLLWAKEUP) &#123; error = ep_create_wakeup_source(epi); if (error) goto error_create_wakeup_source; &#125; else &#123; RCU_INIT_POINTER(epi-&gt;ws, NULL); &#125; /* Initialize the poll table using the queue callback */ epq.epi = epi; //********************************************************************* //初始化回调函数 //(&amp;epq.pt)-&gt;_qproc = ep_ptable_queue_proc //(&amp;epq.pt)-&gt;_key = ~(__poll_t)0 /* all events enabled */ init_poll_funcptr(&amp;epq.pt, ep_ptable_queue_proc); /* * Attach the item to the poll hooks and get current event bits. * We can safely use the file* here because its usage count has * been increased by the caller of this function. Note that after * this operation completes, the poll callback can start hitting * the new item. */ //********************************************************************* revents = ep_item_poll(epi, &amp;epq.pt, 1); /* * We have to check if something went wrong during the poll wait queue * install process. Namely an allocation for a wait queue failed due * high memory pressure. */ error = -ENOMEM; if (epi-&gt;nwait &lt; 0) goto error_unregister; /* Add the current item to the list of active epoll hook for this file */ spin_lock(&amp;tfile-&gt;f_lock); list_add_tail_rcu(&amp;epi-&gt;fllink, &amp;tfile-&gt;f_ep_links); spin_unlock(&amp;tfile-&gt;f_lock); /* * Add the current item to the RB tree. All RB tree operations are * protected by &quot;mtx&quot;, and ep_insert() is called with &quot;mtx&quot; held. */ //插入红黑树 ep_rbtree_insert(ep, epi); /* now check if we&#x27;ve created too many backpaths */ error = -EINVAL; if (full_check &amp;&amp; reverse_path_check()) goto error_remove_epi; /* We have to drop the new item inside our item list to keep track of it */ write_lock_irq(&amp;ep-&gt;lock); /* record NAPI ID of new item if present */ ep_set_busy_poll_napi_id(epi); /* If the file is already &quot;ready&quot; we drop it inside the ready list */ //如果当前有事件已经就绪，那么一开始就会被加入到ready list if (revents &amp;&amp; !ep_is_linked(epi)) &#123; //将epitem插入就绪链表 list_add_tail(&amp;epi-&gt;rdllink, &amp;ep-&gt;rdllist); ep_pm_stay_awake(epi); /* Notify waiting tasks that events are available */ //唤醒epoll wait if (waitqueue_active(&amp;ep-&gt;wq)) wake_up(&amp;ep-&gt;wq); //唤醒file-&gt;poll if (waitqueue_active(&amp;ep-&gt;poll_wait)) pwake++; &#125; write_unlock_irq(&amp;ep-&gt;lock); atomic_long_inc(&amp;ep-&gt;user-&gt;epoll_watches); /* We have to call this outside the lock */ if (pwake) ep_poll_safewake(&amp;ep-&gt;poll_wait); return 0;error_remove_epi: spin_lock(&amp;tfile-&gt;f_lock); list_del_rcu(&amp;epi-&gt;fllink); spin_unlock(&amp;tfile-&gt;f_lock); rb_erase_cached(&amp;epi-&gt;rbn, &amp;ep-&gt;rbr);error_unregister: ep_unregister_pollwait(ep, epi); /* * We need to do this because an event could have been arrived on some * allocated wait queue. Note that we don&#x27;t care about the ep-&gt;ovflist * list, since that is used/cleaned only inside a section bound by &quot;mtx&quot;. * And ep_insert() is called with &quot;mtx&quot; held. */ write_lock_irq(&amp;ep-&gt;lock); if (ep_is_linked(epi)) list_del_init(&amp;epi-&gt;rdllink); write_unlock_irq(&amp;ep-&gt;lock); wakeup_source_unregister(ep_wakeup_source(epi));error_create_wakeup_source: kmem_cache_free(epi_cache, epi); return error;&#125; ep_item_poll 1234567891011121314151617181920212223242526272829/* * Differs from ep_eventpoll_poll() in that internal callers already have * the ep-&gt;mtx so we need to start from depth=1, such that mutex_lock_nested() * is correctly annotated. */static __poll_t ep_item_poll(const struct epitem *epi, poll_table *pt, int depth)&#123; struct eventpoll *ep; bool locked; //赋值pt-&gt;_key pt-&gt;_key = epi-&gt;event.events; if (!is_file_epoll(epi-&gt;ffd.file)) return vfs_poll(epi-&gt;ffd.file, pt) &amp; epi-&gt;event.events; ep = epi-&gt;ffd.file-&gt;private_data; //poll_wait adds your device (represented by the &quot;struct file&quot;) to //the list of those that can wake the process up. //赋值pt-&gt;_qproc //*********************************************** poll_wait(epi-&gt;ffd.file, &amp;ep-&gt;poll_wait, pt); locked = pt &amp;&amp; (pt-&gt;_qproc == ep_ptable_queue_proc); return ep_scan_ready_list(epi-&gt;ffd.file-&gt;private_data, ep_read_events_proc, &amp;depth, depth, locked) &amp; epi-&gt;event.events;&#125; poll_wait 1234567static inline void poll_wait(struct file * filp, wait_queue_head_t * wait_address, poll_table *p)&#123; if (p &amp;&amp; p-&gt;_qproc &amp;&amp; wait_address) p-&gt;_qproc(filp, wait_address, p);&#125; ep_ptable_queue_proc 123456789101112131415161718192021222324252627282930313233/* * This is the callback that is used to add our wait queue to the * target file wakeup lists. *///这是回调函数，用于将我们的等待队列添加到目标文件唤醒列表static void ep_ptable_queue_proc(struct file *file, wait_queue_head_t *whead, poll_table *pt)&#123; struct epitem *epi = ep_item_from_epqueue(pt); struct eppoll_entry *pwq; //nwait:附加到轮询操作的活跃等待队列数 if (epi-&gt;nwait &gt;= 0 &amp;&amp; (pwq = kmem_cache_alloc(pwq_cache, GFP_KERNEL))) &#123; //&amp;pwq-&gt;wait-&gt;func=ep_poll_callback，用于回调唤醒 //epoll_wait会被唤醒 init_waitqueue_func_entry(&amp;pwq-&gt;wait, ep_poll_callback); pwq-&gt;whead = whead; pwq-&gt;base = epi; if (epi-&gt;event.events &amp; EPOLLEXCLUSIVE) add_wait_queue_exclusive(whead, &amp;pwq-&gt;wait); else //这边的whead是sk-&gt;sk_sleep,将当前的waitqueue链入到socket对应的sleep列表（如果是accept的话） add_wait_queue(whead, &amp;pwq-&gt;wait); list_add_tail(&amp;pwq-&gt;llink, &amp;epi-&gt;pwqlist); epi-&gt;nwait++; &#125; else &#123; /* We have to signal that an error occurred */ epi-&gt;nwait = -1; &#125;&#125; 总结 epoll_ctl |-&gt;do_epoll_ctl |-&gt;ep_find |-&gt;ep_insert |-&gt;ep_item_poll |-&gt;poll_wait(epi-&gt;ffd.file, &amp;ep-&gt;poll_wait, pt) |-&gt;ep_ptable_queue_proc |-&gt;waitqueue中 //poll_table添加唤醒回调函数ep_poll_callback |-&gt;add_wait_queue(将当前的waitqueue链入到epitem对应的等待列表) |-&gt;ep_scan_ready_list |-&gt;ep_remove |-&gt;ep_modify ep_find的三个参数：epfd对应的eventpoll,epoll_ctrl参数中的fd对应的file结构，epoll_ctrl参数中的fd ep_find的逻辑：将fd转换为epoll_filefd格式，找rbr红黑树中每个epitem的ffd成员进行比较 ep_insert新建一个epi(epitem),赋值然后插入红黑树 ep_insert创建epq(ep_pqueue),(&amp;epq.pt)-&gt;_qproc = ep_ptable_queue_proc poll队列回调函数 ep_insert创建epq(ep_pqueue),(&amp;epq.pt)-&gt;_key = epi-&gt;event.events(初始化后在ep_item_poll中赋值) poll_wait中执行回调函数ep_ptable_queue_proc ep_ptable_queue_proc新建一个pwq(eppoll_entry),&amp;pwq-&gt;wait-&gt;func=ep_poll_callback(唤醒epoll_wait的函数) ep_ptable_queue_proc中pwq-&gt;base = epi ep_ptable_queue_proc中pwq-&gt;whead = &amp;ep-&gt;poll_wait(file-&gt;poll使用的等待队列，和进程唤醒有关) 图片来源: 从linux源码看epoll epoll_waitepoll_wait 12345678//系统调用epoll_waitSYSCALL_DEFINE4(epoll_wait, int, epfd, struct epoll_event __user *, events, int, maxevents, int, timeout)&#123; return do_epoll_wait(epfd, events, maxevents, timeout);&#125; do_epoll_wait 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/* * Implement the event wait interface for the eventpoll file. It is the kernel * part of the user space epoll_wait(2). */static int do_epoll_wait(int epfd, struct epoll_event __user *events, int maxevents, int timeout)&#123; int error; struct fd f; struct eventpoll *ep; /* The maximum number of event must be greater than zero */ if (maxevents &lt;= 0 || maxevents &gt; EP_MAX_EVENTS) return -EINVAL; /* Verify that the area passed by the user is writeable */ if (!access_ok(events, maxevents * sizeof(struct epoll_event))) return -EFAULT; /* Get the &quot;struct file *&quot; for the eventpoll file */ f = fdget(epfd); if (!f.file) return -EBADF; /* * We have to check that the file structure underneath the fd * the user passed to us _is_ an eventpoll file. */ error = -EINVAL; if (!is_file_epoll(f.file)) goto error_fput; /* * At this point it is safe to assume that the &quot;private_data&quot; contains * our own data structure. */ //取epfd对于的eventpoll结构体 ep = f.file-&gt;private_data; /* Time to fish for events ... */ error = ep_poll(ep, events, maxevents, timeout);error_fput: fdput(f); return error;&#125; ep_poll 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161/** * ep_poll - Retrieves ready events, and delivers them to the caller supplied * event buffer. * * @ep: Pointer to the eventpoll context. * @events: Pointer to the userspace buffer where the ready events should be * stored. * @maxevents: Size (in terms of number of events) of the caller event buffer. * @timeout: Maximum timeout for the ready events fetch operation, in * milliseconds. If the @timeout is zero, the function will not block, * while if the @timeout is less than zero, the function will block * until at least one event has been retrieved (or an error * occurred). * * Returns: Returns the number of ready events which have been fetched, or an * error code, in case of error. */static int ep_poll(struct eventpoll *ep, struct epoll_event __user *events, int maxevents, long timeout)&#123; int res = 0, eavail, timed_out = 0; u64 slack = 0; bool waiter = false; wait_queue_entry_t wait; ktime_t expires, *to = NULL; lockdep_assert_irqs_enabled(); //大于0，设置超时 if (timeout &gt; 0) &#123; struct timespec64 end_time = ep_set_mstimeout(timeout); slack = select_estimate_accuracy(&amp;end_time); to = &amp;expires; *to = timespec64_to_ktime(end_time); //等于0，立刻返回结果 &#125; else if (timeout == 0) &#123; /* * Avoid the unnecessary trip to the wait queue loop, if the * caller specified a non blocking operation. We still need * lock because we could race and not see an epi being added * to the ready list while in irq callback. Thus incorrectly * returning 0 back to userspace. */ timed_out = 1; write_lock_irq(&amp;ep-&gt;lock); //检查是否有可用事件，rdllist就绪链表 //return !list_empty_careful(&amp;ep-&gt;rdllist) ||READ_ONCE(ep-&gt;ovflist) != EP_UNACTIVE_PTR; eavail = ep_events_available(ep); write_unlock_irq(&amp;ep-&gt;lock); goto send_events; &#125; //小于0，无限期阻塞fetch_events: if (!ep_events_available(ep)) ep_busy_loop(ep, timed_out); //检查是否有可用事件，rdllist就绪链表 //return !list_empty_careful(&amp;ep-&gt;rdllist) ||READ_ONCE(ep-&gt;ovflist) != EP_UNACTIVE_PTR; eavail = ep_events_available(ep); if (eavail) goto send_events; /* * Busy poll timed out. Drop NAPI ID for now, we can add * it back in when we have moved a socket with a valid NAPI * ID onto the ready list. */ ep_reset_busy_poll_napi_id(ep); /* * We don&#x27;t have any available event to return to the caller. We need * to sleep here, and we will be woken by ep_poll_callback() when events * become available. */ //我们没有任何可用的事件可返回给呼叫者。我们需要 //睡眠，当事件发生时，我们会被ep_poll_callback（）唤醒变得可用。 if (!waiter) &#123; waiter = true; //初始化等待链表 init_waitqueue_entry(&amp;wait, current); //自旋锁 spin_lock_irq(&amp;ep-&gt;wq.lock); //添加到等待链表 __add_wait_queue_exclusive(&amp;ep-&gt;wq, &amp;wait); spin_unlock_irq(&amp;ep-&gt;wq.lock); &#125; for (;;) &#123; /* * We don&#x27;t want to sleep if the ep_poll_callback() sends us * a wakeup in between. That&#x27;s why we set the task state * to TASK_INTERRUPTIBLE before doing the checks. */ // 设置当前进程状态为可打断 set_current_state(TASK_INTERRUPTIBLE); /* * Always short-circuit for fatal signals to allow * threads to make a timely exit without the chance of * finding more events available and fetching * repeatedly. */ // 检查当前线程是否有信号要处理，有则返回-EINTR if (fatal_signal_pending(current)) &#123; res = -EINTR; break; &#125; //检查是否有可用事件，rdllist就绪链表 //return !list_empty_careful(&amp;ep-&gt;rdllist) ||READ_ONCE(ep-&gt;ovflist) != EP_UNACTIVE_PTR; eavail = ep_events_available(ep); if (eavail) break; if (signal_pending(current)) &#123; res = -EINTR; break; &#125; // sleep until timeout // 让出cpu if (!schedule_hrtimeout_range(to, slack, HRTIMER_MODE_ABS)) &#123; timed_out = 1; break; &#125; &#125; //// 设置进程状态为running __set_current_state(TASK_RUNNING);send_events: /* * Try to transfer events to user space. In case we get 0 events and * there&#x27;s still timeout left over, we go trying again in search of * more luck. */ //尝试将事件转移到用户空间。如果我们收到0个事件，还有剩余的超时时间，我们将再次 //尝试寻找来碰碰运气 if (!res &amp;&amp; eavail &amp;&amp; //// 向用户空间拷贝就绪事件 !(res = ep_send_events(ep, events, maxevents)) &amp;&amp; !timed_out) goto fetch_events; if (waiter) &#123; spin_lock_irq(&amp;ep-&gt;wq.lock); //wq_entry = wait //list_del(&amp;wq_entry-&gt;entry); //从等待链表移除 __remove_wait_queue(&amp;ep-&gt;wq, &amp;wait); spin_unlock_irq(&amp;ep-&gt;wq.lock); &#125; return res;&#125; 总结 epoll_wait |-&gt;do_epoll_wait |-&gt;ep_poll |-&gt;send_events |-&gt;fetch_events ep_poll根据超时时间执行不同策略 ep_poll中判断就绪队列rdllist不为空，则发送就绪事件到用户空间send_events ep_poll没有事件则schedule_hrtimeout_range让出cpu,等待唤醒 ep-&gt;ovflist的作用：记录处理过程中新到来的事件(不是很明确) 中断处理程序执行回调函数唤醒epoll_wait(我的猜测) 图片来源: 从linux源码看epoll ep_send_eventsep_send_events 12345678910111213static int ep_send_events(struct eventpoll *ep, struct epoll_event __user *events, int maxevents)&#123; struct ep_send_events_data esed; esed.maxevents = maxevents; esed.events = events; ep_scan_ready_list(ep, ep_send_events_proc, &amp;esed, 0, false); return esed.res;&#125; ep_scan_ready_list 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103/** * ep_scan_ready_list - Scans the ready list in a way that makes possible for * the scan code, to call f_op-&gt;poll(). Also allows for * O(NumReady) performance. * * @ep: Pointer to the epoll private data structure. * @sproc: Pointer to the scan callback. * @priv: Private opaque data passed to the @sproc callback. * @depth: The current depth of recursive f_op-&gt;poll calls. * * Returns: The same integer error code returned by the @sproc callback. */static int ep_scan_ready_list(struct eventpoll *ep, int (*sproc)(struct eventpoll *, struct list_head *, void *), void *priv, int depth)&#123; int error, pwake = 0; unsigned long flags; struct epitem *epi, *nepi; LIST_HEAD(txlist); /* * We need to lock this because we could be hit by * eventpoll_release_file() and epoll_ctl(). */ mutex_lock_nested(&amp;ep-&gt;mtx, depth); /* * Steal the ready list, and re-init the original one to the * empty list. Also, set ep-&gt;ovflist to NULL so that events * happening while looping w/out locks, are not lost. We cannot * have the poll callback to queue directly on ep-&gt;rdllist, * because we want the &quot;sproc&quot; callback to be able to do it * in a lockless way. */ spin_lock_irqsave(&amp;ep-&gt;lock, flags); //将rdllist链入到txlist list_splice_init(&amp;ep-&gt;rdllist, &amp;txlist); ep-&gt;ovflist = NULL; spin_unlock_irqrestore(&amp;ep-&gt;lock, flags); /* * Now call the callback function. */ //*********************************************************************** //执行函数ep_send_events_proc error = (*sproc)(ep, &amp;txlist, priv); spin_lock_irqsave(&amp;ep-&gt;lock, flags); /* * During the time we spent inside the &quot;sproc&quot; callback, some * other events might have been queued by the poll callback. * We re-insert them inside the main ready-list here. */ for (nepi = ep-&gt;ovflist; (epi = nepi) != NULL; nepi = epi-&gt;next, epi-&gt;next = EP_UNACTIVE_PTR) &#123; /* * We need to check if the item is already in the list. * During the &quot;sproc&quot; callback execution time, items are * queued into -&gt;ovflist but the &quot;txlist&quot; might already * contain them, and the list_splice() below takes care of them. */ if (!ep_is_linked(&amp;epi-&gt;rdllink)) &#123; list_add_tail(&amp;epi-&gt;rdllink, &amp;ep-&gt;rdllist); ep_pm_stay_awake(epi); &#125; &#125; /* * We need to set back ep-&gt;ovflist to EP_UNACTIVE_PTR, so that after * releasing the lock, events will be queued in the normal way inside * ep-&gt;rdllist. */ ep-&gt;ovflist = EP_UNACTIVE_PTR; /* * Quickly re-inject items left on &quot;txlist&quot;. */ list_splice(&amp;txlist, &amp;ep-&gt;rdllist); __pm_relax(ep-&gt;ws); if (!list_empty(&amp;ep-&gt;rdllist)) &#123; /* * Wake up (if active) both the eventpoll wait list and * the -&gt;poll() wait list (delayed after we release the lock). */ if (waitqueue_active(&amp;ep-&gt;wq)) wake_up_locked(&amp;ep-&gt;wq); if (waitqueue_active(&amp;ep-&gt;poll_wait)) pwake++; &#125; spin_unlock_irqrestore(&amp;ep-&gt;lock, flags); mutex_unlock(&amp;ep-&gt;mtx); /* We have to call this outside the lock */ if (pwake) ep_poll_safewake(&amp;ep-&gt;poll_wait); return error;&#125; init_poll_funcptr 123456static inline void init_poll_funcptr(poll_table *pt, poll_queue_proc qproc)&#123; pt-&gt;_qproc = qproc; pt-&gt;_key = ~(__poll_t)0; /* all events enabled */&#125; list_for_each_entry_safe /** * list_for_each_entry_safe - iterate over list of given type safe against removal of list entry * @pos: the type * to use as a loop cursor. * @n: another type * to use as temporary storage * @head: the head for your list. * @member: the name of the list_head within the struct. */ #define list_for_each_entry_safe(pos, n, head, member) \\ for (pos = list_first_entry(head, typeof(*pos), member), \\ n = list_next_entry(pos, member); \\ &amp;pos-&gt;member != (head); \\ pos = n, n = list_next_entry(n, member)) ep_send_events_proc 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102static __poll_t ep_send_events_proc(struct eventpoll *ep, struct list_head *head, void *priv)&#123; struct ep_send_events_data *esed = priv; __poll_t revents; struct epitem *epi, *tmp; struct epoll_event __user *uevent = esed-&gt;events; struct wakeup_source *ws; poll_table pt; //pt-&gt;_qproc = NULL //pt-&gt;_key = ~(__poll_t)0 /* all events enabled */ init_poll_funcptr(&amp;pt, NULL); esed-&gt;res = 0; /* * We can loop without lock because we are passed a task private list. * Items cannot vanish during the loop because ep_scan_ready_list() is * holding &quot;mtx&quot; during this call. */ lockdep_assert_held(&amp;ep-&gt;mtx); //head=ep-&gt;rdllist //遍历rdllink链表，直到其中某个节点的member成员=ep-&gt;rdllist的 //我理解是找到ep-&gt;rdllist就绪链表在内存某个数据结构中的地址 //这个地址用epi指针保存 //******************************************************************* list_for_each_entry_safe(epi, tmp, head, rdllink) &#123; if (esed-&gt;res &gt;= esed-&gt;maxevents) break; /* * Activate ep-&gt;ws before deactivating epi-&gt;ws to prevent * triggering auto-suspend here (in case we reactive epi-&gt;ws * below). * * This could be rearranged to delay the deactivation of epi-&gt;ws * instead, but then epi-&gt;ws would temporarily be out of sync * with ep_is_linked(). */ ws = ep_wakeup_source(epi); if (ws) &#123; if (ws-&gt;active) __pm_stay_awake(ep-&gt;ws); __pm_relax(ws); &#125; list_del_init(&amp;epi-&gt;rdllink); /* * If the event mask intersect the caller-requested one, * deliver the event to userspace. Again, ep_scan_ready_list() * is holding ep-&gt;mtx, so no operations coming from userspace * can change the item. */ //如果事件掩码与调用方请求的掩码相交，则将事件传递到用户空间 //ep_scan_ready_list重新获得锁 //所以来自用户空间的操作不会改变这个epitem //readylist只是表明当前epi有事件，具体的事件信息还是得调用对应file的poll //执行tcp_poll,确认是否是感兴趣的事件 //********************************************************************* revents = ep_item_poll(epi, &amp;pt, 1); if (!revents) continue; //将event放入到用户空间 if (__put_user(revents, &amp;uevent-&gt;events) || __put_user(epi-&gt;event.data, &amp;uevent-&gt;data)) &#123; list_add(&amp;epi-&gt;rdllink, head); ep_pm_stay_awake(epi); if (!esed-&gt;res) esed-&gt;res = -EFAULT; return 0; &#125; esed-&gt;res++; uevent++; if (epi-&gt;event.events &amp; EPOLLONESHOT) epi-&gt;event.events &amp;= EP_PRIVATE_BITS; else if (!(epi-&gt;event.events &amp; EPOLLET)) &#123; /* * If this file has been added with Level * Trigger mode, we need to insert back inside * the ready list, so that the next call to * epoll_wait() will check again the events * availability. At this point, no one can insert * into ep-&gt;rdllist besides us. The epoll_ctl() * callers are locked out by * ep_scan_ready_list() holding &quot;mtx&quot; and the * poll callback will queue them in ep-&gt;ovflist. */ //如果是水平触发，则将当前的epi重新加回到可用列表中，这样就可以下一次继续触发poll, //如果下一次poll的revents不为0，那么用户空间依旧能感知 list_add_tail(&amp;epi-&gt;rdllink, &amp;ep-&gt;rdllist); ep_pm_stay_awake(epi); &#125; //如果是边缘触发，那么就不加回可用列表，因此只能等到下一个可用事件触发的时候才会将对应的epi放到可用列表里面 &#125; return 0;&#125; struct poll_wqueues 1234567891011121314/* * Structures and helpers for select/poll syscall */struct poll_wqueues &#123; poll_table pt; struct poll_table_page *table; struct task_struct *polling_task; int triggered; int error; int inline_index; struct poll_table_entry inline_entries[N_INLINE_POLL_ENTRIES];&#125;; __pollwait(pollwait) 123456789101112131415161718192021222324252627282930313233343536373839/* * Ok, Peter made a complicated, but straightforward multiple_wait() function. * I have rewritten this, taking some shortcuts: This code may not be easy to * follow, but it should be free of race-conditions, and it&#x27;s practical. If you * understand what I&#x27;m doing here, then you understand how the linux * sleep/wakeup mechanism works. * * Two very simple procedures, poll_wait() and poll_freewait() make all the * work. poll_wait() is an inline-function defined in &lt;linux/poll.h&gt;, * as all select/poll functions have to call it to add an entry to the * poll table. */static void __pollwait(struct file *filp, wait_queue_head_t *wait_address, poll_table *p);/* Add a new entry */static void __pollwait(struct file *filp, wait_queue_head_t *wait_address, poll_table *p)&#123; //根据poll_wqueues的成员pt指针p找到所在的poll_wqueues结构指针 struct poll_wqueues *pwq = container_of(p, struct poll_wqueues, pt); //根据pwq找到entry struct poll_table_entry *entry = poll_get_entry(pwq); if (!entry) return; //entry-&gt;filp = get_file(epi-&gt;ffd.file) entry-&gt;filp = get_file(filp); //wait_address = &amp;ep-&gt;poll_wait entry-&gt;wait_address = wait_address; //entry-&gt;key = epi-&gt;event.events entry-&gt;key = p-&gt;_key; //(&amp;entry-&gt;wait)-&gt;func = pollwake init_waitqueue_func_entry(&amp;entry-&gt;wait, pollwake); entry-&gt;wait.private = pwq; // add_wait_queue(wait_address, &amp;entry-&gt;wait);&#125; struct poll_table_entry 1234567struct poll_table_entry &#123; struct file *filp; __poll_t key; wait_queue_entry_t wait; wait_queue_head_t *wait_address;&#125;; init_waitqueue_func_entry 1234567static inline voidinit_waitqueue_func_entry(struct wait_queue_entry *wq_entry, wait_queue_func_t func)&#123; wq_entry-&gt;flags = 0; wq_entry-&gt;private = NULL; wq_entry-&gt;func = func;&#125; vfs_poll 123456789static inline __poll_t vfs_poll(struct file *file, struct poll_table_struct *pt)&#123; if (unlikely(!file-&gt;f_op-&gt;poll)) return DEFAULT_POLLMASK; // 这边的poll即是tcp_poll,根据tcp本身的信息设置掩码(mask)等信息 &amp; 上兴趣事件掩码，则可以得知当前事件是否是epoll_wait感兴趣的事件 return file-&gt;f_op-&gt;poll(file, pt);&#125; 总结 ep_send_events |-&gt;ep_scan_ready_list |-&gt;ep_send_events_proc(poll_table pt) //pt-&gt;_key = epi-&gt;event.events; |-&gt;ep_item_poll(epi, &amp;pt, 1) |-&gt;vfs_poll(epi-&gt;ffd.file, pt) |-&gt;file-&gt;f_op-&gt;poll() ep_send_events只是知道epoll_wait被唤醒，还需要获取具体信息 ep_send_events_proc遍历rdllink链表(全局的)，直到其中某个节点的member成员=ep-&gt;rdllist,找到epi节点 ep_item_poll执行epi-&gt;ffd.file-&gt;f_op-&gt;poll() 这边的poll即是file_poll(网络套接字则是tcp_poll)，根据file本身的信息设置掩码(mask)等信息 &amp; 上兴趣事件掩码 ep_send_events_proc根据上一步的结果确认要不要将event放入用户空间 ep_item_poll有2个分支，在两个2同阶段 图片来源: 从linux源码看epoll ending","categories":[],"tags":[{"name":"IO复用","slug":"IO复用","permalink":"https://riverferry.site/tags/IO%E5%A4%8D%E7%94%A8/"}],"keywords":[]},{"title":"操作系统-处理器调度","slug":"2020-03-04-操作系统-处理器调度","date":"2020-03-04T00:00:00.000Z","updated":"2022-09-12T16:24:32.276Z","comments":true,"path":"2020-03-04-操作系统-处理器调度/","link":"","permalink":"https://riverferry.site/2020-03-04-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E5%A4%84%E7%90%86%E5%99%A8%E8%B0%83%E5%BA%A6/","excerpt":"参考陈向群操作系统 ppt简要整理 正文CPU调度: 即按一定的调度算法从就绪队列中选择一个进程，把CPU的使用权交给被选中的进程如果没有就绪进程，系统会安排一个系统空闲进程或idle进程","text":"参考陈向群操作系统 ppt简要整理 正文CPU调度: 即按一定的调度算法从就绪队列中选择一个进程，把CPU的使用权交给被选中的进程如果没有就绪进程，系统会安排一个系统空闲进程或idle进程 进程切换： 是指一个进程让出处理器，由另一个进程占用处理器的过程 主要做了两项工作： 切换全局页目录以加载一个新的地址空间 切换内核栈和硬件上下文，其中硬件上下文包括了内核执行新进程需要的全部信息，如CPU相关寄存器 场景：进程A下CPU，进程B上CPU 保存进程A的上下文环境（程序计数器、程序状态字、其他寄存器……） 用新状态和其他相关信息更新进程A的PCB 把进程A移至合适的队列（就绪、阻塞……） 将进程B的状态设置为运行态 从进程B的PCB中恢复上下文（程序计数器 、程序状态字、其他寄存器……） 上下文切换开销 直接开销：内核完成切换所用的CPU时间 保存和恢复寄存器…… 切换地址空间（相关指令比较昂贵） 间接开销 高速缓存(Cache)、缓冲区缓存(Buffer Cache)和TLB(Translation Look-aside Buffer)失效 调度算法FIFO 先来先服务 按照进程就绪的先后顺序使用CPU 非抢占 短作业优先(SJF) 具有最短完成时间的进程优先执行 非抢占式 最短剩余时间优先 SJF抢占式版本，即当一个新就绪的进程比当前运行进程具有更短的完成时间时，系统抢占当前进程，选择新就绪的进程执行 容易产生饥饿现象 最高相应比优先 调度时，首先计算每个进程的响应比R；之后，总是选择 R 最高的进程执行 等待时间越久，补偿越大 响应比R = 周转时间 / 处理时间 =（处理时间 + 等待时间）/ 处理时间 = 1 +（等待时间 / 处理时间） 时间片轮转 每个进程分配一个时间片 时钟中断 → 轮换 虚拟轮转法 不记录了 最高优先级 选择优先级最高的进程投入运行优先级反转 多级反馈队列 是UNIX的一个分支BSD （加州大学伯克利分校开发和发布的）5.3版所采用的调度算法 设置多个就绪队列，第一级队列优先级最高 给不同就绪队列中的进程分配长度不同的时间片，第一级队列时间片最小；随着队列优先级别的降低，时间片增大 当第一级队列为空时，在第二级队列调度，以此类推 各级队列按照时间片轮转方式 进行调度 当一个新创建进程就绪后，进入第一级队列 进程用完时间片而放弃CPU，进入下一级就绪队列 由于阻塞而放弃CPU的进程进入相应的等待队列，一旦等待的事件发生，该进程回到原来一级就绪队列(阻塞完成后的进程优先级比较高) 比较 FCFS:FIFO Round Robin: SJF:短作业有限 SRTN:最短时间优先 HRRN:最高响应比 Feedback:多级反馈队列 Linux调度算法 Windows线程调度 调度单位是线程 采用基于动态优先级的、抢占式调度，结合时间配额的调整 调度策略 主动切换 抢占 时间配额用完 I/O完成后的线程优先级提升 在完成I/O操作后，Windows 将临时提升等待该操作线程的优先级，保证该线程能更快上CPU运行进行数据处理 优先级的提升值由设备驱动程序决定，提升建议值保存在系统文件“Wdm.h”或“Ntddk.h”中 优先级的提升幅度与对I/O请求的响应时间要求是一致的，响应时间要求越高，优先级提升幅度越大 设备驱动程序在完成I/O请求时通过内核函数IoCompleteRequest来指定优先级提升的幅度 为避免不公平，在I/O操作完成唤醒等待线程时会将该线程的时间配额减1 饥饿线程的优先级提升 系统线程“平衡集管理器(balance set manager)”每秒钟扫描一次就绪队列，发现是否存在等待时间超过300个时钟中断间隔的线程 平衡集管理器将这些线程的优先级提升到15，并分配给它一个长度为正常值4倍的时间配额 当被提升的线程用完它的时间配额后，立即衰减到它原来的基本优先级 ending","categories":[],"tags":[{"name":"OperatingSystem","slug":"OperatingSystem","permalink":"https://riverferry.site/tags/OperatingSystem/"}],"keywords":[]},{"title":"操作系统-进程线程-原理","slug":"2020-02-29-操作系统-进程线程-原理","date":"2020-02-29T00:00:00.000Z","updated":"2022-09-12T16:24:32.276Z","comments":true,"path":"2020-02-29-操作系统-进程线程-原理/","link":"","permalink":"https://riverferry.site/2020-02-29-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E8%BF%9B%E7%A8%8B%E7%BA%BF%E7%A8%8B-%E5%8E%9F%E7%90%86/","excerpt":"参考陈向群操作系统 关于进程和线程 线程的3种实现方式–内核级线程, 用户级线程和混合型线程","text":"参考陈向群操作系统 关于进程和线程 线程的3种实现方式–内核级线程, 用户级线程和混合型线程 多道处理程序 进程定义： 进程是正在执行的(并发和并行)可执行程序的实例，进程和线程都可以称为任务 特征 程序的一次执行过程 是正在运行程序的抽象 系统资源以进程为单位分配，如内存、文件、…… 每个具有独立的地址空间 进程的意义： 多道程序允许多个程序同时进入内存并运行，每个程序在运行过程中的实例都可以称为进程，进程既包括了程序文件中的信息，还包括堆栈信息，进程表等维持程序运行，切换所需的信息 进程和程序的区别： 进程更能准确刻画并发，而程序不能(一个程序运行2次，就是2个进程) 程序是静态的，进程是动态的 进程有生命周期的，有诞生有消亡，是短暂的；而程序是相对长久的 一个程序可对应多个进程 进程具有创建其他进程的功能 进程的运行状态： 进程的其他状态: 1 创建(new) 已完成创建一进程所必要的工作 – PID、PCB但尚未同意执行该进程– 因为资源有限 2 终止(terminated) 终止执行后，进程进入该状态可完成一些数据统计工作资源回收 3 挂起(suspend) 用于调节负载进程不占用内存空间，其进程映像交换到磁盘上 进程队列： 操作系统为每一类进程建立一个或多个队列 队列元素为PCB 伴随进程状态的改变，其PCB从一个队列进入另一个队列 多个等待队列等待的事件不同 就绪队列也可以多个 单CPU情况下，运行队列中只有一个进程 进程创建： 在Unix种只有一个系统调用可以创建新进程(fork),exec族函数是在原有的进程结构种重新加载程序，pid不变 进程的分类: 系统进程 用户进程 前台进程 后台进程 cpu密集型进程 I/O密集型进程 进程地址空间： 进程上下文切换： 将CPU硬件状态从一个进程换到另一个进程的过程称为上下文切换 进程运行时，其硬件状态保存在CPU上的寄存器(程序计数器、程序状态寄存器、栈指针、通用寄存器、其他控制寄存器的值) 进程不运行时，这些寄存器的值保存在进程控制块PCB中；当操作系统要运行一个新的进程时，将PCB中的相关值送到对应的寄存器中 线程引入线程的原因： 应用的需要 开销的考虑 性能的考虑 如果一个程序想要同时处理多个事情，这些事情又彼此联系，采用进程的话系统开销，资源分配都很大，且进程间交换数据比较麻烦，采用更小颗粒度的控制流显然比较好 线程和进程的不同 线程享有进程的资源，但是可以独立运行的cpu最小调度单位 每个过程都提供执行程序所需的资源。进程具有虚拟地址空间，可执行代码，系统对象的打开句柄，安全上下文，唯一的进程标识符，环境变量，优先级类别，最小和最大工作集大小以及至少一个执行线程。每个进程都从单个线程（通常称为主线程）开始，但是可以从其任何线程中创建其他线程。 一个线程是可以调度执行过程中的实体。进程的所有线程共享其虚拟地址空间和系统资源。另外，每个线程维护异常处理程序，调度优先级，线程本地存储，唯一的线程标识符以及系统将用于保存线程上下文直到被调度的一组结构。的线程上下文包括线程的一组的机器寄存器，内核栈，线程环境块，并在该线程的进程的地址空间中的用户栈。线程也可以具有自己的安全上下文，可用于模拟客户端。 Per process items | Per thread items ------------------------------|----------------- Address space | Program counter Global variables | Registers Open files | Stack Child processes | State Pending alarms | Signals and signal handlers | Accounting information | 用户级线程： 由应用程序所支持的线程实现, 内核意识不到用户级线程的实现 在用户空间建立线程库：提供一组管理线程的过程 运行时系统：完成线程的管理工作（操作、线程表） 内核管理的还是进程，不知道线程的存在 线程切换不需要内核态特权 例子：UNIX 图片来源: https://blog.csdn.net/gatieme/article/details/51892437 内核级线程： 内核级线程又称为内核支持的线程 内核管理所有线程管理，并向应用程序提供API接口 内核维护进程和线程的上下文 线程的切换需要内核支持 以线程为基础进行调度 例子：Windows 图片来源: https://blog.csdn.net/gatieme/article/details/51892437 混合式线程： 两者结合方法 线程创建在用户空间完成 线程调度等在核心态完成 多个用户级线程多路复用多个内核级线程 图片来源: https://blog.csdn.net/gatieme/article/details/51892437 用户级/内核级线程对比 可再入程序（可重入）： 可被多个进程同时调用的程序，具有下列性质： 它是纯代码的，即在执行过程中自身不改变；调用它的进程应该提供数据区 并发和并行: 并发是指两个或多个任务可以在重叠的时间段内启动，运行和完成。但每个时刻只有一个任务在执行。例如，单核计算机上的多任务处理。 并行是指任务实际上在同一时间（例如，在多核处理器上）运行。 其他： 线程表和进程表是一样的task_struct linux不支持内核级线程,线程只是进程的子集，主要区别就是是否有自己的独立的虚拟地址空间 ending","categories":[],"tags":[{"name":"OperatingSystem","slug":"OperatingSystem","permalink":"https://riverferry.site/tags/OperatingSystem/"}],"keywords":[]},{"title":"操作系统-中断和异常","slug":"2020-02-28-操作系统-中断和异常","date":"2020-02-28T00:00:00.000Z","updated":"2022-09-12T16:24:32.276Z","comments":true,"path":"2020-02-28-操作系统-中断和异常/","link":"","permalink":"https://riverferry.site/2020-02-28-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E4%B8%AD%E6%96%AD%E5%92%8C%E5%BC%82%E5%B8%B8/","excerpt":"基本概念主要参考了：陈向群操作系统 图1:","text":"基本概念主要参考了：陈向群操作系统 图1: 处理器的概念处理器由运算器、控制器、一系列的寄存器以及高速缓存构成 寄存器寄存器分为用户可见寄存器，控制和状态寄存器 常见的控制和状态寄存器: 程序计数器（PC：Program Counter），记录将要取出的指令的地址 指令寄存器（IR：Instruction Register），记录最近取出的指令 程序状态字（PSW：Program Status Word），记录处理器的运行状态如条件码、模式、控制位等信息 操作系统操作系统的两种状态： 内核态(Kernel Mode)：运行操作系统程序 用户态(User Mode)：运行用户程序 CPU状态的转换用户态 → 内核态: 唯一途径 → 中断/异常/陷入机制 内核态 → 用户态: 设置程序状态字PSW 陷入指令(访管指令)提供给用户程序的接口，用于调用操作系统的功能（服务） 例如：int，trap，syscall，sysenter/sysexit 中断异常机制中断异常的概念： CPU对系统发生的某个事件作出的一种反应 CPU暂停正在执行的程序，保留现场后自动转去执行相应事件的处理程序，处理完成后返回断点，继续执行被打断的程序 中断的引入:为了支持CPU和设备之间的并行操作 当CPU启动设备进行输入/输出后，设备便可以独立工作，CPU转去处理与此次输入/输出不相关的事情；当设备完成输入/输出后，通过向CPU发中断报告此次输入/输出的结果，让CPU决定如何处理以后的事情 异常的引入：表示CPU执行指令时本身出现的问题 如算术溢出、除零、取数时的奇偶错，访存地址时越界或执行了“陷入指令” 等，这时硬件改变了CPU当前的执行流程，转到相应的错误处理程序或异常处理程序或执行系统调用 图2: 硬件和软件的角色： 硬件：捕获中断源发出的中断/异常请求，以一定方式响应，将处理器控制权交给特定的处理程序 软件：识别中断/异常类型并完成相应的处理 图3: 中断向量: 一个内存单元，存放中断处理程序入口地址和程序运行时所需的处理机状态字 中断处理程序步骤： 系统运行时若响应中断，中断硬件部件将CPU控制权转给中断处理程序: 保存相关寄存器信息 分析中断/异常的具体原因 执行对应的处理功能 恢复现场，返回被事件打断的程序 图4: x86处理器对于中断的处理图5: 图6: 中断/异常的硬件处理过程: 确定与中断或异常关联的向量i 通过IDTR寄存器找到IDT表，获得中断描述符（表中的第i项） 从GDTR寄存器获得GDT的地址；结合中断描述符中的段选择符，在GDT表获取对应的段描述符；从该段描述符中得到中断或异常处理程序所在的段基址 特权级检查 检查是否发生了特权级的变化，如果是，则进行堆栈切换(必须使用与新的特权级相关的栈) 硬件压栈，保存上下文环境；如果异常产生了硬件出错码，也将它保存在栈中 如果是中断，清IF位 通过中断描述符中的段内偏移量和段描述符中的基地址，找到中断/异常处理程序的入口地址，执行其第一条指令 系统调用机制图7: 图8: 123456789#include &lt;unistd.h&gt;int main(int argc, char *argv[])&#123; write(1, &quot;Hello World\\n&quot;, 12); /* write &quot;Hello World&quot; to stdout */ _exit(0); /* exit with error code 0 (no error) */&#125; x86架构常用int 0x80 指令作为陷入指令，x86_64多用 syscall指令 链接 链接 x86 汇编In x86-32 parameters for Linux system call are passed using registers. %eax for syscall_number. %ebx, %ecx, %edx, %esi, %edi, %ebp are used for passing 6 parameters to system calls. 在x86-32中，使用寄存器传递用于Linux系统调用的参数。%eax用于syscall_number。％ebx，％ecx，％edx，％esi，％edi，％ebp用于将6个参数传递给系统调用。 The return value is in %eax. All other registers (including EFLAGS) are preserved across the int $0x80. 返回值为in %eax。所有其他寄存器（包括EFLAGS）都保留在内int $0x80。 _start: movl $4, %eax ; use the write syscall movl $1, %ebx ; write to stdout movl $msg, %ecx ; use string &quot;Hello World&quot; movl $12, %edx ; write 12 characters int $0x80 ; make syscall movl $1, %eax ; use the _exit syscall movl $0, %ebx ; error code 0 int $0x80 ; make syscall x86_64 汇编1 User-level applications use as integer registers for passing the sequence %rdi, %rsi, %rdx, %rcx, %r8 and %r9. The kernel interface uses %rdi, %rsi, %rdx, %r10, %r8 and %r9. 用户级应用程序用作整数寄存器，以传递序列％rdi，％rsi，％rdx，％rcx，％r8和％r9。内核接口使用％rdi，％rsi，％rdx，％r10，％r8和％r9。 2 A system-call is done via the syscall instruction. This clobbers %rcx and %r11 as well as the %rax return value, but other registers are preserved. 通过syscall指令进行系统调用。此副本％rcx和％r11以及％rax返回值，但是保留了其他寄存器。 3 The number of the syscall has to be passed in register %rax. 系统调用的编号必须在寄存器％rax中传递。 4 System-calls are limited to six arguments, no argument is passed directly on the stack. 系统调用仅限于六个参数，没有参数直接在堆栈上传递。 5 Returning from the syscall, register %rax contains the result of the system-call. A value in the range between -4095 and -1 indicates an error, it is -errno. 从系统调用返回，寄存器％rax包含系统调用的结果。介于-4095到-1之间的值表示错误，它是-errno。 6 Only values of class INTEGER or class MEMORY are passed to the kernel. 仅将类INTEGER或类MEMORY的值传递到内核。 _start: movq $1, %rax ; use the write syscall movq $1, %rdi ; write to stdout movq $msg, %rsi ; use string &quot;Hello World&quot; movq $12, %rdx ; write 12 characters syscall ; make syscall movq $60, %rax ; use the _exit syscall movq $0, %rdi ; error code 0 syscall ; make syscall 从trap指令来看系统调用的过程操作系统 设用户进程A在运行中要向已打开的文件写一批数据，为此再用户C源程序中可用如下系统调用语句：rw = write(fd, buf, count); 这条语句编译后的汇编指令： trap4 参数1 参数2 参数3 k1:.... 其中，参数1，2，3分别对应该文件的文件描述符fd,用户信息所在内存始址buf,传送字节数count.这个系统调用的过程如下7步： 1 CPU执行到trap4指令时，产生陷入事件，硬件做出中断响应：保留进程A的PSW和PC的值，取中断向量并放入寄存器(PSW,PC)中。程序控制转向一段核心代码，将进程状态改为核心态。进一步保留现场信息(各通用寄存器的值)，然后进入统一的处理程序trap中，trap程序根据系统低矮用号4查找到系统调用入口表，得到相应处理子程序的入口地址write 2 转入文件系统管理。根据文件描述符fd找到该文件的控制结构-活动I节点，进行权限验证 等操作之后，如果都合法，则调用相应的核心程序将文件的逻辑地址映射到物理块号。再申请和分配缓冲区，将进程A内存区BUF中的信息传送到所分配的缓冲区中。然后，经由内部控制结构(即块设备转接表)进入设备驱动程序。 3 启动设备驱动程序(即磁盘驱动程序)，将缓冲区中的信息写道想用的盘块中。在进行磁盘IO工作时，进程A要等待IO完成，所以进程A让出CPU，处于睡眠状态 4 处理机管理和调用工作。进程调度程序从就绪队列中选中一个合适的进程。例如B,为它恢复现场，使其在CPU上运行。此时CPU在进程B的用户空间运行 5 当写盘工作完成后(即缓冲区的信息都传送到盘块上)磁盘控制器发生IO中断信号。该信号终止进程B的继续运行，硬件做出中断响应，然后转入磁盘中断处理程序 6 磁盘中断处理程序运行。它验证中断来源，如传输无错，则唤醒因等待IO而睡眠的进程A 7 设进程A比进程B的优先级高，则中断处理程序完成后，执行进程调度程序。选中进程A，为进程A恢复现场，然后进程A的程序接着向下执行 ending","categories":[],"tags":[{"name":"OperatingSystem","slug":"OperatingSystem","permalink":"https://riverferry.site/tags/OperatingSystem/"}],"keywords":[]},{"title":"操作系统-编译链接","slug":"2020-02-28-操作系统-编译链接","date":"2020-02-28T00:00:00.000Z","updated":"2022-09-12T16:24:32.276Z","comments":true,"path":"2020-02-28-操作系统-编译链接/","link":"","permalink":"https://riverferry.site/2020-02-28-%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F-%E7%BC%96%E8%AF%91%E9%93%BE%E6%8E%A5/","excerpt":"参考主要参考了：陈向群操作系统, 程序员的自我修养 Gcc 编译的背后 GCC编程四个过程:预处理-编译-汇编-链接","text":"参考主要参考了：陈向群操作系统, 程序员的自我修养 Gcc 编译的背后 GCC编程四个过程:预处理-编译-汇编-链接 helloworld程序的运行过程12345678#include &lt;stdio.h&gt;int main(int argc, char *argv[]) &#123; puts(&quot;hello world&quot;); return 0; &#125; 用户告诉操作系统执行helloworld程序 操作系统：找到helloworld程序的相关信息，检查其类型是否是可执行文件；并通过程序首部信息，确定代码和数据在可执行文件中的位置并计算出对应的磁盘块地址 操作系统：创建一个新的进程，并将helloworld可执行文件映射到该进程结构，表示由该进程执行helloworld程序 操作系统：为helloworld程序设置CPU上下文环境，并跳到程序开始处 执行helloworld程序的第一条指令，发生缺页异常 操作系统：分配一页物理内存，并将代码从磁盘读入内存，然后继续执行helloworld程序 helloworld程序执行puts函数（系统调用），在显示器上写一字符串 操作系统：找到要将字符串送往的显示设备，通常设备是由一个进程控制的，所以，操作系统将要写的字符串送给该进程 操作系统：控制设备的进程告诉设备的窗口系统它要显示字符串，窗口系统确定这是一个合法的操作，然后将字符串转换成像素，将像素写入设备的存储映像区 视频硬件将像素转换成显示器可接收的一组控制/数据信号 显示器解释信号，激发液晶屏 OK！！！我们在屏幕上看到了“hello world” 操作系统的5大功能(从资源管理的角度)1 进程/线程管理（CPU管理）进程线程状态、控制、同步互斥、通信、调度、…… 2 存储管理 分配/回收、地址转换、存储保护、内存扩充、…… 3 文件管理 文件目录、文件操作、磁盘空间、文件存取控制、…… 4 设备管理 设备驱动、分配回收、缓冲技术、…… 5 用户接口 系统命令、编程接口 操作系统的主要特征1 并发 2 共享 3 虚拟 4 随机/异常 linux内核组件 可执行文件的装载与进程可执行文件: [root@localhost bin]# file cgdb cgdb: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), dynamically linked (uses shared libs) for GNU/Linux 2.6.32, BuildID[sha1]=0x7e94e0eb5975bd6a1eb4c7a8c0af6b77475f4362, not stripped [root@localhost bin]# file ShadowsocksR-dotnet2.0.exe ShadowsocksR-dotnet2.0.exe: PE32 executable (GUI) Intel 80386 Mono/.Net assembly,for MS Windows 进程的建立： 创建一个独立的虚拟地址空间(页目录) 虚拟空间和物理内存的映射关系 读取可执行文件头，并且建立虚拟空间与可执行文件的映射关系 虚拟空间和可执行文件的映射关系 将CPU的指令寄存器设置成可执行文件的入口地址，启动运行 可执行文件在装载时实际是被映射的虚拟空间，所以可执行文件很多时候又被叫做映像文件 gcc编译的四步12345678910#include &quot;stdio.h&quot;int main()&#123; puts(&quot;hello, it,s me!&quot;); return 0;&#125; 预处理阶段 头文件的包含，宏定义的扩展，条件编译的选择 gcc -E test.c -o test.i 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869# 1 &quot;test.c&quot;# 1 &quot;&lt;built-in&gt;&quot;# 1 &quot;&lt;命令行&gt;&quot;# 1 &quot;/usr/include/stdc-predef.h&quot; 1 3 4# 1 &quot;&lt;命令行&gt;&quot; 2# 1 &quot;test.c&quot;# 1 &quot;/usr/include/stdio.h&quot; 1 3 4# 27 &quot;/usr/include/stdio.h&quot; 3 4# 1 &quot;/usr/include/features.h&quot; 1 3 4# 375 &quot;/usr/include/features.h&quot; 3 4# 1 &quot;/usr/include/sys/cdefs.h&quot; 1 3 4# 392 &quot;/usr/include/sys/cdefs.h&quot; 3 4# 1 &quot;/usr/include/bits/wordsize.h&quot; 1 3 4# 393 &quot;/usr/include/sys/cdefs.h&quot; 2 3 4# 376 &quot;/usr/include/features.h&quot; 2 3 4# 399 &quot;/usr/include/features.h&quot; 3 4# 1 &quot;/usr/include/gnu/stubs.h&quot; 1 3 4# 10 &quot;/usr/include/gnu/stubs.h&quot; 3 4# 1 &quot;/usr/include/gnu/stubs-64.h&quot; 1 3 4# 11 &quot;/usr/include/gnu/stubs.h&quot; 2 3 4# 400 &quot;/usr/include/features.h&quot; 2 3 4# 28 &quot;/usr/include/stdio.h&quot; 2 3 4# 1 &quot;/usr/lib/gcc/x86_64-redhat-linux/4.8.5/include/stddef.h&quot; 1 3 4# 212 &quot;/usr/lib/gcc/x86_64-redhat-linux/4.8.5/include/stddef.h&quot; 3 4typedef long unsigned int size_t;# 34 &quot;/usr/include/stdio.h&quot; 2 3 4# 1 &quot;/usr/include/bits/types.h&quot; 1 3 4# 27 &quot;/usr/include/bits/types.h&quot; 3 4# 1 &quot;/usr/include/bits/wordsize.h&quot; 1 3 4# 28 &quot;/usr/include/bits/types.h&quot; 2 3 4typedef unsigned char __u_char;typedef unsigned short int __u_short;typedef unsigned int __u_int;typedef unsigned long int __u_long;typedef signed char __int8_t;typedef unsigned char __uint8_t;typedef signed short int __int16_t;typedef unsigned short int __uint16_t;typedef signed int __int32_t;typedef unsigned int __uint32_t;typedef signed long int __int64_t;typedef unsigned long int __uint64_t;---------------省略一大部分内容---------------------------------------------省略一大部分内容------------------------------# 2 &quot;test.c&quot; 2int main()&#123; puts(&quot;hello, it,s me!&quot;); return 0;&#125; 编译阶段 词法分析，语法分析，将源文件代码转为中间汇编代码 gcc -S test.i -o test.s 12345678910111213141516171819202122232425262728 .file &quot;test.c&quot; .section .rodata.LC0: .string &quot;hello, it,s me!&quot; .text .globl main .type main, @functionmain:.LFB0: .cfi_startproc pushq %rbp .cfi_def_cfa_offset 16 .cfi_offset 6, -16 movq %rsp, %rbp .cfi_def_cfa_register 6 movl $.LC0, %edi call puts movl $0, %eax popq %rbp .cfi_def_cfa 7, 8 ret .cfi_endproc.LFE0: .size main, .-main .ident &quot;GCC: (GNU) 4.8.5 20150623 (Red Hat 4.8.5-36)&quot; .section .note.GNU-stack,&quot;&quot;,@progbits 汇编阶段 将汇编代码翻译为目标代码(机器代码),即二进制文件 gcc -c test.s -o test.o 1234567891011121314151617181920212223/*Offset: 00 01 02 03 04 05 06 07 08 09 0A 0B 0C 0D 0E 0F 00000000: 7F 45 4C 46 02 01 01 00 00 00 00 00 00 00 00 00 .ELF............00000010: 01 00 3E 00 01 00 00 00 00 00 00 00 00 00 00 00 ..&gt;.............00000020: 00 00 00 00 00 00 00 00 38 01 00 00 00 00 00 00 ........8.......00000030: 00 00 00 00 40 00 00 00 00 00 40 00 0D 00 0A 00 ....@.....@.....00000040: 55 48 89 E5 BF 00 00 00 00 E8 00 00 00 00 B8 00 UH.e?....h....8.00000050: 00 00 00 5D C3 00 00 00 68 65 6C 6C 6F 2C 20 69 ...]C...hello,.i00000060: 74 2C 73 20 6D 65 21 00 00 47 43 43 3A 20 28 47 t,s.me!..GCC:.(G00000070: 4E 55 29 20 34 2E 38 2E 35 20 32 30 31 35 30 36 NU).4.8.5.20150600000080: 32 33 20 28 52 65 64 20 48 61 74 20 34 2E 38 2E 23.(Red.Hat.4.8.00000090: 35 2D 33 36 29 00 00 00 14 00 00 00 00 00 00 00 5-36)...........000000a0: 01 7A 52 00 01 78 10 01 1B 0C 07 08 90 01 00 00 .zR..x..........000000b0: 1C 00 00 00 1C 00 00 00 00 00 00 00 15 00 00 00 ................000000c0: 00 41 0E 10 86 02 43 0D 06 50 0C 07 08 00 00 00 .A....C..P......000000d0: 00 2E 73 79 6D 74 61 62 00 2E 73 74 72 74 61 62 ..symtab..strtab000000e0: 00 2E 73 68 73 74 72 74 61 62 00 2E 72 65 6C 61 ..shstrtab..rela000000f0: 2E 74 65 78 74 00 2E 64 61 74 61 00 2E 62 73 73 .text..data..bss00000100: 00 2E 72 6F 64 61 74 61 00 2E 63 6F 6D 6D 65 6E ..rodata..commen00000110: 74 00 2E 6E 6F 74 65 2E 47 4E 55 2D 73 74 61 63 t..note.GNU-stac00000120: 6B 00 2E 72 65 6C 61 2E 65 68 5F 66 72 61 6D 65 k..rela.eh_frame-----------------------省略下面的内容----------------------------------*/ 链接阶段 重定位是将符号引用与符号定义进行链接的过程。因此链接是处理可重定位文件，把它们的各种符号引用和符号定义转换为可执行文件中的合适信息（一般是虚拟内存地址）的过程。 链接又分为静态链接和动态链接，前者是程序开发阶段程序员用 ld（gcc 实际上在后台调用了 ld）静态链接器手动链接的过程，而动态链接则是程序运行期间系统调用动态链接器（ld-linux.so）自动链接的过程。 gcc test.o -o test [root@localhost test]# ldd test linux-vdso.so.1 =&gt; (0x00007fff22f44000) libc.so.6 =&gt; /lib64/libc.so.6 (0x00007f80760ec000) /lib64/ld-linux-x86-64.so.2 (0x00007f80764c2000) 函数库一般分为静态库和动态库两种。静态库是指编译链接时，把库文件的代码全部加入到可执行文件中，因此生成的文件比较大，但在运行时也就不再需要库文件了。其后缀名一般为”.a”。动态库与之相反，在编译链接时并没有把库文件的代码加入到可执行文件中，而是在程序执行时由运行时链接文件加载库，这样可以节省系统的开销。动态库一般后缀名为”.so”，如前面所述的libc.so.6就是动态库。gcc在编译时默认使用动态库。 ending","categories":[],"tags":[{"name":"OperatingSystem","slug":"OperatingSystem","permalink":"https://riverferry.site/tags/OperatingSystem/"}],"keywords":[]},{"title":"epoll的原理","slug":"2020-02-26-epoll的原理","date":"2020-02-26T00:00:00.000Z","updated":"2022-09-12T16:24:32.276Z","comments":true,"path":"2020-02-26-epoll的原理/","link":"","permalink":"https://riverferry.site/2020-02-26-epoll%E7%9A%84%E5%8E%9F%E7%90%86/","excerpt":"参考游戏研究院 Epoll的使用详解 源码解读epoll内核机制","text":"参考游戏研究院 Epoll的使用详解 源码解读epoll内核机制 原理分析select原理 图片来源： 游戏研究院 select将进程信息保存在每个需要监视的fd的等待列表中，当任何一个fd有读写事件发生，都会触发中断处理程序进行处理，包括将网卡中数据拷贝到内核空间，以及进行进程调度，让等待的进程优先执行 这里存在几个问题： select函数每次执行前，需要修改FD_SET结构体，更新监视的句柄，每次都要把进程信息加到所有句柄的等待队列中，涉及一次遍历 当select从阻塞状态唤醒，也需要遍历确认是哪个句柄上有动静 要传递所有的fd给内核 epoll_create 12345#include &lt;sys/epoll.h&gt;int epoll_create(int size);int epoll_create1(int flags); epoll_create() creates a new epoll(7) instance. Since Linux 2.6.8, the size argument is ignored, but must be greater than zero; see NOTES below. epoll_create() returns a file descriptor referring to the new epoll instance. This file descriptor is used for all the subsequent calls to the epoll interface. When no longer required, the file descriptor returned by epoll_create() should be closed by using close(2). When all file descriptors referring to an epoll instance have been closed, the kernel destroys the instance and releases the associated resources for reuse. epoll函数 epoll_ctl 1234#include &lt;sys/epoll.h&gt;int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event); This system call is used to add, modify, or remove entries in the interest list of the epoll(7) instance referred to by the file descriptor epfd. It requests that the operation op be performed for the target file descriptor, fd. Valid values for the op argument are: EPOLL_CTL_ADD Add fd to the interest list and associate the settings specified in event with the internal file linked to fd. EPOLL_CTL_MOD Change the settings associated with fd in the interest list to the new settings specified in event. EPOLL_CTL_DEL Remove (deregister) the target file descriptor fd from the interest list. The event argument is ignored and can be NULL (but see BUGS below). 123456789101112typedef union epoll_data &#123; void *ptr; int fd; uint32_t u32; uint64_t u64;&#125; epoll_data_t;struct epoll_event &#123; uint32_t events; /* Epoll events */ epoll_data_t data; /* User data variable */&#125;; events这个参数是一个字节的掩码构成的。下面是可以用的事件： EPOLLIN - 当关联的文件可以执行 read ()操作时。 EPOLLOUT - 当关联的文件可以执行 write ()操作时。 EPOLLRDHUP - (从 linux 2.6.17 开始)当socket关闭的时候，或者半关闭写段的(当使用边缘触发的时候，这个标识在写一些测试代码去检测关闭的* 时候特别好用) EPOLLPRI - 当 read ()能够读取紧急数据的时候。 EPOLLERR - 当关联的文件发生错误的时候，epoll_wait() 总是会等待这个事件，并不是需要必须设置的标识。 EPOLLHUP - 当指定的文件描述符被挂起的时候。epoll_wait() 总是会等待这个事件，并不是需要必须设置的标识。当socket从某一个地方读取数据的时候(管道或者socket),这个事件只是标识出这个已经读取到最后了(EOF)。所有的有效数据已经被读取完毕了，之后任何的读取都会返回0(EOF)。 EPOLLET - 设置指定的文件描述符模式为边缘触发，默认的模式是水平触发。 EPOLLONESHOT - (从 linux 2.6.17 开始)设置指定文件描述符为单次模式。这意味着，在设置后只会有一次从epoll_wait() 中捕获到事件，之后你必须要重新调用 epoll_ctl() 重新设置。 返回值：如果成功，返回0。如果失败，会返回-1， errno将会被设置 有以下几种错误： EBADF - epfd 或者 fd 是无效的文件描述符。 EEXIST - op是EPOLL_CTL_ADD，同时 fd 在之前，已经被注册到epoll中了。 EINVAL - epfd不是一个epoll描述符。或者fd和epfd相同，或者op参数非法。 ENOENT - op是EPOLL_CTL_MOD或者EPOLL_CTL_DEL，但是fd还没有被注册到epoll上。 ENOMEM - 内存不足。 EPERM - 目标的fd不支持epoll。 epoll_wait 123456int epoll_wait(int epfd, struct epoll_event *events,int maxevents, int timeout);//epoll_pwait() 在内核版本 2.6.19 加入。glibc 从版本 2.6 开始支持。 增加了信号的处理int epoll_pwait(int epfd, struct epoll_event *events,int maxevents, int timeout, const sigset_t *sigmask); The epoll_wait() system call waits for events on the epoll(7) instance referred to by the file descriptor epfd. The memory area pointed to by events will contain the events that will be available for the caller. Up to maxevents are returned by epoll_wait(). The maxevents argument must be greater than zero. The timeout argument specifies the number of milliseconds that epoll_wait() will block. Time is measured against the CLOCK_MONOTONIC clock. The call will block until either: * a file descriptor delivers an event; * the call is interrupted by a signal handler; or * the timeout expires. epoll_create的过程主要是创建并初始化数据结构eventpoll，以及创建file实例 1234567891011121314151617181920212223242526272829303132333435363738struct eventpoll &#123; spinlock_t lock; struct mutex mtx; wait_queue_head_t wq; //sys_epoll_wait（）使用的等待队列 wait_queue_head_t poll_wait; //file-&gt;poll()使用的等待队列 struct list_head rdllist; //所有准备就绪的文件描述符列表 struct rb_root rbr; //用于储存已监控fd的红黑树根节点 // 当正在向用户空间传递事件，则就绪事件会临时放到该队列，否则直接放到rdllist struct epitem *ovflist; struct wakeup_source *ws; // 当ep_scan_ready_list运行时使用wakeup_source struct user_struct *user; //创建eventpoll描述符的用户 struct file *file; int visited; //用于优化循环检测检查 struct list_head visited_list_link;struct epitem &#123; union &#123; struct rb_node rbn; //RB树节点将此结构链接到eventpoll RB树 struct rcu_head rcu; //用于释放结构体epitem &#125;; struct list_head rdllink; //用于将此结构链接到eventpoll就绪列表的列表标头 struct epitem *next; //配合ovflist一起使用来保持单向链的条目 struct epoll_filefd ffd; //此条目引用的文件描述符信息 int nwait; //附加到poll轮询中的活跃等待队列数 struct list_head pwqlist; struct eventpoll *ep; //epi所属的ep struct list_head fllink; //链接到file条目列表的列表头 struct wakeup_source __rcu *ws; //设置EPOLLWAKEUP时使用的wakeup_source struct epoll_event event; //监控的事件和文件描述符&#125;;&#125;; 就绪队列 rdllist是用于存储就绪的fd信息，使用双向链表删除，插入效率高 索引结构 红黑树是自平衡二叉查找树，搜索，插入，删除效率高。在epoll_ctrl添加监听fd的时候能够快速判断是否已经存在，以及快速插入，或者移除 源码解读epoll内核机制 ep_poll_callback()：目标fd的就绪事件到来时，将epi-&gt;rdllink加入ep-&gt;rdllist的队列，导致rdlist不空，从而进程被唤醒，epoll_wait得以继续执行。 到epoll_wait()，从队列中移除wait，再将传输就绪事件到用户空间。 epoll比select更高效的一点是：epoll监控的每一个文件fd就绪事件触发，导致相应fd上的回调函数ep_poll_callback()被调用 select poll epoll这三个都是对poll机制的封装 ending","categories":[],"tags":[{"name":"epoll","slug":"epoll","permalink":"https://riverferry.site/tags/epoll/"}],"keywords":[]},{"title":"同步,异步,阻塞,非阻塞","slug":"2020-02-26-同步,异步,阻塞,非阻塞","date":"2020-02-26T00:00:00.000Z","updated":"2022-09-12T16:24:32.276Z","comments":true,"path":"2020-02-26-同步,异步,阻塞,非阻塞/","link":"","permalink":"https://riverferry.site/2020-02-26-%E5%90%8C%E6%AD%A5,%E5%BC%82%E6%AD%A5,%E9%98%BB%E5%A1%9E,%E9%9D%9E%E9%98%BB%E5%A1%9E/","excerpt":"术语 NIO(Non-blocked IO) BIO(blocked IO) AIO(asynchronous I/O)","text":"术语 NIO(Non-blocked IO) BIO(blocked IO) AIO(asynchronous I/O) 概念阻塞/非阻塞阻塞和非阻塞说的是程序在等待调用结果时的状态，取决与CPU会不会在进程时间片未用尽的情况下进行进程切换，将进程变成非运行状态(挂起进程)。 阻塞调用 accept队列为空的时候，进程被挂起，等accept队列不为空了，cpu再唤醒进程 非阻塞调用 不管accept队列内部情况，每次系统调用accept函数都会立即得到一个返回值，进程不会被挂起 可能阻塞的系统调用： 输入操作：read, readv, recv, recvfrom, recvmsg 输出操作：write, writev, send, sendto, sendmsg 接收外来连接：accept 发起外出连接：connect 阻塞IO/非阻塞IO因为IO操作导致的进程被cpu挂起，唤醒即是阻塞IO和非阻塞IO 同步/异步同步： A发出一个’请求’后，一直等待，直到请求执行结束，得到请求的返回值(B发来的) 异步： A发出一个’请求’后，直接返回，此时并不知道执行的结果/返回值。等其他地方(B)处理请求完成后，把结果主动发过来(A通过回调之类的方法去获取)，这个时候A才认为请求执行完成 同步IO/异步IO 异步IO在poxis中的规定： 告诉内核启动某个操作(包括将数据从内核态复制到用户态)完成后通知我们。 需要注意的是同步IO需要进程主动将数据从内核空间拷贝到用户空间，异步则是从内核空间拷贝到用户空间完成后才通知进程。 信号驱动IO就是同步的，因为是内核通知我们何时可以启动IO操作，但IO操作(内核-用户)还未开始 POXIS中的术语： 同步IO操作： 导致请求进程阻塞，直到IO操作完成 异步IO操作： 不导致请求进程阻塞 5种IO的对比 ET触发下，为什么一定要是非阻塞边缘触发下，用阻塞模型会存在功能上的问题，所以要用非阻塞 当阻塞模式下，recv会一直阻塞接受数据，如果没有一次读取完成所有的数据，ET是边缘触发，只能触发一次epoll_wait更新，剩下的未读取完成的数据就不能继续读入了，除非网络另一端发来新的消息。 同样的，如果一次没有写完，则其他待发送数据，只能等到新的写请求才能触发。所以ET再非阻塞模式下要求循环把数据读取完成。 ET触发下，accept问题accept事件一次只能从syn就绪队列中取一个放进accept队列，如果同一时刻有多个就绪连接，只accept一次，剩下的连接在下一次epoll_wait也不会触发，LT模式下就没问题 ET模式下，不管阻塞还是非阻塞，都要一次把所有的就绪队列accept成功。可以使用循环。使用epoll时需要将socket设为非阻塞吗？ ending","categories":[],"tags":[{"name":"IO","slug":"IO","permalink":"https://riverferry.site/tags/IO/"}],"keywords":[]},{"title":"nginx-配置静态网页","slug":"2020-01-18-nginx-配置静态网页","date":"2020-01-18T00:00:00.000Z","updated":"2022-09-12T16:24:32.275Z","comments":true,"path":"2020-01-18-nginx-配置静态网页/","link":"","permalink":"https://riverferry.site/2020-01-18-nginx-%E9%85%8D%E7%BD%AE%E9%9D%99%E6%80%81%E7%BD%91%E9%A1%B5/","excerpt":"前言代理服务器配置，待补充","text":"前言代理服务器配置，待补充 nginx.conf1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071081091101111121131141151161171181191201211 # riverferry.site2 #user nobody;3 worker_processes 4;4 5 #error_log logs/error.log;6 #error_log logs/error.log notice;7 #error_log logs/error.log info;8 9 #pid logs/nginx.pid;10 11 12 events &#123;13 worker_connections 1024;14 &#125;15 16 17 http &#123;18 include mime.types;19 default_type application/octet-stream;20 21 log_format main &#x27;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &#x27;22 # &#x27;$status $body_bytes_sent &quot;$http_referer&quot; &#x27;23 # &#x27;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&#x27;;24 25 access_log logs/access.log main;26 27 sendfile on;28 #tcp_nopush on;29 30 #keepalive_timeout 0;31 keepalive_timeout 65;32 33 gzip on;34 35 server &#123;36 listen 8000;37 server_name localhost;38 39 #charset koi8-r;40 41 access_log logs/host.access.log main;42 43 location / &#123;44 alias wang/;45 autoindex on;46 #root html;47 #index index.html index.htm;48 &#125;49 50 #error_page 404 /404.html;51 52 # redirect server error pages to the static page /50x.html53 #54 error_page 500 502 503 504 /50x.html;55 location = /50x.html &#123;56 root html;57 &#125;58 59 # proxy the PHP scripts to Apache listening on 127.0.0.1:8060 #61 #location ~ \\.php$ &#123;62 # proxy_pass http://127.0.0.1;63 #&#125;64 65 # pass the PHP scripts to FastCGI server listening on 127.0.0.1:900066 #67 #location ~ \\.php$ &#123;68 # root html;69 # fastcgi_pass 127.0.0.1:9000;70 # fastcgi_index index.php;71 # fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name;72 # include fastcgi_params;73 #&#125;74 75 # deny access to .htaccess files, if Apache&#x27;s document root76 # concurs with nginx&#x27;s one77 #78 #location ~ /\\.ht &#123;79 # deny all;80 #&#125;81 &#125;82 83 84 # another virtual host using mix of IP-, name-, and port-based configuration85 #86 #server &#123;87 # listen 8000;88 # listen somename:8080;89 # server_name somename alias another.alias;90 91 # location / &#123;92 # root html;93 # index index.html index.htm;94 # &#125;95 #&#125;96 97 98 # HTTPS server99 #100 #server &#123;101 # listen 443 ssl;102 # server_name localhost;103104 # ssl_certificate cert.pem;105 # ssl_certificate_key cert.key;106107 # ssl_session_cache shared:SSL:1m;108 # ssl_session_timeout 5m;109110 # ssl_ciphers HIGH:!aNULL:!MD5;111 # ssl_prefer_server_ciphers on;112113 # location / &#123;114 # root html;115 # index index.html index.htm;116 # &#125;117 #&#125;118119 &#125;120 文件路径和索引line 44：指定访问的根目录 prefix/wang line 45: 使用自动索引 设置日志路径和格式line 21-25,41 [root@localhost logs]# tailf host.access.log 192.1.1.1 - - [18/Jan/2020:23:16:20 +0800] &quot;GET / HTTP/1.1&quot; access_loglogs/access.logmain 192.1.1.1 - - [18/Jan/2020:23:16:33 +0800] &quot;GET / HTTP/1.1&quot; access_loglogs/access.logmain 192.1.1.1 - - [18/Jan/2020:23:17:21 +0800] &quot;GET / HTTP/1.1&quot; access_loglogs/access.logmain 192.1.1.1 - - [18/Jan/2020:23:17:34 +0800] &quot;GET / HTTP/1.1&quot; access_loglogs/access.logmain 192.1.1.1 - - [18/Jan/2020:23:17:34 +0800] &quot;GET /favicon.ico HTTP/1.1&quot; access_loglogs/access.logmain 192.1.1.1 - - [18/Jan/2020:23:19:08 +0800] &quot;GET / HTTP/1.1&quot; access_loglogs/access.logmain 192.1.1.1 - - [18/Jan/2020:23:19:08 +0800] &quot;GET /favicon.ico HTTP/1.1&quot; access_loglogs/access.logmain 192.1.1.1 - - [18/Jan/2020:23:19:20 +0800] &quot;GET / HTTP/1.1&quot; access_loglogs/access.logmain 192.1.1.1 - - [18/Jan/2020:23:23:11 +0800] &quot;GET / HTTP/1.1&quot; access_loglogs/access.logmain 192.1.1.1 - - [18/Jan/2020:23:23:11 +0800] &quot;GET / HTTP/1.1&quot; access_loglogs/access.logmain 日志备份 nginx -s reopen 重新打开日志 gzipline 33 ending","categories":[],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://riverferry.site/tags/nginx/"}],"keywords":[]},{"title":"http协议","slug":"2020-01-15-http协议","date":"2020-01-15T00:00:00.000Z","updated":"2022-09-12T16:24:32.275Z","comments":true,"path":"2020-01-15-http协议/","link":"","permalink":"https://riverferry.site/2020-01-15-http%E5%8D%8F%E8%AE%AE/","excerpt":"参考","text":"参考 ending","categories":[],"tags":[{"name":"坑","slug":"坑","permalink":"https://riverferry.site/tags/%E5%9D%91/"}],"keywords":[]},{"title":"sip协议","slug":"2020-01-15-sip协议","date":"2020-01-15T00:00:00.000Z","updated":"2022-09-12T16:24:32.275Z","comments":true,"path":"2020-01-15-sip协议/","link":"","permalink":"https://riverferry.site/2020-01-15-sip%E5%8D%8F%E8%AE%AE/","excerpt":"参考","text":"参考 ending","categories":[],"tags":[{"name":"坑","slug":"坑","permalink":"https://riverferry.site/tags/%E5%9D%91/"}],"keywords":[]},{"title":"cgdb安装","slug":"2020-01-14-cgdb安装","date":"2020-01-14T00:00:00.000Z","updated":"2022-09-12T16:24:32.275Z","comments":true,"path":"2020-01-14-cgdb安装/","link":"","permalink":"https://riverferry.site/2020-01-14-cgdb%E5%AE%89%E8%A3%85/","excerpt":"参考CentOS7 安装cgdb 说明在没有外网的centos6下尝试离线安装cgdb,花了很多时间，最后都没有成功，很挫败了。晚上在centos7下联网再试了一次,参考上面的文章轻轻松松搞定，这篇文章主要记录一下,跟参考的连接没有多大区别.","text":"参考CentOS7 安装cgdb 说明在没有外网的centos6下尝试离线安装cgdb,花了很多时间，最后都没有成功，很挫败了。晚上在centos7下联网再试了一次,参考上面的文章轻轻松松搞定，这篇文章主要记录一下,跟参考的连接没有多大区别. 依赖[root@localhost ~]# yum install ncurses-devel [root@localhost ~]# yum install texinfo [root@localhost ~]# yum install readline-devel 编译安装[root@localhost ~]# wget https://github.com/cgdb/cgdb/archive/v0.7.0.tar.gz [root@localhost ~]# tar xf v0.7.0.tar.gz [root@localhost ~]# cd cgdb-0.7.0/ [root@localhost cgdb-0.7.0]# ./autogen.sh [root@localhost cgdb-0.7.0]# ./configure --prefix=$&#123;HOME&#125;/cgdb [root@localhost cgdb-0.7.0]# make &amp;&amp; make install 成果 ending","categories":[],"tags":[{"name":"gdb","slug":"gdb","permalink":"https://riverferry.site/tags/gdb/"}],"keywords":[]},{"title":"gdb进阶","slug":"2020-01-14-gdb进阶","date":"2020-01-14T00:00:00.000Z","updated":"2022-09-12T16:24:32.275Z","comments":true,"path":"2020-01-14-gdb进阶/","link":"","permalink":"https://riverferry.site/2020-01-14-gdb%E8%BF%9B%E9%98%B6/","excerpt":"参考100个gdb小技巧 100-gdb-tips","text":"参考100个gdb小技巧 100-gdb-tips 整理显示gdb版本(gdb) show version GNU gdb (GDB) Red Hat Enterprise Linux 7.6.1-114.el7 Copyright (C) 2013 Free Software Foundation, Inc. License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt; This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. Type &quot;show copying&quot; and &quot;show warranty&quot; for details. This GDB was configured as &quot;x86_64-redhat-linux-gnu&quot;. For bug reporting instructions, please see: &lt;http://www.gnu.org/software/gdb/bugs/&gt;. (gdb) 显示版权信息(gdb) show copying 启动时不显示提示信息gdb -q 也可以在~/.bashrc中，为gdb设置一个别名: alias rm=&#39;rm -i&#39; alias cp=&#39;cp -i&#39; alias mv=&#39;mv -i&#39; alias gdb=&quot;gdb -q&quot; 退出时不显示提示信息(gdb) set confirm off 也可以把这个命令加到.gdbinit文件里,在~路径下 输出信息不会暂停(gdb) set height 0 //方式一 (gdb) set pagination off //方式二 列出函数的名字(gdb) info function All defined functions: File client.c: int main(); Non-debugging symbols: 0x0000000000400630 _init 0x0000000000400630 _init 0x0000000000400660 inet_pton@plt 0x0000000000400670 close@plt 0x0000000000400680 __gmon_start__@plt 0x0000000000400690 puts@plt 0x00000000004006a0 htons@plt 0x00000000004006b0 __libc_start_main@plt 0x00000000004006c0 connect@plt 0x00000000004006d0 socket@plt 0x00000000004006e0 send@plt 0x00000000004006f0 perror@plt 0x0000000000400700 _start 0x0000000000400730 deregister_tm_clones 0x0000000000400760 register_tm_clones 0x00000000004007a0 __do_global_dtors_aux 0x00000000004007c0 frame_dummy 0x0000000000400940 __libc_csu_init 0x00000000004009b0 __libc_csu_fini 0x00000000004009b4 _fini 支持正则： (gdb) info function ^ma All functions matching regular expression &quot;^ma&quot;: File client.c: int main(); 进入带调试信息的函数step s next n 进入不带调试信息的函数123456789101112131415161718192021222324252627282930313233343536373839404142434445464748int main()&#123; int iConnFd = 0; char szAddr[] = &#123;&quot;127.0.0.1&quot;&#125;; struct sockaddr_in stServerAddr = &#123;0&#125;; for (int i = 0; i &lt; 10000; ++i) &#123; if ((iConnFd = socket(AF_INET, SOCK_STREAM, 0)) &lt; 0) &#123; perror(&quot;Failed to create socket!&quot;); return -1; &#125; stServerAddr.sin_family = AF_INET; stServerAddr.sin_port = htons(7777); if (inet_pton(AF_INET, szAddr, (void*)&amp;stServerAddr.sin_addr) &lt;= 0) &#123; perror(&quot;Failed to swicth ip addr!&quot;); close(iConnFd); iConnFd = -1; return -1; &#125; if (connect(iConnFd, (struct sockaddr*)&amp;stServerAddr, sizeof(stServerAddr)) &lt; 0) &#123; perror(&quot;Failed to connect!&quot;); close(iConnFd); &#125; else &#123; puts(&quot;connect ok!&quot;); &#125; if (i &gt;= 7) &#123; send(iConnFd,&quot;12345&quot;,6,0); &#125; if (i &gt; 10) while(1); &#125; return 0;&#125; 在socket这行，step 1,默认是不进入socket函数的，可以修改 (gdb) set step-mode on 退出正在调试的函数finish //到函数运行结束 return expression //直接返回 直接执行函数call func() print func() 打印函数堆栈帧信息(gdb) i frame Stack level 0, frame at 0x7fffffffe260: rip = 0x4007f8 in main (client.c:13); saved rip 0x7ffff721caf5 source language c++. Arglist at 0x7fffffffe250, args: Locals at 0x7fffffffe250, Previous frame&#39;s sp is 0x7fffffffe260 Saved registers: rbp at 0x7fffffffe250, rip at 0x7fffffffe258 (gdb) 打印尾调用堆栈帧信息这个感觉没啥用，也测试不出来 选择函数堆栈帧frame n frame addr //很少用 上下切换函数堆栈帧(gdb) bt #0 a () at test.c:4 #1 0x0000000000400549 in b () at test.c:9 #2 0x0000000000400554 in c () at test.c:14 #3 0x000000000040055f in main () at test.c:19 (gdb) where #0 a () at test.c:4 #1 0x0000000000400549 in b () at test.c:9 #2 0x0000000000400554 in c () at test.c:14 #3 0x000000000040055f in main () at test.c:19 (gdb) up 1 #1 0x0000000000400549 in b () at test.c:9 (gdb) #2 0x0000000000400554 in c () at test.c:14 (gdb) down 1 #1 0x0000000000400549 in b () at test.c:9 (gdb) #0 a () at test.c:4 (gdb) 切换后不打印信息，可以用： up-silently n down-silently n 在匿名空间设置断点12345678910111213141516namespace Foo&#123; void foo() &#123; &#125;&#125;namespace&#123; void bar() &#123; &#125;&#125; (gdb) b Foo::foo (gdb) b (anonymous namespace)::bar 英 /əˈnɒnɪməs/ `` 在程序地址上打断点(gdb) b *address 在程序入口处打断点先查询入口处地址,在b *address readelf [root@localhost wang]# readelf -h client ELF 头： Magic： 7f 45 4c 46 02 01 01 00 00 00 00 00 00 00 00 00 Class: ELF64 Data: 2&#39;s complement, little endian Version: 1 (current) OS/ABI: UNIX - System V ABI Version: 0 Type: EXEC (可执行文件) Machine: Advanced Micro Devices X86-64 Version: 0x1 入口点地址： 0x400700 程序头起点： 64 (bytes into file) Start of section headers: 4504 (bytes into file) 标志： 0x0 本头的大小： 64 (字节) 程序头大小： 56 (字节) Number of program headers: 9 节头大小： 64 (字节) 节头数量： 28 字符串表索引节头： 27 info files (gdb) info files Symbols from &quot;/home/wang/test&quot;. Local exec file: `/home/wang/test&#39;, file type elf64-x86-64. Entry point: 0x400440 0x0000000000400238 - 0x0000000000400254 is .interp 0x0000000000400254 - 0x0000000000400274 is .note.ABI-tag 0x0000000000400274 - 0x0000000000400298 is .note.gnu.build-id 0x0000000000400298 - 0x00000000004002b4 is .gnu.hash 0x00000000004002b8 - 0x0000000000400318 is .dynsym 0x0000000000400318 - 0x0000000000400355 is .dynstr 0x0000000000400318 - 0x0000000000400355 is .dynstr 0x0000000000400356 - 0x000000000040035e is .gnu.version 0x0000000000400360 - 0x0000000000400380 is .gnu.version_r 0x0000000000400380 - 0x0000000000400398 is .rela.dyn 0x0000000000400398 - 0x00000000004003e0 is .rela.plt 0x00000000004003e0 - 0x00000000004003fa is .init 0x0000000000400400 - 0x0000000000400440 is .plt 0x0000000000400440 - 0x00000000004005e2 is .text 0x00000000004005e4 - 0x00000000004005ed is .fini 0x00000000004005f0 - 0x0000000000400610 is .rodata 0x0000000000400610 - 0x000000000040065c is .eh_frame_hdr 0x0000000000400660 - 0x00000000004007b4 is .eh_frame 0x0000000000600e10 - 0x0000000000600e18 is .init_array 0x0000000000600e18 - 0x0000000000600e20 is .fini_array 0x0000000000600e20 - 0x0000000000600e28 is .jcr 0x0000000000600e28 - 0x0000000000600ff8 is .dynamic 0x0000000000600ff8 - 0x0000000000601000 is .got 0x0000000000601000 - 0x0000000000601030 is .got.plt 0x0000000000601030 - 0x0000000000601034 is .data 0x0000000000601034 - 0x0000000000601038 is .bss 在文件行号打断点b filename:linenum (gdb) b test.c:10 Breakpoint 2 at 0x400549: file test.c, line 10. 文件名重复的时候可以加路径 保存已经设置的断点(gdb) save break b.log Saved to file &#39;b.log&#39;. [root@localhost wang]# cat b.log break main break test.c:10 (gdb) source b.log Breakpoint 1 at 0x40055a: file test.c, line 19. Breakpoint 2 at 0x400549: file test.c, line 10. 设置临时断点(gdb) tbreak test.c:11 Temporary breakpoint 3 at 0x40054f: file test.c, line 11. 只生效一次 设置条件断点break ... if cond 忽略断点ignore breaknum count 1234567891011121314151617#include &lt;stdio.h&gt;int main(void)&#123; int i = 0; int sum = 0; for (i = 1; i &lt;= 200; i++) &#123; sum += i; &#125; printf(&quot;%d\\n&quot;, sum); return 0;&#125; ending","categories":[],"tags":[{"name":"gdb","slug":"gdb","permalink":"https://riverferry.site/tags/gdb/"}],"keywords":[]},{"title":"编解码函数","slug":"2019-12-26-编解码函数","date":"2019-12-26T00:00:00.000Z","updated":"2022-09-12T16:24:32.275Z","comments":true,"path":"2019-12-26-编解码函数/","link":"","permalink":"https://riverferry.site/2019-12-26-%E7%BC%96%E8%A7%A3%E7%A0%81%E5%87%BD%E6%95%B0/","excerpt":"参考","text":"参考 ending","categories":[],"tags":[{"name":"坑","slug":"坑","permalink":"https://riverferry.site/tags/%E5%9D%91/"}],"keywords":[]},{"title":"编码格式-utf8-gbk","slug":"2019-12-25-编码格式utf8-gbk","date":"2019-12-25T00:00:00.000Z","updated":"2022-09-12T16:24:32.275Z","comments":true,"path":"2019-12-25-编码格式utf8-gbk/","link":"","permalink":"https://riverferry.site/2019-12-25-%E7%BC%96%E7%A0%81%E6%A0%BC%E5%BC%8Futf8-gbk/","excerpt":"参考彻底搞懂编码 GBK 和 UTF8 维基百科 HexEditor 程序员必备：彻底弄懂常见的7种中文字符编码","text":"参考彻底搞懂编码 GBK 和 UTF8 维基百科 HexEditor 程序员必备：彻底弄懂常见的7种中文字符编码 GB2312 GB2312中对所收汉字进行了“分区”处理，每区含有94个汉字／符号，共计94个区。用所在的区和位来表示字符（实际上就是码位），因此称为区位码（或许叫“区位号”更为恰当）。表示方式也称为区位码。例如“万”字在45区82位，所以“万”字的区位码是：45 82. GB2312编码就是基于区位码的，用双字节编码表示中文和中文符号。GB2312编码方式是：0xA0+区号，0xA0+位号。对于GB 2312，是8比特双字节编码。其汉字编码空间为94 x 94，即有94个区，每个区有94个位（用来编码字符）。实际使用了16-55区编码一级汉字，56-87区编码二级汉字。这些汉字均放在了G1字符块区。这种区位码方案是GB 2312的逻辑设计。其具体的字符编码方案（Character Encoding Scheme）：字节值在0x00-0x7F，为单字节表示一个字符，构成了C0、G0区，与ASCII码兼容。因此，GB 2312是单、双字节混合编码。 单字节和双字节gbk 对于遵从ISO 2022的8比特编码字符集，也是按照上述7比特编码原则设计的编码方案。这种8比特编码字符集很容易兼容当时的7比特宽的通信协议/通信设备。8比特字符编码时，0x00-0x1F表示C0或称CL区（L是left缩写，因为其在字符表的左侧），0x80-0x9F表示C1或称CR（R是Right缩写，因为其在字符表的右侧）。0x20-0x7F表示G0（称GL区），0xA0-0xFF（称GR区）可表示G1, G2, G3。 EUC-CN EUC最初是针对Unix系统，由一些Unix公司所开发，于1991年标准化。EUC基于ISO/IEC 2022的7位编码标准，因此单字节的编码空间为94，双字节的编码空间（区位码）为94x94。把每个区位加上0xA0来表示，以便符合ISO 2022。它主要用于表示及储存汉语文字、日语文字及朝鲜文字。 字符块 低端控制字符(C0) US-ASCII字符集(GL) 高端控制字符(C1) 高端字符(GR)是特定于每个ISO-8859-X变种。例如ISO-8859-1是由ISO-IR-1, ISO-IR-6, ISO-IR-77, ISO-IR-100 组成。 区位码 区位码是1980年中国制定的一个字符编码标准。每一个字符都有对应一个4位十进制数字码位表示，其中前两位为“区”，后两位为“位”。中文汉字的编号区号是从16开始的，位号从1开始。 01~09区（682个）：特殊符号、数字、英文字符、制表符等，包括拉丁字母、希腊字母、日文平假名及片假名字母、俄语西里尔字母等在内的682个全角字符； 10~15区：空区，留待扩展；在附录3，第10区推荐作为 GB 1988–80 中的94个图形字符区域（即第3区字符之半形版本）。 16~55区（3755个）：常用汉字（也称一级汉字），按拼音排序； 56~87区（3008个）：非常用汉字（也称二级汉字），按部首/笔画排序； 88~94区：空区，留待扩展。 啊(1601) 阿(1602) 埃(1603) 挨(1604) 哎(1605) 唉(1606) 哀(1607) 皑(1608) 癌(1609) 蔼(1610)矮(1611) 艾(1612) 碍(1613) 爱(1614) 隘(1615) 鞍(1616) 氨(1617) 安(1618) 俺(1619) 按(1620)暗(1621) 岸(1622) 胺(1623) 案(1624) 肮(1625) 昂(1626) 盎(1627) 凹(1628) 敖(1629) 熬(1630)翱(1631) 袄(1632) 傲(1633) 奥(1634) 懊(1635) 澳(1636) 芭(1637) 捌(1638) 扒(1639) 叭(1640)吧(1641) 笆(1642) 八(1643) 疤(1644) 巴(1645) 拔(1646) 跋(1647) 靶(1648) 把(1649) 耙(1650)坝(1651) 霸(1652) 罢(1653) 爸(1654) 白(1655) 柏(1656) 百(1657) 摆(1658) 佰(1659) 败(1660)拜(1661) 稗(1662) 斑(1663) 班(1664) 搬(1665) 扳(1666) 般(1667) 颁(1668) 板(1669) 版(1670)扮(1671) 拌(1672) 伴(1673) 瓣(1674) 半(1675) 办(1676) 绊(1677) 邦(1678) 帮(1679) 梆(1680)榜(1681) 膀(1682) 绑(1683) 棒(1684) 磅(1685) 蚌(1686) 镑(1687) 傍(1688) 谤(1689) 苞(1690)胞(1691) 包(1692) 褒(1693) 剥(1694) 薄(1701) 雹(1702) 保(1703) 堡(1704) 饱(1705) 宝(1706)抱(1707) 报(1708) 暴(1709) 豹(1710) 鲍(1711) 爆(1712) 杯(1713) 碑(1714) 悲(1715) 卑(1716)北(1717) 辈(1718) 背(1719) 贝(1720) 钡(1721) 倍(1722) 狈(1723) 备(1724) 惫(1725) 焙(1726) 葡(3847) 萄(4449) hex+0XA0: 0XA0+38 0XA0+47 0XA0+44 0XA0+49 C6 CF CC D1 utf-8### FSS-UTF (1992) / UTF-8 (1993)[1] Number of bytes Firstcode point Lastcode point Byte 1 Byte 2 Byte 3 Byte 4 Byte 5 Byte 6 １ U+0000 U+007F 0xxxxxxx &lt;tr&gt; &lt;td&gt;２&lt;/td&gt; &lt;td&gt;U+0080&lt;/td&gt; &lt;td&gt;U+07FF&lt;/td&gt; &lt;td&gt;110xxxxx&lt;/td&gt; &lt;td&gt;10xxxxxx&lt;/td&gt; &lt;td&gt;&lt;/td&gt; &lt;td&gt;&lt;/td&gt; &lt;td&gt;&lt;/td&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;３&lt;/td&gt; &lt;td&gt;U+0800&lt;/td&gt; &lt;td&gt;U+FFFF&lt;/td&gt; &lt;td&gt;1110xxxx&lt;/td&gt; &lt;td&gt;10xxxxxx&lt;/td&gt; &lt;td&gt;10xxxxxx&lt;/td&gt; &lt;td&gt;&lt;/td&gt; &lt;td&gt;&lt;/td&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;４&lt;/td&gt; &lt;td&gt;U+10000&lt;/td&gt; &lt;td&gt;U+1FFFFF&lt;/td&gt; &lt;td&gt;11110xxx&lt;/td&gt; &lt;td&gt;10xxxxxx&lt;/td&gt; &lt;td&gt;10xxxxxx&lt;/td&gt; &lt;td&gt;10xxxxxx&lt;/td&gt; &lt;td&gt;&lt;/td&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;５&lt;/td&gt; &lt;td&gt;U+200000&lt;/td&gt; &lt;td&gt;U+3FFFFFF&lt;/td&gt; &lt;td&gt;111110xx&lt;/td&gt; &lt;td&gt;10xxxxxx&lt;/td&gt; &lt;td&gt;10xxxxxx&lt;/td&gt; &lt;td&gt;10xxxxxx&lt;/td&gt; &lt;td&gt;10xxxxxx&lt;/td&gt; &lt;td&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;６&lt;/td&gt; &lt;td&gt;U+4000000&lt;/td&gt; &lt;td&gt;U+7FFFFFFF&lt;/td&gt; &lt;td&gt;1111110x&lt;/td&gt; &lt;td&gt;10xxxxxx&lt;/td&gt; &lt;td&gt;10xxxxxx&lt;/td&gt; &lt;td&gt;10xxxxxx&lt;/td&gt; &lt;td&gt;10xxxxxx&lt;/td&gt; &lt;td&gt;10xxxxxx&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; 对于UTF-8编码中的任意字节B，如果B的第一位为0，则B独立的表示一个字符(ASCII码)； 如果B的第一位为1，第二位为0，则B为一个多字节字符中的一个字节(非ASCII字符)； 如果B的前两位为1，第三位为0，则B为两个字节表示的字符中的第一个字节，第2个字节是10开头. 如果B的前三位为1，第四位为0，则B为三个字节表示的字符中的第一个字节；第2，3个字节是10开头. 如果B的前四位为1，第五位为0，则B为四个字节表示的字符中的第一个字节；第2，3，4个字节是10开头. 如果B的前五位为1，第五位为0，则B为四个字节表示的字符中的第一个字节；第2，3，4，5个字节是10开头. 如果B的前六位为1，第五位为0，则B为四个字节表示的字符中的第一个字节；第2，3，4，5，6个字节是10开头. UTF-8使用一至六个字节为每个字符编码（尽管如此，2003年11月UTF-8被RFC 3629重新规范，只能使用原来Unicode定义的区域，U+0000到U+10FFFF，也就是说最多四个字节）： 再淡UNICODE待补充 ending","categories":[],"tags":[{"name":"encoding format","slug":"encoding-format","permalink":"https://riverferry.site/tags/encoding-format/"}],"keywords":[]},{"title":"nginx源码分析-内存池","slug":"2019-12-16-nginx源码分析-内存池","date":"2019-12-16T00:00:00.000Z","updated":"2022-09-12T16:24:32.275Z","comments":true,"path":"2019-12-16-nginx源码分析-内存池/","link":"","permalink":"https://riverferry.site/2019-12-16-nginx%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-%E5%86%85%E5%AD%98%E6%B1%A0/","excerpt":"参考Nginx源代码情景分析（3）——Nginx内存管理-1 Nginx源码剖析之内存池，与内存管理 chronolaw/annotated_nginx","text":"参考Nginx源代码情景分析（3）——Nginx内存管理-1 Nginx源码剖析之内存池，与内存管理 chronolaw/annotated_nginx ngx_pool_t123456789101112131415161718192021222324252627282930/* 内存池链表结构体 */typedef struct ngx_pool_s ngx_pool_t; struct ngx_pool_s &#123; ngx_pool_data_t d; size_t max; ngx_pool_t *current; ngx_chain_t *chain; ngx_pool_large_t *large; ngx_pool_cleanup_t *cleanup; ngx_log_t *log;&#125;;/* 小块内存的数据区结构体 */typedef struct &#123; u_char *last; u_char *end; ngx_pool_t *next; ngx_uint_t failed;&#125; ngx_pool_data_t;/* 大块内存的链表结构体 */typedef struct ngx_pool_large_s ngx_pool_large_t;struct ngx_pool_large_s &#123; ngx_pool_large_t *next; void *alloc;&#125;; ngx_create_pool12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455//创建ngx_pool_t内存链表的函数ngx_pool_t *ngx_create_pool(size_t size, ngx_log_t *log)&#123; ngx_pool_t *p; p = ngx_memalign(NGX_POOL_ALIGNMENT, size, log); if (p == NULL) &#123; return NULL; &#125; p-&gt;d.last = (u_char *) p + sizeof(ngx_pool_t); p-&gt;d.end = (u_char *) p + size; p-&gt;d.next = NULL; p-&gt;d.failed = 0; size = size - sizeof(ngx_pool_t); //内存页大小，4096字节 p-&gt;max = (size &lt; NGX_MAX_ALLOC_FROM_POOL) ? size : NGX_MAX_ALLOC_FROM_POOL; p-&gt;current = p; p-&gt;chain = NULL; p-&gt;large = NULL; p-&gt;cleanup = NULL; p-&gt;log = log; return p;&#125;//在main函数中 ngx_cycle_t *cycle, init_cycle;init_cycle.pool = ngx_create_pool(1024, log)//进程启动阶段init_cycle中保存了最早申请的内存池,这时候ngx_poll_t中的date的last的值应该还是没有申请后未使用的.//ngx_memalign函数用于申请小块内存,内部也是调用memalign,具体见下面对此函数的解释void *ngx_memalign(size_t alignment, size_t size, ngx_log_t *log)&#123; void *p; p = memalign(alignment, size); if (p == NULL) &#123; ngx_log_error(NGX_LOG_EMERG, log, ngx_errno, &quot;memalign(%uz, %uz) failed&quot;, alignment, size); &#125; ngx_log_debug3(NGX_LOG_DEBUG_ALLOC, log, 0, &quot;memalign: %p:%uz @%uz&quot;, p, size, alignment); return p;&#125; 12345678910111213141516init_cycle.pool = (ngx_pool_t *) 0x6d2420init_cycle.pool.d = &#123;last = 0x6d2470 &quot;&quot;, end = 0x6d2820 &quot;&quot;, next = 0x0, failed = 0&#125;init_cycle.pool = &#123; d = &#123;last = 0x6d2470 &quot;&quot;, end = 0x6d2820 &quot;&quot;, next = 0x0, failed = 0&#125;, max = 944, current = 0x6d2420, chain = 0x0, large = 0x0, cleanup = 0x0, log = 0x6afe60 &lt;ngx_log&gt; &#125;last - pool = 80 = sizeof(ngx_pool_t)end - pool = 1024 = size 和ngx_create_pool函数是一致的，end指向pool+size的位置，而ngx_pool_t这80个字节是1024的前80字节，也是堆中的内存。所以实际可用的内存只有1024-80 = 944 = max。 memalign1234#include &lt;stdlib.h&gt;void *memalign(size_t alignment, size_t size); The memalign() function returns a block of memory of size bytes aligned to blocksize. The blocksize must be given as a power of two. It sets errno and returns a null pointer upon failure. 函数 memalign返回按alignment个字节对齐的内存。alignment必须是2的幂。 Pointers returned by memalign() may be passed to free(). Pointers passed to realloc() are checked and if not aligned to the system, the realloc() fails and returns NULL. ngx_destroy_pool123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263#define ngx_free free//类似c++的析构函数，这里要释放小块，大块内存，还有自定义的&quot;文件&quot;voidngx_destroy_pool(ngx_pool_t *pool)&#123; ngx_pool_t *p, *n; ngx_pool_large_t *l; ngx_pool_cleanup_t *c; //释放自定义的内存，可能是文件或者套接字之类的 //handle是需要自定义实现的释放函数 for (c = pool-&gt;cleanup; c; c = c-&gt;next) &#123; if (c-&gt;handler) &#123; ngx_log_debug1(NGX_LOG_DEBUG_ALLOC, pool-&gt;log, 0, &quot;run cleanup: %p&quot;, c); c-&gt;handler(c-&gt;data); &#125; &#125;#if (NGX_DEBUG) /* * we could allocate the pool-&gt;log from this pool * so we cannot use this log while free()ing the pool */ for (l = pool-&gt;large; l; l = l-&gt;next) &#123; ngx_log_debug1(NGX_LOG_DEBUG_ALLOC, pool-&gt;log, 0, &quot;free: %p&quot;, l-&gt;alloc); &#125; for (p = pool, n = pool-&gt;d.next; /* void */; p = n, n = n-&gt;d.next) &#123; ngx_log_debug2(NGX_LOG_DEBUG_ALLOC, pool-&gt;log, 0, &quot;free: %p, unused: %uz&quot;, p, p-&gt;d.end - p-&gt;d.last); if (n == NULL) &#123; break; &#125; &#125;#endif //释放大块内存 for (l = pool-&gt;large; l; l = l-&gt;next) &#123; if (l-&gt;alloc) &#123; ngx_free(l-&gt;alloc); &#125; &#125; //先释放大块内存的数据库，然后释放pool，意味着既释放了小块内存的数据区，又把结构体本身释放掉了. //释放小块内存 for (p = pool, n = pool-&gt;d.next; /* void */; p = n, n = n-&gt;d.next) &#123; //申请的时候malloc的返回值就是p,申请的1024个字节在这里就都释放了 ngx_free(p); if (n == NULL) &#123; break; &#125; &#125;&#125; ngx_reset_pool123456789101112131415161718192021222324252627//重置内存池，恢复到创建的初始阶段voidngx_reset_pool(ngx_pool_t *pool)&#123; ngx_pool_t *p; ngx_pool_large_t *l; //删除大块内存 for (l = pool-&gt;large; l; l = l-&gt;next) &#123; if (l-&gt;alloc) &#123; ngx_free(l-&gt;alloc); &#125; &#125; //置last为create时的位置，即小块内存数据区的起始位置 for (p = pool; p; p = p-&gt;d.next) &#123; p-&gt;d.last = (u_char *) p + sizeof(ngx_pool_t); p-&gt;d.failed = 0; &#125; pool-&gt;current = pool; pool-&gt;chain = NULL; pool-&gt;large = NULL;&#125; ngx_palloc/ngx_pnallocngx_palloc 按照字节对齐 ngx_pnalloc 不按照字节对齐 即ngx_palloc_small的第三个参数不同，大块内存都是不考虑对齐的 1234567891011121314151617181920212223242526272829// 如果编译时指定宏NGX_DEBUG_PALLOC// 则不会启用内存池机制，都使用malloc分配内存void *ngx_palloc(ngx_pool_t *pool, size_t size)&#123;//如果小块内存够用就申请小块内存,否则申请大块内存#if !(NGX_DEBUG_PALLOC) if (size &lt;= pool-&gt;max) &#123; return ngx_palloc_small(pool, size, 1); &#125;#endif return ngx_palloc_large(pool, size);&#125;void *ngx_pnalloc(ngx_pool_t *pool, size_t size)&#123;#if !(NGX_DEBUG_PALLOC) if (size &lt;= pool-&gt;max) &#123; return ngx_palloc_small(pool, size, 0); &#125;#endif return ngx_palloc_large(pool, size);&#125; ngx_pcalloc12345678910111213141516//申请内存并初始化,类似cmalloc void *ngx_pcalloc(ngx_pool_t *pool, size_t size)&#123; void *p; p = ngx_palloc(pool, size); if (p) &#123; ngx_memzero(p, size); &#125; return p;&#125; ngx_palloc_small1234567891011121314151617181920212223242526272829303132333435static ngx_inline void *ngx_palloc_small(ngx_pool_t *pool, size_t size, ngx_uint_t align);//static ngx_inline void *ngx_palloc_small(ngx_pool_t *pool, size_t size, ngx_uint_t align)&#123; u_char *m; ngx_pool_t *p; p = pool-&gt;current; do &#123; m = p-&gt;d.last; //后面补充 if (align) &#123; m = ngx_align_ptr(m, NGX_ALIGNMENT); &#125; //遍历链表找到空闲区域 if ((size_t) (p-&gt;d.end - m) &gt;= size) &#123; p-&gt;d.last = m + size; return m; &#125; p = p-&gt;d.next; &#125; while (p); return ngx_palloc_block(pool, size);&#125; ngx_align_ptr123456789101112131415161718192021222324252627282930313233343536#define ngx_align(d, a) (((d) + (a - 1)) &amp; ~(a - 1))#define ngx_align_ptr(p, a) \\ (u_char *) (((uintptr_t) (p) + ((uintptr_t) a - 1)) &amp; ~((uintptr_t) a - 1))//ngx_config.htypedef intptr_t ngx_int_t;typedef uintptr_t ngx_uint_t;//上面intptr_t，uintptr_t的定义在linux系统的文件/usr/include/stdint.h/* Types for `void *&#x27; pointers. */ #if __WORDSIZE == 64 # ifndef __intptr_t_defined typedef long int intptr_t; # define __intptr_t_defined # endif typedef unsigned long int uintptr_t; #else # ifndef __intptr_t_defined typedef int intptr_t; # define __intptr_t_defined # endif typedef unsigned int uintptr_t; #endif/*64位系统下uintptr_t是unsigned long in32位系统下uintptr_t是unsinged int*//*再看(((d) + (a - 1)) &amp; ~(a - 1))这个表达式a是2的幂(memalign返回按alignment个字节对齐的内存。alignment必须是2的幂),所以(a-1)就是二进制位右边为1，左边原来1的那位为0，再取反，然后按位与，就是把a原来右边为0的位清除掉了。保留d在a原来1的那位左边的，并且保证了这个值最小是a。所以肯定是a的倍数.*/ ngx_palloc_large12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849static void *ngx_palloc_large(ngx_pool_t *pool, size_t size);//static void *ngx_palloc_large(ngx_pool_t *pool, size_t size)&#123; void *p; ngx_uint_t n; ngx_pool_large_t *large; //大块内存直接malloc p = ngx_alloc(size, pool-&gt;log); if (p == NULL) &#123; return NULL; &#125; n = 0; //将malloc的地址存于大块内存链表 for (large = pool-&gt;large; large; large = large-&gt;next) &#123; if (large-&gt;alloc == NULL) &#123; large-&gt;alloc = p; return p; &#125; //超过三次放弃，避免便利链表效率太低 //3可能是作者的经验值吧 if (n++ &gt; 3) &#123; break; &#125; &#125; //找不到就重新申请结构体，加入内存池链表 large = ngx_palloc_small(pool, sizeof(ngx_pool_large_t), 1); if (large == NULL) &#123; ngx_free(p); return NULL; &#125; //新申请的存于链表头,头插法 large-&gt;alloc = p; large-&gt;next = pool-&gt;large; pool-&gt;large = large; return p;&#125; ngx_palloc_block12345678910111213141516171819202122232425262728293031323334353637383940414243static void *ngx_palloc_block(ngx_pool_t *pool, size_t size);//注意这个函数是在ngx_palloc_small函数中便利小块内存链表后没有找到空闲链表的情况下调用的，是用来申请新的空间挂接到链表尾的。//不同于ngx_create_pool函数，本函数申请小块内存后last指向要+size大小static void *ngx_palloc_block(ngx_pool_t *pool, size_t size)&#123; u_char *m; size_t psize; ngx_pool_t *p, *new; psize = (size_t) (pool-&gt;d.end - (u_char *) pool); m = ngx_memalign(NGX_POOL_ALIGNMENT, psize, pool-&gt;log); if (m == NULL) &#123; return NULL; &#125; new = (ngx_pool_t *) m; new-&gt;d.end = m + psize; new-&gt;d.next = NULL; new-&gt;d.failed = 0; m += sizeof(ngx_pool_data_t); m = ngx_align_ptr(m, NGX_ALIGNMENT); new-&gt;d.last = m + size; //因为之前create函数已经遍历过没有找到，所以这里给failed+1 //这里应该也是经验值吧，达到5次这里把pool-&gt;current更新为p-&gt;d.next for (p = pool-&gt;current; p-&gt;d.next; p = p-&gt;d.next) &#123; if (p-&gt;d.failed++ &gt; 4) &#123; pool-&gt;current = p-&gt;d.next; &#125; &#125; //新申请的内存挂到链表尾部，尾插法(和大块内存不同) p-&gt;d.next = new; return m;&#125; ngx_pmemalign123456789101112131415161718192021222324252627//申请大块内存，并且字节对齐void *ngx_pmemalign(ngx_pool_t *pool, size_t size, size_t alignment)&#123; void *p; ngx_pool_large_t *large; p = ngx_memalign(alignment, size, pool-&gt;log); if (p == NULL) &#123; return NULL; &#125; large = ngx_palloc_small(pool, sizeof(ngx_pool_large_t), 1); if (large == NULL) &#123; ngx_free(p); return NULL; &#125; large-&gt;alloc = p; large-&gt;next = pool-&gt;large; pool-&gt;large = large; return p;&#125; ngx_pfree12345678910111213141516171819202122//释放指定的大块内存ngx_int_tngx_pfree(ngx_pool_t *pool, void *p)&#123; ngx_pool_large_t *l; for (l = pool-&gt;large; l; l = l-&gt;next) &#123; if (p == l-&gt;alloc) &#123; ngx_log_debug1(NGX_LOG_DEBUG_ALLOC, pool-&gt;log, 0, &quot;free: %p&quot;, l-&gt;alloc); ngx_free(l-&gt;alloc); l-&gt;alloc = NULL; return NGX_OK; &#125; &#125; return NGX_DECLINED;&#125; ngx_pool_cleanup_add1234567891011121314151617181920212223242526272829303132ngx_pool_cleanup_t *ngx_pool_cleanup_add(ngx_pool_t *p, size_t size)&#123; ngx_pool_cleanup_t *c; c = ngx_palloc(p, sizeof(ngx_pool_cleanup_t)); if (c == NULL) &#123; return NULL; &#125; if (size) &#123; c-&gt;data = ngx_palloc(p, size); if (c-&gt;data == NULL) &#123; return NULL; &#125; &#125; else &#123; c-&gt;data = NULL; &#125; c-&gt;handler = NULL; c-&gt;next = p-&gt;cleanup; p-&gt;cleanup = c; ngx_log_debug1(NGX_LOG_DEBUG_ALLOC, p-&gt;log, 0, &quot;add cleanup: %p&quot;, c); return c;&#125; ngx_pool_run_cleanup_file12345678910111213141516171819202122voidngx_pool_run_cleanup_file(ngx_pool_t *p, ngx_fd_t fd)&#123; ngx_pool_cleanup_t *c; ngx_pool_cleanup_file_t *cf; for (c = p-&gt;cleanup; c; c = c-&gt;next) &#123; if (c-&gt;handler == ngx_pool_cleanup_file) &#123; cf = c-&gt;data; if (cf-&gt;fd == fd) &#123; c-&gt;handler(cf); c-&gt;handler = NULL; return; &#125; &#125; &#125;&#125; ngx_pool_cleanup_file12345678910111213141516voidngx_pool_cleanup_file(void *data)&#123; ngx_pool_cleanup_file_t *c = data; ngx_log_debug1(NGX_LOG_DEBUG_ALLOC, c-&gt;log, 0, &quot;file cleanup: fd:%d&quot;, c-&gt;fd); if (ngx_close_file(c-&gt;fd) == NGX_FILE_ERROR) &#123; ngx_log_error(NGX_LOG_ALERT, c-&gt;log, ngx_errno, ngx_close_file_n &quot; \\&quot;%s\\&quot; failed&quot;, c-&gt;name); &#125;&#125; ngx_pool_delete_file123456789101112131415161718192021222324252627voidngx_pool_delete_file(void *data)&#123; ngx_pool_cleanup_file_t *c = data; ngx_err_t err; ngx_log_debug2(NGX_LOG_DEBUG_ALLOC, c-&gt;log, 0, &quot;file cleanup: fd:%d %s&quot;, c-&gt;fd, c-&gt;name); if (ngx_delete_file(c-&gt;name) == NGX_FILE_ERROR) &#123; err = ngx_errno; if (err != NGX_ENOENT) &#123; ngx_log_error(NGX_LOG_CRIT, c-&gt;log, err, ngx_delete_file_n &quot; \\&quot;%s\\&quot; failed&quot;, c-&gt;name); &#125; &#125; if (ngx_close_file(c-&gt;fd) == NGX_FILE_ERROR) &#123; ngx_log_error(NGX_LOG_ALERT, c-&gt;log, ngx_errno, ngx_close_file_n &quot; \\&quot;%s\\&quot; failed&quot;, c-&gt;name); &#125;&#125; 遗留问题ngx_align_ptr和memalign的区别 cleanup函数的使用 ending","categories":[],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://riverferry.site/tags/nginx/"}],"keywords":[]},{"title":"ping携带时间信息-NTP时间同步报错-vmware虚拟机克隆报错","slug":"2019-12-03-ping携带时间信息-NTP时间同步报错-vmware虚拟机克隆报错","date":"2019-12-03T00:00:00.000Z","updated":"2022-09-12T16:24:32.275Z","comments":true,"path":"2019-12-03-ping携带时间信息-NTP时间同步报错-vmware虚拟机克隆报错/","link":"","permalink":"https://riverferry.site/2019-12-03-ping%E6%90%BA%E5%B8%A6%E6%97%B6%E9%97%B4%E4%BF%A1%E6%81%AF-NTP%E6%97%B6%E9%97%B4%E5%90%8C%E6%AD%A5%E6%8A%A5%E9%94%99-vmware%E8%99%9A%E6%8B%9F%E6%9C%BA%E5%85%8B%E9%9A%86%E6%8A%A5%E9%94%99/","excerpt":"ping携带时间信息ping www.baidu.com | awk &#39;&#123; print strftime(&quot;%Y.%m.%d %H:%M:%S&quot;,systime())&quot;\\t&quot; $0 &#125;&#39; &gt; ping.log","text":"ping携带时间信息ping www.baidu.com | awk &#39;&#123; print strftime(&quot;%Y.%m.%d %H:%M:%S&quot;,systime())&quot;\\t&quot; $0 &#125;&#39; &gt; ping.log 说明awk目前还不太熟,暂不研究.需要注意的是这个命令执行后不会立即生效,需要等一会.我电脑上验证大概是每次打印50条左右的结果,然后等1分钟左右再次打印50条,以此循环.猜测应该和awk命令有关吧.网上的资料都没有提到这一点,第一次使用的时候我原以为该命令不可用,还觉得很是奇怪… NTP时间同步报错参考： ntpdate server时出错原因及解决 centos7安装设置NTP服务器 两台windows上NTP服务器和客户端的安装与使用总结 /etc/ntp/keys 如何使用对称密钥配置经过身份验证的NTP 服务器端安装成功: [root@localhost ~]# ntpq -p remote refid st t when poll reach delay offset jitter ============================================================================== 192.168.1.200 .INIT. 16 u - 64 0 0.000 0.000 0.000 h199-182-204-19 .INIT. 16 u - 64 0 0.000 0.000 0.000 *stratum2-1.ntp. 89.175.20.7 2 u 49 64 3 196.692 -288005 1.946 ntp1.flashdance .INIT. 16 u - 64 0 0.000 0.000 0.000 ntp1.ams1.nl.le 130.133.1.10 2 u 45 64 1 301.453 -288005 0.247 LOCAL(0) .LOCL. 5 l 115 64 2 0.000 0.000 0.000 linux客户端同步成功: [root@localhost ~]# ntpdate 192.168.1.200 5 Dec 07:56:54 ntpdate[47053]: step time server 192.168.1.200 offset 83532.353696 sec windows客户端同步成功: C:\\Windows\\system32&gt;ntpdate -b 192.168.1.200 5 Dec 08:17:52 ntpdate[59164]: Raised to realtime priority class 5 Dec 08:17:58 ntpdate[59164]: step time server 192.168.1.200 offset 0.001218 sec 这里主要想说明遇到的一个问题,就是自己搭建的ntp服务器和客户端.当服务器刚启动后,客户端ntpdate -d ServerIp连接服务器会报错:no server suitable for synchronization found.并且错误信息中有stratum 16，stratum是ntp服务器层级，正常情况下stratum的值为“0~15”。而stratum=16是因为NTP server还没有和它的上层NTP server同步上。具体愿意可以看上面的参考文章. 我自己在家里电脑搭了两个虚拟机进行复现居然没复现出来,我怀疑可能是我ntpd服务版本太高,已经把这一点完善了? [root@localhost ~]# ntpd --version ntpd 4.2.6p5 exit 0 so, 本来想记录一个问题的解决方法,最后阴差阳错,变成了Ntpd的安装过程记录. 卸载ntpsystemctl stop ntpd #停止ntp服务 systemctl disable ntpd #禁止ntp服务随系统启动 yum remove ntp #卸载ntp软件包 libopts.so.25安装完后有包过一次过,提示没有libopts.so.25这个库文件,下载地址: libopts.so.25 然后rpm -iv autogen-libopts-5.18-5.el7.x86_64 vmware虚拟机克隆报错参考: VMware虚拟机中如何配置静态IP CentOS7 Failed to start LSB: Bring up/down networking 说明 我电脑只装了一个虚拟机,这回需要两台配合使用.从头搭建比较麻烦,就使用了vmware的克隆功能,克隆后出现了一些问题,记录下: 首先是网络问题,克隆后所有配置都和上一台原始机器一致,导致ip地址不可用.我上一台机器的网络都是配置好了的,这里克隆机需要修改的地方不多. 路径 /etc/sysconfig/network-scripts/ifcfg-eth0 [root@localhost network-scripts]# cat ifcfg-eno16777736 HWADDR=**:**:**:**:**:** TYPE=Ethernet BOOTPROTO=static DEFROUTE=yes PEERDNS=yes PEERROUTES=yes IPV4_FAILURE_FATAL=no IPV6INIT=no IPV6_AUTOCONF=yes IPV6_DEFROUTE=yes IPV6_PEERDNS=yes IPV6_PEERROUTES=yes IPV6_FAILURE_FATAL=no NAME=eno16777736 UUID=9b89c5b7-6cd0-488f-baf4-59aa6f711264 ONBOOT=yes IPADDR=192.***.*.*** GATEWAY=192.168.1.2 NETMASK=255.255.255.0 DNS1=8.8.8.8 将上面文件中的IPADDR这一项IP地址修改为新的值,然后我尝试重启network: Failed to start LSB: Bring up/down networking 原因是mac地址不对,通过ip addr查看本机mac地址填入/etc/sysconfig/network-scripts/ifcfg-eth0文件对应HWADDR即可. ending","categories":[],"tags":[{"name":"运维","slug":"运维","permalink":"https://riverferry.site/tags/%E8%BF%90%E7%BB%B4/"}],"keywords":[]},{"title":"linux文件系统","slug":"2019-12-05-linux文件系统","date":"2019-12-03T00:00:00.000Z","updated":"2022-09-12T16:24:32.275Z","comments":true,"path":"2019-12-05-linux文件系统/","link":"","permalink":"https://riverferry.site/2019-12-05-linux%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/","excerpt":"前言linux文件系统内部结构是一直感兴趣的地方,但这块网上资料很少也很零散,并且浮于表面的居多.正好近期遇到的项目和这块有一丁点关系,今天先开个篇.希望后面能够把这块整体梳理一遍.","text":"前言linux文件系统内部结构是一直感兴趣的地方,但这块网上资料很少也很零散,并且浮于表面的居多.正好近期遇到的项目和这块有一丁点关系,今天先开个篇.希望后面能够把这块整体梳理一遍. 正文ending","categories":[],"tags":[{"name":"坑","slug":"坑","permalink":"https://riverferry.site/tags/%E5%9D%91/"}],"keywords":[]},{"title":"nginx源码分析-main","slug":"2019-12-10-nginx源码分析-main","date":"2019-12-03T00:00:00.000Z","updated":"2022-09-12T16:24:32.275Z","comments":true,"path":"2019-12-10-nginx源码分析-main/","link":"","permalink":"https://riverferry.site/2019-12-10-nginx%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90-main/","excerpt":"前言Nginx开发从入门到精通 reading-code-of-nginx-1.9.2","text":"前言Nginx开发从入门到精通 reading-code-of-nginx-1.9.2 正文//用最新的nginx版本和源码进行学习 [root@localhost ~]# nginx -v nginx version: nginx/1.17.6 pid process 9774 master 9775 worker root 9774 0.0 0.0 46380 996 ? Ss 23:05 0:00 nginx: master process nginx nginx 9775 0.0 0.0 46776 1944 ? S 23:05 0:00 nginx: worker process root 10019 0.0 0.0 112676 976 pts/0 R+ 23:10 0:00 grep --color=auto nginx nginx,9774 └─nginx,9775 stack 9775 #0 0x00007f39d163f763 in __epoll_wait_nocancel () from /lib64/libc.so.6 #1 0x00007f39d2d241c3 in ngx_epoll_process_events () #2 0x00007f39d2d1a8e4 in ngx_process_events_and_timers () #3 0x00007f39d2d226e1 in ngx_worker_process_cycle () #4 0x00007f39d2d20b8b in ngx_spawn_process () #5 0x00007f39d2d21d90 in ngx_start_worker_processes () #6 0x00007f39d2d230a3 in ngx_master_process_cycle () #7 0x00007f39d2cfa12f in main () stack 9774 #0 0x00007f39d157e916 in sigsuspend () from /lib64/libc.so.6 #1 0x00007f39d2d230f6 in ngx_master_process_cycle () #2 0x00007f39d2cfa12f in main () master &gt; mainngx_int_t ngx_strerror_init(void); 函数作用:把系统错误信息保存到数组ngx_sys_errlist内,相当于重写了stderr: NGX_SYS_NERR，这是一个宏定义，是在auto/unix脚本中设置的 ngx_sys_errlist: len = 7, data = 0x6d0890 &quot;Success&quot; len = 23, data = 0x6d08b0 &quot;Operation not permitted&quot; len = 25, data = 0x6d08d0 &quot;No such file or directory&quot; len = 15, data = 0x6d0900 &quot;No such process&quot; len = 23, data = 0x6d0920 &quot;Interrupted system call&quot; len = 18, data = 0x6d0940 &quot;Input/output error&quot; len = 25, data = 0x6d0960 &quot;No such device or address&quot; len = 22, data = 0x6d0990 &quot;Argument list too long&quot; len = 17, data = 0x6d09b0 &quot;Exec format error&quot; len = 19, data = 0x6d09d0 &quot;Bad file descriptor&quot; len = 18, data = 0x6d09f0 &quot;No child processes&quot; len = 32, data = 0x6d0a10 &quot;Resource temporarily unavailable&quot; len = 22, data = 0x6d0a40 &quot;Cannot allocate memory&quot; len = 17, data = 0x6d0a60 &quot;Permission denied&quot; len = 11, data = 0x6d0a80 &quot;Bad address&quot; len = 21, data = 0x6d0aa0 &quot;Block device required&quot; len = 23, data = 0x6d0ac0 &quot;Device or resource busy&quot; len = 11, data = 0x6d0ae0 &quot;File exists&quot; ... 数组大小135 linux错误码： errno.00 is: Success errno.01 is: Operation not permitted errno.02 is: No such file or directory errno.03 is: No such process errno.04 is: Interrupted system call errno.05 is: Input/output error errno.06 is: No such device or address errno.07 is: Argument list too long errno.08 is: Exec format error errno.09 is: Bad file descriptor errno.10 is: No child processes errno.11 is: Resource temporarily unavailable errno.12 is: Cannot allocate memory errno.13 is: Permission denied errno.14 is: Bad address errno.15 is: Block device required errno.16 is: Device or resource busy errno.17 is: File exists ending","categories":[],"tags":[{"name":"nginx","slug":"nginx","permalink":"https://riverferry.site/tags/nginx/"}],"keywords":[]},{"title":"nginx开篇和安装","slug":"2019-12-02-nginx开篇和安装","date":"2019-12-02T00:00:00.000Z","updated":"2022-09-12T16:24:32.275Z","comments":true,"path":"2019-12-02-nginx开篇和安装/","link":"","permalink":"https://riverferry.site/2019-12-02-nginx%E5%BC%80%E7%AF%87%E5%92%8C%E5%AE%89%E8%A3%85/","excerpt":"前言开始学习nginx,目前主要参考: Nginx开发从入门到精通 深入理解Nginx模块开发与架构解析第2版.pdf","text":"前言开始学习nginx,目前主要参考: Nginx开发从入门到精通 深入理解Nginx模块开发与架构解析第2版.pdf nginx的安装RHEL/CentOS Install the prerequisites: sudo yum install yum-utils To set up the yum repository, create the file named /etc/yum.repos.d/nginx.repo with the following contents: [nginx-stable] name=nginx stable repo baseurl=http://nginx.org/packages/centos/$releasever/$basearch/ gpgcheck=1 enabled=1 gpgkey=https://nginx.org/keys/nginx_signing.key module_hotfixes=true [nginx-mainline] name=nginx mainline repo baseurl=http://nginx.org/packages/mainline/centos/$releasever/$basearch/ gpgcheck=1 enabled=0 gpgkey=https://nginx.org/keys/nginx_signing.key module_hotfixes=true By default, the repository for stable nginx packages is used. If you would like to use mainline nginx packages, run the following command: sudo yum-config-manager --enable nginx-mainline To install nginx, run the following command: sudo yum install nginx When prompted to accept the GPG key, verify that the fingerprint matches 573B FD6B 3D8F BC64 1079 A6AB ABF5 BD82 7BD9 BF62, and if so, accept it. makefile编译安装,附加-g参数 修改auto/cc/conf文件 ngx_compile_opt=&quot;-c&quot; 变为 ngx_compile_opt=&quot;-c -g&quot; 然后,基本的安装三步即可… 内核参数优化使用nginx需要调整下服务器配置,因为默认的系统配置是最通用的,而不是最有效率的.书中提供的参考是修改/etc/sysctl.conf来优化内核参数: fs.file-max = 999999 net.ipv4.tcp_tw_reuse = 1 net.ipv4.tcp_keepalive_time = 600 net.ipv4.tcp_fin_timeout = 30 net.ipv4.tcp_max_tw_buckets = 5000 net.ipv4.ip_local_port_range = 1024 61000 net.ipv4.tcp_rmem = 4096 32768 262142 net.ipv4.tcp_wmem = 4096 32768 262142 net.core.netdev_max_backlog = 8096 net.core.rmem_default = 262144 net.core.wmem_default = 262144 net.core.rmem_max = 2097152 net.core.wmem_max = 2097152 net.ipv4.tcp_syncookies = 1 net.ipv4.tcp_max_syn.backlog=1024 file-max 这个参数表示进程（比如一个worker进程）可以同时打开的最大句柄数，这个参数直接限制最大并发连接数，需根据实际情况配置。 tcp_tw_reuse 这个参数设置为1，表示允许将TIME-WAIT状态的socket重新用于新的TCP连接，这对于服务器来说很有意义，因为服务器上总会有大量TIME-WAIT状态的连接。 tcp_keepalive_time 这个参数表示当keepalive启用时，TCP发送keepalive消息的频度。默认是2小时，若将其设置得小一些，可以更快地清理无效的连接。 tcp_fin_timeout 这个参数表示当服务器主动关闭连接时，socket保持在FIN-WAIT-2状态的最大时间。 tcp_max_tw_buckets 这个参数表示操作系统允许TIME_WAIT套接字数量的最大值，如果超过这个数字，TIME_WAIT套接字将立刻被清除并打印警告信息。该参数默认为180000，过多的TIME_WAIT套接字会使Web服务器变慢。 tcp_max_syn_backlog 这个参数表示TCP三次握手建立阶段接收SYN请求队列的最大长度，默认为1024，将其设置得大一些可以使出现Nginx繁忙来不及accept新连接的情况,Linux不至于丢失客户端发起的连接请求。 ip_local_port_range 这个参数定义了在UDP和TCP连接中本地（不包括连接的远端）端口的取值范围。 net.ipv4.tcp_rmem 这个参数定义了TCP接收缓存（用于TCP接收滑动窗口）的最小值、默认值、最大值。 net.ipv4.tcp_wmem 这个参数定义了TCP发送缓存（用于TCP发送滑动窗口）的最小值、默认值、最大值。 netdev_max_backlog 当网卡接收数据包的速度大于内核处理的速度时，会有一个队列保存这些数据包。这个参数表示该队列的最大值。 rmem_default 这个参数表示内核套接字接收缓存区默认的大小。 wmem_default 这个参数表示内核套接字发送缓存区默认的大小。 rmem_max 这个参数表示内核套接字接收缓存区的最大大小。 wmem_max 这个参数表示内核套接字发送缓存区的最大大小。 tcp_syncookies 该参数与性能无关，用于解决TCP的SYN攻击。 注意 滑动窗口的大小与套接字缓存区会在一定程度上影响并发连接的数目。每个TCP连接都会为维护TCP滑动窗口而消耗内存，这个窗口会根据服务器的处理速度收缩或扩张。参数wmem_max的设置，需要平衡物理内存的总大小、Nginx并发处理的最大连接数量（由nginx.conf中的worker_processes和worker_connections参数决定）而确定。当然，如果仅仅为了提高并发量使服务器不出现Out Of Memory问题而去降低滑动窗口大小，那么并不合适，因为滑动窗口过小会影响大数据量的传输速度。rmem_default、wmem_default、rmem_max、wmem_max这4个参数的设置需要根据我们的业务特性以及实际的硬件成本来综合考虑。 上面的部分参数我之前有总结过,还有部分比如滑动窗口还不是很熟悉,后面遇到了再单独总结. ending","categories":[],"tags":[{"name":"note","slug":"note","permalink":"https://riverferry.site/tags/note/"}],"keywords":[]},{"title":"一次短暂的逃离","slug":"2019-11-21-一次短暂的逃离","date":"2019-11-21T00:00:00.000Z","updated":"2022-09-12T16:24:32.274Z","comments":true,"path":"2019-11-21-一次短暂的逃离/","link":"","permalink":"https://riverferry.site/2019-11-21-%E4%B8%80%E6%AC%A1%E7%9F%AD%E6%9A%82%E7%9A%84%E9%80%83%E7%A6%BB/","excerpt":"今天缘于一点惰性,早上睁开眼犹豫了一会之后决定修一天假.可能也和最近几天的状态有关吧,处理了半年的局点问题,现在终于可以脱身出来做别的事情.在这交接的过渡阶段，上面安排的任务也不够具体,给了自己一些可以自我发挥的空间,直白的说,就是可以适当偷偷懒. 这的确很美好,我早已经想脱离出来,做做需求特性了.哪怕是比较坑的特性,总需要转换下给点新鲜感,尤其是长期做这种很纠缠,很折磨人的局点.但是突然间生活节奏变慢了,长期的惯性很难短时间去适应。导致最近整个人没有状态,完全的无精打采,迷迷糊糊.","text":"今天缘于一点惰性,早上睁开眼犹豫了一会之后决定修一天假.可能也和最近几天的状态有关吧,处理了半年的局点问题,现在终于可以脱身出来做别的事情.在这交接的过渡阶段，上面安排的任务也不够具体,给了自己一些可以自我发挥的空间,直白的说,就是可以适当偷偷懒. 这的确很美好,我早已经想脱离出来,做做需求特性了.哪怕是比较坑的特性,总需要转换下给点新鲜感,尤其是长期做这种很纠缠,很折磨人的局点.但是突然间生活节奏变慢了,长期的惯性很难短时间去适应。导致最近整个人没有状态,完全的无精打采,迷迷糊糊. 今天请假,我给了自己很多充分的理由来做这个决定.前段时间工作任务很多,自己最近游戏也晚的多,透支了很多精力.天宫也不作美,鼻炎在这种天气很受罪.的确是需要自我放松下了. 现在回想起来今天毫无目的的漫步,总体还是蛮有意思的.我凭记忆把今天的大致路线记录了下来: 整段路程有意思的地方,首先是村庄,拆迁的村庄.每家每户都在盖房,有的已经盖好了,全新的瓷钻,大概6层到8层左右的高度.可以明显的看出来,都是在原先1层或者2层的基础上加盖的,新加的楼层显得很粗糙,内部都没有用水泥粉刷.外面崭新的瓷砖上写的拆迁，验收的字样.房子的高度在这样原先2层左右的村庄布局下显得十分拥挤,我误打误撞来到这里目睹了这一切.看到坐在自己门前的户主的眼神,我能体会到一些他们的感受.别人都在盖房,大家都想多拿点拆迁补助款,都跟着盖.有些房子明显之前没人住的,或者以前是很简陋的土房,现在都一致的在做同样的事情。这些人里面,我看到了部分很久没回过村庄的人,应该是在外面打工或者已经搬进城里,现在确有一人(大多是妻子)回来看着盖房,给工人烧水.为了拿这些可以说是中彩票一样的中国这个阶段特有的意外之财.还有一些可以看到以前比较贫苦的人家，现在也在盖高层,只为了不久后把新房推倒.我想这些人的亲戚在这个阶段应该是最慷概的,不管盖几层高的房子应该都是可以借到钱的吧.还有一个房子,可以看到不久前刚办完丧事,现在屋内已经没人了.从这个村庄走过,让我有一种走进dayuejin的感觉。所有人家都在盖房,邻居打招呼都是:房子盖好了没？这是怎样一种景观.真是有趣啊. 穿过村庄,可以看到基本每个出村的路口都有一些穿着保安制服的人.和办公大楼的保安不同的是,这里的保安对陌生人(我)总是格外的感兴趣,异样的看着我,似乎想在我身上找到摄像头一般的东西.看得出来,他们非常的警惕和专业.话说回来,黑社会的人应该也挺专业的吧. 在往后面走,是一片片一望无际的田野.我已经很久没遇到过这种景观了.真的是一望无际,没有那么多信号塔,没有高楼,田野中还有野鸡.我似乎一下子回到了童年,在我小学阶段，故乡的麦田也是这样,还可以放风筝.压抑许久的我终于得到了可以释放的途径,不由自主的奔跑了起来.穿惯了紧身的衣服,在办公室兢兢业业的工作,这是我努力得来的体面的工作.我为此压抑了自己的天性,自己的孩子气,就为了这一点点相对于工地的优越性,真是一点点,却又是那么遥远,那么难.需要从小学到大学毕业这么久的时间. 说到工地,旁边拆迁完的地方已经在盖新楼了,有盖居民楼的,有修净水厂的,有建科研中心的,还有挖地铁的.不知道有多大面积,但确实目所能及,很大的一片规划用地被征用了.打工的人,来自全国各地,本地人居多,我漫步的过程种听到他们普通的交谈,这和我之前在深圳遇到的场面很是相似.一度我以为自己来到了深圳郊外. 如果说上个世纪,农民工的史诗是煤矿,是地下.那现在,一定是举世闻名的中国大基建了.所有的地方都在基建,人们已经习惯了这种噪音.在武汉的时候,那里到处在修,在深圳的时候,在修.我想每个城市都是这样,不过需要去寻找,一定会有某个城区,某个地段,全国各地同谋一样的在做这件事.在为国家经济的引擎加力. 回来的路上,比较孤单和无聊.一度还走错了路,人也已经筋疲力尽.在傍晚穿过城中村的时候,还能听到远处拆迁的声音,楼倒的声音.村里里现有人烟,看不到灯火.楼是那么的高,孤零零的我甚至有些恐惧.不时的可以遇见一些猫,这些在农村生活惯了的猫,会被村民搬迁的时候一并带走吗,还是就此成为了野猫.这里的人对自己遇到的这一切恐怕都解释不了吧,我想这些猫,心里更是感到奇怪吧. 不过这也许就是生活吧,时代的力量是阻止不了的,人也不过是一种生物.更何况我只是其中不起眼的一个.挺晚了,早点睡了.许久没打字了,也的确是今天想到了很多事情.愿以后的生活会更好,世界会更好吧. ending","categories":[],"tags":[{"name":"note","slug":"note","permalink":"https://riverferry.site/tags/note/"}],"keywords":[]},{"title":"lua-协同程序","slug":"2019-11-05-lua-协程","date":"2019-11-05T00:00:00.000Z","updated":"2022-09-12T16:24:32.274Z","comments":true,"path":"2019-11-05-lua-协程/","link":"","permalink":"https://riverferry.site/2019-11-05-lua-%E5%8D%8F%E7%A8%8B/","excerpt":"引用programming in lua 编译、运行、错误处理 britzl/traceback.lua The Implementation of Lua5.0.pdf","text":"引用programming in lua 编译、运行、错误处理 britzl/traceback.lua The Implementation of Lua5.0.pdf 协同基础协同程序(coroutine)与多线程情况下的线程比价类似：有自己的堆栈,自己的局部变量,有自己的指令指针，和其他协调程序共享全局变量等信息. 线程和协同程序的区别:在多处理器情况下,从概念上讲多线程程序同时运行多个和线程;而协同程序是通过协作来完成,在任一指定时刻只有一个协同程序在运行.并且这个正在运行的协同程序只有在明确的被要求挂起的时候才会被挂起. 简单的讲： 1 任一时刻只有一个协同程序在运行,这个后面总结并发和并行的时候再另行总结 2 协同只能主动挂起,无法在外部终止 函数coroutine.create (f) Creates a new coroutine, with body f. f must be a function. Returns this new coroutine, an object with type “thread”. create函数创建一个新的协同程序,create只有一个参数；协同程序将要运行的代码封装而成的函数,返回值为thread类型的值表示创建了一个新的协同程序. Lua 5.3.5 Copyright (C) 1994-2018 Lua.org, PUC-Rio &gt; co = coroutine.create( &gt;&gt; function() &gt;&gt; print(&quot;hello！&quot;); &gt;&gt; end &gt;&gt; ) &gt; &gt; print(co); thread: 0115e154 协同程序有三个状态：挂起态，运行态，停止态。当我们创建一个协同程序时它开始的状态是挂起态,也就是说我们创建协同程序的时候不会自动运行,可以使用status函数检查协同的状态. coroutine.status (co) Returns the status of coroutine co, as a string: “running”, if the coroutine is running (that is, it called status); “suspended”, if the coroutine is suspended in a call to yield, or if it has not started running yet; “normal” if the coroutine is active but not running (that is, it has resumed another coroutine); and “dead” if the coroutine has finished its body function, or if it has stopped with an error. &gt; print(coroutine.status(co)) suspended coroutine.resume (co [, val1, ···]) Starts or continues the execution of coroutine co. The first time you resume a coroutine, it starts running its body. The values val1, … are passed as the arguments to the body function. If the coroutine has yielded, resume restarts it; the values val1, … are passed as the results from the yield. If the coroutine runs without any errors, resume returns true plus any values passed to yield (when the coroutine yields) or any values returned by the body function (when the coroutine terminates). If there is any error, resume returns false plus the error message. &gt; coroutine.resume(co) hello！ true &gt; print(coroutine.status(co)) dead coroutine.yield (···) Suspends the execution of the calling coroutine. Any arguments to yield are passed as extra results to resume. &gt; co = coroutine.create( &gt;&gt; function() &gt;&gt; for i=1, 5 do &gt;&gt; print(&quot;num = &quot; .. i); &gt;&gt; coroutine.yield(); &gt;&gt; end &gt;&gt; end &gt;&gt; ) &gt; &gt; print(coroutine.resume(co)); num = 1 true &gt; print(coroutine.resume(co)); num = 2 true &gt; print(coroutine.resume(co)); num = 3 true &gt; print(coroutine.resume(co)); num = 4 true &gt; print(coroutine.resume(co)); num = 5 true &gt; print(coroutine.resume(co)); true &gt; print(coroutine.resume(co)); false cannot resume dead coroutine example 1 The first time you resume a coroutine, it starts running its body. The values val1, … are passed as the arguments to the body function. &gt; co = coroutine.create( &gt;&gt; function(a, b) &gt;&gt; print(&quot;co&quot;,a,b); &gt;&gt; end &gt;&gt; ) &gt; &gt; print(coroutine.resume(co, 1, 2)); co 1 2 true example 2 If the coroutine has yielded, resume restarts it; the values val1, … are passed as the results from the yield. //yield不带其他参数 &gt; co = coroutine.create( &gt;&gt; function() &gt;&gt; print(&quot;co&quot;,coroutine.yield()); &gt;&gt; end &gt;&gt; ) &gt; &gt; print(coroutine.resume(co)); true &gt; print(coroutine.resume(co, 1, 2)); co 1 2 true //yield带参数 &gt; co = coroutine.create( &gt;&gt; function() &gt;&gt; print(&quot;co&quot;,coroutine.yield(a,b)); &gt;&gt; print(a,b); &gt;&gt; end &gt;&gt; ) &gt; &gt; print(coroutine.resume(co)); true nil nil &gt; print(coroutine.resume(co, 1, 2)); co 1 2 nil nil true //一定要注意是yield的额外参数作为resume的返回值,resume的额外参数作为yield的返回值.这句话不好理解的. example 3 当协同代码结束时,主函数返回的值都会传给相应的resume &gt; co = coroutine.create( &gt;&gt; function() &gt;&gt; print(&quot;co&quot;); &gt;&gt; return 1,2,3,4,5; &gt;&gt; end &gt;&gt; ) &gt; &gt; print(coroutine.resume(co)); co true 1 2 3 4 5 //注意print的返回值顺序,这里和yield传值时候true的顺序不太一样.这一点还比较奇怪 coroutine.running () Returns the running coroutine plus a boolean, true when the running coroutine is the main one. coroutine.wrap (f) Creates a new coroutine, with body f. f must be a function. Returns a function that resumes the coroutine each time it is called. Any arguments passed to the function behave as the extra arguments to resume. Returns the same values returned by resume, except the first boolean. In case of error, propagates the error. coroutine.isyieldable () Returns true when the running coroutine can yield. A running coroutine is yieldable if it is not the main thread and it is not inside a non-yieldable C function. 对称协同与不对称协同待补充.. ending","categories":[],"tags":[{"name":"lua","slug":"lua","permalink":"https://riverferry.site/tags/lua/"}],"keywords":[]},{"title":"lua-编译-运行-调试","slug":"2019-10-22-lua-编译-运行-调试","date":"2019-10-22T00:00:00.000Z","updated":"2022-09-12T16:24:32.274Z","comments":true,"path":"2019-10-22-lua-编译-运行-调试/","link":"","permalink":"https://riverferry.site/2019-10-22-lua-%E7%BC%96%E8%AF%91-%E8%BF%90%E8%A1%8C-%E8%B0%83%E8%AF%95/","excerpt":"引用programming in lua 编译、运行、错误处理 britzl/traceback.lua The Implementation of Lua5.0.pdf","text":"引用programming in lua 编译、运行、错误处理 britzl/traceback.lua The Implementation of Lua5.0.pdf 前言Lua会预先把代码预编译成中间码然后再执行.在解释型语言中存在编译阶段听起来不太合适.然而,解释型语言的特征不在于是否被编译,而是编译时是否是运行时的一部分.执行编译产生的中间码速度会更快.函数dofile的存在就是说明可以将lua作为解释型语言被调用。 difile其实是个辅助的函数,真正完成功能的是loadfile函数. loadfile ([filename [, mode [, env]]]) Similar to load, but gets the chunk from file filename or from the standard input, if no file name is given. 与dofile不同的是,loadfile编译代码成中间码并且返回编译后的chunk作为一个函数,而不执行代码.另外,loadfile不会抛出异常,而是返回错误代码. int luaL_loadstring (lua_State *L, const char *s) [-0, +1, –] Loads a string as a Lua chunk. This function uses lua_load to load the chunk in the zero-terminated string s. loadstring与loadfile类似,但它不是读取文件，而是读取串，but,现在这个函数不能用了.老的教程都没有提到这一点.参考:From Lua 5.2 reference manual: Function loadstring is deprecated. Use load instead; it now accepts string arguments and are exactly equivalent to loadstring. //不推荐使用函数loadstring。使用load代替；它现在接受字符串参数，并且完全等同于loadstring。 &gt; i=3 &gt; loadstring(&quot;i=i+1&quot;) stdin:1: attempt to call a nil value (global &#39;loadstring&#39;) stack traceback: stdin:1: in main chunk [C]: in ? &gt; &gt; f = load(&quot;i = i + 1&quot;) &gt; f() &gt; print(i) 4 &gt; f() &gt; print(i) 5 lua把每一个chunk都当成一个匿名函数处理。例如, chunk “a = 1” 等价于: function a = 1 end 注意点1 load和loadfile都不会抛出错误,如果发生错误他们将返回nil加上错误信息 print(load(&quot;1 + &quot;)) nil [string &quot;1 + &quot;]:1: unexpected symbol near &#39;1&#39; 2 load和loadfile都不会有边界效应,他们仅仅编译chunk成为他们内部实现的一个匿名函数.通常对他们的误解是他们定义了函数.lua中的函数定义是发生在运行时的赋值而不是发生在编译时.例如: --file foo.lua function foo(x) print(x) end 当我们执行命令f = loadfile(“foo.lua”)时，foo被编译了但还没有被定义.如果要定义,必须运行: f() --defines &#39;foo&#39; 3 load编译的时候不关心词法范围： //仔细看下面的代码,注意哪个是全局变量i,哪个是局部变量i &gt; function test() &gt;&gt; print(i) &gt;&gt; local i = 0 &gt;&gt; &gt;&gt; f = load(&quot;i = i + 1&quot;) &gt;&gt; f() &gt;&gt; print(i) &gt;&gt; &gt;&gt; function g() &gt;&gt; i = i + 1 &gt;&gt; end &gt;&gt; &gt;&gt; g() &gt;&gt; print(i) &gt;&gt; end &gt; &gt; test() 8 0 1 &gt; test() 9 0 1 4 load通常用于运行程序外部的代码,load期望一个chunk，即语句.如果想要加载表达式,需要在表达式前加return,那样将返回表达式的值. 表达式，是由数字、算符、数字分组符号（括号）、自由变量和约束变量等以能求得数值的有意义排列方法所得的组合。约束变量在表达式中已被指定数值，而自由变量则可以在表达式之外另行指定数值。 //书上是local sql, 但前面提到的loadstring是用的全局变量,这里sql我就用了全局变量，不然会和实际有出入的 Lua 5.1.4 Copyright (C) 1994-2008 Lua.org, PUC-Rio &gt; print&quot;enter you r expression:&quot; enter your expression: &gt; sql = io.read() 6 &gt; func = assert(loadstring(&quot;return &quot; .. sql)) &gt; print(&quot;the value of your expression is &quot; .. func()) the value of your expression is 6 Lua 5.3.5 Copyright (C) 1994-2018 Lua.org, PUC-Rio &gt; print&quot;enter you r expression:&quot; enter you r expression: &gt; sql = io.read() 5 &gt; func = assert(load(&quot;return &quot; .. sql)) &gt; print(&quot;the value of your expression is &quot; .. func()) the value of your expression is 5 reuire函数lua提供更高级的require函数来加载运行库。require和dofile有两点不同：1 require会搜索目录加载文件2 require会判断文件是否已经加载避免重复加载同一文件。 require使用的路径和普通我们看到的路径还有些区别,我们一般看到的路径都是一个目录列表.require的路径是一个模式列表,每一个模式指明一种由虚文件名(require的参数)转成实文件名的方法.匹配的时候lua会首先将问号用虚文件名替换,然后看是否有这样的文件存在.如果不存在继续用同样的方法用第二个模式匹配. 例如,路径如下: ?;?.lua;C:\\windows?;/usr/local/lua/?/?.lua 调用 require(&quot;lili&quot;)时会尝试打开这些文件: lili lili.lua c:\\windows\\lili /usr/local/lili/lili.lua require只关心分号和问号,其他的信息在路径中定义. 路径：Lua将require搜索的模式字符串放在变量package.path中。当Lua启动后，便以环境变量LUA_PATH的值来初始化这个变量。如果没有找到该环境变量，则使用一个编译时定义的默认路径来初始化。如果require无法找到与模块名相符的Lua文件，就会找C程序库。C程序库的搜索模式存放在变量package.cpath中。而这个变量则是通过环境变量LUA_CPATH来初始化的。 &gt; print(&quot;LUA MODULES:\\n&quot;,(package.path:gsub(&quot;%;&quot;,&quot;\\n\\t&quot;)),&quot;\\n\\n C MODULES:\\n&quot;,(package.cpath:gsub(&quot;%;&quot;,&quot;\\n\\t&quot;))) LUA MODULES: ./?.lua /usr/share/lua/5.1/?.lua /usr/share/lua/5.1/?/init.lua /usr/lib64/lua/5.1/?.lua /usr/lib64/lua/5.1/?/init.lua C MODULES: ./?.so /usr/lib64/lua/5.1/?.so /usr/lib64/lua/5.1/loadall.so 一个路径中的模式也可以不包含问号而只是一个固定的路径,比如: ?;?.lua;/usr/local/default.lua 这种情况下,require没有匹配的时候就会用这个固定的文件(这个缺省的文件放在模式列表的最后才有意义) 异常和错误处理如果在lua中需要处理错误,需要调用pcall函数封装你的代码,从而捕捉异常和错误.pcall在保护模式下调用它的第一个参数并运行,因此可以捕获所有的异常和错误.如果没有异常和错误,pcall返回true和调用返回的任何值: &gt; first,second = pcall( function() print(&quot;code blocks...&quot;) return &quot;success!&quot; end) code blocks... &gt; print(first, second) true success! 否则,返回nil加错误信息: &gt; first,second = pcall( function() error(&#123;err1 = &quot;step one&quot;&#125;) end) &gt; print(first, second) false table: 0xbd6690 &gt; print(second.err1) step one 错误信息不一定非要是字符串,传递给error的任何信息都会被pcall返回.这种机制提供了我么在lua中处理异常和错误的全部内容。我们通过error抛出异常,然后通过pcall来捕获它. 错误信息和回跟踪error函数 debug.traceback() 当pcall返回错误的时候它已经释放了保存错误发生情况的栈的信息，而我们想获取相关的堆栈信息就必须在pcall返回前获取,lua提供了xpcall来实现这个功能,xpcall接受2个参数,调用函数和错误处理函数.可以手动调用debug或者debug.traceback来查看错误信息. &gt; function a() &gt;&gt; print(&quot;a&quot; + 1) &gt;&gt; end &gt; &gt; function b() &gt;&gt; a() &gt;&gt; end &gt; &gt; function c() &gt;&gt; b() &gt;&gt; end &gt; &gt; function err() &gt;&gt; print(&quot;deal err func:&quot;) &gt;&gt; print(debug.traceback()) &gt;&gt; end &gt; &gt; print(xpcall( c, err)) deal err func: stack traceback: stdin:3: in function &lt;stdin:1&gt; stdin:2: in function &#39;a&#39; stdin:2: in function &#39;b&#39; stdin:2: in function &lt;stdin:1&gt; [C]: in function &#39;xpcall&#39; stdin:1: in main chunk [C]: ? false nil ending","categories":[],"tags":[{"name":"lua","slug":"lua","permalink":"https://riverferry.site/tags/lua/"}],"keywords":[]},{"title":"lua-迭代器","slug":"2019-10-14-lua-迭代器与范性for","date":"2019-10-14T00:00:00.000Z","updated":"2022-09-12T16:24:32.274Z","comments":true,"path":"2019-10-14-lua-迭代器与范性for/","link":"","permalink":"https://riverferry.site/2019-10-14-lua-%E8%BF%AD%E4%BB%A3%E5%99%A8%E4%B8%8E%E8%8C%83%E6%80%A7for/","excerpt":"引用programming in lua The Implementation of Lua5.0.pdf","text":"引用programming in lua The Implementation of Lua5.0.pdf 范性for范性for的文法: for &lt;var-list&gt; in &lt;exp-list&gt; do codeblock end 也即: for var_1, ..., var_n in explist do block end 等价于: do local _f, _s, _var = explist while true do local var_1, ..., var_n = _f(_s, _var) _var = var_1 if _var = nil then break end block end end 说明： _f: 迭代函数 _s: 状态常量 _var_n: 控制变量 无状态的迭代器无状态的迭代器是指不保留任何状态的迭代器,因此在循环中我们可以利用无状态迭代器避免创建闭包花费额外的代价.每一次迭代,迭代函数都是用两个变量(状态常量和控制变量)的值作为参数被调用,一个无状态的迭代器利用这两个值可以获取下一个元素. input: function iter(a, i) i = i + 1 if a[i] then return i,a[i] end end function mypairs(a) return iter, a, 0 end a = &#123;&quot;one&quot;, &quot;two&quot;, &quot;three&quot;&#125;; for k,v in mypairs(a) do print(k, v) end output: 1 one 2 two 3 three 说明: 不同于闭包,迭代的”索引”不是通过upvalue来保存,而是利用范性for自身的_var = var_1来给迭代函数代入新的索引参数.需要注意的是,写无状态的迭代器的时候,函数要返回三个值,分别是迭代函数,状态常量,控制变量.参数个数不足的自动用nil替代,多了的自动抛弃. 闭包的函数定义是写在工厂函数内部的,无状态迭代器则是写在函数外面的.目前还不肯定是否这样就不会创建闭包.这里后续熟悉了再补充. 多状态的迭代器无状态迭代器通过传入状态常量和控制变量给范性for循环来控制迭代,而有时需要更多的参数来控制.使用闭包可以完成,还可以通过table作为迭代器的状态常量，把所有需要的值放进table内来实现. input: function iter(tab) i = tab.index if tab[i] then tab.index = i + 1 return i,tab[i] end end function mypairs(tab) return iter, tab, nil end tab = &#123;&quot;one&quot;, &quot;two&quot;, &quot;three&quot;, index = 1&#125;; for k,v in mypairs(tab) do print(k, v) end output: 1 one 2 two 3 three 说明:应该尽可能的使用无状态的迭代器,由for循环来保存状态.这样不需要创建对象花费的代价少次之,可以用闭包最后使用table这种多状态的迭代器,因为创建闭包的代价比table少,并且lua处理闭包的速度比table快. ending","categories":[],"tags":[{"name":"lua","slug":"lua","permalink":"https://riverferry.site/tags/lua/"}],"keywords":[]},{"title":"lua-闭包","slug":"2019-10-13-lua-闭包","date":"2019-10-13T00:00:00.000Z","updated":"2022-09-12T16:24:32.274Z","comments":true,"path":"2019-10-13-lua-闭包/","link":"","permalink":"https://riverferry.site/2019-10-13-lua-%E9%97%AD%E5%8C%85/","excerpt":"引用programming in lua The Implementation of Lua5.0.pdf","text":"引用programming in lua The Implementation of Lua5.0.pdf 函数和闭包当 Lua 编译一个函数时，会生成一个原型。该原型包含有函数的虚拟机指令 、常数值（数值、字符串等），以及一些调试信息。在运行期，任何时候只要 Lua执行一个 function...end 表达式，它就会创建一个新的闭包。每个闭包都有一个对函数原型的引用、一个对环境的引用（环境其实是一个表，函数可在该表中索引全局变量，后面细述），和一个数组，数组中每个元素都是一个对 upvalue 的引用，可通过该数组来存取外层的局部变量。 lua的函数lua的函数是带有词法界定的第一类值 词法界定：被嵌套的函数可以访问它外部的局部变量 LUA function newCounter() local i = 0; return function() i = i + 1; return i; end end c1 = newCounter(); print(c1()); print(c1()); C/C++ int function() &#123; i = i + 1; return i; &#125; int newCounter() &#123; int i = 0; return function(); &#125; int main() &#123; cout &lt;&lt; newCounter() &lt;&lt; endl; return 0; &#125; error: &#39;i&#39; was not declared in this scope| 第一类值:在lua中函数和其他值(数值,字符串)一样,函数可以被存放在变量中，也可以存放在表中,可以作为函数的参数,还可以作为函数的返回值. upvalue在内部函数变量i既不是全局变量,也不是局部变量,这种称为外部局部变量或者upvalue. Lua 用一种称为 upvalue 的结构来实现闭包。对任何外层局部变量的存取间接地通过 upvalue 来进行。upvalue 最初指向栈中变量活跃的地方（图 4 左 边 ）。当离开变量作用域时（超过变量生存期时），变量被复制到 upvalue 中（图 4 右边）。由于对变量的存取是通过 upvalue 里的指针间接进行的，因此复制动作对任何存取此变量的代码来说都是没有影响的。与内层函数不同的是，声明该局部变量的函数直接在堆栈中存取它的局部变量。 通过为每个变量至少创建一个 upvalue 并按所需情况进行重复利用，保证了未决状态（是否超过生存期）的局部变量（pending vars）能够在闭包间正确地共享。为了保证这种唯一性，Lua 为整个运行栈保存了一个链接着所有正打开着的 upvalue（那些当前正指向栈内局部变量的 upvalue）的链表（图 4 中未决状态的局部变量的链表）。当 Lua 创建一个新的闭包时，它开始遍历所有的外层局部变量，对于其中的每一个，若在上述 upvalue 链表中找到它，就重用此 upvalue，否则，Lua 将创建一个新的 upvalue 并加入链表中。注意，一般情况下这种遍历过程在探查了少数几个节点后就结束了，因为对于每个被内层函数用到的外层局部变量来说，该链表至少包含一个与其对应的入口（upvalue）。一旦某个关闭的upvalue 不再被任何闭包所引用，那么它的存储空间就立刻被回收。 一个函数有可能存取其更外层函数而非直接外层函数的局部变量。这种情况下，有可能当闭包创建时，此局部变量尚不存在。Lua 使用 flat 闭包来处理这种情况。有了 flat 闭包，无论何时只要函数存取更外层的局部变量，该变量也会进入其直接外层函数的闭包中。这样，当一个函数被实例化时，所有进入其闭包的变量就在直接外层函数的栈或闭包中了。 ending","categories":[],"tags":[{"name":"lua","slug":"lua","permalink":"https://riverferry.site/tags/lua/"}],"keywords":[]},{"title":"人间值得","slug":"2019-10-09-人间值得","date":"2019-10-09T00:00:00.000Z","updated":"2022-09-12T16:24:32.274Z","comments":true,"path":"2019-10-09-人间值得/","link":"","permalink":"https://riverferry.site/2019-10-09-%E4%BA%BA%E9%97%B4%E5%80%BC%E5%BE%97/","excerpt":"前言博客停了2个月了,中间尝试了一些其他的东西,工作这段时间也很忙,耽搁了.今天翻阅邮箱的时候,又回首了一些往日时光,更觉得人真是健忘的，以前的种种形成了现在的自己,现在的自己也在构成以后的那个人,而适当的思考下已经走过的路，遇过的,经历的,也能带来一些思考.重新审视,自己从一开始继承的,好的,错误的东西.以及可以从他人那里参考的.岁月流逝,我越发清晰的认识到人和人的不同,哪怕朝夕相处的两个人,可能看到的是两个完全不同的世界,但却在相同的空间下,彼此知/不知.生活中还是有很多可以重复熟悉的东西,我今天再看3年前上一家公司领导的一封邮件,发现其中部分文字是今天才能领悟，感同身受到的.真的自己走的路,不过是他人的重复罢了.多说无益,邮箱中找到了几张图片,是大概16年村子里有一家的老人去世了,儿子当时葬礼办的很热闹,很用心.之前多少经过好些次这家门前,对其有一些简单的认识,感觉为人忠厚,有种几十年如一日的感觉,稍微传统一些.图片是儿子给去世的母亲写的,我今天看了便也很有感触,贴一部分出来,也激励下我自己,不要荒废生活，人间还是值得的,也多回家看看,与朋友聚聚,偶尔思考下.","text":"前言博客停了2个月了,中间尝试了一些其他的东西,工作这段时间也很忙,耽搁了.今天翻阅邮箱的时候,又回首了一些往日时光,更觉得人真是健忘的，以前的种种形成了现在的自己,现在的自己也在构成以后的那个人,而适当的思考下已经走过的路，遇过的,经历的,也能带来一些思考.重新审视,自己从一开始继承的,好的,错误的东西.以及可以从他人那里参考的.岁月流逝,我越发清晰的认识到人和人的不同,哪怕朝夕相处的两个人,可能看到的是两个完全不同的世界,但却在相同的空间下,彼此知/不知.生活中还是有很多可以重复熟悉的东西,我今天再看3年前上一家公司领导的一封邮件,发现其中部分文字是今天才能领悟，感同身受到的.真的自己走的路,不过是他人的重复罢了.多说无益,邮箱中找到了几张图片,是大概16年村子里有一家的老人去世了,儿子当时葬礼办的很热闹,很用心.之前多少经过好些次这家门前,对其有一些简单的认识,感觉为人忠厚,有种几十年如一日的感觉,稍微传统一些.图片是儿子给去世的母亲写的,我今天看了便也很有感触,贴一部分出来,也激励下我自己,不要荒废生活，人间还是值得的,也多回家看看,与朋友聚聚,偶尔思考下. ending","categories":[],"tags":[{"name":"note","slug":"note","permalink":"https://riverferry.site/tags/note/"}],"keywords":[]},{"title":"排序","slug":"2019-08-04-排序","date":"2019-08-04T00:00:00.000Z","updated":"2022-09-12T16:24:32.274Z","comments":true,"path":"2019-08-04-排序/","link":"","permalink":"https://riverferry.site/2019-08-04-%E6%8E%92%E5%BA%8F/","excerpt":"前言参考: 白话经典算法系列之八 MoreWindows白话经典算法之七大排序总结篇 &lt;编程珠玑&gt; &lt;C程序设计语言&gt;","text":"前言参考: 白话经典算法系列之八 MoreWindows白话经典算法之七大排序总结篇 &lt;编程珠玑&gt; &lt;C程序设计语言&gt; 冒泡排序 冒泡排序（英语：Bubble Sort）是一种简单的排序算法。它重复地走访过要排序的数列，一次比较两个元素，如果他们的顺序错误就把他们交换过来。走访数列的工作是重复地进行直到没有再需要交换，也就是说该数列已经排序完成。这个算法的名字由来是因为越小的元素会经由交换慢慢“浮”到数列的顶端。 #include &quot;pch.h&quot; #include &lt;iostream&gt; using namespace std; void BubbleSort(int a[], int n) &#123; int i, j; i = j = 0; for (i = 0; i &lt; n; i++) &#123; for (j = 1; j &lt; n - i; j++) &#123; if (a[j] &lt; a[j - 1]) //升序 swap(a[j], a[j - 1]); &#125; &#125; &#125; void BubbleSort2(int a[], int n) &#123; int i,j,f,k; i = j = f = k = 0; f = n; while(f &gt; 0) &#123; k = f; f = 0; for (j = 1; j &lt; k; j++) &#123; if (a[j] &lt; a[j - 1]) //升序 &#123; swap(a[j], a[j - 1]); f = j; &#125; &#125; &#125; &#125; int main() &#123; int a[] = &#123;4,5,1,2,9,45,4225,11,452,4,254,14,1,454,555,4,26&#125;; int n = sizeof(a) / sizeof(int); cout &lt;&lt; &quot;Old: &quot; &lt;&lt; endl; for (int i = 0; i &lt; n; i++) cout &lt;&lt; a[i] &lt;&lt; &quot; &quot;; cout &lt;&lt; endl; BubbleSort2(a, n); cout &lt;&lt; &quot;New: &quot; &lt;&lt; endl; for (int i = 0; i &lt; n; i++) cout &lt;&lt; a[i] &lt;&lt; &quot; &quot;; cout &lt;&lt; endl; &#125; 结果: Old: 4 5 1 2 9 45 4225 11 452 4 254 14 1 454 555 4 26 New: 1 1 2 4 4 4 5 9 11 14 26 45 254 452 454 555 4225 总结: 冒泡排序比较基本,效率很差,很少有人用.纯是初学者拿来玩. BubbleSort: for(记录冒泡最顶端的数n-i) for(两两交换,将一趟中最大的数移动到顶端n-i) BubbleSort2: while(flag记录当前冒泡顶端的位置,以及判断本趟有没有有效移动,可以提前结束) for(一趟比较和移动,终点是上次移动的顶端k/f,跳过右边本来有序的情况) 插入排序大多数纸牌游戏都采用插入排序来让玩家手上的牌有序,当拿到一张新牌时,将其插入到合适的位置 #include &quot;pch.h&quot; #include &lt;iostream&gt; using namespace std; void InsertSort(int a[], int n) &#123; int i, j, t; i = j = t = 0; for (i = 1; i &lt; n; i++) &#123; t = a[i]; for (j = i - 1; j &gt;=0 &amp;&amp; a[j] &gt; t; j-- ) //升序 &#123; a[j + 1] = a[j]; &#125; a[j + 1] = t; &#125; &#125; void InsertSort2(int a[], int n) &#123; int i = 0; int j = 0; for (i = 1; i &lt; n; i++) &#123; for (j = i - 1; j &gt;= 0 &amp;&amp; a[j] &gt; a[j + 1]; j--) //升序 &#123; swap(a[j], a[j + 1]); &#125; &#125; &#125; int main() &#123; int a[] = &#123;4,5,1,2,9,45,4225,11,452,4,254,14,1,454,555,4,26&#125;; int n = sizeof(a) / sizeof(int); cout &lt;&lt; &quot;Old: &quot; &lt;&lt; endl; for (int i = 0; i &lt; n; i++) cout &lt;&lt; a[i] &lt;&lt; &quot; &quot;; cout &lt;&lt; endl; InsertSort2(a, n); cout &lt;&lt; &quot;New: &quot; &lt;&lt; endl; for (int i = 0; i &lt; n; i++) cout &lt;&lt; a[i] &lt;&lt; &quot; &quot;; cout &lt;&lt; endl; &#125; 结果: Old: 4 5 1 2 9 45 4225 11 452 4 254 14 1 454 555 4 26 New: 1 1 2 4 4 4 5 9 11 14 26 45 254 452 454 555 4225 Process returned 0 (0x0) execution time : 0.024 s Press any key to continue. 总结： 左边是一个有序数组,从a[0]开始到a[n - 1] for(将a[1...n-1]插入a[0]) for(插入a[i]需要进行的交换(挪位)操作) InsertSort:将左边的依次右移,最后把a[i]放到合适的位置 InsertSort2:从右边开始,把乱序的左右两个数交换,直到整体有序.有点像是冒泡排序其中的一点思路. 选择排序直接选择排序和直接插入排序很相似: 直接选择排序是把无序区的最小值挪到有序区的最右边(升序)，无序区从j=1开始,有序区初始是a[0] 直接插入排序是把无序区的第一个值挪到有序区的合适位置,无序区从j=1开始,有序区初始是a[0] #include &quot;pch.h&quot; #include &lt;iostream&gt; using namespace std; void SelectSort(int a[], int n) &#123; int i, j, nMinIndex; i = j = nMinIndex = 0; for (i = 0; i &lt; n; i++) &#123; nMinIndex = i; for (j = i+1; j &lt; n; j++) &#123; if (a[j] &lt; a[nMinIndex]) //升序 nMinIndex = j; &#125; swap(a[i], a[nMinIndex]); &#125; &#125; int main() &#123; int a[] = &#123;4,5,1,2,9,45,4225,11,452,4,254,14,1,454,555,4,26&#125;; int n = sizeof(a) / sizeof(int); cout &lt;&lt; &quot;Old: &quot; &lt;&lt; endl; for (int i = 0; i &lt; n; i++) cout &lt;&lt; a[i] &lt;&lt; &quot; &quot;; cout &lt;&lt; endl; SelectSort(a, n); cout &lt;&lt; &quot;New: &quot; &lt;&lt; endl; for (int i = 0; i &lt; n; i++) cout &lt;&lt; a[i] &lt;&lt; &quot; &quot;; cout &lt;&lt; endl; &#125; 结果: Old: 4 5 1 2 9 45 4225 11 452 4 254 14 1 454 555 4 26 New: 1 1 2 4 4 4 5 9 11 14 26 45 254 452 454 555 4225 shell(希尔)排序wikipedia: 希尔排序，也称递减增量排序算法，是插入排序的一种更高效的改进版本。希尔排序是非稳定排序算法。 希尔排序是基于插入排序的以下两点性质而提出改进方法的： 1 插入排序在对几乎已经排好序的数据操作时，效率高，即可以达到线性排序的效率 2 但插入排序一般来说是低效的，因为插入排序每次只能将数据移动一位 #include &quot;pch.h&quot; #include &lt;iostream&gt; using namespace std; void ShellSort(int a[], int n) &#123; int i, j, gap; i = j = gap = 0; int t = 0; for (gap = n / 2; gap &gt; 0; gap /= 2) &#123; for (i = gap; i &lt; n; i++) &#123; for (j = i - gap; j &gt;= 0 &amp;&amp; a[j] &gt; a[j + gap]; j -= gap) &#123; swap(a[j], a[j + gap]); &#125; &#125; &#125; &#125; void ShellSort2(int a[], int n) &#123; int i, j, gap, t; i = j = gap = t = 0; for (gap = n / 2; gap &gt; 0; gap /= 2) &#123; for (i = gap; i &lt; n; i++) &#123; t = a[i]; for (j = i - gap; j &gt;= 0 &amp;&amp; a[j] &gt; t; j -= gap) &#123; a[j + gap] = a[j]; &#125; a[j + gap] = t; &#125; &#125; &#125; int main() &#123; int a[] = &#123;4,5,1,2,9,45,4225,11,452,4,254,14,1,454,555,4,26&#125;; int n = sizeof(a) / sizeof(int); cout &lt;&lt; &quot;Old: &quot; &lt;&lt; endl; for (int i = 0; i &lt; n; i++) cout &lt;&lt; a[i] &lt;&lt; &quot; &quot;; cout &lt;&lt; endl; ShellSort2(a, n); cout &lt;&lt; &quot;New: &quot; &lt;&lt; endl; for (int i = 0; i &lt; n; i++) cout &lt;&lt; a[i] &lt;&lt; &quot; &quot;; cout &lt;&lt; endl; &#125; 总结:理解插入排序是理解希尔排序的关键.gap = 1的时候就是完全的插入排序,gap != 1的时候,是为了让总体有序,提高插入排序的效率.因为插入排序在总体有序的情况下,效率比较高.步长(gap)一般是取一半,这并不是最优的方案.暂不深入研究. 快速排序快速排序使用分治法（Divide and conquer）策略来把一个序列（list）分为较小和较大的2个子序列，然后递归地排序两个子序列 #include &quot;pch.h&quot; #include &lt;iostream&gt; using namespace std; void QuickSort(int a[], int left, int right) &#123; int i, middle; i = middle = 0; if (left &gt;= right) return; middle = left; for (i = left + 1; i &lt;= right; i++) &#123; if (a[i] &lt; a[left]) &#123; swap(a[++middle], a[i]); &#125; &#125; swap(a[left], a[middle]); QuickSort(a, left, middle - 1); QuickSort(a, middle + 1, right); &#125; int main() &#123; int a[] = &#123;4,5,1,2,9,45,4225,11,452,4,254,14,1,454,555,4,26&#125;; int n = sizeof(a) / sizeof(int); cout &lt;&lt; &quot;Old: &quot; &lt;&lt; endl; for (int i = 0; i &lt; n; i++) cout &lt;&lt; a[i] &lt;&lt; &quot; &quot;; cout &lt;&lt; endl; QuickSort(a, 0, n - 1); cout &lt;&lt; &quot;New: &quot; &lt;&lt; endl; for (int i = 0; i &lt; n; i++) cout &lt;&lt; a[i] &lt;&lt; &quot; &quot;; cout &lt;&lt; endl; &#125; 总结: 快排有很多的版本,网上很多人实现的代码比较复杂,不利于理解.效率也不好说,更重要的是很难论证是否正确,快排使用递归函数,有的时候很难简单的判断是否有误.上面记录的实现方式,是在两本书中都出现过的,一种简单的快速排序.就记住这一种吧. 理解这个的难点是middle的变化. 归并排序堆排序ending","categories":[],"tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://riverferry.site/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"}],"keywords":[]},{"title":"理解平均负载","slug":"2019-07-31-理解平均负载","date":"2019-07-31T00:00:00.000Z","updated":"2022-09-12T16:24:32.274Z","comments":true,"path":"2019-07-31-理解平均负载/","link":"","permalink":"https://riverferry.site/2019-07-31-%E7%90%86%E8%A7%A3%E5%B9%B3%E5%9D%87%E8%B4%9F%E8%BD%BD/","excerpt":"前言在极客时间上学习的Linux性能优化实战这里把自己实践的过程记录下，文章会援引很多课程中的资料,详情还是建议点击上面的链接去购买课程","text":"前言在极客时间上学习的Linux性能优化实战这里把自己实践的过程记录下，文章会援引很多课程中的资料,详情还是建议点击上面的链接去购买课程 什么是平均负载平均负载是指单位时间内，系统处于可运行状态和不可中断状态的平均进程数，也就是平均活跃进程数，它和 CPU 使用率并没有直接关系。所谓可运行状态的进程，是指正在使用 CPU 或者正在等待 CPU 的进程，也就是我们常用 ps 命令看到的，处于 R 状态（Running 或 Runnable）的进程。而不可中断状态的进程，则是正处于内核态关键流程中的进程，并且这些流程是不可打断的，比如最常见的是等待硬件设备的 I/O 响应，也就是我们在 ps 命令中看到的 D 状态（Uninterruptible Sleep，也称为 Disk Sleep）的进程。比如，当一个进程向磁盘读写数据时，为了保证数据的一致性，在得到磁盘回复前，它是不能被其他进程或者中断打断的，这个时候的进程就处于不可中断状态。如果此时的进程被打断了，就容易出现磁盘数据与进程数据不一致的问题。所以，不可中断状态实际上是系统对进程和硬件设备的一种保护机制。 查看平均负载[root@localhost /]# uptime 08:18:23 up 9:10, 2 users, load average: 0.44, 0.68, 0.86 [root@localhost /]# date 2019年 07月 31日 星期三 08:18:57 CST [root@localhost /]# who root tty1 2019-07-30 23:08 root pts/0 2019-07-30 23:08 (192.168.1.5) [root@localhost /]# who -b 系统引导 2019-07-30 23:08 uptime的结果: 08:18:23 //当前时间 up 9:10 //系统运行时间 2 users //登录用户数 0.44 //过去1分钟的平均负载 0.68 //过去5分钟的平均负载 0.86 //过去15分钟的平均负载 平均负载是否合理平均负载可以理解为平均活跃进程数,即平均负载等于CPU个数的时候，是比较理想的,CPU被充分利用.超过CPU个数则负载高 查看CPU个数[root@localhost ~]# grep &#39;model name&#39; /proc/cpuinfo | wc -l 1 [root@localhost ~]# grep &#39;model name&#39; /proc/cpuinfo model name : AMD Ryzen 5 2600X Six-Core Processor 网上看的另一种查看的方法: [root@localhost ~]# cat /proc/cpuinfo processor : 0 vendor_id : AuthenticAMD cpu family : 23 model : 8 model name : AMD Ryzen 5 2600X Six-Core Processor stepping : 2 microcode : 0x800820b cpu MHz : 3599.994 cache size : 512 KB physical id : 0 siblings : 1 core id : 0 cpu cores : 1 apicid : 0 initial apicid : 0 fpu : yes fpu_exception : yes cpuid level : 13 wp : yes flags : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 syscall nx mmxext fxsr_opt pdpe1gb rdtscp lm constant_tsc rep_good nopl tsc_reliable nonstop_tsc eagerfpu pni pclmulqdq ssse3 fma cx16 sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm extapic cr8_legacy abm sse4a misalignsse 3dnowprefetch osvw arat xsaveopt fsgsbase bmi1 avx2 smep bmi2 rdseed adx smap bogomips : 7199.98 TLB size : 2560 4K pages clflush size : 64 cache_alignment : 64 address sizes : 43 bits physical, 48 bits virtual power management: 其中physical id代表第几个CPU,cpu cores代表CPU的核数.即1个CPU 与实际一致： 根据网上说的,平均负载超出70%就需要重视了,可以排查下导致负载高的原因. 模拟测试需要两个2个工具: 安装stress: yum install -y epel-release yum install -y stress 第二部安装的时候报错了: [root@localhost ~]# yum install -y stress 已加载插件：fastestmirror base | 3.6 kB 00:00:00 One of the configured repositories failed (未知), and yum doesn&#39;t have enough cached data to continue. At this point the only safe thing yum can do is fail. There are a few ways to work &quot;fix&quot; this: 1. Contact the upstream for the repository and get them to fix the problem. 2. Reconfigure the baseurl/etc. for the repository, to point to a working upstream. This is most often useful if you are using a newer distribution release than is supported by the repository (and the packages for the previous distribution release still work). 3. Disable the repository, so yum won&#39;t use it by default. Yum will then just ignore the repository until you permanently enable it again or use --enablerepo for temporary usage: yum-config-manager --disable &lt;repoid&gt; 4. Configure the failing repository to be skipped, if it is unavailable. Note that yum will try to contact the repo. when it runs most commands, so will have to try and fail each time (and thus. yum will be be much slower). If it is a very temporary problem though, this is often a nice compromise: yum-config-manager --save --setopt=&lt;repoid&gt;.skip_if_unavailable=true Cannot retrieve metalink for repository: epel/x86_64. Please verify its path and try again 网上找了种解决方法: vim /etc/yum.repos.d/epel.repo 修改,让baseurl生效,注释掉metalink baseurl=http://download.fedoraproject.org/pub/epel/7/$basearch #metalink=https://mirrors.fedoraproject.org/metalink?repo=epel-7&amp;arch=$basearch 然后,就可以了: [root@localhost ~]# stress `stress&#39; imposes certain types of compute stress on your system Usage: stress [OPTION [ARG]] ... -?, --help show this help statement 显示帮助信息 --version show version statement 显示版本号 -v, --verbose be verbose -q, --quiet be quiet 不显示运行信息 -n, --dry-run show what would have been done 显示已完成的指令情况 -t, --timeout N timeout after N seconds 指定运行N秒后停止 --backoff N wait factor of N microseconds before work starts 等待N微妙后开始运行 -c, --cpu N spawn N workers spinning on sqrt() 产生n个进程 每个进程都反复不停的计算随机数的平方根 -i, --io N spawn N workers spinning on sync() 产生n个进程 每个进程反复调用sync()，sync()用于将内存上的内容写到硬盘上 -m, --vm N spawn N workers spinning on malloc()/free() 产生n个进程,每个进程不断调用内存分配malloc和内存释放free函数 --vm-bytes B malloc B bytes per vm worker (default is 256MB) 指定malloc时内存的字节数 （默认256MB） --vm-stride B touch a byte every B bytes (default is 4096) --vm-hang N sleep N secs before free (default none, 0 is inf) 指定在free时的秒数 --vm-keep redirty memory instead of freeing and reallocating -d, --hdd N spawn N workers spinning on write()/unlink() --hdd-bytes B write B bytes per hdd worker (default is 1GB) Example: stress --cpu 8 --io 4 --vm 2 --vm-bytes 128M --timeout 10s Note: Numbers may be suffixed with s,m,h,d,y (time) or B,K,M,G (size). 安装sysstat: yum install sysstat 安装完后可以用到这个包的两个命令: mpstat pidstat mpstat mpstat是Multiprocessor Statistics的缩写，是实时监控工具，报告与cpu的一些统计信息这些信息都存在/proc/stat文件中，在多CPU系统里，其不但能查看所有的CPU的平均状况的信息，而且能够有查看特定的cpu信息，mpstat最大的特点是:可以查看多核心的cpu中每个计算核心的统计数据；而且类似工具vmstat只能查看系统的整体cpu情况。 详解mpstat、iostat、sar、vmstat命令的使用 [root@localhost ~]# mpstat Linux 3.10.0-123.el7.x86_64 (localhost.localdomain) 2019年08月01日 _x86_64_ (1 CPU) [root@localhost ~]# mpstat --help 用法: mpstat [ 选项 ] [ &lt;时间间隔&gt; [ &lt;次数&gt; ] ] 选项: [ -A ] [ -u ] [ -V ] [ -I &#123; SUM | CPU | SCPU | ALL &#125; ] [ -P &#123; &lt;cpu&gt; [,...] | ON | ALL &#125; ] pidstat pidstat主要用于监控全部或指定进程占用系统资源的情况，如CPU，内存、设备IO、任务切换、线程等。pidstat首次运行时显示自系统启动开始的各项统计信息，之后运行pidstat将显示自上次运行该命令以后的统计信息。用户可以通过指定统计的次数和时间来获得所需的统计信息 linux命令—pidstat [root@localhost ~]# pidstat Linux 3.10.0-123.el7.x86_64 (localhost.localdomain) 2019年08月01日 _x86_64_ (1 CPU) 06时58分02秒 UID PID %usr %system %guest %CPU CPU Command 06时58分02秒 0 1 0.01 0.05 0.00 0.06 0 systemd 06时58分02秒 0 2 0.00 0.00 0.00 0.00 0 kthreadd 06时58分02秒 0 3 0.00 0.00 0.00 0.00 0 ksoftirqd/0 06时58分02秒 0 6 0.00 0.01 0.00 0.01 0 kworker/u256:0 06时58分02秒 0 137 0.00 0.02 0.00 0.02 0 rcu_sched 06时58分02秒 0 138 0.00 0.04 0.00 0.04 0 rcuos/0 06时58分02秒 0 266 0.00 0.00 0.00 0.00 0 watchdog/0 06时58分02秒 0 274 0.00 0.00 0.00 0.00 0 khubd 06时58分02秒 0 280 0.00 0.02 0.00 0.02 0 khugepaged 06时58分02秒 0 292 0.00 0.00 0.00 0.00 0 kworker/u256:1 06时58分02秒 0 812 0.00 0.00 0.00 0.00 0 scsi_eh_0 06时58分02秒 0 2024 0.00 0.01 0.00 0.01 0 kworker/0:1H 06时58分02秒 0 2025 0.00 0.02 0.00 0.02 0 xfsaild/dm-1 06时58分02秒 0 2098 0.00 0.00 0.00 0.00 0 systemd-journal 06时58分02秒 0 2133 0.01 0.00 0.00 0.01 0 systemd-udevd 06时58分02秒 0 3729 0.00 0.00 0.00 0.00 0 auditd 06时58分02秒 81 3762 0.00 0.00 0.00 0.00 0 dbus-daemon 06时58分02秒 0 3763 0.00 0.00 0.00 0.00 0 systemd-logind 06时58分02秒 0 3769 0.00 0.00 0.00 0.00 0 rsyslogd 06时58分02秒 70 3770 0.00 0.00 0.00 0.00 0 avahi-daemon 06时58分02秒 0 3771 0.01 0.01 0.00 0.02 0 tuned 06时58分02秒 0 4633 0.00 0.00 0.00 0.00 0 iprinit 06时58分02秒 0 4635 0.00 0.00 0.00 0.00 0 iprupdate 06时58分02秒 0 5078 0.00 0.00 0.00 0.00 0 login 06时58分02秒 0 5171 0.00 0.00 0.00 0.00 0 master 06时58分02秒 0 5727 0.00 0.01 0.00 0.01 0 sshd 06时58分02秒 0 8944 0.00 0.01 0.00 0.01 0 sshd 06时58分02秒 0 8946 0.00 0.00 0.00 0.00 0 bash 06时58分02秒 999 15236 0.00 0.00 0.00 0.00 0 polkitd 06时58分02秒 0 15644 0.00 0.01 0.00 0.01 0 kworker/0:0 06时58分02秒 0 15901 0.00 0.01 0.00 0.01 0 kworker/0:1 06时58分02秒 0 16170 0.00 0.00 0.00 0.00 0 kworker/0:2 06时58分02秒 0 16346 0.00 0.00 0.00 0.00 0 pidstat CPU密集型进程/大量使用CPU进程stress： [root@localhost ~]# stress -c 1 -t 600 stress: info: [17214] dispatching hogs: 1 cpu, 0 io, 0 vm, 0 hdd uptime： [root@localhost ~]# uptime 07:17:32 up 1:05, 6 users, load average: 1.05, 0.54, 0.42 mpstat： [root@localhost ~]# mpstat -P ALL 5 3 Linux 3.10.0-123.el7.x86_64 (localhost.localdomain) 2019年08月01日 _x86_64_ (1 CPU) 07时16分51秒 CPU %usr %nice %sys %iowait %irq %soft %steal %guest %gnice %idle 07时16分56秒 all 99.40 0.00 0.60 0.00 0.00 0.00 0.00 0.00 0.00 0.00 07时16分56秒 0 99.40 0.00 0.60 0.00 0.00 0.00 0.00 0.00 0.00 0.00 07时16分56秒 CPU %usr %nice %sys %iowait %irq %soft %steal %guest %gnice %idle 07时17分01秒 all 99.60 0.00 0.40 0.00 0.00 0.00 0.00 0.00 0.00 0.00 07时17分01秒 0 99.60 0.00 0.40 0.00 0.00 0.00 0.00 0.00 0.00 0.00 07时17分01秒 CPU %usr %nice %sys %iowait %irq %soft %steal %guest %gnice %idle 07时17分06秒 all 99.20 0.00 0.80 0.00 0.00 0.00 0.00 0.00 0.00 0.00 07时17分06秒 0 99.20 0.00 0.80 0.00 0.00 0.00 0.00 0.00 0.00 0.00 平均时间: CPU %usr %nice %sys %iowait %irq %soft %steal %guest %gnice %idle 平均时间: all 99.40 0.00 0.60 0.00 0.00 0.00 0.00 0.00 0.00 0.00 平均时间: 0 99.40 0.00 0.60 0.00 0.00 0.00 0.00 0.00 0.00 0.00 pidstat： [root@localhost ~]# pidstat -u 5 3 Linux 3.10.0-123.el7.x86_64 (localhost.localdomain) 2019年08月01日 _x86_64_ (1 CPU) 07时16分54秒 UID PID %usr %system %guest %CPU CPU Command 07时16分59秒 0 2025 0.00 0.20 0.00 0.20 0 xfsaild/dm-1 07时16分59秒 0 16706 0.00 0.20 0.00 0.20 0 sshd 07时16分59秒 0 17215 98.61 0.00 0.00 98.61 0 stress 07时16分59秒 0 17429 0.00 0.20 0.00 0.20 0 top 07时16分59秒 0 17532 0.00 0.20 0.00 0.20 0 pidstat 07时16分59秒 UID PID %usr %system %guest %CPU CPU Command 07时17分04秒 0 17215 99.20 0.00 0.00 99.20 0 stress 07时17分04秒 0 17532 0.00 0.40 0.00 0.40 0 pidstat 07时17分04秒 UID PID %usr %system %guest %CPU CPU Command 07时17分09秒 0 1 0.00 0.20 0.00 0.20 0 systemd 07时17分09秒 0 17215 98.80 0.00 0.00 98.80 0 stress 07时17分09秒 0 17429 0.20 0.20 0.00 0.40 0 top 07时17分09秒 0 17532 0.00 0.20 0.00 0.20 0 pidstat 平均时间: UID PID %usr %system %guest %CPU CPU Command 平均时间: 0 1 0.00 0.07 0.00 0.07 - systemd 平均时间: 0 2025 0.00 0.07 0.00 0.07 - xfsaild/dm-1 平均时间: 0 16706 0.00 0.07 0.00 0.07 - sshd 平均时间: 0 17215 98.87 0.00 0.00 98.87 - stress 平均时间: 0 17429 0.07 0.13 0.00 0.20 - top 平均时间: 0 17532 0.00 0.27 0.00 0.27 - pidstat 选项 说明 %usr 在统计周期内，用户态任务和其子任务耗时统计（ms），包括或者不包括调优时间，注意不包括运行虚拟处理器时间 %system 在统计周期内，内核态任务和其子任务耗时统计（ms） %guest 在统计周期内，虚拟态任务和其子任务耗时统计（ms） top： Tasks: 349 total, 3 running, 346 sleeping, 0 stopped, 0 zombie %Cpu(s):100.0 us, 0.0 sy, 0.0 ni, 0.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st KiB Mem: 3869020 total, 775460 used, 3093560 free, 1232 buffers KiB Swap: 4079612 total, 0 used, 4079612 free. 563764 cached Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 17215 root 20 0 7260 96 0 R 99.4 0.0 3:17.02 stress 1 root 20 0 49904 4180 2472 S 0.0 0.1 0:01.68 systemd CPU密集型进程:使用大量CPU导致平均负载升高 IO密集型stress [root@localhost ~]# stress -i 1 --hdd 1 -t 600 stress: info: [23947] dispatching hogs: 0 cpu, 1 io, 0 vm, 1 hdd uptime [root@localhost ~]# uptime 08:09:24 up 1:57, 9 users, load average: 2.78, 1.84, 1.80 mpstat [root@localhost sysstat-12.1.5]# mpstat -P ALL 5 3 Linux 3.10.0-123.el7.x86_64 (localhost.localdomain) 2019年08月01日 _x86_64_ (1 CPU) 08时07分33秒 CPU %usr %nice %sys %iowait %irq %soft %steal %guest %gnice %idle 08时07分38秒 all 0.21 0.00 35.48 50.83 0.00 13.49 0.00 0.00 0.00 0.00 08时07分38秒 0 0.21 0.00 35.48 50.83 0.00 13.49 0.00 0.00 0.00 0.00 08时07分38秒 CPU %usr %nice %sys %iowait %irq %soft %steal %guest %gnice %idle 08时07分43秒 all 0.21 0.00 25.51 61.73 0.00 12.55 0.00 0.00 0.00 0.00 08时07分43秒 0 0.21 0.00 25.51 61.73 0.00 12.55 0.00 0.00 0.00 0.00 08时07分43秒 CPU %usr %nice %sys %iowait %irq %soft %steal %guest %gnice %idle 08时07分48秒 all 0.21 0.00 25.47 68.63 0.00 5.68 0.00 0.00 0.00 0.00 08时07分48秒 0 0.21 0.00 25.47 68.63 0.00 5.68 0.00 0.00 0.00 0.00 平均时间: CPU %usr %nice %sys %iowait %irq %soft %steal %guest %gnice %idle 平均时间: all 0.21 0.00 28.83 60.36 0.00 10.60 0.00 0.00 0.00 0.00 平均时间: 0 0.21 0.00 28.83 60.36 0.00 10.60 0.00 0.00 0.00 0.00 pidstat [root@localhost wang]# pidstat -u 5 3 Linux 3.10.0-123.el7.x86_64 (localhost.localdomain) 2019年08月01日 _x86_64_ (1 CPU) 08时07分35秒 UID PID %usr %system %guest %CPU CPU Command 08时07分40秒 0 3 0.00 0.83 0.00 0.83 0 ksoftirqd/0 08时07分40秒 0 137 0.00 0.21 0.00 0.21 0 rcu_sched 08时07分40秒 0 2024 0.00 0.21 0.00 0.21 0 kworker/0:1H 08时07分40秒 0 23777 0.00 0.21 0.00 0.21 0 kworker/0:1 08时07分40秒 0 23805 0.00 0.41 0.00 0.41 0 kworker/0:3 08时07分40秒 0 23807 0.00 11.41 0.00 11.41 0 kworker/u256:2 08时07分40秒 0 23942 0.21 0.21 0.00 0.41 0 top 08时07分40秒 0 23948 0.00 2.49 0.00 2.49 0 stress 08时07分40秒 0 23949 0.00 25.73 0.00 25.73 0 stress 08时07分40秒 0 24011 0.00 0.41 0.00 0.41 0 pidstat 08时07分40秒 UID PID %usr %system %guest %CPU CPU Command 08时07分45秒 0 3 0.00 0.61 0.00 0.61 0 ksoftirqd/0 08时07分45秒 0 266 0.00 0.20 0.00 0.20 0 watchdog/0 08时07分45秒 0 23777 0.00 0.61 0.00 0.61 0 kworker/0:1 08时07分45秒 0 23805 0.00 0.41 0.00 0.41 0 kworker/0:3 08时07分45秒 0 23806 0.00 0.82 0.00 0.82 0 kworker/0:4 08时07分45秒 0 23807 0.00 15.95 0.00 15.95 0 kworker/u256:2 08时07分45秒 0 23942 0.61 0.82 0.00 1.43 0 top 08时07分45秒 0 23948 0.00 6.13 0.00 6.13 0 stress 08时07分45秒 0 23949 0.00 36.40 0.00 36.40 0 stress 08时07分45秒 0 24011 0.20 0.20 0.00 0.41 0 pidstat 08时07分45秒 UID PID %usr %system %guest %CPU CPU Command 08时07分50秒 0 3 0.00 0.21 0.00 0.21 0 ksoftirqd/0 08时07分50秒 0 138 0.00 0.21 0.00 0.21 0 rcuos/0 08时07分50秒 0 23806 0.00 0.42 0.00 0.42 0 kworker/0:4 08时07分50秒 0 23807 0.00 1.49 0.00 1.49 0 kworker/u256:2 08时07分50秒 0 23942 0.21 0.00 0.00 0.21 0 top 08时07分50秒 0 23948 0.00 0.21 0.00 0.21 0 stress 08时07分50秒 0 23949 0.00 4.67 0.00 4.67 0 stress 08时07分50秒 0 23955 0.21 0.00 0.00 0.21 0 watch 08时07分50秒 0 24011 0.00 0.21 0.00 0.21 0 pidstat 平均时间: UID PID %usr %system %guest %CPU CPU Command 平均时间: 0 3 0.00 0.55 0.00 0.55 - ksoftirqd/0 平均时间: 0 137 0.00 0.07 0.00 0.07 - rcu_sched 平均时间: 0 138 0.00 0.07 0.00 0.07 - rcuos/0 平均时间: 0 266 0.00 0.07 0.00 0.07 - watchdog/0 平均时间: 0 2024 0.00 0.07 0.00 0.07 - kworker/0:1H 平均时间: 0 23777 0.00 0.28 0.00 0.28 - kworker/0:1 平均时间: 0 23805 0.00 0.28 0.00 0.28 - kworker/0:3 平均时间: 0 23806 0.00 0.42 0.00 0.42 - kworker/0:4 平均时间: 0 23807 0.00 9.71 0.00 9.71 - kworker/u256:2 平均时间: 0 23942 0.35 0.35 0.00 0.69 - top 平均时间: 0 23948 0.00 2.98 0.00 2.98 - stress 平均时间: 0 23949 0.00 22.47 0.00 22.47 - stress 平均时间: 0 23955 0.07 0.00 0.00 0.07 - watch 平均时间: 0 24011 0.07 0.28 0.00 0.35 - pidstat [root@localhost wang]# pidstat -d 5 3 Linux 3.10.0-123.el7.x86_64 (localhost.localdomain) 2019年08月01日 _x86_64_ (1 CPU) 08时08分32秒 UID PID kB_rd/s kB_wr/s kB_ccwr/s Command 08时08分37秒 0 23948 0.00 0.00 33647.20 stress 08时08分37秒 0 23949 0.00 838860.80 150474.40 stress 08时08分37秒 UID PID kB_rd/s kB_wr/s kB_ccwr/s Command 08时08分42秒 0 292 0.00 6036.21 0.00 kworker/u256:1 08时08分42秒 0 23949 0.00 441505.68 236369.68 stress 08时08分42秒 UID PID kB_rd/s kB_wr/s kB_ccwr/s Command 08时08分47秒 0 292 0.00 34784.07 0.00 kworker/u256:1 08时08分47秒 0 23948 0.00 0.00 60896.44 stress 08时08分47秒 0 23949 0.00 439654.51 112327.88 stress 平均时间: UID PID kB_rd/s kB_wr/s kB_ccwr/s Command 平均时间: 0 292 0.00 13401.65 0.00 kworker/u256:1 平均时间: 0 23948 0.00 0.00 31591.74 stress 平均时间: 0 23949 0.00 577727.82 166042.15 stress top [root@localhost ~]# top top - 08:09:12 up 1:57, 9 users, load average: 2.74, 1.80, 1.79 Tasks: 361 total, 2 running, 359 sleeping, 0 stopped, 0 zombie %Cpu(s): 0.3 us, 28.2 sy, 0.0 ni, 0.0 id, 59.9 wa, 0.0 hi, 11.5 si, 0.0 st KiB Mem: 3869020 total, 1910484 used, 1958536 free, 1232 buffers KiB Swap: 4079612 total, 0 used, 4079612 free. 1653112 cached Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 23949 root 20 0 8164 1124 32 D 21.6 0.0 0:35.57 stress 292 root 20 0 0 0 0 D 9.6 0.0 0:10.20 kworker/u256:1 以上大量IO导致平均负载升高，cpu占用并不高 大量等待CPU的进程stress [root@localhost ~]# stress -c 8 -t 600 stress: info: [24363] dispatching hogs: 8 cpu, 0 io, 0 vm, 0 hdd uptime [root@localhost ~]# uptime 08:15:23 up 2:03, 9 users, load average: 7.63, 4.09, 2.59 mpstat [root@localhost sysstat-12.1.5]# mpstat -P ALL 5 3 Linux 3.10.0-123.el7.x86_64 (localhost.localdomain) 2019年08月01日 _x86_64_ (1 CPU) 08时15分27秒 CPU %usr %nice %sys %iowait %irq %soft %steal %guest %gnice %idle 08时15分32秒 all 99.80 0.00 0.20 0.00 0.00 0.00 0.00 0.00 0.00 0.00 08时15分32秒 0 99.80 0.00 0.20 0.00 0.00 0.00 0.00 0.00 0.00 0.00 08时15分32秒 CPU %usr %nice %sys %iowait %irq %soft %steal %guest %gnice %idle 08时15分37秒 all 99.40 0.00 0.60 0.00 0.00 0.00 0.00 0.00 0.00 0.00 08时15分37秒 0 99.40 0.00 0.60 0.00 0.00 0.00 0.00 0.00 0.00 0.00 08时15分37秒 CPU %usr %nice %sys %iowait %irq %soft %steal %guest %gnice %idle 08时15分42秒 all 99.60 0.00 0.40 0.00 0.00 0.00 0.00 0.00 0.00 0.00 08时15分42秒 0 99.60 0.00 0.40 0.00 0.00 0.00 0.00 0.00 0.00 0.00 平均时间: CPU %usr %nice %sys %iowait %irq %soft %steal %guest %gnice %idle 平均时间: all 99.60 0.00 0.40 0.00 0.00 0.00 0.00 0.00 0.00 0.00 平均时间: 0 99.60 0.00 0.40 0.00 0.00 0.00 0.00 0.00 0.00 0.00 pidstat wait值为0，明天再定位 -c 40，wait也是0,不知道什么原因.cpu性能太好?先不管了,以后再说. top [root@localhost ~]# top top - 08:21:56 up 2:10, 4 users, load average: 7.72, 5.76, 3.78 Tasks: 355 total, 10 running, 345 sleeping, 0 stopped, 0 zombie %Cpu(s):100.0 us, 0.0 sy, 0.0 ni, 0.0 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st KiB Mem: 3869020 total, 820136 used, 3048884 free, 1232 buffers KiB Swap: 4079612 total, 0 used, 4079612 free. 604588 cached Mem PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 25022 root 20 0 7260 92 0 R 12.6 0.0 0:19.44 stress 25023 root 20 0 7260 92 0 R 12.6 0.0 0:19.44 stress 25024 root 20 0 7260 92 0 R 12.6 0.0 0:19.44 stress 25025 root 20 0 7260 92 0 R 12.6 0.0 0:19.44 stress 25026 root 20 0 7260 92 0 R 12.6 0.0 0:19.44 stress 25020 root 20 0 7260 92 0 R 12.3 0.0 0:19.43 stress 25021 root 20 0 7260 92 0 R 12.3 0.0 0:19.43 stress 25027 root 20 0 7260 92 0 R 12.3 0.0 0:19.43 stress 问题 pidstat不显示%wait 安装新版本的sysstat:下载地址 iowait无法升高 stress -i 时刷新内存缓冲区数据到磁盘,新装的虚拟机缓冲区比较小,没有那么大的压力.只是系统调用导致的cpu升高可以用stress -i 1 –hdd 1 -t 600 //–hdd表示读写临时文件 ending","categories":[],"tags":[{"name":"运维","slug":"运维","permalink":"https://riverferry.site/tags/%E8%BF%90%E7%BB%B4/"}],"keywords":[]},{"title":"TheRiver的由来","slug":"2019-07-30-TheRiver的由来","date":"2019-07-30T00:00:00.000Z","updated":"2022-09-12T16:24:32.273Z","comments":true,"path":"2019-07-30-TheRiver的由来/","link":"","permalink":"https://riverferry.site/2019-07-30-TheRiver%E7%9A%84%E7%94%B1%E6%9D%A5/","excerpt":"前言从初中开始,因为一款回合制游戏其中的一段渊源,我从那个时候就一直用的这个网名:江上摆渡翁 几乎后来所有我玩的游戏,还有网站，社交平台,需要ID的我都会沿用这个名称. 后来,我打算换个简洁的英文的网名,结合了river这个人物和TheShy的名字,又保留了我原先的江上这个词的意境,最终定为:TheRiver","text":"前言从初中开始,因为一款回合制游戏其中的一段渊源,我从那个时候就一直用的这个网名:江上摆渡翁 几乎后来所有我玩的游戏,还有网站，社交平台,需要ID的我都会沿用这个名称. 后来,我打算换个简洁的英文的网名,结合了river这个人物和TheShy的名字,又保留了我原先的江上这个词的意境,最终定为:TheRiver Who is river原文：上帝宠爱的人都会在年轻时死去这里把上面链接的文章复制过来,作者:李荷西 非常喜欢的一篇文章 前几天刷了个电影，斯蒂芬.金的小说《尸体》改编的《伴我同行》（stand by me）。 按罗伯特.麦基在《故事》这本书里的划分，这应该是属于小情节电影里的教育情节电影。 电影故事简介： 这是一部关于成长的电影。著名作家戈迪（理查德•德莱福斯 Richard Dreyfuss 饰）回忆起他12岁时的一次冒险活动：当时，年少的戈迪（威尔•惠顿 Wil Wheaton 饰）与他的三个小伙伴克里斯（瑞凡•菲尼克斯 River Phoenix 饰）、泰迪（科里•费尔德曼 Corey Feldman 饰）和维恩为了当一回“英雄”去河的对岸的森林里寻找一具12岁男孩的尸体。 4个少年家庭各有问题，他们都有自己的心事。在旅程中每个人的性格都被体现得淋漓尽致：四个男孩性格中的软弱和坚强，在闪火车，翻铁门，越森林等一系列的行动中被最大限度的放大；每个人都有自己可望而不可及的梦想…… 1987年金球奖最佳电影、最佳导演提名，1987年奥斯卡奖最佳编剧提名。 整体来说，这个电影并无大冲突，是一个作家对于自己12岁那年的一段回忆的讲述。电影表面上是在讲一段少年的冒险以及友情，实际上是在说家庭。每一个12岁的少年，都身穿着家庭所给予的枷锁。 世界上没有完美的父母，没有完美的Family。每个人都在试图挣脱着家的牢笼。12岁的男孩最强烈。 4个小男孩儿，一个承受着父母只偏爱哥哥的冷暴力，一个爸爸酗酒哥哥坐牢，一个的爸爸是曾经登陆过诺曼底的精神病患者，另一个是笨笨的不那么敏感的胖子。 River Phoenix在里面饰演男主作家最好的朋友Chris。 他在电影里长这样： 这部影片给他赢来了会演又长得很帅的声誉。之后的《不设通缉令》更为他赢得了奥斯卡最佳男配的提名。《不羁的天空》又名《我自己的爱荷达》让他坐上了威尼斯电影节影帝的位置。 比起15岁出演《伴我同行》时，这个少年清俊了许多。 他是一个特别的孩子。从名字上就可以看出来。 1970年，8月23日，母亲在公路上难产三天后生下他，来到世间便仿佛奇迹。凤凰城，河流，嬉皮士父母给了他这个名字。却恰恰切合了漂流一生在雨季归去的宿命。父母以赫尔曼·黑塞（Hermann Hesse）的小说《席特哈尔塔》中的“生命的河流”为第一个孩子取名River，即河流，中间名裘德（Jude）则取自甲壳虫乐队的著名歌曲《Hey Jude》。 －－－引自豆瓣和百度百科 18岁出演《夺宝奇兵3》，21岁和基努里维斯合作出演《我自己的爱荷达》，成为基努里维斯的密友，在圈内与约翰尼德普交好。曾经有人说，如果River还活着，那么他绝对就可以和约翰尼德普平分“最性感男人”之称。而当时寂寂无名的莱昂纳多迪卡普里奥，把他视为偶像。 River，1993年在准备参加约翰尼德普的万圣节派对前去世，死因是吸毒过量。他体内海洛因与古柯碱的含量是致死量的八倍。 看到这里，可能很多人会说，这是一个被上帝宠坏了的孩子。年纪轻轻便坐拥巨大名利，在好莱坞的镁光灯下，他迷失了，变坏了。 事实并非如此。16岁之后，River便负担父母和4个兄妹的全部家用。他给予很多人人道主义帮助，还是环境保护者，买了800英亩的濒危雨林。并且，他终身素食。 他16岁那年交了个女朋友，他非常喜欢她。共进晚餐时，女朋友点了一盘软壳蟹。他无法忍受地跑出了餐厅。她找到他时，他正在哭：“我这么爱你，为什么？” 他理解不了人们吃任何生命体，哪怕是最喜欢的女朋友也不行。 同时，他还写歌，有自己的乐队，是词曲作者和主音吉他。 这样一个光芒万丈、有才华、内心温柔的人，为什么会吸毒？那么大的剂量，根本就是自杀！ 世人都被他忧伤淡淡的表情和独特脆弱的气质所吸引，而这些也许并不是他所刻意营造的“popular”外在，也许是埋在骨子里，与生具来的。 他的眉间总是锁紧。他从未演过阳光热情或者凶悍的角色。 生前接到的最后两个片约一部是《夜访吸血鬼》，一部是《黑血》。当时他准备拍完这两部电影就退出娱乐圈。《夜访吸血鬼》因为他的离世无法参演，但电影出来后，最后出现的字幕上，可以看到这样的文字:”仅以此献给瑞凡·菲尼克斯 (River Phoenix)”. 而《黑血》这部影片，在他去世时，只差11天就杀青。直到2012年才面世。 有网友评论这张《黑血》的剧照说： 从很小开始，眉心就一直紧皱，从未舒展。。。心疼啊~来过这么快的一下子… 可是，到底是什么让这样一个孩子从小就不开心呢？他明明拥有了所有人都羡慕的一切。 然后我找到了这样的一段记录： 当菲尼克斯还在蹒跚学步的时候，他的父母约翰和艾琳就加入了一个名为“上帝之子”（the Children of God）的邪教组织。他们起初在南部一带过着居无定所的生活，最终选择了“上帝之子”的公社所在地、委内瑞拉的加拉加斯生活。该邪教教徒把孩子们送到街头唱歌卖艺，如果不这么做，孩子们就得挨饿。 更有甚者，“上帝之子”被认为是一个和性有关的邪教组织。儿童被鼓励彼此之间、并和成年人发生性关系。他们的宗教仪式包括祈祷，随后彼此间发生性关系以实现“性的探索”，参与该“仪式”的甚至包括年仅三岁的儿童。在接受《Details》杂志专访时，菲尼克斯坦承自己第一次与人发生性关系是在他四岁的时候，对方也是一个孩子。“但是后来我杜绝了这一行为。10至14岁之间我是完全禁欲的。”直到菲尼克斯7岁的时候，父母才脱离了这一邪教组织，原因是上级指令女教徒必须通过色诱招募更多的男教徒，这令菲尼克斯的母亲有所犹豫。直到这时她才发出抗议：“组织的领导者疯了。他想要通过性去吸引富有的门徒。没门！” 尽管脱离邪教，但往后菲尼克斯家庭的行为依然让人觉得颇为怪异。比如菲尼克斯15岁那年，是在自家后院由父母特意为之搭建并装饰得漂漂亮亮的帐篷里再度与他人发生性关系的！据与菲尼克斯合作《伴我同行》的男演员科里·费尔德曼透露，在菲尼克斯看来，那相当于夺走自己的“第二次童贞”。对方是家族的朋友，那次充满仪式感的性行为是双方父母的共同安排。 这段记录来自于River Phoenix的传记。 如果真如传记所说，那么River算是有着极深且不堪的童年阴影。他一生都在努力走出这种阴影。从小被送去学表演，拍广告，成为童星，接拍电影，最终深陷好莱坞的漩涡中心。每一步似乎都身不由己。什么才是他真正想做的呢？大概只有音乐。 什么是他真正想拥有的呢？大概是一个健康美满又平凡的家庭。 他曾经这样形容在世人眼中无限荣光的好莱坞：肮脏、恶心。 如果用那句著名的“眼睛是心理的投射”来解释的话，River也许从来不够自信。 也许对他来说，活着太过绵长。就算功成名就也无法自救。英年早逝，让太多人都记得他最漂亮时候的样子。 西方有一句谚语：”上帝爱的人都会在很年轻的时候就死去，这是上帝爱之子才具有的权利.” 也许死亡，是上帝赋予他的又一个权力。他用死亡和自己也和这个荒诞的世界和解了。","categories":[],"tags":[{"name":"River","slug":"River","permalink":"https://riverferry.site/tags/River/"}],"keywords":[]},{"title":"题库","slug":"2019-07-30-题库","date":"2019-07-30T00:00:00.000Z","updated":"2022-09-12T16:24:32.274Z","comments":true,"path":"2019-07-30-题库/","link":"","permalink":"https://riverferry.site/2019-07-30-%E9%A2%98%E5%BA%93/","excerpt":"前言一些零碎的面试知识点，先放这里","text":"前言一些零碎的面试知识点，先放这里 基本知识回顾已知strcpy函数的原型是： char * strcpy(char * strDest,const char * strSrc); 1.不调用库函数，实现strcpy函数。 2.解释为什么要返回char *。 错误示例: char * strcpy(char * strDest,const char * strSrc) &#123; if（NULL == strDest） &#123; return NULL: &#125; if (NULL == strSrc) &#123; return strDest; &#125; if (NULL != strSrc) &#123; strDest++ = strSrc++; &#125; *strDest = &#39;\\0&#39;; &#125; 参考答案: char * strcpy(char * strDest,const char * strSrc) &#123; if ((strDest==NULL)||(strSrc==NULL)) //[1] throw &quot;Invalid argument(s)&quot;; //[2] char * strDestCopy=strDest; //[3] while ((*strDest++=*strSrc++)!=&#39;\\0&#39;); //[4] return strDestCopy; &#125; 注意点: 1：检查指针的有效性，注意隐式的类型转换，用NULL来检查比较合理 2：异常的处理,不管是源还是目的指针,为空都抛出异常。或者return NULL 打印异常:terminate called after throwing an instance of &#39;char const*&#39; 3：函数返回值,保存目的字符串的起始位置返回,不是源字符串,这样可以使函数支持链式表达式 链式表达式: int iLength=strlen(strcpy(strA,strB)); char * strA=strcpy(new char[10],strB); 4：最简洁的语句 while (*strDest++=*strSrc++); 链接1.求下面函数的返回值 int countx = 0; while(x) &#123; countx ++; x = x&amp;(x-1); &#125; return countx; 参考答案: while循环每次把2进制的右边的1消除,返回值是循环的次数,循环的次数是x的二进制位中包含1的个数 2.什么是“引用”?声明和使用“引用”要注意哪些问题? 参考答案: 引用就是某个目标变量的“别名”，对引用的操作与对变量直接操作效果完全相同 声明一个引用的时候，切记要对其进行初始化 它本身不是一种数据类型，因此引用本身不占存储单元 网上有的地方说数组不能引用,其实是可以的,参考: 关于数组的引用和引用的数组 //数组的引用 int a[10] =&#123;0&#125;; int (&amp;b)[10] = a; 网上有的地方说引用一经定义,就不可更改,但是我用vs2017是可以的: int a = 1; int c = 2; int &amp; b = a; b = c; 3.将“引用”作为函数参数有哪些特点? 类似指针,不同于传值调用会自动创建临时变量副本,提高效率 不同于指针,传入指针,函数也会申请临时的指针变量存放实际变量的地址,而引用不会.且引用的可读性更好 4.在什么时候需要使用“常引用”? 如果既要利用引用提高程序的效率，又要保护传递给函数的数据不在函数中被改变，就应使用常引用。常引用声明方式：const 类型标识符 &amp;引用名=目标变量名; //有点像是常量指针 int a ; const int &amp;ra=a; ra=1; //错误 a=1; //正确 int main() &#123; string foo(); void bar(string &amp; s); bar(foo()); //错误,非常量引用的初始值必须是左值 无法从const string 转换为 string &amp; bar(&quot;hello world&quot;); //错误,利用拷贝构造函数会生成const string,但无法转为string &amp; //改成bar(const string &amp; s)就好了 &#125; 非常量引用的初始值必须是左值 5.“引用”与指针的区别是什么? 6.线程与进程的区别 进程和线程都是一个时间段的描述，是CPU工作时间段的描述，不过是颗粒大小不同 线程是共享了进程的上下文环境，的更为细小的CPU时间段 线程和进程的区别是什么？","categories":[],"tags":[{"name":"work","slug":"work","permalink":"https://riverferry.site/tags/work/"}],"keywords":[]},{"title":"sipp总结","slug":"2019-07-17-sipp总结","date":"2019-07-17T00:00:00.000Z","updated":"2022-09-12T16:24:32.273Z","comments":true,"path":"2019-07-17-sipp总结/","link":"","permalink":"https://riverferry.site/2019-07-17-sipp%E6%80%BB%E7%BB%93/","excerpt":"说明本文一些资料从网络获得,出处已经找不到了，就不粘原文了.","text":"说明本文一些资料从网络获得,出处已经找不到了，就不粘原文了. 介绍SIPp是一个测试SIP协议性能的开源工具软件 功能脚本模拟 通过Xml格式的自定义脚本文件格式，模拟 真实网元进行UAS和UAC等场景的话务量性 能测试。 运行控制 支持外部配置文件的导入、内部及外部命令 处理、过程监控和统计结果的输出。 消息构造 提供标准化的sip协议支持，便捷的消息构造。 支持多种运行参数，应对不同测试场景要求 程序设计 支持branch分支、变量处理、正则表达式、 算术运算等功能，便于构建程序化脚本 除了以上主要功能外，SIPp还提供了包括TLS、鉴权、 密码认证、RTP媒体流收发等其他的特性支持 安装sipp有windows版和linux版本,本人比较习惯用linux下的. 官方下载链接 3.3 version 百度网盘 链接：https://pan.baidu.com/s/145iR5wK_RyZZEVEw9NsD_Q 提取码：08a3 中文翻译版使用手册 链接：https://pan.baidu.com/s/1cZVl-_xqRJZh1Dsvk24lJQ 提取码：ea5n 有如下四个选项来编译 SIPp： 不包含对 TLS，SCTP 或 PCAP 的支持 tar -xvzf sipp-xxx.tar cd sipp ./configure make 包含 TLS 支持 tar -xvzf sipp-xxx.tar cd sipp ./configure --with-openssl make 包含 PCAP play 支持 tar -xvzf sipp-xxx.tar cd sipp ./configure --with-pcap make 包含 SCTP 支持 tar -xvzf sipp-xxx.tar cd sipp ./configure --with-sctp make 或者组合支持以上功能 tar -xvzf sipp-xxx.tar cd sipp ./configure --with-sctp --with-pcap --with-openssl make 使用 我的启动脚本 #!/bin/sh ./sipp-3.5.1/sipp 192.169.1.111:7100 -sf main.xml -p 7777 -i 192.169.1.108 -m 1 -oocsf message.xml -trace_err exit 简单说明 -m: 设置最本最大的呼叫个数，当 sipp 达到该指定值会自动退出 -oocsf: 加载 out-of-call 脚本 OCC（Out-of-call）脚本作为特殊类型的脚本，通常不会单独使用，而是与UAC脚本配合使用（也只能与UAC脚本配合，UAS等类型脚本无法支持-occsn等执行命令）。主要作用为扩展UAC脚本的适用范围，使UAC脚本能够在接收到不同会话内的非预期消息时，不至于直接丢弃。如注册客户端可能会遇到接收到通知NOTIFY的消息，此时就需要在运行register脚本的时候适用-oocsn或-oocsf参数，配合ooc脚本，实现对NOTIFY消息返回200的操作。 示例脚本main.xml&lt;![CDATA[ &lt;?xml version=&quot;1.0&quot; encoding=&quot;gb2312&quot;?&gt;&lt;!DOCTYPE scenario SYSTEM &quot;sipp.dtd&quot;&gt; &lt;scenario name=&quot;Catalog&quot;&gt; &lt;send&gt; &lt;![CDATA[ REGISTER sip:1234567890@192.169.1.201:7100 SIP/2.0 Via: SIP/2.0/UDP 192.169.1.107:7100;branch=[call_number] Call-ID: [call_id] From: &lt;sip:23232323232004567890@192.169.1.107:7100&gt;;tag=[call_number] To: &lt;sip:23232323232004567890@192.169.1.107&gt; CSeq:65 REGISTER Contact: &lt;sip:23232323232004567890@[local_ip]:[local_port]&gt; OutUserInfo: DomainId=23232323232004567890u;UserName=1234567890;UserPri=10 Max-Forwards: 70 Expires: 3600 User-Agent: hik RegMode: PLAT;Describe=hik-xxxx;Register;DevVer=Plat1.0 Content-Length: 0 ]]&gt; &lt;/send&gt; &lt;recv response=&quot;200&quot;&gt; &lt;/recv&gt; &lt;!--recv response=&quot;400&quot; next=&quot;message&quot;&gt; &lt;/recv--&gt; &lt;!--recv response=&quot;487&quot; next=&quot;message&quot;&gt; &lt;/recv--&gt; &lt;pause hide=&quot;true&quot; milliseconds=&quot;20000&quot;/&gt; &lt;/scenario&gt; ]]&gt; message.xml&lt;![CDATA[ &lt;?xml version=&quot;1.0&quot; encoding=&quot;gb2312&quot;?&gt;&lt;!DOCTYPE scenario SYSTEM &quot;sipp.dtd&quot;&gt; &lt;scenario name=&quot;Catalog&quot;&gt; &lt;!--recv request=&quot;REGISTER&quot; optional=&quot;true&quot; next=&quot;message&quot;&gt; &lt;/recv--&gt; &lt;label id=&quot;message&quot;/&gt; &lt;recv request=&quot;MESSAGE&quot;&gt; &lt;action&gt; &lt;ereg regexp=&quot;&lt;CmdType&gt;([[:alnum:]]*)&lt;/CmdType&gt;&quot; search_in=&quot;body&quot; check_it=&quot;false&quot; assign_to=&quot;1,2&quot; /&gt; &lt;strcmp assign_to=&quot;flag&quot; variable=&quot;2&quot; value=&quot;Catalog&quot; /&gt; &lt;test assign_to=&quot;result&quot; variable=&quot;flag&quot; compare=&quot;not_equal&quot; value=&quot;0&quot; /&gt; &lt;ereg regexp=&quot;&lt;SN&gt;([[:alnum:]]*)&lt;/SN&gt;&quot; search_in=&quot;body&quot; check_it=&quot;false&quot; assign_to=&quot;3,4&quot; /&gt; &lt;ereg regexp=&quot;CSeq: ([[:alnum:]]*)&quot; search_in=&quot;msg&quot; check_it=&quot;false&quot; assign_to=&quot;5,6,7&quot; /&gt; &lt;todouble assign_to=&quot;8&quot; variable=&quot;6&quot; /&gt; &lt;add assign_to=&quot;8&quot; value=&quot;1&quot; /&gt; &lt;assignstr assign_to=&quot;9&quot; value=&quot;[$8]&quot; /&gt; &lt;ereg regexp=&quot;([[:alnum:]]*).0000&quot; variable=&quot;9&quot; search_in=&quot;var&quot; check_it=&quot;false&quot; assign_to=&quot;tmp,cseq&quot; /&gt; &lt;exec command=&quot;echo \\&quot;arg2:[$2]\\n arg4:[$4]\\n arg6:[$6]\\n [$8]\\n arg9:[$9] \\ncseq:[$cseq]\\&quot; &gt;log.log &quot;/&gt; &lt;/action&gt; &lt;/recv&gt; &lt;Reference variables=&quot;1,2,3,4,5,6,7,8,9,flag,result,tmp,cseq&quot; /&gt; &lt;!--nop hide=&quot;true&quot; next=&quot;message&quot; test=&quot;result&quot; /--&gt; &lt;pause hide=&quot;true&quot; milliseconds=&quot;20&quot;/&gt; &lt;send&gt; &lt;![CDATA[ SIP/2.0 200 OK [last_Via:] [last_Call-ID:] [last_From:] [last_To:] [last_CSeq:] Contact: &lt;sip:23232323232004567890@[local_ip]:[local_port]&gt; User-Agent: hik Content-Length: 0 ]]&gt; &lt;/send&gt; &lt;pause hide=&quot;true&quot; milliseconds=&quot;20&quot;/&gt; &lt;send&gt; &lt;![CDATA[ MESSAGE sip:1234567890@192.169.1.201:7100 SIP/2.0 Via: SIP/2.0/UDP 192.169.1.107:7100;branch=[call_number] Call-ID: [call_id]@192.169.1.107 From: &lt;sip:23232323232004567890@192.169.1.107:7100;transport=udp&gt;;tag=[call_number] To: &lt;sip:1234567890@192.169.1.201;transport=udp&gt; CSeq: [$cseq] MESSAGE Max-Forwards: 70 Expires: 90 User-Agent: hik Contact: &lt;sip:23232323232004567890@192.169.1.107:7100&gt; Content-Length: [len] Content-Type: application/MANSCDP+xml &lt;?xml version=&quot;1.0&quot; encoding=&quot;GB2312&quot;?&gt; &lt;Response&gt; &lt;CmdType&gt;Catalog&lt;/CmdType&gt; &lt;SN&gt;[$4]&lt;/SN&gt; &lt;DeviceID&gt;23232323232004567890&lt;/DeviceID&gt; &lt;SumNum&gt;1&lt;/SumNum&gt; &lt;DeviceList Num=&quot;1&quot;&gt; &lt;Item&gt; &lt;DeviceID&gt;61000000001310001000&lt;/DeviceID&gt; &lt;Name&gt;22&lt;/Name&gt; &lt;Manufacturer&gt;hik&lt;/Manufacturer&gt; &lt;Model&gt;hik&lt;/Model&gt; &lt;Owner&gt;hik&lt;/Owner&gt; &lt;CivilCode&gt;3402&lt;/CivilCode&gt; &lt;Block&gt;[$6]&lt;/Block&gt; &lt;Address&gt;192.169.1.107&lt;/Address&gt; &lt;Parental&gt;0&lt;/Parental&gt; &lt;ParentID&gt;23232323232004567890/34020000002150000001&lt;/ParentID&gt; &lt;IPAddress&gt;&lt;/IPAddress&gt; &lt;Port&gt;7777&lt;/Port&gt; &lt;Password&gt;admin&lt;/Password&gt; &lt;Status&gt;OFF&lt;/Status&gt; &lt;Longitude&gt;&lt;/Longitude&gt; &lt;Latitude&gt;&lt;/Latitude&gt; &lt;Info&gt; &lt;CameraType&gt;3&lt;/CameraType&gt; &lt;PTZType&gt;3&lt;/PTZType&gt; &lt;BusinessGroupID&gt;34020000002150000001&lt;/BusinessGroupID&gt; &lt;/Info&gt; &lt;/Item&gt; &lt;/DeviceList&gt; &lt;/Response&gt; ]]&gt; &lt;/send&gt; &lt;/scenario&gt; ]]&gt; 说明sipp不同于简单的tcp/udp发送工具,sipp可以自动填充计算一些sipp头域的值，支持正则表达式,是会话相关的,有错误日志记录.总之功能很强大,目前我用到的场景还比较局限,常用于模拟复现一些问题,对于解决问题帮助很大.关于sipp的使用其实就是前面提到的中文文档,熟读文档，应有尽有. ending","categories":[],"tags":[{"name":"sip","slug":"sip","permalink":"https://riverferry.site/tags/sip/"}],"keywords":[]},{"title":"gsoap添加header","slug":"2019-07-15-gsoap添加header","date":"2019-07-15T00:00:00.000Z","updated":"2022-09-12T16:24:32.273Z","comments":true,"path":"2019-07-15-gsoap添加header/","link":"","permalink":"https://riverferry.site/2019-07-15-gsoap%E6%B7%BB%E5%8A%A0header/","excerpt":"Foreword前端时间碰到个事,axis的相机onvif接入,告警订阅有些问题.折磨了好久,后来自己买了个2手的axis相机,试着改了下gsoap的代码,才搞定,记录下","text":"Foreword前端时间碰到个事,axis的相机onvif接入,告警订阅有些问题.折磨了好久,后来自己买了个2手的axis相机,试着改了下gsoap的代码,才搞定,记录下 Solution这里有类似的问题:ONVIF PullPointSubscriptionClient.PullMessages I&#39;m trying to get event messages from some ONVIF devices. My code is in C#. On a (Axis camera) device on EventPortTypeClient.CreatePullPointSubscription returns: Address.Value: http : / /192.168.8.48/onvif/services ReferenceParameters.Any.First().OuterXml: &lt;dom0:SubscriptionId xmlns:dom0=&quot;http : / /www.axis.com/2009/event&quot;&gt;38&lt;/dom0:SubscriptionId&gt; So I add the &quot;To&quot; and &quot;SubscriptionId&quot; soap headers and can get event messages with PullPointSubscriptionClient.PullMessages(&quot;PT5M&quot;, 99, Any, out CurrentTime, out NotificationMessages) &lt;s:Envelope xmlns:a=&quot;http://www.w3.org/2005/08/addressing&quot; xmlns:s=&quot;http://www.w3.org/2003/05/soap-envelope&quot;&gt; &lt;s:Header&gt; &lt;a:Action s:mustUnderstand=&quot;1&quot;&gt;http://www.onvif.org/ver10/events/wsdl/PullPointSubscription/PullMessagesRequest&lt;/a:Action&gt; &lt;a:MessageID&gt;urn:uuid:f243dbe4-b082-4a6c-aa65-8145468fcf3e&lt;/a:MessageID&gt; &lt;a:ReplyTo&gt; &lt;a:Address&gt;http://www.w3.org/2005/08/addressing/anonymous&lt;/a:Address&gt; &lt;/a:ReplyTo&gt; &lt;VsDebuggerCausalityData xmlns=&quot;http://schemas.microsoft.com/vstudio/diagnostics/servicemodelsink&quot;&gt;uIDPo0zfnhoyh15KqPZwP/IS9H0AAAAAdCoo8EjbCUScx/bG/DGcdXp8kY6WrAJDp0TTtNAtj0EACQAA&lt;/VsDebuggerCausalityData&gt; &lt;Security s:mustUnderstand=&quot;1&quot; xmlns=&quot;http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-wssecurity-secext-1.0.xsd&quot;&gt; &lt;wsse:UsernameToken xmlns:wsse=&quot;http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-wssecurity-secext-1.0.xsd&quot; xmlns:wsu=&quot;http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-wssecurity-utility-1.0.xsd&quot; wsu:Id=&quot;SecurityToken-GWt5XP2ogUljZ/fzEJvnX0WhGpx3FV4i/dRnE539OFU=&quot;&gt; &lt;wsse:Username xmlns:wsse=&quot;http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-wssecurity-secext-1.0.xsd&quot;&gt;root&lt;/wsse:Username&gt; &lt;wsse:Password Type=&quot;http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-username-token-profile-1.0#PasswordDigest&quot; xmlns:wsse=&quot;http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-wssecurity-secext-1.0.xsd&quot;&gt;pjwOOO0hOXtUZyJb6B6Lb0ctRIU=&lt;/wsse:Password&gt; &lt;wsse:Nonce EncodingType=&quot;http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-soap-message-security-1.0#Base64Binary&quot; xmlns:wsse=&quot;http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-wssecurity-secext-1.0.xsd&quot;&gt;DEE/P1c/P1E/eG9XTT87Pz8/&lt;/wsse:Nonce&gt; &lt;wsu:Created xmlns:wsu=&quot;http://docs.oasis-open.org/wss/2004/01/oasis-200401-wss-wssecurity-utility-1.0.xsd&quot;&gt;2015-03-02T19:06:54.269Z&lt;/wsu:Created&gt; &lt;/wsse:UsernameToken&gt; &lt;/Security&gt; &lt;a:To s:mustUnderstand=&quot;1&quot;&gt;http://192.168.8.48/onvif/services&lt;/a:To&gt; &lt;SubscriptionId s:mustUnderstand=&quot;1&quot; xmlns=&quot;http://www.axis.com/2009/event&quot;&gt;38&lt;/SubscriptionId&gt; &lt;/s:Header&gt; &lt;s:Body xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:xsd=&quot;http://www.w3.org/2001/XMLSchema&quot;&gt; &lt;PullMessages xmlns=&quot;http://www.onvif.org/ver10/events/wsdl&quot;&gt; &lt;Timeout&gt;PT5M&lt;/Timeout&gt; &lt;MessageLimit&gt;99&lt;/MessageLimit&gt; &lt;/PullMessages&gt; &lt;/s:Body&gt; &lt;/s:Envelope&gt; onvif告警订阅的流程: 订阅 client –&gt; subscribe –&gt; server(ipc) server –&gt; 200 ok –&gt; client 续订 client –&gt; renew –&gt; server(ipc) server –&gt; 200 ok –&gt; client 取消订阅 client –&gt; unsubscribe –&gt; server(ipc) server –&gt; 200 ok –&gt; client 现在的问题是,axis的ipc在subscirbe的200 ok中携带了subscirbeid，他们用这个来区分订阅源的实例.并且要求client在renew和unsubscibe中携带这个subscribeid.这就比较麻烦了200 ok携带的subscribeid: 现在需要在renew和unsubscribe的header中添加一个字段 参考gSoap: How to add info to SOAP Header using gSOAP step 1 //soap-&gt;header中添加一个字段 struct SOAP_ENV__Header &#123; public: void *dummy; /* transient */ char *username; ... char *subscribeid; &#125;; step 2 //在对应的renew和unsubscribe的gsoap函数下，添加 if (NULL != soap-&gt;header-&gt;subscribeid) &#123; soap_element_begin_out(soap, &quot;SubscriptionId a:IsReferenceParameter=\\&quot;true\\&quot; xmlns=\\&quot;http://www.axis.com/2009/event\\&quot;&quot;, -1, &quot;&quot;) || soap_string_out(soap, a-&gt;subscribe_id, 0) || soap_element_end_out(soap, &quot;SubscriptionId&quot;) &#125; step 3 //我省略了这步 //Add the namespace mapping to namespaces array in .nsmap file. &#123;&quot;headerNS&quot;, &quot;http://customeheader.test.com&quot;, NULL, NULL&#125;, step 4 //在对应的地方给subscirbeid赋值,即200 ok中返回的值,需要解析EndpointReference struct soap soap; soap_init(&amp;soap); ... strcpy(soap-&gt;header-&gt;username, username); strcpy(soap-&gt;header-&gt;password, passwd); ... poSoap-&gt;header-&gt;subscribe_id = &quot;EndpointReference&quot; Finally, like this: ending","categories":[],"tags":[{"name":"onvif","slug":"onvif","permalink":"https://riverferry.site/tags/onvif/"}],"keywords":[]},{"title":"listen的backup参数","slug":"2019-07-08-listen的backup参数","date":"2019-07-08T00:00:00.000Z","updated":"2022-09-12T16:24:32.273Z","comments":true,"path":"2019-07-08-listen的backup参数/","link":"","permalink":"https://riverferry.site/2019-07-08-listen%E7%9A%84backup%E5%8F%82%E6%95%B0/","excerpt":"参考深入探索 Linux listen() 函数 backlog 的含义 Linux之TCP IP内核参数优化 对 Linux TCP 的若干疑点和误会Share this","text":"参考深入探索 Linux listen() 函数 backlog 的含义 Linux之TCP IP内核参数优化 对 Linux TCP 的若干疑点和误会Share this 正文 对于连接的初始阶段,服务端会维持2个队列.一个SYN队列,一个accept队列.限制syn队列的值： [root@localhost ~]# cat /proc/sys/net/ipv4/tcp_max_syn_backlog 65535 [root@localhost ~]# 限制accept队列的值: listen(fd, backlog); [root@localhost wang]# cat /proc/sys/net/core/somaxconn 65535 [root@localhost wang]# //取这两个的较小值 //直接修改配置文件只能临时生效,永久的方案是修改/etc/sysctl.conf,然后执行sysctl -p. 验证1 修改了/proc/sys/net/ipv4/tcp_max_syn_backlog=5，但实测SYN_RECV在6-9之间,没有严格按照配置文件的值来算.后来找到一篇文章,作者做了验证,可参考linux诡异的半连接(SYN_RECV)队列长度 tcp 0 0 127.0.0.1:7777 127.0.0.1:58653 SYN_RECV - tcp 0 0 127.0.0.1:7777 127.0.0.1:58655 SYN_RECV - tcp 0 0 127.0.0.1:7777 127.0.0.1:58650 SYN_RECV - tcp 0 0 127.0.0.1:7777 127.0.0.1:58651 SYN_RECV - tcp 0 0 127.0.0.1:7777 127.0.0.1:58657 SYN_RECV - tcp 0 0 127.0.0.1:7777 127.0.0.1:58656 SYN_RECV - tcp 0 0 127.0.0.1:7777 127.0.0.1:58654 SYN_RECV - tcp 0 0 127.0.0.1:7777 127.0.0.1:58652 SYN_RECV - tcp 0 0 127.0.0.1:7777 127.0.0.1:58649 SYN_RECV - 2 修改backlog=5,进行测试.ESTABLISHED=6.不增不减.可参考深入探索 Linux listen() 函数 backlog 的含义，应该就是backlog+1 tcp 0 0 127.0.0.1:7777 127.0.0.1:40454 ESTABLISHED - tcp 0 0 127.0.0.1:7777 127.0.0.1:40455 ESTABLISHED - tcp 0 0 127.0.0.1:7777 127.0.0.1:40452 ESTABLISHED - tcp 0 0 127.0.0.1:7777 127.0.0.1:40450 ESTABLISHED - tcp 0 0 127.0.0.1:7777 127.0.0.1:40451 ESTABLISHED - tcp 0 0 127.0.0.1:7777 127.0.0.1:40453 ESTABLISHED - 疑问当SYN队列值很大,backlog很小的时候.在accept队列满了的时候,客户端再发送数据,服务器会怎么处理这些数据?实验证明:accept队列达到backlog+1后,再accept会报错的,如果服务端线程accept是个循环,有可能导致服务端直接退出的: accept(3, &#123;sa_family=AF_INET, sin_port=htons(57100), sin_addr=inet_addr(&quot;127.0.0.1&quot;)&#125;, [16]) = 4 accept(3, &#123;sa_family=AF_INET, sin_port=htons(57101), sin_addr=inet_addr(&quot;127.0.0.1&quot;)&#125;, [16]) = 5 accept(3, &#123;sa_family=AF_INET, sin_port=htons(57102), sin_addr=inet_addr(&quot;127.0.0.1&quot;)&#125;, [16]) = 6 accept(3, 0x7fff429f1f70, [16]) = -1 EAGAIN (Resource temporarily unavailable) 还有一种情况,backup=3,我用nc起了4个客户端.客户端是4个ESTABLISHED，服务端是3个ESTABLISHED，一个SYN_RECV.我在第4个客户端发了一串字符，此时第4个客户端对应服务器的连接还是SYN_RECV,然后服务端close掉第3个客户端(57111),再去accept第4个客户端(57112),此时57112之前发的数据还能收到.证明了处于SYN_RECV状态的连接,是会保留收到的数据的(可能会有其他一些条件的限制) [root@localhost ~]# netstat -anp | grep 6666 tcp 1 0 0.0.0.0:6666 0.0.0.0:* LISTEN 22982/./server tcp 0 0 127.0.0.1:6666 127.0.0.1:57110 ESTABLISHED 22982/./server tcp 0 0 127.0.0.1:57111 127.0.0.1:6666 CLOSE_WAIT 23025/nc tcp 27 0 127.0.0.1:6666 127.0.0.1:57112 ESTABLISHED - tcp 0 0 127.0.0.1:6666 127.0.0.1:57111 FIN_WAIT2 - tcp 0 0 127.0.0.1:57112 127.0.0.1:6666 ESTABLISHED 23026/nc tcp 0 0 127.0.0.1:6666 127.0.0.1:57109 ESTABLISHED 22982/./server tcp 0 0 127.0.0.1:57109 127.0.0.1:6666 ESTABLISHED 23022/nc tcp 0 0 127.0.0.1:57110 127.0.0.1:6666 ESTABLISHED 23023/nc 第4个客户端: [root@localhost ~]# nc 127.0.0.1 6666 99999999999999999999999999 服务端: i= 0 i= 1 i= 2 close fd i= 3 read data: 99999999999999999999999999 客户端代码#include&lt;stdio.h&gt; #include&lt;stdlib.h&gt; #include&lt;string.h&gt; #include&lt;errno.h&gt; #include &lt;unistd.h&gt; #include&lt;sys/types.h&gt; #include&lt;sys/socket.h&gt; #include&lt;netinet/in.h&gt; #include&lt;arpa/inet.h&gt; int main() &#123; int iConnFd = 0; char szAddr[] = &#123;&quot;127.0.0.1&quot;&#125;; struct sockaddr_in stServerAddr = &#123;0&#125;; for (int i = 0; i &lt; 10000; ++i) &#123; if ((iConnFd = socket(AF_INET, SOCK_STREAM, 0)) &lt; 0) &#123; perror(&quot;Failed to create socket!&quot;); return -1; &#125; stServerAddr.sin_family = AF_INET; stServerAddr.sin_port = htons(7777); if (inet_pton(AF_INET, szAddr, (void*)&amp;stServerAddr.sin_addr) &lt;= 0) &#123; perror(&quot;Failed to swicth ip addr!&quot;); close(iConnFd); iConnFd = -1; return -1; &#125; if (connect(iConnFd, (struct sockaddr*)&amp;stServerAddr, sizeof(stServerAddr)) &lt; 0) &#123; perror(&quot;Failed to connect!&quot;); close(iConnFd); &#125; else &#123; puts(&quot;connect ok!&quot;); &#125; &#125; return 0; &#125; 服务端代码#include &lt;stdio.h&gt; #include &lt;unistd.h&gt; #include &lt;sys/types.h&gt; #include &lt;sys/socket.h&gt; #include &lt;errno.h&gt; #include &lt;stdlib.h&gt; #include &lt;string.h&gt; #include &lt;netdb.h&gt; #include &lt;netinet/in.h&gt; #include &lt;arpa/inet.h&gt; int main() &#123; struct sockaddr_in serveraAddr , clientAddr; socklen_t clientAddrLen; int nFd = 0,linkFd = 0; int nRet = 0; int nReadLen = 0; char szBuff[BUFSIZ] = &#123;0&#125;; nFd = socket(AF_INET,SOCK_STREAM,0); if(-1 == nFd) &#123; perror(&quot;socket:&quot;); return -1; &#125; memset(&amp;serveraAddr,0,sizeof(struct sockaddr_in)); serveraAddr.sin_family = AF_INET; serveraAddr.sin_addr.s_addr = htonl(INADDR_ANY); serveraAddr.sin_port = htons(7777); int isReuse = 1; setsockopt(nFd,SOL_SOCKET,SO_REUSEADDR,(const char*)&amp;isReuse,sizeof(isReuse)); nRet = bind(nFd,(struct sockaddr*)&amp;serveraAddr,sizeof(serveraAddr)); if(-1 == nRet) &#123; perror(&quot;bind:&quot;); return -1; &#125; listen(nFd,5); #if 0 clientAddrLen = sizeof(struct sockaddr_in); linkFd = accept(nFd,(struct sockaddr*)&amp;clientAddr,&amp;clientAddrLen); if(-1 == linkFd) &#123; perror(&quot;accept:&quot;); return -1; &#125; while(1) &#123; memset(szBuff,0,BUFSIZ); nReadLen = read(linkFd,szBuff,BUFSIZ); if(nReadLen &gt; 0) &#123; printf(&quot;read data: %s\\n&quot;,szBuff); &#125; &#125; #endif while(1) ; return 0; &#125;","categories":[],"tags":[{"name":"日记","slug":"日记","permalink":"https://riverferry.site/tags/%E6%97%A5%E8%AE%B0/"}],"keywords":[]},{"title":"Tcp_握手流程","slug":"2019-07-05-Tcp握手流程","date":"2019-07-05T00:00:00.000Z","updated":"2022-09-12T16:24:32.273Z","comments":true,"path":"2019-07-05-Tcp握手流程/","link":"","permalink":"https://riverferry.site/2019-07-05-Tcp%E6%8F%A1%E6%89%8B%E6%B5%81%E7%A8%8B/","excerpt":"流程图","text":"流程图 报文 三次握手 四次挥手 三次挥手 TIME_WAIT的作用摘自:TIME_WAIT状态存在的意义 1 可靠地实现了TCP全双工连接的终止 我们知道，TCP是比较可靠的。当TCP向另一端发送数据时，他要求对端返回一个确认（如同我们关闭时候的FIN和ACK）。如果没有收到确认，则会重发。回忆一下我们最终的那个FIN与ACK，被动关闭方发送FIN，并等待主动关闭方返回的ACK。我们假设最终的ACK丢失，被动关闭方将需要重新发送它的最终那个FIN，主动关闭方必须维护状态信息（TIME_WAIT），以允许它重发最终的那个ACK。如果没有了这个状态，当他第二次收到FIN时，会响应一个RST（也是一种类型的TCP分节），会被服务器解释成一个错误。为了TCP打算执行必要的工作以彻底终止某个连接两个方向上的数据流（即全双工关闭），那么他必须要正确处理连接终止四个分节中任何一个分节丢失的情况。 2 允许老的重复分节在网络中的消逝（为什么需要2MSL） 首先，存在这样的情况，某个路由器崩溃或者两个路由器之间的某个链接断开时，路由协议需要花费数秒到数分钟的时间才能稳定找出另一条通路。在这段时间内，可能发生路由循环（路由器A把分组发送给B，B又发送回给A），这种情况我们称之为迷途。假设迷途的分组是一个TCP分节，在迷途期间，发送端TCP超时并重传该分组，重传分组通过某路径到达目的地，而后不久（最多MSL秒）路由循环修复，早先迷失在这个循环中的分组最终也被送到目的地。这种分组被称之为重复分组或者漫游的重复分组，TCP必须要正确处理这些重复的分组。我们假设ip1:port1和ip2:port2 之间有一个TCP连接。我们关闭了这个链接，过一段时间后在相同IP和端口之间建立了另一个连接。TCP必须防止来自之前那个连接的老的重复分组在新连接上出现。为了做到这一点，TCP将不复用处于TIME_WAIT状态的连接。2MSL的时间足以让某个方向上的分组存活MSL秒后被丢弃，另一个方向上的应答也最多存活MSL秒后被丢弃。","categories":[],"tags":[{"name":"网络","slug":"网络","permalink":"https://riverferry.site/tags/%E7%BD%91%E7%BB%9C/"}],"keywords":[]},{"title":"Tcp_keepalive","slug":"2019-06-30-Tcp_keepalive","date":"2019-06-30T00:00:00.000Z","updated":"2022-09-12T16:24:32.273Z","comments":true,"path":"2019-06-30-Tcp_keepalive/","link":"","permalink":"https://riverferry.site/2019-06-30-Tcp_keepalive/","excerpt":"墨菲定律墨菲定律，又译为摩菲定律，具体内容是“凡是可能出错的事就一定会出错” 前言一个学徒,在第一次接触一件事物时,不能很全面,很深入的认知.一段时间后,没了新鲜感,容易失去兴趣,流于表面.就像我,简单的tcp握手,挥手流程,一直没有真正的了解过,心存侥幸,等到真正遇到这方面的问题,才方恨少于读书.吃了墨菲定律的亏,所以说,还是要一步一步,踏踏实实的行进啊.心存侥幸的,都是赌徒.做学徒,不做赌徒.","text":"墨菲定律墨菲定律，又译为摩菲定律，具体内容是“凡是可能出错的事就一定会出错” 前言一个学徒,在第一次接触一件事物时,不能很全面,很深入的认知.一段时间后,没了新鲜感,容易失去兴趣,流于表面.就像我,简单的tcp握手,挥手流程,一直没有真正的了解过,心存侥幸,等到真正遇到这方面的问题,才方恨少于读书.吃了墨菲定律的亏,所以说,还是要一步一步,踏踏实实的行进啊.心存侥幸的,都是赌徒.做学徒,不做赌徒. 参考TCP Keepalive HOWTO 随手记之TCP Keepalive笔记 介绍keepalive概念非常简单：当您设置TCP连接时，您可以关联一组计时器。其中一些计时器处理keepalive程序。当keepalive定时器到达零时，您向对等体发送一个keepalive探测数据包，其中没有数据并且ACK标志已打开。 正文一般服务器进程间都会有一定的保活机制,确保对端已经建立的连接是有效的,如果保活失败则可以进行一定的重连操作尝试恢复.或者直接清理掉无效的连接,减少系统的资源. 除此之外,操作系统(姑且这样认为吧)提供了一些参数,可以设置后通过其实现对连接进行检测.我接触到keeplaive也是在这样的情境下.当上层程序因为种种原因,或是其他网络原因,配置原因.一些tcp连接没有成功释放,例如我最近遇到的:CLOSE_WAIT.系统中存在大量的连接处于CLOSE_WAIT状态,使得进程占用的open file很快就达到上限,严重影响其他业务. CLOSE_WAIT状态 tcp四次挥手的过程中,作为被动关闭方,在收到主动关闭方发来的FIN后,回复ACK确认,然后自己便处于CLOSE_WAIT状态,通常这个状态持续的时间比较短,如果发现环境中存在大量的CLOSE_WAIT状态的连接,则一定有问题了. 解决CLOSE_WAIT 找到问题的根因，对症下药 可以抓包结合日志等分析,造成问题的具体原因,再去对应的做修改 暂时规避 通过设置tcp的keepalive值,让操作系统代理对tcp连接进行保活,及时释放有问题的连接 具体操作可以这样查看当前配置的值: [root@localhost ~]# sysctl -a | grep keepalive net.ipv4.tcp_keepalive_intvl = 75 net.ipv4.tcp_keepalive_probes = 9 net.ipv4.tcp_keepalive_time = 7200 修改系统的缺省值: echo &quot;net.ipv4.tcp_keepalive_time=7200&quot; &gt; /etc/sysctl.conf echo &quot;net.ipv4.tcp_keepalive_intvl=75&quot; &gt;&gt; /etc/sysctl.conf echo &quot;net.ipv4.tcp_keepalive_probes=9&quot; &gt;&gt; /etc/sysctl.conf //使其生效 sysctl -p 值的解释: TCP_KEEPDILE 设置连接上如果没有数据发送的话，多久后发送keepalive探测分组，单位是秒 TCP_KEEPINTVL 前后两次探测之间的时间间隔，单位是秒 TCP_KEEPCNT 关闭一个非活跃连接之前的最大重试次数 必要的一步: 手动修改,或者用下面介绍的LD_PRELOAD加载的libkeepalive.so setsockopt(sockfd, SOL_SOCKET, SO_KEEPALIVE, &amp;optval, sizeof(optval)); //打开keepalive开关 setsockopt(sockfd, SOL_TCP, TCP_KEEPCNT, &amp;optval, sizeof(optval)); //探测的次数 setsockopt(sockfd, SOL_TCP, TCP_KEEPIDLE, &amp;optval, sizeof(optval)); //多少秒没有数据往来开始探测 setsockopt(sockfd, SOL_TCP, TCP_KEEPINTVL, &amp;optval, sizeof(optval)); //探测的间隔时间 //以此来让创建的sockfd被代理进行保活 libkeepalive.so下载地址 源码: #define _GNU_SOURCE #include &lt;dlfcn.h&gt; #include &lt;errno.h&gt; #include &lt;stdlib.h&gt; #include &lt;strings.h&gt; #include &lt;sys/types.h&gt; #include &lt;sys/socket.h&gt; #include &lt;netinet/tcp.h&gt; int socket(int domain, int type, int protocol); int socket(int domain, int type, int protocol) &#123; static int (*orig_socket)(int, int, int) = NULL; int sockfd = -1, optval = 1; char *env; do &#123; /* if the original function is NULL, try to resolve it or break */ if(!orig_socket &amp;&amp; !(*(void **)(&amp;orig_socket) = dlsym(RTLD_NEXT, &quot;socket&quot;))) &#123; errno = EACCES; break; &#125; /* call original function with parameters */ if((sockfd = (*orig_socket)(domain, type, protocol)) == -1) break; /* socket must be IPv4 or IPv6 */ if((domain != AF_INET) &amp;&amp; (domain != AF_INET6)) break; /* socket must be TCP */ if(!(type &amp; SOCK_STREAM)) break; /* if environment variable KEEPALIVE is set to &quot;off&quot;, break */ if((env = getenv(&quot;KEEPALIVE&quot;)) &amp;&amp; !strcasecmp(env, &quot;off&quot;)) break; /* if setting keepalive fails, break */ if(setsockopt(sockfd, SOL_SOCKET, SO_KEEPALIVE, &amp;optval, sizeof(optval)) == -1) break; #ifdef TCP_KEEPCNT /* if environment variable KEEPCNT is set, override the default option value */ if((env = getenv(&quot;KEEPCNT&quot;))) &#123; optval = atoi(env); setsockopt(sockfd, SOL_TCP, TCP_KEEPCNT, &amp;optval, sizeof(optval)); &#125; #endif #ifdef TCP_KEEPIDLE /* if environment variable KEEPIDLE is set, override the default option value */ if((env = getenv(&quot;KEEPIDLE&quot;))) &#123; optval = atoi(env); setsockopt(sockfd, SOL_TCP, TCP_KEEPIDLE, &amp;optval, sizeof(optval)); &#125; #endif #ifdef TCP_KEEPINTVL /* if environment variable KEEPINTVL is set, override the default option value */ if((env = getenv(&quot;KEEPINTVL&quot;))) &#123; optval = atoi(env); setsockopt(sockfd, SOL_TCP, TCP_KEEPINTVL, &amp;optval, sizeof(optval)); &#125; #endif &#125; while(0); return sockfd; &#125; preload更改函数调用 就这么点代码,使用了PRELOAD修改了原有的socket函数，默认都加了设置保活参数的setsockopt. 下面VMWARE验证:找到了之前的一个简单代码改了下,作为客户端和本地的21端口建立连接,通过preload预加载的方式将libkeepalive.so加载进去: #include&lt;stdio.h&gt; #include&lt;stdlib.h&gt; #include&lt;string.h&gt; #include&lt;errno.h&gt; #include &lt;unistd.h&gt; #include&lt;sys/types.h&gt; #include&lt;sys/socket.h&gt; #include&lt;netinet/in.h&gt; #include&lt;arpa/inet.h&gt; int main() &#123; int iConnFd = 0; char szAddr[] = &#123;&quot;127.0.0.1&quot;&#125;; struct sockaddr_in stServerAddr = &#123;0&#125;; for (int i = 0; i &lt; 10000; ++i) &#123; if ((iConnFd = socket(AF_INET, SOCK_STREAM, 0)) &lt; 0) &#123; perror(&quot;Failed to create socket!&quot;); return -1; &#125; stServerAddr.sin_family = AF_INET; stServerAddr.sin_port = htons(21); if (inet_pton(AF_INET, szAddr, (void*)&amp;stServerAddr.sin_addr) &lt;= 0) &#123; perror(&quot;Failed to swicth ip addr!&quot;); close(iConnFd); iConnFd = -1; return -1; &#125; if (connect(iConnFd, (struct sockaddr*)&amp;stServerAddr, sizeof(stServerAddr)) &lt; 0) &#123; perror(&quot;Failed to connect!&quot;); close(iConnFd); &#125; while(1) ; &#125; return 0; &#125; 可以看到客户端和21端口建立三次握手成功5秒后，就开始发keepalive探测消息了.再看看系统调用: socket(AF_INET, SOCK_STREAM, IPPROTO_IP) = 3 setsockopt(3, SOL_SOCKET, SO_KEEPALIVE, [1], 4) = 0 setsockopt(3, SOL_TCP, TCP_KEEPCNT, [5], 4) = 0 setsockopt(3, SOL_TCP, TCP_KEEPIDLE, [5], 4) = 0 setsockopt(3, SOL_TCP, TCP_KEEPINTVL, [5], 4) = 0 connect(3, &#123;sa_family=AF_INET, sin_port=htons(21), sin_addr=inet_addr(&quot;127.0.0.1&quot;)&#125;, 16) = 0 使用的命令: env LD_PRELOAD=&quot;/home/wang/libkeepalive-0.3/libkeepalive.so&quot; KEEPCNT=5 KEEPIDLE=5 KEEPINTVL=5 ./a.out ending","categories":[],"tags":[{"name":"网络","slug":"网络","permalink":"https://riverferry.site/tags/%E7%BD%91%E7%BB%9C/"}],"keywords":[]},{"title":"wireshark切割报文","slug":"2019-06-24-wireshark切割报文","date":"2019-06-24T00:00:00.000Z","updated":"2022-09-12T16:24:32.273Z","comments":true,"path":"2019-06-24-wireshark切割报文/","link":"","permalink":"https://riverferry.site/2019-06-24-wireshark%E5%88%87%E5%89%B2%E6%8A%A5%E6%96%87/","excerpt":"前言有的时候抓的报文太大,打开比较费时间.甚至打开时报错,这个时候就需要分割报文了.当然如果能够在抓包的时候进行必要的过滤,让原始包就没那么大,就最好了.此文只描述将已经抓到的大报文进行切割.","text":"前言有的时候抓的报文太大,打开比较费时间.甚至打开时报错,这个时候就需要分割报文了.当然如果能够在抓包的时候进行必要的过滤,让原始包就没那么大,就最好了.此文只描述将已经抓到的大报文进行切割. 声明文章主要参考了: 抓包信息使用Wireshark无法打开查看 正文用到的命令:// -C 100 :按照100个frame来切割， // D:\\test.pcapng :原始包路径// D: :新生成的报文路径//editcap.exe在wireshark的安装路径下 editcap.exe -c 100 D:\\test.pcapng D:\\ 敲命令 生成的文件 每个文件都是100 frame ending哈哈,水了一篇博客,最近真是有点懒惰了","categories":[],"tags":[{"name":"运维","slug":"运维","permalink":"https://riverferry.site/tags/%E8%BF%90%E7%BB%B4/"}],"keywords":[]},{"title":"rtsp_digest加解密","slug":"2019-06-17-rtsp_digest加解密","date":"2019-06-17T00:00:00.000Z","updated":"2022-09-12T16:24:32.273Z","comments":true,"path":"2019-06-17-rtsp_digest加解密/","link":"","permalink":"https://riverferry.site/2019-06-17-rtsp_digest%E5%8A%A0%E8%A7%A3%E5%AF%86/","excerpt":"维基百科 Digest access authentication is one of the agreed-upon methods a web server can use to negotiate credentials, such as username or password, with a user’s web browser. This can be used to confirm the identity of a user before sending sensitive information, such as online banking transaction history. It applies a hash function to the username and password before sending them over the network. 摘要访问身份验证是Web服务器可以用来与用户的Web浏览器协商凭据（例如用户名或密码）的商定方法之一。这可用于在发送敏感信息（例如在线银行交易历史记录）之前确认用户的身份。它在通过网络发送之前将哈希函数应用于用户名和密码","text":"维基百科 Digest access authentication is one of the agreed-upon methods a web server can use to negotiate credentials, such as username or password, with a user’s web browser. This can be used to confirm the identity of a user before sending sensitive information, such as online banking transaction history. It applies a hash function to the username and password before sending them over the network. 摘要访问身份验证是Web服务器可以用来与用户的Web浏览器协商凭据（例如用户名或密码）的商定方法之一。这可用于在发送敏感信息（例如在线银行交易历史记录）之前确认用户的身份。它在通过网络发送之前将哈希函数应用于用户名和密码 加解密流程摘要访问身份验证最初由RFC 2069（HTTP扩展：摘要访问身份验证）指定。RFC 2069大致规定了传统的摘要式身份验证方案，其安全性由服务器生成的nonce值维护。身份验证响应形成如下（其中HA1和HA2是字符串变量的名称） rtsp digest加密onvif实况要走rtsp协议(目前还不是很熟悉这块,不确定是否必须).但ODM工具实况是走rtsp的.我也抓了报文： 链接：https://pan.baidu.com/s/1h1hUiPAQDKzugfRLNUmdPg 提取码：0rp8 DESCRIBE rtsp://192.168.1.18/media/video1 RTSP/1.0 CSeq: 3 User-Agent: LIVE555 Streaming Media v2012.06.17 Accept: application/sdp RTSP/1.0 401 ClientUnAuthorized CSeq: 3 WWW-Authenticate: Digest realm=&quot;48ea630ea6b6&quot;,nonce=&quot;1560111814178281114221112111111170273871&quot;, stale=&quot;FALSE&quot; DESCRIBE rtsp://192.168.1.18/media/video1 RTSP/1.0 CSeq: 4 Authorization: Digest username=&quot;admin&quot;, realm=&quot;48ea630ea6b6&quot;, nonce=&quot;1560111814178281114221112111111170273871&quot;, uri=&quot;rtsp://192.168.1.18/media/video1&quot;, response=&quot;100bcc84410727cf46a8b33db7258c01&quot; User-Agent: LIVE555 Streaming Media v2012.06.17 Accept: application/sdp RTSP/1.0 200 OK CSeq: 4 Content-Base: rtsp://192.168.1.18/media/video1 Content-Length: 508 Content-Type: application/sdp v=0 o=- 1001 1 IN IP4 192.168.1.18 s=VCP IPC Realtime stream m=video 0 RTP/AVP 105 c=IN IP4 192.168.1.18 a=control:rtsp://192.168.1.18/media/video1/video a=rtpmap:105 H264/90000 a=fmtp:105 profile-level-id=64001f; packetization-mode=1; sprop-parameter-sets=Z2QAH6wrUCgC3QgAAB9AAAYahCAA,aO4xsg== a=recvonly m=application 0 RTP/AVP 107 c=IN IP4 192.168.1.18 a=control:rtsp://192.168.1.18/media/video1/metadata a=rtpmap:107 vnd.onvif.metadata/90000 a=fmtp:107 DecoderTag=h3c-v3 RTCP=0 a=recvonly 流程第一次发rtsp.method == DESCRIBE，没有带用户名密码,服务端返回401鉴权不通过,并在401 response中携带了域名(realm),nonce客户端基于realm,nonce进行digest摘要字组串加密,第二次发rtsp.method == DESCRIBE ，并携带鉴权信息.其中response=”100bcc84410727cf46a8b33db7258c01”就是最后的加密信息,服务端也会生成一份response与客户端的进行校验. response的生成逻辑HA1 = MD5（用户名：域名(realm)：密码） HA2 = MD5（方法：digestURI） 响应= MD5（HA1：nonce：HA2） HA1 = MD5（admin:48ea630ea6b6:***） = a913b0ee8a4c9d05cf6d34b597b45e1f HA2 = MD5（DESCRIBE:rtsp://192.168.1.18/media/video1）= 68010645697e5e209583dde1323ca453 响应= MD5（a913b0ee8a4c9d05cf6d34b597b45e1f:1560111814178281114221112111111170273871:68010645697e5e209583dde1323ca453） = 100bcc84410727cf46a8b33db7258c01 Md5加密这里我用的md5sum命令在服务器上进行加密,比较方便 ending","categories":[],"tags":[{"name":"加密","slug":"加密","permalink":"https://riverferry.site/tags/%E5%8A%A0%E5%AF%86/"}],"keywords":[]},{"title":"gsoap的安装过程","slug":"2019-06-03-gsoap的安装 - 副本","date":"2019-06-03T00:00:00.000Z","updated":"2022-09-12T16:24:32.273Z","comments":true,"path":"2019-06-03-gsoap的安装 - 副本/","link":"","permalink":"https://riverferry.site/2019-06-03-gsoap%E7%9A%84%E5%AE%89%E8%A3%85%20-%20%E5%89%AF%E6%9C%AC/","excerpt":"前言最近在搞onvif，gsoap是绕不过的坎,安装的过程大大超出了预期,可以说是相当的艰难了,大概记录下过程.","text":"前言最近在搞onvif，gsoap是绕不过的坎,安装的过程大大超出了预期,可以说是相当的艰难了,大概记录下过程. 漫长的安装过程1.下载gsoap: 开源下载链接 2.下载,解压缩. $ cd gsoap-2.8$ ./configure –with-openssl=/usr/local/ssl$ make$ make install 3.解决错误. 然后大概会报错：aclocal-1.16: 未找到命令 ,网上找到的解决办法:autoreconf -ivf .为此要安装autoconf和automake,参考: 在CentOS中安装autoconf和automake.安装autoconf和automake的时候又报错了,真是头大.参考我的操作步骤吧(精简了下),也记不起来了 06:03:31 autoreconf -ivf 06:05:51 wget http://ftp.gnu.org/gnu/autoconf/autoconf-2.69.tar.gz 06:06:10 yum -y install wget 06:06:18 wget http://ftp.gnu.org/gnu/autoconf/autoconf-2.69.tar.gz 06:09:47 ls 06:09:54 tar -xzvf autoconf-2.69.tar.gz 06:09:58 cd autoconf-2.69 06:10:04 ./configure 06:10:10 make 06:10:21 make | grep err 06:11:18 cd .. 06:11:22 wget http://www.cpan.org/modules/by-module/Data/Data-Dumper-2.173.tar.gz 06:12:01 tar -xzvf Data-Dumper-2.173.tar.gz 06:12:04 cd Data-Dumper-2.173 06:12:15 perl Makefile.PL 06:13:01 cd .. 06:13:03 wget http://files.directadmin.com/services/9.0/ExtUtils-MakeMaker-6.31.tar.gz 06:13:30 tar -xzvf ExtUtils-MakeMaker-6.31.tar.gz 06:13:35 cd ExtUtils-MakeMaker-6.31 06:13:50 perl Makefile.PL 06:14:08 yum install perl-ExtUtils-MakeMaker 06:14:15 perl Makefile.PL 06:15:01 cd autoconf-2.69 06:15:20 ./configure 06:15:25 make 06:16:15 cd Data-Dumper-2.173 06:16:18 make 06:16:23 make install 06:16:34 cd ExtUtils-MakeMaker-6.31 06:16:37 make 06:16:41 make install 06:16:42 cd .. 06:16:48 cd autoconf-2.69 06:16:49 ls 06:16:50 make 06:16:57 make install 06:17:02 cd .. 06:17:09 cd gsoap-2.8/ 06:17:10 ls 06:17:12 make 06:17:18 ./configure 06:17:44 make 06:17:50 autoconf --version 06:18:06 wget http://ftp.gnu.org/gnu/automake/automake-1.14.tar.gz 06:23:25 tar -xzvf automake-1.14.tar.gz 06:23:28 cd automake-1.14 06:23:55 ./bootstrap.sh 06:26:29 yum install perl-Thread-Queue 06:26:35 ./bootstrap.sh 06:26:42 ./configure 06:26:51 make 06:26:57 make install 06:27:04 automake --version 06:27:07 cd .. 06:27:07 ls 06:27:11 cd gsoap-2.8/ 06:27:12 ls 06:27:16 ./configure 06:27:30 ls 06:27:31 make 06:27:54 autoreconf -ivf&lt;br&gt; aclocal-1.16这个问题大概是解决了.接着执行: ./configure –with-openssl=/usr/local/ssl 又报错.大概是ssl有问题.于是: yum install openssl yum install openssl-devel cd / find . -name openssl 找到openssl的头文件的地址，我的是 ./usr/include/openssl 然后: ./configure --with-openssl=/usr/include/openssl 又报错找不到yacc，继续: yum install byacc yum install flex 安装完,make的时候又报奇怪的错误.重新configure后就好了: ./configure --with-openssl=/usr/include/openssl make make install which wsdl2h soapcpp2 wsdl2h -h 大功告成.整个安装过程着实捉急.凭印象和history信息进行了整理.有点混乱,可能记录也不全面.就这样吧.","categories":[],"tags":[{"name":"gsoap","slug":"gsoap","permalink":"https://riverferry.site/tags/gsoap/"}],"keywords":[]},{"title":"人为什么会悲伤","slug":"2019-05-30-人为什么会悲伤","date":"2019-05-30T00:00:00.000Z","updated":"2022-09-12T16:24:32.273Z","comments":true,"path":"2019-05-30-人为什么会悲伤/","link":"","permalink":"https://riverferry.site/2019-05-30-%E4%BA%BA%E4%B8%BA%E4%BB%80%E4%B9%88%E4%BC%9A%E6%82%B2%E4%BC%A4/","excerpt":"&emsp;&emsp;&emsp;最近好几次不经意间,会去思考悲伤是怎样的一种情绪.人为什么会悲伤?此时此刻,我十分冷静的,来思考悲伤这种情绪.以此,在陷入悲伤时,能够早点超脱出来.得以自已.","text":"&emsp;&emsp;&emsp;最近好几次不经意间,会去思考悲伤是怎样的一种情绪.人为什么会悲伤?此时此刻,我十分冷静的,来思考悲伤这种情绪.以此,在陷入悲伤时,能够早点超脱出来.得以自已. &emsp;&emsp;&emsp;如何定义悲伤?维基百科上对悲伤的解释: 悲伤是种情绪反应，多数高等哺乳动物均有此反应，其中，人类对此反应最为显著。人类的悲伤通常来自经历上的挫折失败，如：无法抗拒的住所改变，亲友死亡、离婚、毕业或失业。另外，这类生物反应又会因生活经验与文化特质而异。举例来说，失去亲人往往让人觉得悲伤，但悲伤的表达方式则因当事者年龄，经历而有所不同。悲伤表现在外即为沮丧心情。通常悲伤也会伴与落泪与沉默。悲伤是保罗·艾克曼提出的六种基本情感之一：愤怒、厌恶、恐惧、快乐、悲伤、惊讶。 &emsp;&emsp;&emsp;最后这句,我觉得很有意思.悲伤是人类的一种基本情感.是人类的，并且是基本的情感.试想,我们总是沉浸在学习中,玩乐中,工作中.总是适应在自己所处的时代,社会中.而一旦悲伤起来,便会变得沉默,并感到痛苦.这时候,我们总是异常冷静而专注的沉浸在让自己感到悲伤的事情之中.总是免不了会去想为什么会发生这种事情,应该如何解决,又会对自己往后的生活产生什么影响.这种时候,我们其实是从俗世的生活中跳脱出来了,疏远了单一独特的个体,来到了人类共性的领域.&emsp;&emsp;&emsp;产生悲伤的原因有很多,但其实细细想来,大多数悲伤产生的原因都大同小异.每个人都会在一定的阶段接触,经历一些事情的变化，跃迁.如果准备的不够充分,没有足够的人生经历或至始至终没有解决,解释通一种挫折,便会必然的陷入悲伤.这看来,像是上帝安排的，作为人所必须经历的一道坎.悲伤对人的影响因人而异,和宗教,文化,生活经历有关.想了想,我大胆的认为悲伤对人的影响取决于人对于死亡和生存的看法.&emsp;&emsp;&emsp;我总是觉得西方人相对于东方人,对于悲伤处理的更好一些.从对死亡的角度来看,西方人也会痛苦,但是在痛苦发生的阶段,他们往往还能冷静的处理俗世,基本生活中的事情,并且会以一种寄予希望的形式来处理，比如会在坟墓，在死亡地点,放置一些鲜花.点蜡烛,与亲朋好友一起祷告.（没去过西方,影视作品带给我的印象）。再来看生存的角度,我们常说西方人少系列,在众多冒险类项目中,西方是遥遥领先于东方的.爬山,攀登,骑行,西方人更有勇气去尝试,并且对糟糕结果的接受程度很多,能够容忍高风险的事情.西方的父母更愿意支持孩子做自己喜欢的事情,即使安全风险很高.&emsp;&emsp;&emsp;作为一个传统的东方人,我试图借鉴一些西方的处世之道.希望在不愿意发生的事情发生的时候,能够冷静的对待.避免自身长时间的陷入一种低免疫力的失落状态中.从而在挫折发生阶段做更多有意义的时候,早点为以后的生活做打算,进行弥补.即使跳脱出悲伤的情绪,能够理智的向前看.(我其实很不情愿用理智这个词)&emsp;&emsp;&emsp;想一想,你所谓的悲伤,在这个世界,其实很多人都会经历.很少的挫折是罕见的.有那么多人冒着生命危险去尝试新鲜的,有趣的事情.并且已经有很多人为此付出了性命,那么你为什么,不能在挫折发生的时候，激励自己,改变自己，让自己活得更出色,更有趣呢.这何尝不是一个契机,让你做出改变,去尝试更多以前没有接触的活动,眼界放开,才会认识更多的人.明白很多人都一直在做有趣的事情,开心的事情.很多人都为自己的优秀做出了努力.这样在你别人击败时，还会茫然吗？&emsp;&emsp;&emsp;悲伤的时候,经常会不知所措.我想这是悲伤的初级阶段吧,正是自己的无能为力,不知所措,才让自己处于一种被动的,无助的状态中.只有自己强大了,才能最好的抵御悲伤带来的负面影响.接受已经发生的,尽力去弥补,同时也不要忘记让自己活得更好.&emsp;&emsp;&emsp;悲伤本身,有什么意义呢？当你回头看的时候，里面的自己还是现在的自己吗?活在当下,勇于接受,改变自己,和大家共勉. ending","categories":[],"tags":[{"name":"日记","slug":"日记","permalink":"https://riverferry.site/tags/%E6%97%A5%E8%AE%B0/"}],"keywords":[]},{"title":"POE相机的安装配置","slug":"2019-05-17-POE相机的配置","date":"2019-05-17T00:00:00.000Z","updated":"2022-09-12T16:24:32.273Z","comments":true,"path":"2019-05-17-POE相机的配置/","link":"","permalink":"https://riverferry.site/2019-05-17-POE%E7%9B%B8%E6%9C%BA%E7%9A%84%E9%85%8D%E7%BD%AE/","excerpt":"前言这篇文章简单记录下自己安装的两个IPC的过程,以后会基于此总结一些onvif和sip的知识.","text":"前言这篇文章简单记录下自己安装的两个IPC的过程,以后会基于此总结一些onvif和sip的知识. 什么是POE引用自: 关于POE你知道多少？POE知识汇总！ POE（Power Over Ethernet）是有源以太网供电的简称，指的是在现有的以太网Cat.5布线基础架构不作任何改动的情况下，在为一些基于IP的终端（如IP电话机、无线局域网接入点AP、网络摄像机等）传输数据信号的同时，还能为此类设备提供直流供电的技术。POE技术能在确保现有结构化布线安全的同时保证现有网络的正常运作，最大限度地降低成本。 简单来看就是相比普通的网线多了4条线来供电. 尝试部署POE相机最近在咸鱼上买了2个二手的IPC,一个大华的IPC-HDW2120C,一个宇视的IPC3331S-IRS-PF80-DT,都挺老的型号了.也不支持H.265.耐不住便宜啊，也支持POE.买来研究下onvif和sip. 实物图: 安装过程中还是遇到了一些麻烦,因为对硬件不熟,之前都不知道POE.后来在卖家的指导以及自己查了点资料后才搞定.具体遇到的一些难点说明一下: 1:网络摄像机既要传输网络,又要供电.但POE线是可以同时满足这两点的.文章前面也说明了原理. 2:这两个摄像头都是支持POE供电的,但我的网线是4芯的,不能供电,并且我的wifi装置也不支持POE.因此我在网上又买了POE网线和POE”交换机”,可以看我拍的实物图. 3：都是二手的相机,也没有说明书.不知道摄像头的IP.所以需要工具.宇视相机查IP可以用EzTool工具,大华的用大华快速配置工具.在官网上都能找到.如图: 大华快速配置工具:EzTool: 对了,相机的ip地址要和自己电脑在同一网段才能显示出来.可以先配成一个网段链接相机后再修改相机的ip地址. 登陆界面： 实况就不截图了,工具配置完成.希望后面能坚持下去,好好利用下.","categories":[],"tags":[{"name":"视频","slug":"视频","permalink":"https://riverferry.site/tags/%E8%A7%86%E9%A2%91/"}],"keywords":[]},{"title":"文件审计-auditd","slug":"2019-05-11-文件审计auditd","date":"2019-05-11T00:00:00.000Z","updated":"2022-09-12T16:24:32.272Z","comments":true,"path":"2019-05-11-文件审计auditd/","link":"","permalink":"https://riverferry.site/2019-05-11-%E6%96%87%E4%BB%B6%E5%AE%A1%E8%AE%A1auditd/","excerpt":"目录 前言 audit简介 auditd工具 auditd使用方法 auditctl autrace ausearch aureport 配置文件 日志文件 实践","text":"目录 前言 audit简介 auditd工具 auditd使用方法 auditctl autrace ausearch aureport 配置文件 日志文件 实践 前言 文件系统是计算机信息系统中至关重要的资源，而文件监控正是监控系统安全状态，保证计算机系统安全的关键技术。在Linux系统中，诸如 /etc/passwd, /usr/local/sbin 的文件和目录尤为关键。任何对这些文件的破坏和篡改都会引起严重的安全问题。甚至造成系统瘫痪，因此我们有必要使用一种好的策略和工具来对文件系统进行保护。 audit简介 audit是linux系统中用于记录用户底层调用情况的系统，如记录用户执行的open、exit等系统调用。并会将记录写到日志文件中。在内核里有内核审计模块，核外有核外的审计后台进程auditd。应用进程给内核发送审计消息，内核的审计模块再把消息转发给用户空间的后台进程auditd处理 auditd工具 auditd是audit系统的用户空间程序.主要作用是将audit记录信息写到磁盘上auditd在大多数linux系统中默认安装的,如果没有的话网上搜索下安装也比较简单 auditd在启动时会读取2个配置文件: /etc/audit/auditd.conf audit配置文件 /etc/audit/audit.rules audit规则文件 auditd使用方法 auditd [ -f ] 选项-f表示让auditctl在前台运行，以方便调试，消息可以直接输出到stderr，而不是输出到log系统 auditctl 工具auditctl控制行为、得到状态、从内核审计系统增加或删除规则 选项名 选项的值 说明 -b 设置内核允许的缓冲区数，默认值为64 -e [0|1] 关闭或启动内核审计系统 -f [0..2] 设置失败标识0=silent 1=printk 2=panic，默认值为1。设置内核如何处理临界错误，如：backlog限制超出、内存错误等 -h 帮助信息 -i 当从文件中读取规则时忽略错误 -l 列出所有的规则，每行一条规则 -k [key] 设置审计规则上的过滤关键词key，key是不超过32字节长的任意字符串，它能唯一鉴别由watch产生的审计记录 -m text 仅由root用户发送用户空间消息到审计系统。为文件系统watch设置许可过滤器。r=read，w=write，x=execute，a=attribute change。这些许可不是文件的标准许可，而是系统调用使用的，read和write系统调用将忽略这种设置，否则它们将淹没log -r [rate] 设置每秒传输的消息数限制，默认值为0，表示无限制 -R [file] 从file文件中读取规则 -s 报告状态 -a [l,a] 追加规则到l链表，a表示规则的动作 有效链表名l task 追加规则到每个任务链表AUDIT_FILTER_TASK 。域应用任务创建时的uid、gid等 有效链表名l entry 追加规则到系统调用进入链表AUDIT_FILTER_ENTRY，用于决定进入到系统调用时是否创建审计事件 有效链表名l exit 追加规则到系统调用退出链表AUDIT_FILTER_EXIT 。用于决定退出系统调用时是否创建审计事件 有效链表名l user 追加规则到用户消息过滤链表AUDIT_FILTER_USER ，内核在转播用户空间产生的事件到审计后台之前，用这个链表过滤这些事件。仅域为uid、auid、gid和pid时有效 有效链表名l exclude 用于过滤不想看到的事件，对应内核消息过滤链表AUDIT_FILTER_TYPE 规则的有效动作a never 不产生审计记录 规则的有效动作a always 分配一个审计上下文，在系统调用退出时填充 -A [l,a] 添加规则到l链表头，动作为a -d [l,a] 从带有a动作的l链表删除规则 -D 删除所有的规则和watch -S [系统调用名或号|all] 如果程序使用指定的系统调用，则它启动一项审计记录。如果给出域规则而没有指定系统调用，它将默认为所有系统调用 -F [n=v | n!=v | n&lt;v | n&gt;v | n&lt;=v | n&gt;=v] 创建一个规则域：名字、操作、值。可以单个命令行传递最多64个域。每个域必须启动一个审计记录。可支持6种操作：等于、不等于、小于、大于、小于或等于和大于或等于 -w [path] 为文件系统对象[path]插入一个watch（监视）。不支持匹配符 -W [path] 移去文件系统对象[path]上的watch -F 对应的域 autrace autrace是一个程序，它将添加审计规则、类似于strace跟踪一个进程，审计信息的结果将记录在审计log文件中。在目标程序执行的前后，它都将删除审计规则。目前没用,以后补充 ausearch 工具ausearch用于查询审计后台的日志，它能基于不同搜索规则的事件查询审计后台日志。每个系统调用进入内核空间运行时有个唯一的事件ID，系统调用在进入内核后的运行过程的审计事件共享这个ID option full name description -a --event audit-event-id 基于event ID检索（msg里包含time_stamp和eventID） -c --comm 基于comm名称检索 -e --exit 基于exit code或errno检索 -f --file 基于filename检索 -ga --gid-all all-group-id 基于group ID或groupname检索 -ge --gid-effectuve effective-group-id 基于effective group ID或name检索 -gi --gid group-id 基于group ID或name检索 -h --help 帮助信息 -hn --host host-name 基于hostname检索，hostname不会进行解析 -i --interpret 将数字编码解析问字符串（很多字段都进行了数字编码，通过此参数还原） -if --input file-name 搜索给定的文件，而不会去系统的audit日志中检索。通过这个参数可以将日志导出到其他机器上进行检索 --input-logs 使用auditd.conf中配置的日志文件路径来做检索，该参数用于写cron job的时候配合使用 --just-one 当出现了第一条匹配的日志时即停止检索，所以只会检索出第一条匹配的结果 -k --key key-string 基于key进行检索 -l --line-buffered 如果默认的缓冲规则不能满足需要，通过此参数可以将每条输出都立即flush到连接的stdout流中 -m --message message-type |comma-sep-message-type-list 使用messagetype进行索引，可以指定某个type，也可以使用“逗号”将多个messagetype并列起来，逗号两侧不能有空格。可以使用ALL作为message type，用于匹配所有message type -n --node node-name 匹配node name -o --objectSE-Linux-context-string 匹配tcontext(object) -p --pid process-id 匹配process ID -pp --ppidparent-process-id 匹配parent process ID -r --raw 将未经格式化处理的原日志输出 -sc --syscallsyscall-name-or-value 匹配syscall参数 -se --context SE-Linux-context-string 匹配scontext/subject或tcontext/object --session Login-Session-ID 匹配用户的Login Session ID -su --subject SE-Linux-context-string 匹配scontext(subject) -sv --success success-value 匹配success value -te --end[end-date][end-time] 匹配time stamp等于或早于给定参数的event，时间格式与本地时间格式匹配，如果省略掉日期，则默认指定today作为默认值。如果省略掉时间，则now作为默认值，使用24小时制。例如09/03/2009 18:00:00。常用的一些预定义的关键字：now/recent/today/yesterday/this-week/week-ago/this-month/this-year，其中，recent表示10分钟之前，其他的都可以按照字面意思理解 -ts --start [start-date][start-time] 与-te参数类似，用于过滤日期和时间晚于给定时间的event。区别是如果时间参数省略，会以midnight作为默认值 -tm --terminal terminal 匹配terminal参数 -ua --uid-all all-user-id 匹配user ID/effective user ID/login user ID(auid) -ue --uid-effective effective-user-id：匹配effective user ID -ui --uid user-id 匹配user ID -ul --loginuid login-id 匹配login user ID -uu --uuid guest-uuid 匹配guest UUID -v --version 打印版本 -vm --vm-name guest-name 匹配guest name -w --word 条件中如果有字符串匹配，必须完全匹配，例如filename/hostname/terminal/SELinux context -x --executable executable 匹配executable名 aureport 工具aureport用于产生审计后台日志的总结报告 配置文件/etc/audit/auditd.conf 有以下作用 1. 设置审计消息的专用日志文件 2. 确定是否循环使用日志文件 3. 如果日志文件的启动用掉了太多磁盘空间则发出警告 4. 配置审计规则记录更详细的信息 5. 激活文件和目录观察器 [root@localhost ~]# cat /etc/audit/auditd.conf # # This file controls the configuration of the audit daemon # log_file = /var/log/audit/audit.log log_format = RAW log_group = root priority_boost = 4 flush = INCREMENTAL freq = 20 num_logs = 5 disp_qos = lossy dispatcher = /sbin/audispd name_format = NONE ##name = mydomain max_log_file = 6 max_log_file_action = ROTATE space_left = 75 space_left_action = SYSLOG action_mail_acct = root admin_space_left = 50 admin_space_left_action = SUSPEND disk_full_action = SUSPEND disk_error_action = SUSPEND ##tcp_listen_port = tcp_listen_queue = 5 tcp_max_per_addr = 1 ##tcp_client_ports = 1024-65535 tcp_client_max_idle = 0 enable_krb5 = no krb5_principal = auditd ##krb5_key_file = /etc/audit/audit.key 配置文件说明 log_file 审计日志文件的完整路径。如果您配置守护进程向除默认/var/log/audit/外的目录中写日志文件时，一定要修改它上面的文件权限，使得只有根用户有读、写和执行权限。所有其他用户都不能访问这个目录或这个目录中的日志文件 log_format 写日志时要使用的格式。当设置为RAW时，数据会以从内核中检索到的格式写到日志文件中。当设置为NOLOG时，数据不会写到日志文件中，但是如果用dispatcher选项指定了一个，则数据仍然会发送到审计事件调度程序中 priority_boost 审计应采用多少优先级推进守护进程。必须是非负数。0表示没有变化 flush 多长时间向日志文件中写一次数据。值可以是NONE、INCREMENTAL、DATA和SYNC之一。如果设置为NONE，则不需要做特殊努力来将数据 刷新到日志文件中。如果设置为INCREMENTAL，则freq参数用于确定发出显式刷新磁盘的频率。如果设置为DATA，则审计数据和日志文 件一直是同步的。如果设置为SYNC，则每次写到日志文件时，数据和元数据是同步的 freq 如果flush设置为INCREMETNAL，审计守护进程在写到日志文件中前从内核中接收的记录数 num_logs max_log_file_action设置为ROTATE时要保存的日志文件数目。必须是0~99之间的数。如果设置为小于2，则不会循环日志。如果递 增了日志文件的数目，就可能有必要递增/etc/audit/audit.rules中的内核backlog设置值，以便留出日志循环的时间。如果没有设 置num_logs值，它就默认为0，意味着从来不循环日志文件 dispatcher 当启动这个守护进程时，由审计守护进程自动启动程序。所有守护进程都传递给这个程序。可以用它来进一步定制报表或者以与您的自定义分析程序兼容的不同格式 产生它们。自定义程序的示例代码可以在/usr/share/doc/audit- [version]/skeleton.c中找到。由于调度程序用根用户特权运行，因此使用这个选项时要极其小心。这个选项不是必需的 disp_qos 控制调度程序与审计守护进程之间的通信类型。有效值为lossy和lossless。如果设置为lossy，若审计守护进程与调度程序之间的缓冲区已满 (缓冲区为128千字节)，则发送给调度程序的引入事件会被丢弃。然而，只要log_format没有设置为nolog，事件就仍然会写到磁盘中。如果设 置为lossless，则在向调度程序发送事件之前和将日志写到磁盘之前，调度程序会等待缓冲区有足够的空间 max_log_file 以兆字节表示的最大日志文件容量。当达到这个容量时，会执行max_log_file _action指定的动作 max_log_file_action 当达到max_log_file的日志文件大小时采取的动作。值必须是IGNORE、SYSLOG、SUSPEND、ROTATE和KEEP_LOGS之 一。如果设置为IGNORE，则在日志文件达到max_log_file后不采取动作。如果设置为SYSLOG，则当达到文件容量时会向系统日志/var /log/messages中写入一条警告。如果设置为SUSPEND，则当达到文件容量后不会向日志文件写入审计消息。如果设置为ROTATE，则当达 到指定文件容量后会循环日志文件，但是只会保存一定数目的老文件，这个数目由num_logs参数指定。老文件的文件名将为audit.log.N，其中 N是一个数字。这个数字越大，则文件越老。如果设置为KEEP_LOGS，则会循环日志文件，但是会忽略num_logs参数，因此不会删除日志文件 space_left 以兆字节表示的磁盘空间数量。当达到这个水平时，会采取space_left_action参数中的动作 space_left_action 当磁盘空间量达到space_left中的值时，采取这个动作。有效值为IGNORE、SYSLOG、EMAIL、SUSPEND、SINGLE和 HALT。如果设置为IGNORE，则不采取动作。如果设置为SYSLOG，则向系统日志/var/log/messages写一条警告消息。如果设置为 EMAIL，则从action_mail_acct向这个地址发送一封电子邮件，并向/var/log/messages中写一条警告消息。如果设置为 SUSPEND，则不再向审计日志文件中写警告消息。如果设置为SINGLE，则系统将在单用户模式下。如果设置为SALT，则系统会关闭 action_mail_acct 负责维护审计守护进程和日志的管理员的电子邮件地址。如果地址没有主机名，则假定主机名为本地地址，比如root。必须安装sendmail并配置为向指定电子邮件地址发送电子邮件 admin_space_left 以兆字节表示的磁盘空间数量。用这个选项设置比space_left_action更多的主动性动作，以防万一space_left_action没有让 管理员释放任何磁盘空间。这个值应小于space_left_action。如果达到这个水平，则会采取admin_space_left_ action所指定的动作 admin_space_left_action 当自由磁盘空间量达到admin_space_left指定的值时，则采取动作。有效值为IGNORE、SYSLOG、EMAIL、SUSPEND、SINGLE和HALT。与这些值关联的动作与space_left_action中的相同 disk_full_action 如果含有这个审计文件的分区已满，则采取这个动作。可能值为IGNORE、SYSLOG、SUSPEND、SINGLE和HALT。与这些值关联的动作与space_left _action中的相同。提示：如果不循环审计日志文件，则含有/var/log/audit/的分区可能变满并引起系统错误。因此，建议让/var/log/audit/位于一个单独的专用分区 disk_error_action 如果在写审计日志或循环日志文件时检测到错误时采取的动作。值必须是IGNORE、SYSLOG、SUSPEND、SINGLE和HALT之一。与这些值关的动作与space_left_action中的相同。 日志文件日志文件字段说明 type=SYSCALL msg=audit(1557677628.183:175): arch=c000003e syscall=59 success=yes exit=0 a0=c3a2d0 a1=c39d60 a2=c20a00 a3=7fff1f5044e0 items=3 ppid=5886 pid=6624 auid=0 uid=0 gid=0 euid=0 suid=0 fsuid=0 egid=0 sgid=0 fsgid=0 tty=pts1 ses=4 comm=”river.sh” exe=”/usr/bin/bash” key=”TheRiver”type=EXECVE msg=audit(1557677628.183:175): argc=2 a0=”/bin/sh” a1=”./river.sh”type=CWD msg=audit(1557677628.183:175): cwd=”/home/river”type=PATH msg=audit(1557677628.183:175): item=0 name=”./river.sh” inode=1000168 dev=fd:01 mode=0100755 ouid=0 ogid=0 rdev=00:00 objtype=NORMALtype=PATH msg=audit(1557677628.183:175): item=1 name=(null) inode=67111165 dev=fd:01 mode=0100755 ouid=0 ogid=0 rdev=00:00 objtype=NORMALtype=PATH msg=audit(1557677628.183:175): item=2 name=(null) inode=146951365 dev=fd:01 mode=0100755 ouid=0 ogid=0 rdev=00:00 objtype=NORMAL type=SYSCALL这一行说明了audit的消息类型，audit消息类型可以对照https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Security_Guide/sec-Audit_Record_Types.html的表格进程查看，SYSCALL说明此次audit记录的是一次系统调用Kernel的记录 msg=audit(1557677628.183:175)这一行的格式是(time_stamp:ID)，time_stamp是unix时间，可以将其转化为其他时间格式，可以使用站长工具进行转换：http://tool.chinaz.com/Tools/unixtime.aspx。相同的audit event可能会产生多条time_stamp和event ID相同的log msg后面跟了很多形式为“name=value”的键值对，这些键值对由kernel或者用户空间的进程产生 arch=c000003e标明CPU的类型，c000003e对应x86_64，使用ausearch查看audit日志时会自动将其解码 syscall=59指出了发送给kernel的系统调用的类型，可以使用ausyscall –dump来显示所有的syscall的说明 succeed=yes/no，说明此次syscall成功或失败 exit=0说明syscall的返回值是0 a0，a1，a2，a3指明了前4个参数，也是编码成16进制，通过ausearch命令可以解码查看 items指出event中的path记录的数量 ppid=5886输入栏记录了父进程ID（PPID） pid=6624输入栏记录了进程ID（PID） auid=0输入栏记录了审核用户ID，这个是loginuid。这个ID是用户在登录时使用的并且即使当用户身份改变时，也可以通过每个进程获取该ID。（例如，通过切换用户账户，使用su - john命令） uid=0指出了对应进程的所有者ID gid=0对应进程的group ID euid=0对应进程的effective user ID suid=0对应set user ID fsuid对应file system user ID egid=0对应effective group ID sgid对应set group ID fsgid对应file system group ID tty=pts1指出对应进程是在哪个终端启动的 ses=4指出了对应进程的session ID comm=&quot;river.sh&quot;对应了进程执行的命令 exe=&quot;/usr/bin/bash&quot;指出了进程的执行文件的路径 key=&quot;TheRiver&quot;是管理员定义的标明是哪条rule输出了这条audit日志 CWD指出了进程的执行目录（current working directory），cwd字段指出了第一条日志中syscall的执行路径 第三条日志用来记录所有传递给syscall作为参数的路径，在这个audit事件中，仅有/etc/ssh/sshd_config作为参数进行传递，通过name字段指明 inode指出了与文件或目录相对应的inode number，可以通过下面的命令查看inode对应的文件或目录:find / -inum [inode number] -print – /home/river/river.sh dev=fd:01指出文件或目录对应的device ID mode=0100755对应文件或目录的权限:rwxr-xr-x 1 root root ouid对应文件的owner’s user ID ogid对应文件的owner’s group ID 实践 auditctl加入的规则是临时生效的,想永久生效需要在规则文件中加入,然后重启:service auditd restart","categories":[],"tags":[{"name":"运维","slug":"运维","permalink":"https://riverferry.site/tags/%E8%BF%90%E7%BB%B4/"}],"keywords":[]},{"title":"句柄泄露的定位过程","slug":"2019-05-05-句柄泄露的定位过程","date":"2019-05-05T00:00:00.000Z","updated":"2022-09-12T16:24:32.272Z","comments":true,"path":"2019-05-05-句柄泄露的定位过程/","link":"","permalink":"https://riverferry.site/2019-05-05-%E5%8F%A5%E6%9F%84%E6%B3%84%E9%9C%B2%E7%9A%84%E5%AE%9A%E4%BD%8D%E8%BF%87%E7%A8%8B/","excerpt":"目录 目录 流程 前言 说明 strace介绍 strace参数 demo实践","text":"目录 目录 流程 前言 说明 strace介绍 strace参数 demo实践 流程 前言 定位句柄泄露问题,目前掌握的最好用的就是strace命令.可以监测指定进程的系统调用,来寻找是否存在持续创建socket并且未释放的地方.当前,strace命令还有其他用武之处,但不在本文所描述的范畴内 说明 本文主要讲解strace的用法.用尝试写一个简单的句柄泄露的Demo来分析 strace介绍 strace命令是一个集诊断、调试、统计与一体的工具，我们可以使用strace对应用的系统调用和信号传递的跟踪结果来对应用进行分析，以达到解决问题或者是了解应用工作过程的目的。当然strace与专业的调试工具比如说gdb之类的是没法相比的，因为它不是一个专业的调试器。 strace的最简单的用法就是执行一个指定的命令，在指定的命令结束之后它也就退出了。在命令执行的过程中，strace会记录和解析命令进程的所有系统调用以及这个进程所接收到的所有的信号值。 strace参数 参数名 说明 -c 统计每一系统调用的所执行的时间,次数和出错的次数等 -d 输出strace关于标准错误的调试信息 -f 跟踪由fork调用所产生的子进程 -F 尝试跟踪vfork调用.在-f时,vfork不被跟踪 -ff 如果提供-o filename,则所有进程的跟踪结果输出到相应的filename.pid中,pid是各进程的进程号 -h 输出简要的帮助信息 -i 输出系统调用的入口指针 -q 禁止输出关于脱离的消息 -r 打印出相对时间,关于每一个系统调用 -t 在输出中的每一行前加上时间信息 -tt 在输出中的每一行前加上时间信息,微秒级 -T 显示每一调用所耗的时间 -v 输出所有的系统调用.一些调用关于环境变量,状态,输入输出等调用由于使用频繁,默认不输出 -V 输出strace的版本信息 -x 以十六进制形式输出非标准字符串 -xx 所有字符串以十六进制形式输出 -a column 设置返回值的输出位置.默认为40 -e expr 指定一个表达式,用来控制如何跟踪 -e trace=set 跟踪指定的系统 调用.例如:-e trace=open,close,rean,write表示只跟踪这四个系统调用.默认的为set=all. -e trace=file 只跟踪有关文件操作的系统调用 -e trace=process 只跟踪有关进程控制的系统调用 -e trace=network 跟踪与网络有关的所有系统调用 -e strace=signal 跟踪所有与系统信号有关的系统调用 -e trace=ipc 跟踪所有与进程间通讯有关的系统调用 -e abbrev=set 设定strace输出的系统调用的结果集.-v 等与 abbrev=none.默认为abbrev=all -e raw=set 将指定的系统调用的参数以十六进制显示 -e signal=set 指定跟踪的系统信号.默认为all.如 signal=!SIGIO(或者signal=!io),表示不跟踪SIGIO信号 -e read=set 输出从指定文件中读出 的数据.例如: -e read=3,5 -e write=set 输出写入到指定文件中的数据 -o filename 将strace的输出写入文件filename -p pid 跟踪指定的进程pid -s strsize 指定输出的字符串的最大长度.默认为32.文件名一直全部输出 -u username 以username的UID和GID执行被跟踪的命令 demo实践 写了个最简化的句柄泄露的Demo,思路是客户端创建socket后发给本机一个没被监听的端口.connect失败后直接return.当前也可以用open后直接return等方法.这里顺便再熟悉下socket的创建流程. #include&lt;stdio.h&gt; #include&lt;stdlib.h&gt; #include&lt;string.h&gt; #include&lt;errno.h&gt; #include &lt;unistd.h&gt; #include&lt;sys/types.h&gt; #include&lt;sys/socket.h&gt; #include&lt;netinet/in.h&gt; #include&lt;arpa/inet.h&gt; int main() &#123; int iConnFd = 0; char szAddr[] = &#123;&quot;127.0.0.1&quot;&#125;; struct sockaddr_in stServerAddr = &#123;0&#125;; for (int i = 0; i &lt; 10000; ++i) &#123; if ((iConnFd = socket(AF_INET, SOCK_STREAM, 0)) &lt; 0) &#123; perror(&quot;Failed to create socket!&quot;); return -1; &#125; stServerAddr.sin_family = AF_INET; stServerAddr.sin_port = htons(7777); if (inet_pton(AF_INET, szAddr, (void*)&amp;stServerAddr.sin_addr) &lt;= 0) &#123; perror(&quot;Failed to swicth ip addr!&quot;); close(iConnFd); iConnFd = -1; return -1; &#125; if (connect(iConnFd, (struct sockaddr*)&amp;stServerAddr, sizeof(stServerAddr)) &lt; 0) &#123; perror(&quot;Failed to connect!&quot;); //close(iConnFd); &#125; sleep(1); &#125; return 0; &#125; 如图: 可以清晰的看出来,进程一直在创建socket，然后connect，cconnect失败后没有回收socket.当然这是很理想的情况,生产环境下比较复杂了,需要具体问题具体分析.","categories":[],"tags":[{"name":"运维","slug":"运维","permalink":"https://riverferry.site/tags/%E8%BF%90%E7%BB%B4/"}],"keywords":[]},{"title":"正则表达式基础","slug":"2019-04-27-正则表达式基础","date":"2019-04-27T00:00:00.000Z","updated":"2022-09-12T16:24:32.272Z","comments":true,"path":"2019-04-27-正则表达式基础/","link":"","permalink":"https://riverferry.site/2019-04-27-%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%9F%BA%E7%A1%80/","excerpt":"目录 前言 说明 正文","text":"目录 前言 说明 正文 前言 &emsp;&emsp;&emsp;对正则表达式不熟悉,目前用到的地方也不多.但是偶尔学习过程中遇到了会阻碍自己的理解.所以打算把正则表达式的基础用法总结下. 说明 1.本文参考了下面的文章: 系统地学习正则表达式2.测试正则语法的网站: regex101 正文文本字符匹配 Regular expression Input OutPut string This is a string. string 匹配任意单个字符 Regular expression Input OutPut a.c abc abc a.c abbc not match a.c a5c a5c 匹配特殊字符(需要转义) Regular expression Input OutPut a\\.c a.c a.c a\\.c abc not match a\\+c a+c a+c a+c aac aac a\\+c aac not match a\\[c a[c a[c a[c a[c error a\\\\c a\\c a\\c a\\c a\\c error 字符集合 [abc] 匹配a/b/c其中一个,取反:[^abc] [a-z] 匹配一个小写字母,取反:[^a-z] [0-9] 匹配一位数，相当于[0123456789],取反:[^0-9] [0-9a-zA-Z] 与上面类似,[]中可以存在多种规则 约定俗成的 元字符 描述 \\d [0-9] \\D [^0-9] \\w [0-9a-zA-Z_] \\W [^0-9a-zA-Z_] \\s [\\f\\n\\r\\t\\v] \\S [^\\f\\n\\r\\t\\v] 匹配次数 正则表达式 描述 Regular expression Input Output {1,3} 匹配1个到3个 a{1,3}d aad aad {2} 匹配2个 a{2}d aaad aad * 0个到多个,同{0,} a*d addddddddddd ad,d,d,d,d,d,d,d,d,d,d 11种结果 + 1个到多个,同{1,} a+d addddddddddd ad 字符串边界 Regular expression Input OutPut Describe ^begin begin and end begin 表示以begin开头的字符串 ^begin from begin to end not match begin不在字符串的开始就匹配不上 end$ begin and end end 表示以end结束的字符串 end$ begin and end ... not match end不在字符串的结束就匹配不上 注意 ^[] 和 [^] 的区别 ^[0-9] 表示字符串是以数字开始的[^0-9] 表示一个不是数字的字符 Regular expression Input OutPut Describe ^[0-9a-zA-Z]{4,}$ 12cd5678 12cd5678 表示由数字和字母组成的字符串,且字符串的长度>=4 ^[0-9a-zA-Z]{4,}$ 12cd5>678 not match 有其他字符> ^[0-9a-zA-Z]{4,}$ a5c not match 不足4位> 贪婪词汇 贪婪匹配:正则表达式总是寻找最大的匹配，而不是最小的 贪婪量词 非贪婪量词 * *？ + +？ {n,} {n,}? 贪婪版本 Input Output Describe s.*g xiao song xiao song song xiao song s和g之间有0到多个任意字符 非贪婪版本 Input Output s.*?g xiao song xiao song song,song","categories":[],"tags":[{"name":"语法","slug":"语法","permalink":"https://riverferry.site/tags/%E8%AF%AD%E6%B3%95/"}],"keywords":[]},{"title":"开源数据库[postgresql]资料汇总","slug":"2019-04-21-postgresql相关","date":"2019-04-24T00:00:00.000Z","updated":"2022-09-12T16:24:32.272Z","comments":true,"path":"2019-04-21-postgresql相关/","link":"","permalink":"https://riverferry.site/2019-04-21-postgresql%E7%9B%B8%E5%85%B3/","excerpt":"连接方式 pgadmin 自带客户端(windows),最新版本已经可以在浏览器登录了 dbvis JDBC(咱也不懂,咱也不想查),反正oracle,sqlserver,pgsql都能连.用着也顺手,就是不免费 psql 自带客户端(linux) /home/postgres/pgsql/bin/psql -U username -H hostaddr -d database","text":"连接方式 pgadmin 自带客户端(windows),最新版本已经可以在浏览器登录了 dbvis JDBC(咱也不懂,咱也不想查),反正oracle,sqlserver,pgsql都能连.用着也顺手,就是不免费 psql 自带客户端(linux) /home/postgres/pgsql/bin/psql -U username -H hostaddr -d database 配置文件 配置文件postgresql.conf,里面的含义网上都有.搜索下很方便查到.这里只记录几个个人常用的配置项: log_statement (string) 开启后数据库日志pg_log会更新,方便定位问题 ddl包括所有数据定义语句，如CREATE、ALTER和DROP语句mod包括所有ddl语句和更新数据的语句，例如INSERT、UPDATE、DELETE、TRUNCATE、 COPY FROM、PREPARE和 EXECUTEAll包括所有的语句。只有超级用户才能修改这个参数 shared_buffers (integer) 设置pgsql共享缓存区大小,吃内存.但可以提高命中率（好像需要和其他参数配合使用,后续补充） 这个参数只有在启动数据库时，才能被设置。它表示数据缓冲区中的数据块的个数，每个数据块的大小是8KB。数据缓冲区位于数据库的共享内存中，它越大越好，不能小于128KB。默认值是1024 常用语句 查数据库大小 SELECT d.datname AS Name, pg_catalog.pg_get_userbyid(d.datdba) AS Owner,CASE WHEN pg_catalog.has_database_privilege(d.datname, ‘CONNECT’)THEN pg_catalog.pg_size_pretty(pg_catalog.pg_database_size(d.datname))ELSE ‘No Access’END AS SIZEFROM pg_catalog.pg_database dORDER BYCASE WHEN pg_catalog.has_database_privilege(d.datname, ‘CONNECT’)THEN pg_catalog.pg_database_size(d.datname)ELSE NULLEND DESC – nulls firstLIMIT 20 查占用空间最大的20张表 SELECT nspname || ‘.’ || relname AS “relation”,pg_size_pretty(pg_total_relation_size(C.oid)) AS “total_size”FROM pg_class CLEFT JOIN pg_namespace N ON (N.oid = C.relnamespace)WHERE nspname NOT IN (‘pg_catalog’, ‘information_schema’)AND C.relkind &lt;&gt; ‘i’AND nspname !~ ‘^pg_toast’ORDER BY pg_total_relation_size(C.oid) DESCLIMIT 20; 查所有的表 select tablename from pg_tables where tablename like ‘%fav%’; 查所有表的字段 select count(attname) from pg_attribute; 查某张表中所有字段 select * from information_schema.columns where table_schema=’public’ and table_name = ‘tbl_user’; 查看某个字段存在与哪张表中 SELECT * from information_schema.columns WHERE COLUMN_NAME = ‘name’ ;SELECT * from information_schema.columns WHERE COLUMN_NAME like ‘%parent%’; 查看数据库连接 select * from pg_stat_activity; 查看各客户端的连接数 SELECT client_addr,count() from pg_stat_activity group by client_addr order by count() desc; 数据库的oid select * from pg_database where oid=16384; 表的oid select relname from pg_class where relfilenode = 25207; 按占用时间统计,pgadmin中运行 SELECT query, calls, total_time/calls AS onecall_time, total_time, shared_blks_hit,shared_blks_dirtied,shared_blks_read,shared_blks_written,rows, 100.0 * shared_blks_hit /nullif(shared_blks_hit + shared_blks_read, 0) AS hit_percent FROM pg_stat_statements WHERE query like ‘select%tbl_res%’ ORDER BY total_time DESC LIMIT 1000; 按调用次数统计,pgadmin中运行 SELECT query, calls, total_time/calls AS onecall_time, total_time, rows, 100.0 * shared_blks_hit /nullif(shared_blks_hit + shared_blks_read, 0) AS hit_percent FROM pg_stat_statements ORDER BY calls DESC LIMIT 50; 查看正在执行的sql 每个进程一行,会覆盖 select * from pg_stat_activity where query_start is not null and query like ‘%tbl_bm_poll_info%’ order by query_start DESC; 查询闲置连接数 select count(*) from pg_stat_activity where state=’idle’;select * from pg_stat_activity where state != ‘idle’; 清空统计结果 select pg_stat_statements_reset() ; 修改密码 ALTER USER postgres PASSWORD ‘admin’; 创建pg_stat_statements create extension pg_stat_statements;","categories":[],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://riverferry.site/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"}],"keywords":[]},{"title":"从禅者的初心开始","slug":"2019-04-15-最开始的地方","date":"2019-04-16T00:00:00.000Z","updated":"2022-09-12T16:24:32.272Z","comments":true,"path":"2019-04-15-最开始的地方/","link":"","permalink":"https://riverferry.site/2019-04-15-%E6%9C%80%E5%BC%80%E5%A7%8B%E7%9A%84%E5%9C%B0%E6%96%B9/","excerpt":"目录 目录 test 前言 摘抄 共勉","text":"目录 目录 test 前言 摘抄 共勉 test前言 &emsp;&emsp;&emsp;许久没有敲字,确是生疏了,心里又暗示要在这个节点写下第一篇文章. &emsp;&emsp;&emsp;想起近几年来的遭遇,不回头不知凶险，也要庆幸于几个关键时期的幸运.苦于留下的,是扭曲的人格和无我的状态. &emsp;&emsp;&emsp;好吧,便以引用来开启这一新的阶段 摘抄 &emsp;&emsp;一位禅师就是实现了完全自由的人,而着这种完全自由是所有人类的潜能。他无拘无束的生活在他整个存在的丰盈里。他的意识之流不是我们一般自我中心意识那种固定的重复模式,而是会依实际的当下环境自然地生发出来。结果就是，他的人格表现出来各种不凡的素质：轻快、活力充沛、坦率、简朴、谦卑、真诚、喜气洋洋、无比善悟与深不可测的慈悲。他的整个人见证了所谓“活在当下”的真实之中。 &emsp;&emsp;但到头来，让众弟子感到困惑、入迷和被深化的、并不是老师的不平凡、而是他的无比平凡。因为他只是他自己，所以得以成为众弟子的一面镜子。与他在一起时，我们意识到了自己的优点和缺点，但在此同时又不会感受到他又一丝赞美或责难。在他面前，我们看到了自己的未来面目，也看到了他的各种不平凡只是我们自己的真实本性。当我们学会把本性释放出来，师徒之间的界限就会消失，消失在佛心展开而成的一道存在于欢愉的深流里。 共勉 当你想要寻找一个上师，那么你的身边就会出现一位。 自己教育自己","categories":[],"tags":[{"name":"日记","slug":"日记","permalink":"https://riverferry.site/tags/%E6%97%A5%E8%AE%B0/"}],"keywords":[]},{"title":"c++ 反射","slug":"1999-02-15-c++ 反射","date":"1999-02-15T00:00:00.000Z","updated":"2022-09-12T16:24:32.272Z","comments":true,"path":"1999-02-15-c++ 反射/","link":"","permalink":"https://riverferry.site/1999-02-15-c++%20%E5%8F%8D%E5%B0%84/","excerpt":"todo","text":"todo","categories":[],"tags":[{"name":"c++","slug":"c","permalink":"https://riverferry.site/tags/c/"}],"keywords":[]},{"title":"零拷贝","slug":"1999-01-25-zero copy","date":"1999-01-25T00:00:00.000Z","updated":"2022-09-12T16:24:32.272Z","comments":true,"path":"1999-01-25-zero copy/","link":"","permalink":"https://riverferry.site/1999-01-25-zero%20copy/","excerpt":"todo","text":"todo","categories":[],"tags":[{"name":"linux","slug":"linux","permalink":"https://riverferry.site/tags/linux/"}],"keywords":[]},{"title":"无锁队列","slug":"1999-01-24-lockfree queue","date":"1999-01-24T00:00:00.000Z","updated":"2022-09-12T16:24:32.272Z","comments":true,"path":"1999-01-24-lockfree queue/","link":"","permalink":"https://riverferry.site/1999-01-24-lockfree%20queue/","excerpt":"todo","text":"todo","categories":[],"tags":[{"name":"mq","slug":"mq","permalink":"https://riverferry.site/tags/mq/"}],"keywords":[]},{"title":"分布式事务","slug":"1999-01-23-分布式事务","date":"1999-01-23T00:00:00.000Z","updated":"2022-09-12T16:24:32.272Z","comments":true,"path":"1999-01-23-分布式事务/","link":"","permalink":"https://riverferry.site/1999-01-23-%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/","excerpt":"todo","text":"todo","categories":[],"tags":[{"name":"分布式","slug":"分布式","permalink":"https://riverferry.site/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"}],"keywords":[]}]}